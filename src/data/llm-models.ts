// Auto-generated file - DO NOT EDIT
// Generated at: 2026-02-05T14:05:19.425Z
// Source: https://getbifrost.ai/datasheet
// Run `npm run generate:llm-data` to regenerate

import type { ModelData, ProcessedModel } from '@/types/model';

export const LLM_MODELS: ProcessedModel[] = [
  {
    "id": "ai21.j2-mid-v1",
    "name": "ai21.j2-mid-v1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.0000125,
      "max_input_tokens": 8191,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.0000125,
      "provider": "bedrock"
    },
    "slug": "ai21.j2-mid-v1",
    "displayName": "ai21.j2-mid-v1"
  },
  {
    "id": "ai21.j2-ultra-v1",
    "name": "ai21.j2-ultra-v1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.0000188,
      "max_input_tokens": 8191,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.0000188,
      "provider": "bedrock"
    },
    "slug": "ai21.j2-ultra-v1",
    "displayName": "ai21.j2-ultra-v1"
  },
  {
    "id": "ai21.jamba-1-5-large-v1:0",
    "name": "ai21.jamba-1-5-large-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 0.000008,
      "provider": "bedrock"
    },
    "slug": "ai21.jamba-1-5-large-v1-0",
    "displayName": "ai21.jamba-1-5-large-v1:0"
  },
  {
    "id": "ai21.jamba-1-5-mini-v1:0",
    "name": "ai21.jamba-1-5-mini-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "provider": "bedrock"
    },
    "slug": "ai21.jamba-1-5-mini-v1-0",
    "displayName": "ai21.jamba-1-5-mini-v1:0"
  },
  {
    "id": "ai21.jamba-instruct-v1:0",
    "name": "ai21.jamba-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 5e-7,
      "max_input_tokens": 70000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 7e-7,
      "supports_system_messages": true,
      "provider": "bedrock"
    },
    "slug": "ai21.jamba-instruct-v1-0",
    "displayName": "ai21.jamba-instruct-v1:0"
  },
  {
    "id": "us.writer.palmyra-x4-v1:0",
    "name": "us.writer.palmyra-x4-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "provider": "bedrock_converse"
    },
    "slug": "us.writer.palmyra-x4-v1-0",
    "displayName": "us.writer.palmyra-x4-v1:0"
  },
  {
    "id": "us.writer.palmyra-x5-v1:0",
    "name": "us.writer.palmyra-x5-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000006,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "provider": "bedrock_converse"
    },
    "slug": "us.writer.palmyra-x5-v1-0",
    "displayName": "us.writer.palmyra-x5-v1:0"
  },
  {
    "id": "writer.palmyra-x4-v1:0",
    "name": "writer.palmyra-x4-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "provider": "bedrock_converse"
    },
    "slug": "writer.palmyra-x4-v1-0",
    "displayName": "writer.palmyra-x4-v1:0"
  },
  {
    "id": "writer.palmyra-x5-v1:0",
    "name": "writer.palmyra-x5-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000006,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "provider": "bedrock_converse"
    },
    "slug": "writer.palmyra-x5-v1-0",
    "displayName": "writer.palmyra-x5-v1:0"
  },
  {
    "id": "amazon.nova-lite-v1:0",
    "name": "amazon.nova-lite-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 6e-8,
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "max_tokens": 10000,
      "mode": "chat",
      "output_cost_per_token": 2.4e-7,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "provider": "bedrock_converse"
    },
    "slug": "amazon.nova-lite-v1-0",
    "displayName": "amazon.nova-lite-v1:0"
  },
  {
    "id": "amazon.nova-2-lite-v1:0",
    "name": "amazon.nova-2-lite-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_read_input_token_cost": 7.5e-8,
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.0000025,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_video_input": true,
      "supports_vision": true,
      "provider": "bedrock_converse"
    },
    "slug": "amazon.nova-2-lite-v1-0",
    "displayName": "amazon.nova-2-lite-v1:0"
  },
  {
    "id": "amazon.nova-2-pro-preview-20251202-v1:0",
    "name": "amazon.nova-2-pro-preview-20251202-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_read_input_token_cost": 5.46875e-7,
      "input_cost_per_token": 0.0000021875,
      "input_cost_per_image_token": 0.0000021875,
      "input_cost_per_audio_token": 0.0000021875,
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.0000175,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_video_input": true,
      "supports_vision": true,
      "provider": "bedrock_converse"
    },
    "slug": "amazon.nova-2-pro-preview-20251202-v1-0",
    "displayName": "amazon.nova-2-pro-preview-20251202-v1:0"
  },
  {
    "id": "apac.amazon.nova-2-lite-v1:0",
    "name": "apac.amazon.nova-2-lite-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_read_input_token_cost": 8.25e-8,
      "input_cost_per_token": 3.3e-7,
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.00000275,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_video_input": true,
      "supports_vision": true,
      "provider": "bedrock_converse"
    },
    "slug": "apac.amazon.nova-2-lite-v1-0",
    "displayName": "apac.amazon.nova-2-lite-v1:0"
  },
  {
    "id": "apac.amazon.nova-2-pro-preview-20251202-v1:0",
    "name": "apac.amazon.nova-2-pro-preview-20251202-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_read_input_token_cost": 5.46875e-7,
      "input_cost_per_token": 0.0000021875,
      "input_cost_per_image_token": 0.0000021875,
      "input_cost_per_audio_token": 0.0000021875,
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.0000175,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_video_input": true,
      "supports_vision": true,
      "provider": "bedrock_converse"
    },
    "slug": "apac.amazon.nova-2-pro-preview-20251202-v1-0",
    "displayName": "apac.amazon.nova-2-pro-preview-20251202-v1:0"
  },
  {
    "id": "eu.amazon.nova-2-lite-v1:0",
    "name": "eu.amazon.nova-2-lite-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_read_input_token_cost": 8.25e-8,
      "input_cost_per_token": 3.3e-7,
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.00000275,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_video_input": true,
      "supports_vision": true,
      "provider": "bedrock_converse"
    },
    "slug": "eu.amazon.nova-2-lite-v1-0",
    "displayName": "eu.amazon.nova-2-lite-v1:0"
  },
  {
    "id": "eu.amazon.nova-2-pro-preview-20251202-v1:0",
    "name": "eu.amazon.nova-2-pro-preview-20251202-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_read_input_token_cost": 5.46875e-7,
      "input_cost_per_token": 0.0000021875,
      "input_cost_per_image_token": 0.0000021875,
      "input_cost_per_audio_token": 0.0000021875,
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.0000175,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_video_input": true,
      "supports_vision": true,
      "provider": "bedrock_converse"
    },
    "slug": "eu.amazon.nova-2-pro-preview-20251202-v1-0",
    "displayName": "eu.amazon.nova-2-pro-preview-20251202-v1:0"
  },
  {
    "id": "us.amazon.nova-2-lite-v1:0",
    "name": "us.amazon.nova-2-lite-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_read_input_token_cost": 8.25e-8,
      "input_cost_per_token": 3.3e-7,
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.00000275,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_video_input": true,
      "supports_vision": true,
      "provider": "bedrock_converse"
    },
    "slug": "us.amazon.nova-2-lite-v1-0",
    "displayName": "us.amazon.nova-2-lite-v1:0"
  },
  {
    "id": "us.amazon.nova-2-pro-preview-20251202-v1:0",
    "name": "us.amazon.nova-2-pro-preview-20251202-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_read_input_token_cost": 5.46875e-7,
      "input_cost_per_token": 0.0000021875,
      "input_cost_per_image_token": 0.0000021875,
      "input_cost_per_audio_token": 0.0000021875,
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.0000175,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_video_input": true,
      "supports_vision": true,
      "provider": "bedrock_converse"
    },
    "slug": "us.amazon.nova-2-pro-preview-20251202-v1-0",
    "displayName": "us.amazon.nova-2-pro-preview-20251202-v1:0"
  },
  {
    "id": "amazon.nova-2-multimodal-embeddings-v1:0",
    "name": "amazon.nova-2-multimodal-embeddings-v1:0",
    "provider": "bedrock",
    "data": {
      "max_input_tokens": 8172,
      "max_tokens": 8172,
      "mode": "embedding",
      "input_cost_per_token": 1.35e-7,
      "input_cost_per_image": 0.00006,
      "input_cost_per_video_per_second": 0.0007,
      "input_cost_per_audio_per_second": 0.00014,
      "output_cost_per_token": 0,
      "output_vector_size": 3072,
      "source": "https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1#/model-catalog/serverless/amazon.nova-2-multimodal-embeddings-v1:0",
      "supports_embedding_image_input": true,
      "supports_image_input": true,
      "supports_video_input": true,
      "supports_audio_input": true,
      "provider": "bedrock"
    },
    "slug": "amazon.nova-2-multimodal-embeddings-v1-0",
    "displayName": "amazon.nova-2-multimodal-embeddings-v1:0"
  },
  {
    "id": "amazon.nova-micro-v1:0",
    "name": "amazon.nova-micro-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 3.5e-8,
      "max_input_tokens": 128000,
      "max_output_tokens": 10000,
      "max_tokens": 10000,
      "mode": "chat",
      "output_cost_per_token": 1.4e-7,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "provider": "bedrock_converse"
    },
    "slug": "amazon.nova-micro-v1-0",
    "displayName": "amazon.nova-micro-v1:0"
  },
  {
    "id": "amazon.nova-pro-v1:0",
    "name": "amazon.nova-pro-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 8e-7,
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "max_tokens": 10000,
      "mode": "chat",
      "output_cost_per_token": 0.0000032,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "provider": "bedrock_converse"
    },
    "slug": "amazon.nova-pro-v1-0",
    "displayName": "amazon.nova-pro-v1:0"
  },
  {
    "id": "amazon.titan-embed-image-v1",
    "name": "amazon.titan-embed-image-v1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_image": 0.00006,
      "input_cost_per_token": 8e-7,
      "max_input_tokens": 128,
      "max_tokens": 128,
      "metadata": {
        "notes": "'supports_image_input' is a deprecated field. Use 'supports_embedding_image_input' instead."
      },
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_vector_size": 1024,
      "source": "https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1#/providers?model=amazon.titan-image-generator-v1",
      "supports_embedding_image_input": true,
      "supports_image_input": true,
      "provider": "bedrock"
    },
    "slug": "amazon.titan-embed-image-v1",
    "displayName": "amazon.titan-embed-image-v1"
  },
  {
    "id": "amazon.titan-embed-text-v1",
    "name": "amazon.titan-embed-text-v1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 8192,
      "max_tokens": 8192,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_vector_size": 1536,
      "provider": "bedrock"
    },
    "slug": "amazon.titan-embed-text-v1",
    "displayName": "amazon.titan-embed-text-v1"
  },
  {
    "id": "amazon.titan-embed-text-v2:0",
    "name": "amazon.titan-embed-text-v2:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 8192,
      "max_tokens": 8192,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_vector_size": 1024,
      "provider": "bedrock"
    },
    "slug": "amazon.titan-embed-text-v2-0",
    "displayName": "amazon.titan-embed-text-v2:0"
  },
  {
    "id": "twelvelabs.marengo-embed-2-7-v1:0",
    "name": "twelvelabs.marengo-embed-2-7-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.00007,
      "max_input_tokens": 77,
      "max_tokens": 77,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_vector_size": 1024,
      "supports_embedding_image_input": true,
      "supports_image_input": true,
      "provider": "bedrock"
    },
    "slug": "twelvelabs.marengo-embed-2-7-v1-0",
    "displayName": "twelvelabs.marengo-embed-2-7-v1:0"
  },
  {
    "id": "us.twelvelabs.marengo-embed-2-7-v1:0",
    "name": "us.twelvelabs.marengo-embed-2-7-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.00007,
      "input_cost_per_video_per_second": 0.0007,
      "input_cost_per_audio_per_second": 0.00014,
      "input_cost_per_image": 0.0001,
      "max_input_tokens": 77,
      "max_tokens": 77,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_vector_size": 1024,
      "supports_embedding_image_input": true,
      "supports_image_input": true,
      "provider": "bedrock"
    },
    "slug": "us.twelvelabs.marengo-embed-2-7-v1-0",
    "displayName": "us.twelvelabs.marengo-embed-2-7-v1:0"
  },
  {
    "id": "eu.twelvelabs.marengo-embed-2-7-v1:0",
    "name": "eu.twelvelabs.marengo-embed-2-7-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.00007,
      "input_cost_per_video_per_second": 0.0007,
      "input_cost_per_audio_per_second": 0.00014,
      "input_cost_per_image": 0.0001,
      "max_input_tokens": 77,
      "max_tokens": 77,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_vector_size": 1024,
      "supports_embedding_image_input": true,
      "supports_image_input": true,
      "provider": "bedrock"
    },
    "slug": "eu.twelvelabs.marengo-embed-2-7-v1-0",
    "displayName": "eu.twelvelabs.marengo-embed-2-7-v1:0"
  },
  {
    "id": "twelvelabs.pegasus-1-2-v1:0",
    "name": "twelvelabs.pegasus-1-2-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_video_per_second": 0.00049,
      "output_cost_per_token": 0.0000075,
      "mode": "chat",
      "supports_video_input": true,
      "provider": "bedrock"
    },
    "slug": "twelvelabs.pegasus-1-2-v1-0",
    "displayName": "twelvelabs.pegasus-1-2-v1:0"
  },
  {
    "id": "us.twelvelabs.pegasus-1-2-v1:0",
    "name": "us.twelvelabs.pegasus-1-2-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_video_per_second": 0.00049,
      "output_cost_per_token": 0.0000075,
      "mode": "chat",
      "supports_video_input": true,
      "provider": "bedrock"
    },
    "slug": "us.twelvelabs.pegasus-1-2-v1-0",
    "displayName": "us.twelvelabs.pegasus-1-2-v1:0"
  },
  {
    "id": "eu.twelvelabs.pegasus-1-2-v1:0",
    "name": "eu.twelvelabs.pegasus-1-2-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_video_per_second": 0.00049,
      "output_cost_per_token": 0.0000075,
      "mode": "chat",
      "supports_video_input": true,
      "provider": "bedrock"
    },
    "slug": "eu.twelvelabs.pegasus-1-2-v1-0",
    "displayName": "eu.twelvelabs.pegasus-1-2-v1:0"
  },
  {
    "id": "amazon.titan-text-express-v1",
    "name": "amazon.titan-text-express-v1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.0000013,
      "max_input_tokens": 42000,
      "max_output_tokens": 8000,
      "max_tokens": 8000,
      "mode": "chat",
      "output_cost_per_token": 0.0000017,
      "provider": "bedrock"
    },
    "slug": "amazon.titan-text-express-v1",
    "displayName": "amazon.titan-text-express-v1"
  },
  {
    "id": "amazon.titan-text-lite-v1",
    "name": "amazon.titan-text-lite-v1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 42000,
      "max_output_tokens": 4000,
      "max_tokens": 4000,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "provider": "bedrock"
    },
    "slug": "amazon.titan-text-lite-v1",
    "displayName": "amazon.titan-text-lite-v1"
  },
  {
    "id": "amazon.titan-text-premier-v1:0",
    "name": "amazon.titan-text-premier-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 5e-7,
      "max_input_tokens": 42000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "provider": "bedrock"
    },
    "slug": "amazon.titan-text-premier-v1-0",
    "displayName": "amazon.titan-text-premier-v1:0"
  },
  {
    "id": "anthropic.claude-3-5-haiku-20241022-v1:0",
    "name": "anthropic.claude-3-5-haiku-20241022-v1:0",
    "provider": "bedrock",
    "data": {
      "cache_creation_input_token_cost": 0.000001,
      "cache_read_input_token_cost": 8e-8,
      "input_cost_per_token": 8e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000004,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "bedrock"
    },
    "slug": "anthropic.claude-3-5-haiku-20241022-v1-0",
    "displayName": "anthropic.claude-3-5-haiku-20241022-v1:0"
  },
  {
    "id": "anthropic.claude-haiku-4-5-20251001-v1:0",
    "name": "anthropic.claude-haiku-4-5-20251001-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_creation_input_token_cost": 0.00000125,
      "cache_read_input_token_cost": 1e-7,
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000005,
      "source": "https://aws.amazon.com/about-aws/whats-new/2025/10/claude-4-5-haiku-anthropic-amazon-bedrock",
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 346,
      "provider": "bedrock_converse"
    },
    "slug": "anthropic.claude-haiku-4-5-20251001-v1-0",
    "displayName": "anthropic.claude-haiku-4-5-20251001-v1:0"
  },
  {
    "id": "anthropic.claude-haiku-4-5@20251001",
    "name": "anthropic.claude-haiku-4-5@20251001",
    "provider": "bedrock_converse",
    "data": {
      "cache_creation_input_token_cost": 0.00000125,
      "cache_read_input_token_cost": 1e-7,
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000005,
      "source": "https://aws.amazon.com/about-aws/whats-new/2025/10/claude-4-5-haiku-anthropic-amazon-bedrock",
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 346,
      "supports_native_streaming": true,
      "provider": "bedrock_converse"
    },
    "slug": "anthropic.claude-haiku-4-5-20251001",
    "displayName": "anthropic.claude-haiku-4-5@20251001"
  },
  {
    "id": "anthropic.claude-3-5-sonnet-20240620-v1:0",
    "name": "anthropic.claude-3-5-sonnet-20240620-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 1000000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "input_cost_per_token_above_200k_tokens": 0.000006,
      "output_cost_per_token_above_200k_tokens": 0.00003,
      "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
      "cache_read_input_token_cost_above_200k_tokens": 6e-7,
      "cache_creation_input_token_cost_above_1hr": 0.0000075,
      "cache_creation_input_token_cost_above_1hr_above_200k_tokens": 0.000015,
      "cache_creation_input_token_cost": 0.00000375,
      "cache_read_input_token_cost": 3e-7,
      "provider": "bedrock"
    },
    "slug": "anthropic.claude-3-5-sonnet-20240620-v1-0",
    "displayName": "anthropic.claude-3-5-sonnet-20240620-v1:0"
  },
  {
    "id": "anthropic.claude-3-5-sonnet-20241022-v2:0",
    "name": "anthropic.claude-3-5-sonnet-20241022-v2:0",
    "provider": "bedrock",
    "data": {
      "cache_creation_input_token_cost": 0.00000375,
      "cache_read_input_token_cost": 3e-7,
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "input_cost_per_token_above_200k_tokens": 0.000006,
      "output_cost_per_token_above_200k_tokens": 0.00003,
      "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
      "cache_read_input_token_cost_above_200k_tokens": 6e-7,
      "cache_creation_input_token_cost_above_1hr": 0.0000075,
      "cache_creation_input_token_cost_above_1hr_above_200k_tokens": 0.000015,
      "provider": "bedrock"
    },
    "slug": "anthropic.claude-3-5-sonnet-20241022-v2-0",
    "displayName": "anthropic.claude-3-5-sonnet-20241022-v2:0"
  },
  {
    "id": "anthropic.claude-3-7-sonnet-20240620-v1:0",
    "name": "anthropic.claude-3-7-sonnet-20240620-v1:0",
    "provider": "bedrock",
    "data": {
      "cache_creation_input_token_cost": 0.0000045,
      "cache_read_input_token_cost": 3.6e-7,
      "input_cost_per_token": 0.0000036,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000018,
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "anthropic.claude-3-7-sonnet-20240620-v1-0",
    "displayName": "anthropic.claude-3-7-sonnet-20240620-v1:0"
  },
  {
    "id": "anthropic.claude-3-7-sonnet-20250219-v1:0",
    "name": "anthropic.claude-3-7-sonnet-20250219-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_creation_input_token_cost": 0.00000375,
      "cache_read_input_token_cost": 3e-7,
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "bedrock_converse"
    },
    "slug": "anthropic.claude-3-7-sonnet-20250219-v1-0",
    "displayName": "anthropic.claude-3-7-sonnet-20250219-v1:0"
  },
  {
    "id": "anthropic.claude-3-haiku-20240307-v1:0",
    "name": "anthropic.claude-3-haiku-20240307-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 2.5e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00000125,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "anthropic.claude-3-haiku-20240307-v1-0",
    "displayName": "anthropic.claude-3-haiku-20240307-v1:0"
  },
  {
    "id": "anthropic.claude-3-opus-20240229-v1:0",
    "name": "anthropic.claude-3-opus-20240229-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000075,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "anthropic.claude-3-opus-20240229-v1-0",
    "displayName": "anthropic.claude-3-opus-20240229-v1:0"
  },
  {
    "id": "anthropic.claude-3-sonnet-20240229-v1:0",
    "name": "anthropic.claude-3-sonnet-20240229-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "anthropic.claude-3-sonnet-20240229-v1-0",
    "displayName": "anthropic.claude-3-sonnet-20240229-v1:0"
  },
  {
    "id": "anthropic.claude-instant-v1",
    "name": "anthropic.claude-instant-v1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 8e-7,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.0000024,
      "supports_tool_choice": true,
      "provider": "bedrock"
    },
    "slug": "anthropic.claude-instant-v1",
    "displayName": "anthropic.claude-instant-v1"
  },
  {
    "id": "anthropic.claude-opus-4-1-20250805-v1:0",
    "name": "anthropic.claude-opus-4-1-20250805-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_creation_input_token_cost": 0.00001875,
      "cache_read_input_token_cost": 0.0000015,
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.000075,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "bedrock_converse"
    },
    "slug": "anthropic.claude-opus-4-1-20250805-v1-0",
    "displayName": "anthropic.claude-opus-4-1-20250805-v1:0"
  },
  {
    "id": "anthropic.claude-opus-4-20250514-v1:0",
    "name": "anthropic.claude-opus-4-20250514-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_creation_input_token_cost": 0.00001875,
      "cache_read_input_token_cost": 0.0000015,
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.000075,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "bedrock_converse"
    },
    "slug": "anthropic.claude-opus-4-20250514-v1-0",
    "displayName": "anthropic.claude-opus-4-20250514-v1:0"
  },
  {
    "id": "anthropic.claude-opus-4-5-20251101-v1:0",
    "name": "anthropic.claude-opus-4-5-20251101-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_creation_input_token_cost": 0.00000625,
      "cache_read_input_token_cost": 5e-7,
      "input_cost_per_token": 0.000005,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000025,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "bedrock_converse"
    },
    "slug": "anthropic.claude-opus-4-5-20251101-v1-0",
    "displayName": "anthropic.claude-opus-4-5-20251101-v1:0"
  },
  {
    "id": "anthropic.claude-sonnet-4-20250514-v1:0",
    "name": "anthropic.claude-sonnet-4-20250514-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_creation_input_token_cost": 0.00000375,
      "cache_read_input_token_cost": 3e-7,
      "input_cost_per_token": 0.000003,
      "input_cost_per_token_above_200k_tokens": 0.000006,
      "output_cost_per_token_above_200k_tokens": 0.0000225,
      "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
      "cache_read_input_token_cost_above_200k_tokens": 6e-7,
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "bedrock_converse"
    },
    "slug": "anthropic.claude-sonnet-4-20250514-v1-0",
    "displayName": "anthropic.claude-sonnet-4-20250514-v1:0"
  },
  {
    "id": "anthropic.claude-sonnet-4-5-20250929-v1:0",
    "name": "anthropic.claude-sonnet-4-5-20250929-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_creation_input_token_cost": 0.00000375,
      "cache_read_input_token_cost": 3e-7,
      "input_cost_per_token": 0.000003,
      "input_cost_per_token_above_200k_tokens": 0.000006,
      "output_cost_per_token_above_200k_tokens": 0.0000225,
      "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
      "cache_read_input_token_cost_above_200k_tokens": 6e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "bedrock_converse"
    },
    "slug": "anthropic.claude-sonnet-4-5-20250929-v1-0",
    "displayName": "anthropic.claude-sonnet-4-5-20250929-v1:0"
  },
  {
    "id": "anthropic.claude-v1",
    "name": "anthropic.claude-v1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000008,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000024,
      "provider": "bedrock"
    },
    "slug": "anthropic.claude-v1",
    "displayName": "anthropic.claude-v1"
  },
  {
    "id": "anthropic.claude-v2:1",
    "name": "anthropic.claude-v2:1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000008,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000024,
      "supports_tool_choice": true,
      "provider": "bedrock"
    },
    "slug": "anthropic.claude-v2-1",
    "displayName": "anthropic.claude-v2:1"
  },
  {
    "id": "anyscale/HuggingFaceH4/zephyr-7b-beta",
    "name": "zephyr-7b-beta",
    "provider": "anyscale",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 1.5e-7,
      "provider": "anyscale"
    },
    "slug": "zephyr-7b-beta",
    "displayName": "zephyr-7b-beta"
  },
  {
    "id": "anyscale/codellama/CodeLlama-34b-Instruct-hf",
    "name": "CodeLlama-34b-Instruct-hf",
    "provider": "anyscale",
    "data": {
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000001,
      "provider": "anyscale"
    },
    "slug": "codellama-34b-instruct-hf",
    "displayName": "CodeLlama-34b-Instruct-hf"
  },
  {
    "id": "anyscale/codellama/CodeLlama-70b-Instruct-hf",
    "name": "CodeLlama-70b-Instruct-hf",
    "provider": "anyscale",
    "data": {
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000001,
      "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/codellama-CodeLlama-70b-Instruct-hf",
      "provider": "anyscale"
    },
    "slug": "codellama-70b-instruct-hf",
    "displayName": "CodeLlama-70b-Instruct-hf"
  },
  {
    "id": "anyscale/google/gemma-7b-it",
    "name": "gemma-7b-it",
    "provider": "anyscale",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 1.5e-7,
      "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/google-gemma-7b-it",
      "provider": "anyscale"
    },
    "slug": "gemma-7b-it",
    "displayName": "gemma-7b-it"
  },
  {
    "id": "anyscale/meta-llama/Llama-2-13b-chat-hf",
    "name": "Llama-2-13b-chat-hf",
    "provider": "anyscale",
    "data": {
      "input_cost_per_token": 2.5e-7,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 2.5e-7,
      "provider": "anyscale"
    },
    "slug": "llama-2-13b-chat-hf",
    "displayName": "Llama-2-13b-chat-hf"
  },
  {
    "id": "anyscale/meta-llama/Llama-2-70b-chat-hf",
    "name": "Llama-2-70b-chat-hf",
    "provider": "anyscale",
    "data": {
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000001,
      "provider": "anyscale"
    },
    "slug": "llama-2-70b-chat-hf",
    "displayName": "Llama-2-70b-chat-hf"
  },
  {
    "id": "anyscale/meta-llama/Llama-2-7b-chat-hf",
    "name": "Llama-2-7b-chat-hf",
    "provider": "anyscale",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 1.5e-7,
      "provider": "anyscale"
    },
    "slug": "llama-2-7b-chat-hf",
    "displayName": "Llama-2-7b-chat-hf"
  },
  {
    "id": "anyscale/meta-llama/Meta-Llama-3-70B-Instruct",
    "name": "Meta-Llama-3-70B-Instruct",
    "provider": "anyscale",
    "data": {
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000001,
      "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/meta-llama-Meta-Llama-3-70B-Instruct",
      "provider": "anyscale"
    },
    "slug": "meta-llama-3-70b-instruct",
    "displayName": "Meta-Llama-3-70B-Instruct"
  },
  {
    "id": "anyscale/meta-llama/Meta-Llama-3-8B-Instruct",
    "name": "Meta-Llama-3-8B-Instruct",
    "provider": "anyscale",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 1.5e-7,
      "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/meta-llama-Meta-Llama-3-8B-Instruct",
      "provider": "anyscale"
    },
    "slug": "meta-llama-3-8b-instruct",
    "displayName": "Meta-Llama-3-8B-Instruct"
  },
  {
    "id": "anyscale/mistralai/Mistral-7B-Instruct-v0.1",
    "name": "Mistral-7B-Instruct-v0.1",
    "provider": "anyscale",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 1.5e-7,
      "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mistral-7B-Instruct-v0.1",
      "supports_function_calling": true,
      "provider": "anyscale"
    },
    "slug": "mistral-7b-instruct-v0.1",
    "displayName": "Mistral-7B-Instruct-v0.1"
  },
  {
    "id": "anyscale/mistralai/Mixtral-8x22B-Instruct-v0.1",
    "name": "Mixtral-8x22B-Instruct-v0.1",
    "provider": "anyscale",
    "data": {
      "input_cost_per_token": 9e-7,
      "max_input_tokens": 65536,
      "max_output_tokens": 65536,
      "max_tokens": 65536,
      "mode": "chat",
      "output_cost_per_token": 9e-7,
      "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mixtral-8x22B-Instruct-v0.1",
      "supports_function_calling": true,
      "provider": "anyscale"
    },
    "slug": "mixtral-8x22b-instruct-v0.1",
    "displayName": "Mixtral-8x22B-Instruct-v0.1"
  },
  {
    "id": "anyscale/mistralai/Mixtral-8x7B-Instruct-v0.1",
    "name": "Mixtral-8x7B-Instruct-v0.1",
    "provider": "anyscale",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 1.5e-7,
      "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mixtral-8x7B-Instruct-v0.1",
      "supports_function_calling": true,
      "provider": "anyscale"
    },
    "slug": "mixtral-8x7b-instruct-v0.1",
    "displayName": "Mixtral-8x7B-Instruct-v0.1"
  },
  {
    "id": "apac.amazon.nova-lite-v1:0",
    "name": "apac.amazon.nova-lite-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 6.3e-8,
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "max_tokens": 10000,
      "mode": "chat",
      "output_cost_per_token": 2.52e-7,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "provider": "bedrock_converse"
    },
    "slug": "apac.amazon.nova-lite-v1-0",
    "displayName": "apac.amazon.nova-lite-v1:0"
  },
  {
    "id": "apac.amazon.nova-micro-v1:0",
    "name": "apac.amazon.nova-micro-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 3.7e-8,
      "max_input_tokens": 128000,
      "max_output_tokens": 10000,
      "max_tokens": 10000,
      "mode": "chat",
      "output_cost_per_token": 1.48e-7,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "provider": "bedrock_converse"
    },
    "slug": "apac.amazon.nova-micro-v1-0",
    "displayName": "apac.amazon.nova-micro-v1:0"
  },
  {
    "id": "apac.amazon.nova-pro-v1:0",
    "name": "apac.amazon.nova-pro-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 8.4e-7,
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "max_tokens": 10000,
      "mode": "chat",
      "output_cost_per_token": 0.00000336,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "provider": "bedrock_converse"
    },
    "slug": "apac.amazon.nova-pro-v1-0",
    "displayName": "apac.amazon.nova-pro-v1:0"
  },
  {
    "id": "apac.anthropic.claude-3-5-sonnet-20240620-v1:0",
    "name": "apac.anthropic.claude-3-5-sonnet-20240620-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "apac.anthropic.claude-3-5-sonnet-20240620-v1-0",
    "displayName": "apac.anthropic.claude-3-5-sonnet-20240620-v1:0"
  },
  {
    "id": "apac.anthropic.claude-3-5-sonnet-20241022-v2:0",
    "name": "apac.anthropic.claude-3-5-sonnet-20241022-v2:0",
    "provider": "bedrock",
    "data": {
      "cache_creation_input_token_cost": 0.00000375,
      "cache_read_input_token_cost": 3e-7,
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "apac.anthropic.claude-3-5-sonnet-20241022-v2-0",
    "displayName": "apac.anthropic.claude-3-5-sonnet-20241022-v2:0"
  },
  {
    "id": "apac.anthropic.claude-3-haiku-20240307-v1:0",
    "name": "apac.anthropic.claude-3-haiku-20240307-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 2.5e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00000125,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "apac.anthropic.claude-3-haiku-20240307-v1-0",
    "displayName": "apac.anthropic.claude-3-haiku-20240307-v1:0"
  },
  {
    "id": "apac.anthropic.claude-haiku-4-5-20251001-v1:0",
    "name": "apac.anthropic.claude-haiku-4-5-20251001-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_creation_input_token_cost": 0.000001375,
      "cache_read_input_token_cost": 1.1e-7,
      "input_cost_per_token": 0.0000011,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.0000055,
      "source": "https://aws.amazon.com/about-aws/whats-new/2025/10/claude-4-5-haiku-anthropic-amazon-bedrock",
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 346,
      "provider": "bedrock_converse"
    },
    "slug": "apac.anthropic.claude-haiku-4-5-20251001-v1-0",
    "displayName": "apac.anthropic.claude-haiku-4-5-20251001-v1:0"
  },
  {
    "id": "apac.anthropic.claude-3-sonnet-20240229-v1:0",
    "name": "apac.anthropic.claude-3-sonnet-20240229-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "apac.anthropic.claude-3-sonnet-20240229-v1-0",
    "displayName": "apac.anthropic.claude-3-sonnet-20240229-v1:0"
  },
  {
    "id": "apac.anthropic.claude-sonnet-4-20250514-v1:0",
    "name": "apac.anthropic.claude-sonnet-4-20250514-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_creation_input_token_cost": 0.00000375,
      "cache_read_input_token_cost": 3e-7,
      "input_cost_per_token": 0.000003,
      "input_cost_per_token_above_200k_tokens": 0.000006,
      "output_cost_per_token_above_200k_tokens": 0.0000225,
      "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
      "cache_read_input_token_cost_above_200k_tokens": 6e-7,
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "bedrock_converse"
    },
    "slug": "apac.anthropic.claude-sonnet-4-20250514-v1-0",
    "displayName": "apac.anthropic.claude-sonnet-4-20250514-v1:0"
  },
  {
    "id": "au.anthropic.claude-sonnet-4-5-20250929-v1:0",
    "name": "au.anthropic.claude-sonnet-4-5-20250929-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_creation_input_token_cost": 0.000004125,
      "cache_read_input_token_cost": 3.3e-7,
      "input_cost_per_token": 0.0000033,
      "input_cost_per_token_above_200k_tokens": 0.0000066,
      "output_cost_per_token_above_200k_tokens": 0.00002475,
      "cache_creation_input_token_cost_above_200k_tokens": 0.00000825,
      "cache_read_input_token_cost_above_200k_tokens": 6.6e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.0000165,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 346,
      "provider": "bedrock_converse"
    },
    "slug": "au.anthropic.claude-sonnet-4-5-20250929-v1-0",
    "displayName": "au.anthropic.claude-sonnet-4-5-20250929-v1:0"
  },
  {
    "id": "azure/ada",
    "name": "ada",
    "provider": "azure",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 8191,
      "max_tokens": 8191,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "provider": "azure"
    },
    "slug": "ada",
    "displayName": "ada"
  },
  {
    "id": "azure/codex-mini",
    "name": "codex-mini",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 3.75e-7,
      "input_cost_per_token": 0.0000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "responses",
      "output_cost_per_token": 0.000006,
      "supported_endpoints": [
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "codex-mini",
    "displayName": "codex-mini"
  },
  {
    "id": "azure/command-r-plus",
    "name": "command-r-plus",
    "provider": "azure",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_function_calling": true,
      "provider": "azure"
    },
    "slug": "command-r-plus",
    "displayName": "command-r-plus"
  },
  {
    "id": "azure_ai/claude-haiku-4-5",
    "name": "claude-haiku-4-5",
    "provider": "azure_ai",
    "data": {
      "cache_creation_input_token_cost": 0.00000125,
      "cache_creation_input_token_cost_above_1hr": 0.000002,
      "cache_read_input_token_cost": 1e-7,
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000005,
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure_ai"
    },
    "slug": "claude-haiku-4-5",
    "displayName": "claude-haiku-4-5"
  },
  {
    "id": "azure_ai/claude-opus-4-5",
    "name": "claude-opus-4-5",
    "provider": "azure_ai",
    "data": {
      "cache_creation_input_token_cost": 0.00000625,
      "cache_creation_input_token_cost_above_1hr": 0.00001,
      "cache_read_input_token_cost": 5e-7,
      "input_cost_per_token": 0.000005,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000025,
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure_ai"
    },
    "slug": "claude-opus-4-5",
    "displayName": "claude-opus-4-5"
  },
  {
    "id": "azure_ai/claude-opus-4-1",
    "name": "claude-opus-4-1",
    "provider": "azure_ai",
    "data": {
      "cache_creation_input_token_cost": 0.00001875,
      "cache_creation_input_token_cost_above_1hr": 0.00003,
      "cache_read_input_token_cost": 0.0000015,
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.000075,
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure_ai"
    },
    "slug": "claude-opus-4-1",
    "displayName": "claude-opus-4-1"
  },
  {
    "id": "azure_ai/claude-sonnet-4-5",
    "name": "claude-sonnet-4-5",
    "provider": "azure_ai",
    "data": {
      "cache_creation_input_token_cost": 0.00000375,
      "cache_creation_input_token_cost_above_1hr": 0.000006,
      "cache_read_input_token_cost": 3e-7,
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure_ai"
    },
    "slug": "claude-sonnet-4-5",
    "displayName": "claude-sonnet-4-5"
  },
  {
    "id": "azure/computer-use-preview",
    "name": "computer-use-preview",
    "provider": "azure",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "max_tokens": 1024,
      "mode": "chat",
      "output_cost_per_token": 0.000012,
      "supported_endpoints": [
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": false,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "computer-use-preview",
    "displayName": "computer-use-preview"
  },
  {
    "id": "azure_ai/gpt-oss-120b",
    "name": "gpt-oss-120b",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "output_cost_per_token": 6e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "source": "https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "azure_ai"
    },
    "slug": "gpt-oss-120b",
    "displayName": "gpt-oss-120b"
  },
  {
    "id": "azure_ai/model_router",
    "name": "model_router",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 1.4e-7,
      "output_cost_per_token": 0,
      "mode": "chat",
      "source": "https://azure.microsoft.com/en-us/pricing/details/ai-services/",
      "comment": "Flat cost of $0.14 per M input tokens for Azure AI Foundry Model Router infrastructure. Use pattern: azure_ai/model_router/<deployment-name> where deployment-name is your Azure deployment (e.g., azure-model-router)",
      "provider": "azure_ai"
    },
    "slug": "model_router",
    "displayName": "model_router"
  },
  {
    "id": "azure/eu/gpt-4o-2024-08-06",
    "name": "gpt-4o-2024-08-06",
    "provider": "azure",
    "data": {
      "deprecation_date": "2026-02-27",
      "cache_read_input_token_cost": 0.000001375,
      "input_cost_per_token": 0.00000275,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.000011,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-4o-2024-08-06",
    "displayName": "gpt-4o-2024-08-06"
  },
  {
    "id": "azure/eu/gpt-4o-2024-11-20",
    "name": "gpt-4o-2024-11-20",
    "provider": "azure",
    "data": {
      "deprecation_date": "2026-03-01",
      "cache_creation_input_token_cost": 0.00000138,
      "input_cost_per_token": 0.00000275,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.000011,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-4o-2024-11-20",
    "displayName": "gpt-4o-2024-11-20"
  },
  {
    "id": "azure/eu/gpt-4o-mini-2024-07-18",
    "name": "gpt-4o-mini-2024-07-18",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 8.3e-8,
      "input_cost_per_token": 1.65e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 6.6e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-4o-mini-2024-07-18",
    "displayName": "gpt-4o-mini-2024-07-18"
  },
  {
    "id": "azure/eu/gpt-4o-mini-realtime-preview-2024-12-17",
    "name": "gpt-4o-mini-realtime-preview-2024-12-17",
    "provider": "azure",
    "data": {
      "cache_creation_input_audio_token_cost": 3.3e-7,
      "cache_read_input_token_cost": 3.3e-7,
      "input_cost_per_audio_token": 0.000011,
      "input_cost_per_token": 6.6e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_audio_token": 0.000022,
      "output_cost_per_token": 0.00000264,
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "azure"
    },
    "slug": "gpt-4o-mini-realtime-preview-2024-12-17",
    "displayName": "gpt-4o-mini-realtime-preview-2024-12-17"
  },
  {
    "id": "azure/eu/gpt-4o-realtime-preview-2024-10-01",
    "name": "gpt-4o-realtime-preview-2024-10-01",
    "provider": "azure",
    "data": {
      "cache_creation_input_audio_token_cost": 0.000022,
      "cache_read_input_token_cost": 0.00000275,
      "input_cost_per_audio_token": 0.00011,
      "input_cost_per_token": 0.0000055,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_audio_token": 0.00022,
      "output_cost_per_token": 0.000022,
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "azure"
    },
    "slug": "gpt-4o-realtime-preview-2024-10-01",
    "displayName": "gpt-4o-realtime-preview-2024-10-01"
  },
  {
    "id": "azure/eu/gpt-4o-realtime-preview-2024-12-17",
    "name": "gpt-4o-realtime-preview-2024-12-17",
    "provider": "azure",
    "data": {
      "cache_read_input_audio_token_cost": 0.0000025,
      "cache_read_input_token_cost": 0.00000275,
      "input_cost_per_audio_token": 0.000044,
      "input_cost_per_token": 0.0000055,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_audio_token": 0.00008,
      "output_cost_per_token": 0.000022,
      "supported_modalities": [
        "text",
        "audio"
      ],
      "supported_output_modalities": [
        "text",
        "audio"
      ],
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "azure"
    },
    "slug": "gpt-4o-realtime-preview-2024-12-17",
    "displayName": "gpt-4o-realtime-preview-2024-12-17"
  },
  {
    "id": "azure/eu/gpt-5-2025-08-07",
    "name": "gpt-5-2025-08-07",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 1.375e-7,
      "input_cost_per_token": 0.000001375,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000011,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5-2025-08-07",
    "displayName": "gpt-5-2025-08-07"
  },
  {
    "id": "azure/eu/gpt-5-mini-2025-08-07",
    "name": "gpt-5-mini-2025-08-07",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 2.75e-8,
      "input_cost_per_token": 2.75e-7,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.0000022,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5-mini-2025-08-07",
    "displayName": "gpt-5-mini-2025-08-07"
  },
  {
    "id": "azure/eu/gpt-5.1",
    "name": "gpt-5.1",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 1.4e-7,
      "input_cost_per_token": 0.00000138,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000011,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5.1",
    "displayName": "gpt-5.1"
  },
  {
    "id": "azure/eu/gpt-5.1-chat",
    "name": "gpt-5.1-chat",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 1.4e-7,
      "input_cost_per_token": 0.00000138,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000011,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5.1-chat",
    "displayName": "gpt-5.1-chat"
  },
  {
    "id": "azure/eu/gpt-5.1-codex",
    "name": "gpt-5.1-codex",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 1.4e-7,
      "input_cost_per_token": 0.00000138,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "responses",
      "output_cost_per_token": 0.000011,
      "supported_endpoints": [
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": false,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5.1-codex",
    "displayName": "gpt-5.1-codex"
  },
  {
    "id": "azure/eu/gpt-5.1-codex-mini",
    "name": "gpt-5.1-codex-mini",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 2.8e-8,
      "input_cost_per_token": 2.75e-7,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "responses",
      "output_cost_per_token": 0.0000022,
      "supported_endpoints": [
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": false,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5.1-codex-mini",
    "displayName": "gpt-5.1-codex-mini"
  },
  {
    "id": "azure/eu/gpt-5-nano-2025-08-07",
    "name": "gpt-5-nano-2025-08-07",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 5.5e-9,
      "input_cost_per_token": 5.5e-8,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 4.4e-7,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5-nano-2025-08-07",
    "displayName": "gpt-5-nano-2025-08-07"
  },
  {
    "id": "azure/eu/o1-2024-12-17",
    "name": "o1-2024-12-17",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 0.00000825,
      "input_cost_per_token": 0.0000165,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "chat",
      "output_cost_per_token": 0.000066,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "o1-2024-12-17",
    "displayName": "o1-2024-12-17"
  },
  {
    "id": "azure/eu/o1-mini-2024-09-12",
    "name": "o1-mini-2024-09-12",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 6.05e-7,
      "input_cost_per_token": 0.00000121,
      "input_cost_per_token_batches": 6.05e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "max_tokens": 65536,
      "mode": "chat",
      "output_cost_per_token": 0.00000484,
      "output_cost_per_token_batches": 0.00000242,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_vision": false,
      "provider": "azure"
    },
    "slug": "o1-mini-2024-09-12",
    "displayName": "o1-mini-2024-09-12"
  },
  {
    "id": "azure/eu/o1-preview-2024-09-12",
    "name": "o1-preview-2024-09-12",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 0.00000825,
      "input_cost_per_token": 0.0000165,
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.000066,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_vision": false,
      "provider": "azure"
    },
    "slug": "o1-preview-2024-09-12",
    "displayName": "o1-preview-2024-09-12"
  },
  {
    "id": "azure/eu/o3-mini-2025-01-31",
    "name": "o3-mini-2025-01-31",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 6.05e-7,
      "input_cost_per_token": 0.00000121,
      "input_cost_per_token_batches": 6.05e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "chat",
      "output_cost_per_token": 0.00000484,
      "output_cost_per_token_batches": 0.00000242,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "azure"
    },
    "slug": "o3-mini-2025-01-31",
    "displayName": "o3-mini-2025-01-31"
  },
  {
    "id": "azure/global-standard/gpt-4o-2024-08-06",
    "name": "gpt-4o-2024-08-06",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 0.00000125,
      "deprecation_date": "2026-02-27",
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-4o-2024-08-06",
    "displayName": "gpt-4o-2024-08-06"
  },
  {
    "id": "azure/global-standard/gpt-4o-2024-11-20",
    "name": "gpt-4o-2024-11-20",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 0.00000125,
      "deprecation_date": "2026-03-01",
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-4o-2024-11-20",
    "displayName": "gpt-4o-2024-11-20"
  },
  {
    "id": "azure/global-standard/gpt-4o-mini",
    "name": "gpt-4o-mini",
    "provider": "azure",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-4o-mini",
    "displayName": "gpt-4o-mini"
  },
  {
    "id": "azure/global/gpt-4o-2024-08-06",
    "name": "gpt-4o-2024-08-06",
    "provider": "azure",
    "data": {
      "deprecation_date": "2026-02-27",
      "cache_read_input_token_cost": 0.00000125,
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-4o-2024-08-06",
    "displayName": "gpt-4o-2024-08-06"
  },
  {
    "id": "azure/global/gpt-4o-2024-11-20",
    "name": "gpt-4o-2024-11-20",
    "provider": "azure",
    "data": {
      "deprecation_date": "2026-03-01",
      "cache_read_input_token_cost": 0.00000125,
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-4o-2024-11-20",
    "displayName": "gpt-4o-2024-11-20"
  },
  {
    "id": "azure/global/gpt-5.1",
    "name": "gpt-5.1",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "input_cost_per_token": 0.00000125,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5.1",
    "displayName": "gpt-5.1"
  },
  {
    "id": "azure/global/gpt-5.1-chat",
    "name": "gpt-5.1-chat",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "input_cost_per_token": 0.00000125,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5.1-chat",
    "displayName": "gpt-5.1-chat"
  },
  {
    "id": "azure/global/gpt-5.1-codex",
    "name": "gpt-5.1-codex",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "input_cost_per_token": 0.00000125,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "responses",
      "output_cost_per_token": 0.00001,
      "supported_endpoints": [
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": false,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5.1-codex",
    "displayName": "gpt-5.1-codex"
  },
  {
    "id": "azure/global/gpt-5.1-codex-mini",
    "name": "gpt-5.1-codex-mini",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 2.5e-8,
      "input_cost_per_token": 2.5e-7,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "responses",
      "output_cost_per_token": 0.000002,
      "supported_endpoints": [
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": false,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5.1-codex-mini",
    "displayName": "gpt-5.1-codex-mini"
  },
  {
    "id": "azure/gpt-3.5-turbo",
    "name": "gpt-3.5-turbo",
    "provider": "azure",
    "data": {
      "input_cost_per_token": 5e-7,
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "azure"
    },
    "slug": "gpt-3.5-turbo",
    "displayName": "gpt-3.5-turbo"
  },
  {
    "id": "azure/gpt-3.5-turbo-0125",
    "name": "gpt-3.5-turbo-0125",
    "provider": "azure",
    "data": {
      "deprecation_date": "2025-03-31",
      "input_cost_per_token": 5e-7,
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "provider": "azure"
    },
    "slug": "gpt-3.5-turbo-0125",
    "displayName": "gpt-3.5-turbo-0125"
  },
  {
    "id": "azure/gpt-3.5-turbo-instruct-0914",
    "name": "gpt-3.5-turbo-instruct-0914",
    "provider": "azure_text",
    "data": {
      "input_cost_per_token": 0.0000015,
      "max_input_tokens": 4097,
      "max_tokens": 4097,
      "mode": "completion",
      "output_cost_per_token": 0.000002,
      "provider": "azure_text"
    },
    "slug": "gpt-3.5-turbo-instruct-0914",
    "displayName": "gpt-3.5-turbo-instruct-0914"
  },
  {
    "id": "azure/gpt-35-turbo",
    "name": "gpt-35-turbo",
    "provider": "azure",
    "data": {
      "input_cost_per_token": 5e-7,
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "azure"
    },
    "slug": "gpt-35-turbo",
    "displayName": "gpt-35-turbo"
  },
  {
    "id": "azure/gpt-35-turbo-0125",
    "name": "gpt-35-turbo-0125",
    "provider": "azure",
    "data": {
      "deprecation_date": "2025-05-31",
      "input_cost_per_token": 5e-7,
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "provider": "azure"
    },
    "slug": "gpt-35-turbo-0125",
    "displayName": "gpt-35-turbo-0125"
  },
  {
    "id": "azure/gpt-35-turbo-0301",
    "name": "gpt-35-turbo-0301",
    "provider": "azure",
    "data": {
      "deprecation_date": "2025-02-13",
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "provider": "azure"
    },
    "slug": "gpt-35-turbo-0301",
    "displayName": "gpt-35-turbo-0301"
  },
  {
    "id": "azure/gpt-35-turbo-0613",
    "name": "gpt-35-turbo-0613",
    "provider": "azure",
    "data": {
      "deprecation_date": "2025-02-13",
      "input_cost_per_token": 0.0000015,
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "provider": "azure"
    },
    "slug": "gpt-35-turbo-0613",
    "displayName": "gpt-35-turbo-0613"
  },
  {
    "id": "azure/gpt-35-turbo-1106",
    "name": "gpt-35-turbo-1106",
    "provider": "azure",
    "data": {
      "deprecation_date": "2025-03-31",
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "provider": "azure"
    },
    "slug": "gpt-35-turbo-1106",
    "displayName": "gpt-35-turbo-1106"
  },
  {
    "id": "azure/gpt-35-turbo-16k",
    "name": "gpt-35-turbo-16k",
    "provider": "azure",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000004,
      "supports_tool_choice": true,
      "provider": "azure"
    },
    "slug": "gpt-35-turbo-16k",
    "displayName": "gpt-35-turbo-16k"
  },
  {
    "id": "azure/gpt-35-turbo-16k-0613",
    "name": "gpt-35-turbo-16k-0613",
    "provider": "azure",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000004,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "azure"
    },
    "slug": "gpt-35-turbo-16k-0613",
    "displayName": "gpt-35-turbo-16k-0613"
  },
  {
    "id": "azure/gpt-35-turbo-instruct",
    "name": "gpt-35-turbo-instruct",
    "provider": "azure_text",
    "data": {
      "input_cost_per_token": 0.0000015,
      "max_input_tokens": 4097,
      "max_tokens": 4097,
      "mode": "completion",
      "output_cost_per_token": 0.000002,
      "provider": "azure_text"
    },
    "slug": "gpt-35-turbo-instruct",
    "displayName": "gpt-35-turbo-instruct"
  },
  {
    "id": "azure/gpt-35-turbo-instruct-0914",
    "name": "gpt-35-turbo-instruct-0914",
    "provider": "azure_text",
    "data": {
      "input_cost_per_token": 0.0000015,
      "max_input_tokens": 4097,
      "max_tokens": 4097,
      "mode": "completion",
      "output_cost_per_token": 0.000002,
      "provider": "azure_text"
    },
    "slug": "gpt-35-turbo-instruct-0914",
    "displayName": "gpt-35-turbo-instruct-0914"
  },
  {
    "id": "azure/gpt-4",
    "name": "gpt-4",
    "provider": "azure",
    "data": {
      "input_cost_per_token": 0.00003,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00006,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "azure"
    },
    "slug": "gpt-4",
    "displayName": "gpt-4"
  },
  {
    "id": "azure/gpt-4-0125-preview",
    "name": "gpt-4-0125-preview",
    "provider": "azure",
    "data": {
      "input_cost_per_token": 0.00001,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00003,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "provider": "azure"
    },
    "slug": "gpt-4-0125-preview",
    "displayName": "gpt-4-0125-preview"
  },
  {
    "id": "azure/gpt-4-0613",
    "name": "gpt-4-0613",
    "provider": "azure",
    "data": {
      "input_cost_per_token": 0.00003,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00006,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "azure"
    },
    "slug": "gpt-4-0613",
    "displayName": "gpt-4-0613"
  },
  {
    "id": "azure/gpt-4-1106-preview",
    "name": "gpt-4-1106-preview",
    "provider": "azure",
    "data": {
      "input_cost_per_token": 0.00001,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00003,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "provider": "azure"
    },
    "slug": "gpt-4-1106-preview",
    "displayName": "gpt-4-1106-preview"
  },
  {
    "id": "azure/gpt-4-32k",
    "name": "gpt-4-32k",
    "provider": "azure",
    "data": {
      "input_cost_per_token": 0.00006,
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00012,
      "supports_tool_choice": true,
      "provider": "azure"
    },
    "slug": "gpt-4-32k",
    "displayName": "gpt-4-32k"
  },
  {
    "id": "azure/gpt-4-32k-0613",
    "name": "gpt-4-32k-0613",
    "provider": "azure",
    "data": {
      "input_cost_per_token": 0.00006,
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00012,
      "supports_tool_choice": true,
      "provider": "azure"
    },
    "slug": "gpt-4-32k-0613",
    "displayName": "gpt-4-32k-0613"
  },
  {
    "id": "azure/gpt-4-turbo",
    "name": "gpt-4-turbo",
    "provider": "azure",
    "data": {
      "input_cost_per_token": 0.00001,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00003,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "provider": "azure"
    },
    "slug": "gpt-4-turbo",
    "displayName": "gpt-4-turbo"
  },
  {
    "id": "azure/gpt-4-turbo-2024-04-09",
    "name": "gpt-4-turbo-2024-04-09",
    "provider": "azure",
    "data": {
      "input_cost_per_token": 0.00001,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00003,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-4-turbo-2024-04-09",
    "displayName": "gpt-4-turbo-2024-04-09"
  },
  {
    "id": "azure/gpt-4-turbo-vision-preview",
    "name": "gpt-4-turbo-vision-preview",
    "provider": "azure",
    "data": {
      "input_cost_per_token": 0.00001,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00003,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-4-turbo-vision-preview",
    "displayName": "gpt-4-turbo-vision-preview"
  },
  {
    "id": "azure/gpt-4.1",
    "name": "gpt-4.1",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 5e-7,
      "input_cost_per_token": 0.000002,
      "input_cost_per_token_batches": 0.000001,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.000008,
      "output_cost_per_token_batches": 0.000004,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": false,
      "provider": "azure"
    },
    "slug": "gpt-4.1",
    "displayName": "gpt-4.1"
  },
  {
    "id": "azure/gpt-4.1-2025-04-14",
    "name": "gpt-4.1-2025-04-14",
    "provider": "azure",
    "data": {
      "deprecation_date": "2026-11-04",
      "cache_read_input_token_cost": 5e-7,
      "input_cost_per_token": 0.000002,
      "input_cost_per_token_batches": 0.000001,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.000008,
      "output_cost_per_token_batches": 0.000004,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": false,
      "provider": "azure"
    },
    "slug": "gpt-4.1-2025-04-14",
    "displayName": "gpt-4.1-2025-04-14"
  },
  {
    "id": "azure/gpt-4.1-mini",
    "name": "gpt-4.1-mini",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 1e-7,
      "input_cost_per_token": 4e-7,
      "input_cost_per_token_batches": 2e-7,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.0000016,
      "output_cost_per_token_batches": 8e-7,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": false,
      "provider": "azure"
    },
    "slug": "gpt-4.1-mini",
    "displayName": "gpt-4.1-mini"
  },
  {
    "id": "azure/gpt-4.1-mini-2025-04-14",
    "name": "gpt-4.1-mini-2025-04-14",
    "provider": "azure",
    "data": {
      "deprecation_date": "2026-11-04",
      "cache_read_input_token_cost": 1e-7,
      "input_cost_per_token": 4e-7,
      "input_cost_per_token_batches": 2e-7,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.0000016,
      "output_cost_per_token_batches": 8e-7,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": false,
      "provider": "azure"
    },
    "slug": "gpt-4.1-mini-2025-04-14",
    "displayName": "gpt-4.1-mini-2025-04-14"
  },
  {
    "id": "azure/gpt-4.1-nano",
    "name": "gpt-4.1-nano",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 2.5e-8,
      "input_cost_per_token": 1e-7,
      "input_cost_per_token_batches": 5e-8,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "output_cost_per_token_batches": 2e-7,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-4.1-nano",
    "displayName": "gpt-4.1-nano"
  },
  {
    "id": "azure/gpt-4.1-nano-2025-04-14",
    "name": "gpt-4.1-nano-2025-04-14",
    "provider": "azure",
    "data": {
      "deprecation_date": "2026-11-04",
      "cache_read_input_token_cost": 2.5e-8,
      "input_cost_per_token": 1e-7,
      "input_cost_per_token_batches": 5e-8,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "output_cost_per_token_batches": 2e-7,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-4.1-nano-2025-04-14",
    "displayName": "gpt-4.1-nano-2025-04-14"
  },
  {
    "id": "azure/gpt-4.5-preview",
    "name": "gpt-4.5-preview",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 0.0000375,
      "input_cost_per_token": 0.000075,
      "input_cost_per_token_batches": 0.0000375,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.00015,
      "output_cost_per_token_batches": 0.000075,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-4.5-preview",
    "displayName": "gpt-4.5-preview"
  },
  {
    "id": "azure/gpt-4o",
    "name": "gpt-4o",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 0.00000125,
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-4o",
    "displayName": "gpt-4o"
  },
  {
    "id": "azure/gpt-4o-2024-05-13",
    "name": "gpt-4o-2024-05-13",
    "provider": "azure",
    "data": {
      "input_cost_per_token": 0.000005,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-4o-2024-05-13",
    "displayName": "gpt-4o-2024-05-13"
  },
  {
    "id": "azure/gpt-4o-2024-08-06",
    "name": "gpt-4o-2024-08-06",
    "provider": "azure",
    "data": {
      "deprecation_date": "2026-02-27",
      "cache_read_input_token_cost": 0.00000125,
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-4o-2024-08-06",
    "displayName": "gpt-4o-2024-08-06"
  },
  {
    "id": "azure/gpt-4o-2024-11-20",
    "name": "gpt-4o-2024-11-20",
    "provider": "azure",
    "data": {
      "deprecation_date": "2026-03-01",
      "cache_read_input_token_cost": 0.00000125,
      "input_cost_per_token": 0.00000275,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.000011,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-4o-2024-11-20",
    "displayName": "gpt-4o-2024-11-20"
  },
  {
    "id": "azure/gpt-audio-2025-08-28",
    "name": "gpt-audio-2025-08-28",
    "provider": "azure",
    "data": {
      "input_cost_per_audio_token": 0.00004,
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_audio_token": 0.00008,
      "output_cost_per_token": 0.00001,
      "supported_endpoints": [
        "/v1/chat/completions"
      ],
      "supported_modalities": [
        "text",
        "audio"
      ],
      "supported_output_modalities": [
        "text",
        "audio"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": false,
      "supports_reasoning": false,
      "supports_response_schema": false,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "azure"
    },
    "slug": "gpt-audio-2025-08-28",
    "displayName": "gpt-audio-2025-08-28"
  },
  {
    "id": "azure/gpt-audio-mini-2025-10-06",
    "name": "gpt-audio-mini-2025-10-06",
    "provider": "azure",
    "data": {
      "input_cost_per_audio_token": 0.00001,
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_audio_token": 0.00002,
      "output_cost_per_token": 0.0000024,
      "supported_endpoints": [
        "/v1/chat/completions"
      ],
      "supported_modalities": [
        "text",
        "audio"
      ],
      "supported_output_modalities": [
        "text",
        "audio"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": false,
      "supports_reasoning": false,
      "supports_response_schema": false,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "azure"
    },
    "slug": "gpt-audio-mini-2025-10-06",
    "displayName": "gpt-audio-mini-2025-10-06"
  },
  {
    "id": "azure/gpt-4o-audio-preview-2024-12-17",
    "name": "gpt-4o-audio-preview-2024-12-17",
    "provider": "azure",
    "data": {
      "input_cost_per_audio_token": 0.00004,
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_audio_token": 0.00008,
      "output_cost_per_token": 0.00001,
      "supported_endpoints": [
        "/v1/chat/completions"
      ],
      "supported_modalities": [
        "text",
        "audio"
      ],
      "supported_output_modalities": [
        "text",
        "audio"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": false,
      "supports_reasoning": false,
      "supports_response_schema": false,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "azure"
    },
    "slug": "gpt-4o-audio-preview-2024-12-17",
    "displayName": "gpt-4o-audio-preview-2024-12-17"
  },
  {
    "id": "azure/gpt-4o-mini",
    "name": "gpt-4o-mini",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 7.5e-8,
      "input_cost_per_token": 1.65e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 6.6e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-4o-mini",
    "displayName": "gpt-4o-mini"
  },
  {
    "id": "azure/gpt-4o-mini-2024-07-18",
    "name": "gpt-4o-mini-2024-07-18",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 7.5e-8,
      "input_cost_per_token": 1.65e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 6.6e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-4o-mini-2024-07-18",
    "displayName": "gpt-4o-mini-2024-07-18"
  },
  {
    "id": "azure/gpt-4o-mini-audio-preview-2024-12-17",
    "name": "gpt-4o-mini-audio-preview-2024-12-17",
    "provider": "azure",
    "data": {
      "input_cost_per_audio_token": 0.00004,
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_audio_token": 0.00008,
      "output_cost_per_token": 0.00001,
      "supported_endpoints": [
        "/v1/chat/completions"
      ],
      "supported_modalities": [
        "text",
        "audio"
      ],
      "supported_output_modalities": [
        "text",
        "audio"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": false,
      "supports_reasoning": false,
      "supports_response_schema": false,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "azure"
    },
    "slug": "gpt-4o-mini-audio-preview-2024-12-17",
    "displayName": "gpt-4o-mini-audio-preview-2024-12-17"
  },
  {
    "id": "azure/gpt-4o-mini-realtime-preview-2024-12-17",
    "name": "gpt-4o-mini-realtime-preview-2024-12-17",
    "provider": "azure",
    "data": {
      "cache_creation_input_audio_token_cost": 3e-7,
      "cache_read_input_token_cost": 3e-7,
      "input_cost_per_audio_token": 0.00001,
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_audio_token": 0.00002,
      "output_cost_per_token": 0.0000024,
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "azure"
    },
    "slug": "gpt-4o-mini-realtime-preview-2024-12-17",
    "displayName": "gpt-4o-mini-realtime-preview-2024-12-17"
  },
  {
    "id": "azure/gpt-realtime-2025-08-28",
    "name": "gpt-realtime-2025-08-28",
    "provider": "azure",
    "data": {
      "cache_creation_input_audio_token_cost": 0.000004,
      "cache_read_input_token_cost": 0.000004,
      "input_cost_per_audio_token": 0.000032,
      "input_cost_per_image": 0.000005,
      "input_cost_per_token": 0.000004,
      "max_input_tokens": 32000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_audio_token": 0.000064,
      "output_cost_per_token": 0.000016,
      "supported_endpoints": [
        "/v1/realtime"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio"
      ],
      "supported_output_modalities": [
        "text",
        "audio"
      ],
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "azure"
    },
    "slug": "gpt-realtime-2025-08-28",
    "displayName": "gpt-realtime-2025-08-28"
  },
  {
    "id": "azure/gpt-realtime-mini-2025-10-06",
    "name": "gpt-realtime-mini-2025-10-06",
    "provider": "azure",
    "data": {
      "cache_creation_input_audio_token_cost": 3e-7,
      "cache_read_input_token_cost": 6e-8,
      "input_cost_per_audio_token": 0.00001,
      "input_cost_per_image": 8e-7,
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 32000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_audio_token": 0.00002,
      "output_cost_per_token": 0.0000024,
      "supported_endpoints": [
        "/v1/realtime"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio"
      ],
      "supported_output_modalities": [
        "text",
        "audio"
      ],
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "azure"
    },
    "slug": "gpt-realtime-mini-2025-10-06",
    "displayName": "gpt-realtime-mini-2025-10-06"
  },
  {
    "id": "azure/gpt-4o-mini-transcribe",
    "name": "gpt-4o-mini-transcribe",
    "provider": "azure",
    "data": {
      "input_cost_per_audio_token": 0.000003,
      "input_cost_per_token": 0.00000125,
      "max_input_tokens": 16000,
      "max_output_tokens": 2000,
      "mode": "audio_transcription",
      "output_cost_per_token": 0.000005,
      "supported_endpoints": [
        "/v1/audio/transcriptions"
      ],
      "provider": "azure"
    },
    "slug": "gpt-4o-mini-transcribe",
    "displayName": "gpt-4o-mini-transcribe"
  },
  {
    "id": "azure/gpt-4o-mini-tts",
    "name": "gpt-4o-mini-tts",
    "provider": "azure",
    "data": {
      "input_cost_per_token": 0.0000025,
      "mode": "audio_speech",
      "output_cost_per_audio_token": 0.000012,
      "output_cost_per_second": 0.00025,
      "output_cost_per_token": 0.00001,
      "supported_endpoints": [
        "/v1/audio/speech"
      ],
      "supported_modalities": [
        "text",
        "audio"
      ],
      "supported_output_modalities": [
        "audio"
      ],
      "provider": "azure"
    },
    "slug": "gpt-4o-mini-tts",
    "displayName": "gpt-4o-mini-tts"
  },
  {
    "id": "azure/gpt-4o-realtime-preview-2024-10-01",
    "name": "gpt-4o-realtime-preview-2024-10-01",
    "provider": "azure",
    "data": {
      "cache_creation_input_audio_token_cost": 0.00002,
      "cache_read_input_token_cost": 0.0000025,
      "input_cost_per_audio_token": 0.0001,
      "input_cost_per_token": 0.000005,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_audio_token": 0.0002,
      "output_cost_per_token": 0.00002,
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "azure"
    },
    "slug": "gpt-4o-realtime-preview-2024-10-01",
    "displayName": "gpt-4o-realtime-preview-2024-10-01"
  },
  {
    "id": "azure/gpt-4o-realtime-preview-2024-12-17",
    "name": "gpt-4o-realtime-preview-2024-12-17",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 0.0000025,
      "input_cost_per_audio_token": 0.00004,
      "input_cost_per_token": 0.000005,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_audio_token": 0.00008,
      "output_cost_per_token": 0.00002,
      "supported_modalities": [
        "text",
        "audio"
      ],
      "supported_output_modalities": [
        "text",
        "audio"
      ],
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "azure"
    },
    "slug": "gpt-4o-realtime-preview-2024-12-17",
    "displayName": "gpt-4o-realtime-preview-2024-12-17"
  },
  {
    "id": "azure/gpt-4o-transcribe",
    "name": "gpt-4o-transcribe",
    "provider": "azure",
    "data": {
      "input_cost_per_audio_token": 0.000006,
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 16000,
      "max_output_tokens": 2000,
      "mode": "audio_transcription",
      "output_cost_per_token": 0.00001,
      "supported_endpoints": [
        "/v1/audio/transcriptions"
      ],
      "provider": "azure"
    },
    "slug": "gpt-4o-transcribe",
    "displayName": "gpt-4o-transcribe"
  },
  {
    "id": "azure/gpt-4o-transcribe-diarize",
    "name": "gpt-4o-transcribe-diarize",
    "provider": "azure",
    "data": {
      "input_cost_per_audio_token": 0.000006,
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 16000,
      "max_output_tokens": 2000,
      "mode": "audio_transcription",
      "output_cost_per_token": 0.00001,
      "supported_endpoints": [
        "/v1/audio/transcriptions"
      ],
      "provider": "azure"
    },
    "slug": "gpt-4o-transcribe-diarize",
    "displayName": "gpt-4o-transcribe-diarize"
  },
  {
    "id": "azure/gpt-5.1-2025-11-13",
    "name": "gpt-5.1-2025-11-13",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "cache_read_input_token_cost_priority": 2.5e-7,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_priority": 0.0000025,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_priority": 0.00002,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_service_tier": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5.1-2025-11-13",
    "displayName": "gpt-5.1-2025-11-13"
  },
  {
    "id": "azure/gpt-5.1-chat-2025-11-13",
    "name": "gpt-5.1-chat-2025-11-13",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "cache_read_input_token_cost_priority": 2.5e-7,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_priority": 0.0000025,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_priority": 0.00002,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_function_calling": false,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": false,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": false,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5.1-chat-2025-11-13",
    "displayName": "gpt-5.1-chat-2025-11-13"
  },
  {
    "id": "azure/gpt-5.1-codex-2025-11-13",
    "name": "gpt-5.1-codex-2025-11-13",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "cache_read_input_token_cost_priority": 2.5e-7,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_priority": 0.0000025,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "responses",
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_priority": 0.00002,
      "supported_endpoints": [
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": false,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5.1-codex-2025-11-13",
    "displayName": "gpt-5.1-codex-2025-11-13"
  },
  {
    "id": "azure/gpt-5.1-codex-mini-2025-11-13",
    "name": "gpt-5.1-codex-mini-2025-11-13",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 2.5e-8,
      "cache_read_input_token_cost_priority": 4.5e-8,
      "input_cost_per_token": 2.5e-7,
      "input_cost_per_token_priority": 4.5e-7,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "responses",
      "output_cost_per_token": 0.000002,
      "output_cost_per_token_priority": 0.0000036,
      "supported_endpoints": [
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": false,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5.1-codex-mini-2025-11-13",
    "displayName": "gpt-5.1-codex-mini-2025-11-13"
  },
  {
    "id": "azure/gpt-5",
    "name": "gpt-5",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "input_cost_per_token": 0.00000125,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5",
    "displayName": "gpt-5"
  },
  {
    "id": "azure/gpt-5-2025-08-07",
    "name": "gpt-5-2025-08-07",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "input_cost_per_token": 0.00000125,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5-2025-08-07",
    "displayName": "gpt-5-2025-08-07"
  },
  {
    "id": "azure/gpt-5-chat",
    "name": "gpt-5-chat",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "input_cost_per_token": 0.00000125,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "source": "https://azure.microsoft.com/en-us/blog/gpt-5-in-azure-ai-foundry-the-future-of-ai-apps-and-agents-starts-here/",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5-chat",
    "displayName": "gpt-5-chat"
  },
  {
    "id": "azure/gpt-5-chat-latest",
    "name": "gpt-5-chat-latest",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "input_cost_per_token": 0.00000125,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5-chat-latest",
    "displayName": "gpt-5-chat-latest"
  },
  {
    "id": "azure/gpt-5-codex",
    "name": "gpt-5-codex",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "input_cost_per_token": 0.00000125,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "responses",
      "output_cost_per_token": 0.00001,
      "supported_endpoints": [
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5-codex",
    "displayName": "gpt-5-codex"
  },
  {
    "id": "azure/gpt-5-mini",
    "name": "gpt-5-mini",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 2.5e-8,
      "input_cost_per_token": 2.5e-7,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5-mini",
    "displayName": "gpt-5-mini"
  },
  {
    "id": "azure/gpt-5-mini-2025-08-07",
    "name": "gpt-5-mini-2025-08-07",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 2.5e-8,
      "input_cost_per_token": 2.5e-7,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5-mini-2025-08-07",
    "displayName": "gpt-5-mini-2025-08-07"
  },
  {
    "id": "azure/gpt-5-nano",
    "name": "gpt-5-nano",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 5e-9,
      "input_cost_per_token": 5e-8,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5-nano",
    "displayName": "gpt-5-nano"
  },
  {
    "id": "azure/gpt-5-nano-2025-08-07",
    "name": "gpt-5-nano-2025-08-07",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 5e-9,
      "input_cost_per_token": 5e-8,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5-nano-2025-08-07",
    "displayName": "gpt-5-nano-2025-08-07"
  },
  {
    "id": "azure/gpt-5-pro",
    "name": "gpt-5-pro",
    "provider": "azure",
    "data": {
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "responses",
      "output_cost_per_token": 0.00012,
      "source": "https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-models/concepts/models-sold-directly-by-azure?pivots=azure-openai&tabs=global-standard-aoai%2Cstandard-chat-completions%2Cglobal-standard#gpt-5",
      "supported_endpoints": [
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5-pro",
    "displayName": "gpt-5-pro"
  },
  {
    "id": "azure/gpt-5.1",
    "name": "gpt-5.1",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "input_cost_per_token": 0.00000125,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5.1",
    "displayName": "gpt-5.1"
  },
  {
    "id": "azure/gpt-5.1-chat",
    "name": "gpt-5.1-chat",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "input_cost_per_token": 0.00000125,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5.1-chat",
    "displayName": "gpt-5.1-chat"
  },
  {
    "id": "azure/gpt-5.1-codex",
    "name": "gpt-5.1-codex",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "input_cost_per_token": 0.00000125,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "responses",
      "output_cost_per_token": 0.00001,
      "supported_endpoints": [
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": false,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5.1-codex",
    "displayName": "gpt-5.1-codex"
  },
  {
    "id": "azure/gpt-5.1-codex-max",
    "name": "gpt-5.1-codex-max",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "input_cost_per_token": 0.00000125,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "responses",
      "output_cost_per_token": 0.00001,
      "supported_endpoints": [
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": false,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5.1-codex-max",
    "displayName": "gpt-5.1-codex-max"
  },
  {
    "id": "azure/gpt-5.1-codex-mini",
    "name": "gpt-5.1-codex-mini",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 2.5e-8,
      "input_cost_per_token": 2.5e-7,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "responses",
      "output_cost_per_token": 0.000002,
      "supported_endpoints": [
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": false,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5.1-codex-mini",
    "displayName": "gpt-5.1-codex-mini"
  },
  {
    "id": "azure/gpt-5.2",
    "name": "gpt-5.2",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 1.75e-7,
      "input_cost_per_token": 0.00000175,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000014,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5.2",
    "displayName": "gpt-5.2"
  },
  {
    "id": "azure/gpt-5.2-2025-12-11",
    "name": "gpt-5.2-2025-12-11",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 1.75e-7,
      "cache_read_input_token_cost_priority": 3.5e-7,
      "input_cost_per_token": 0.00000175,
      "input_cost_per_token_priority": 0.0000035,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000014,
      "output_cost_per_token_priority": 0.000028,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_service_tier": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5.2-2025-12-11",
    "displayName": "gpt-5.2-2025-12-11"
  },
  {
    "id": "azure/gpt-5.2-chat",
    "name": "gpt-5.2-chat",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 1.75e-7,
      "cache_read_input_token_cost_priority": 3.5e-7,
      "input_cost_per_token": 0.00000175,
      "input_cost_per_token_priority": 0.0000035,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.000014,
      "output_cost_per_token_priority": 0.000028,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5.2-chat",
    "displayName": "gpt-5.2-chat"
  },
  {
    "id": "azure/gpt-5.2-chat-2025-12-11",
    "name": "gpt-5.2-chat-2025-12-11",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 1.75e-7,
      "cache_read_input_token_cost_priority": 3.5e-7,
      "input_cost_per_token": 0.00000175,
      "input_cost_per_token_priority": 0.0000035,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.000014,
      "output_cost_per_token_priority": 0.000028,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5.2-chat-2025-12-11",
    "displayName": "gpt-5.2-chat-2025-12-11"
  },
  {
    "id": "azure/gpt-5.2-codex",
    "name": "gpt-5.2-codex",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 1.75e-7,
      "input_cost_per_token": 0.00000175,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "responses",
      "output_cost_per_token": 0.000014,
      "supported_endpoints": [
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5.2-codex",
    "displayName": "gpt-5.2-codex"
  },
  {
    "id": "azure/gpt-5.2-pro",
    "name": "gpt-5.2-pro",
    "provider": "azure",
    "data": {
      "input_cost_per_token": 0.000021,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "responses",
      "output_cost_per_token": 0.000168,
      "supported_endpoints": [
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "azure"
    },
    "slug": "gpt-5.2-pro",
    "displayName": "gpt-5.2-pro"
  },
  {
    "id": "azure/gpt-5.2-pro-2025-12-11",
    "name": "gpt-5.2-pro-2025-12-11",
    "provider": "azure",
    "data": {
      "input_cost_per_token": 0.000021,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "responses",
      "output_cost_per_token": 0.000168,
      "supported_endpoints": [
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "azure"
    },
    "slug": "gpt-5.2-pro-2025-12-11",
    "displayName": "gpt-5.2-pro-2025-12-11"
  },
  {
    "id": "azure/gpt-image-1",
    "name": "gpt-image-1",
    "provider": "azure",
    "data": {
      "cache_read_input_image_token_cost": 0.0000025,
      "cache_read_input_token_cost": 0.00000125,
      "input_cost_per_image_token": 0.00001,
      "input_cost_per_token": 0.000005,
      "mode": "image_generation",
      "output_cost_per_image_token": 0.00004,
      "supported_endpoints": [
        "/v1/images/generations",
        "/v1/images/edits"
      ],
      "provider": "azure"
    },
    "slug": "gpt-image-1",
    "displayName": "gpt-image-1"
  },
  {
    "id": "azure/gpt-image-1-mini",
    "name": "gpt-image-1-mini",
    "provider": "azure",
    "data": {
      "cache_read_input_image_token_cost": 2.5e-7,
      "cache_read_input_token_cost": 2e-7,
      "input_cost_per_image_token": 0.0000025,
      "input_cost_per_token": 0.000002,
      "mode": "image_generation",
      "output_cost_per_image_token": 0.000008,
      "supported_endpoints": [
        "/v1/images/generations",
        "/v1/images/edits"
      ],
      "provider": "azure"
    },
    "slug": "gpt-image-1-mini",
    "displayName": "gpt-image-1-mini"
  },
  {
    "id": "azure/gpt-image-1.5",
    "name": "gpt-image-1.5",
    "provider": "azure",
    "data": {
      "cache_read_input_image_token_cost": 0.000002,
      "cache_read_input_token_cost": 0.00000125,
      "input_cost_per_token": 0.000005,
      "input_cost_per_image_token": 0.000008,
      "mode": "image_generation",
      "output_cost_per_image_token": 0.000032,
      "supported_endpoints": [
        "/v1/images/generations",
        "/v1/images/edits"
      ],
      "provider": "azure"
    },
    "slug": "gpt-image-1.5",
    "displayName": "gpt-image-1.5"
  },
  {
    "id": "azure/gpt-image-1.5-2025-12-16",
    "name": "gpt-image-1.5-2025-12-16",
    "provider": "azure",
    "data": {
      "cache_read_input_image_token_cost": 0.000002,
      "cache_read_input_token_cost": 0.00000125,
      "input_cost_per_token": 0.000005,
      "input_cost_per_image_token": 0.000008,
      "mode": "image_generation",
      "output_cost_per_image_token": 0.000032,
      "supported_endpoints": [
        "/v1/images/generations",
        "/v1/images/edits"
      ],
      "provider": "azure"
    },
    "slug": "gpt-image-1.5-2025-12-16",
    "displayName": "gpt-image-1.5-2025-12-16"
  },
  {
    "id": "azure/mistral-large-2402",
    "name": "mistral-large-2402",
    "provider": "azure",
    "data": {
      "input_cost_per_token": 0.000008,
      "max_input_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.000024,
      "supports_function_calling": true,
      "provider": "azure"
    },
    "slug": "mistral-large-2402",
    "displayName": "mistral-large-2402"
  },
  {
    "id": "azure/mistral-large-latest",
    "name": "mistral-large-latest",
    "provider": "azure",
    "data": {
      "input_cost_per_token": 0.000008,
      "max_input_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.000024,
      "supports_function_calling": true,
      "provider": "azure"
    },
    "slug": "mistral-large-latest",
    "displayName": "mistral-large-latest"
  },
  {
    "id": "azure/o1",
    "name": "o1",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 0.0000075,
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "chat",
      "output_cost_per_token": 0.00006,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "o1",
    "displayName": "o1"
  },
  {
    "id": "azure/o1-2024-12-17",
    "name": "o1-2024-12-17",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 0.0000075,
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "chat",
      "output_cost_per_token": 0.00006,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "o1-2024-12-17",
    "displayName": "o1-2024-12-17"
  },
  {
    "id": "azure/o1-mini",
    "name": "o1-mini",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 6.05e-7,
      "input_cost_per_token": 0.00000121,
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "max_tokens": 65536,
      "mode": "chat",
      "output_cost_per_token": 0.00000484,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_vision": false,
      "provider": "azure"
    },
    "slug": "o1-mini",
    "displayName": "o1-mini"
  },
  {
    "id": "azure/o1-mini-2024-09-12",
    "name": "o1-mini-2024-09-12",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 5.5e-7,
      "input_cost_per_token": 0.0000011,
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "max_tokens": 65536,
      "mode": "chat",
      "output_cost_per_token": 0.0000044,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_vision": false,
      "provider": "azure"
    },
    "slug": "o1-mini-2024-09-12",
    "displayName": "o1-mini-2024-09-12"
  },
  {
    "id": "azure/o1-preview",
    "name": "o1-preview",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 0.0000075,
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.00006,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_vision": false,
      "provider": "azure"
    },
    "slug": "o1-preview",
    "displayName": "o1-preview"
  },
  {
    "id": "azure/o1-preview-2024-09-12",
    "name": "o1-preview-2024-09-12",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 0.0000075,
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.00006,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_vision": false,
      "provider": "azure"
    },
    "slug": "o1-preview-2024-09-12",
    "displayName": "o1-preview-2024-09-12"
  },
  {
    "id": "azure/o3",
    "name": "o3",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 5e-7,
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "chat",
      "output_cost_per_token": 0.000008,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_parallel_function_calling": false,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "o3",
    "displayName": "o3"
  },
  {
    "id": "azure/o3-2025-04-16",
    "name": "o3-2025-04-16",
    "provider": "azure",
    "data": {
      "deprecation_date": "2026-04-16",
      "cache_read_input_token_cost": 5e-7,
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "chat",
      "output_cost_per_token": 0.000008,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_parallel_function_calling": false,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "o3-2025-04-16",
    "displayName": "o3-2025-04-16"
  },
  {
    "id": "azure/o3-deep-research",
    "name": "o3-deep-research",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 0.0000025,
      "input_cost_per_token": 0.00001,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "responses",
      "output_cost_per_token": 0.00004,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "azure"
    },
    "slug": "o3-deep-research",
    "displayName": "o3-deep-research"
  },
  {
    "id": "azure/o3-mini",
    "name": "o3-mini",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 5.5e-7,
      "input_cost_per_token": 0.0000011,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "chat",
      "output_cost_per_token": 0.0000044,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "azure"
    },
    "slug": "o3-mini",
    "displayName": "o3-mini"
  },
  {
    "id": "azure/o3-mini-2025-01-31",
    "name": "o3-mini-2025-01-31",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 5.5e-7,
      "input_cost_per_token": 0.0000011,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "chat",
      "output_cost_per_token": 0.0000044,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "azure"
    },
    "slug": "o3-mini-2025-01-31",
    "displayName": "o3-mini-2025-01-31"
  },
  {
    "id": "azure/o3-pro",
    "name": "o3-pro",
    "provider": "azure",
    "data": {
      "input_cost_per_token": 0.00002,
      "input_cost_per_token_batches": 0.00001,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "responses",
      "output_cost_per_token": 0.00008,
      "output_cost_per_token_batches": 0.00004,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_parallel_function_calling": false,
      "supports_prompt_caching": false,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "o3-pro",
    "displayName": "o3-pro"
  },
  {
    "id": "azure/o3-pro-2025-06-10",
    "name": "o3-pro-2025-06-10",
    "provider": "azure",
    "data": {
      "input_cost_per_token": 0.00002,
      "input_cost_per_token_batches": 0.00001,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "responses",
      "output_cost_per_token": 0.00008,
      "output_cost_per_token_batches": 0.00004,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_parallel_function_calling": false,
      "supports_prompt_caching": false,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "o3-pro-2025-06-10",
    "displayName": "o3-pro-2025-06-10"
  },
  {
    "id": "azure/o4-mini",
    "name": "o4-mini",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 2.75e-7,
      "input_cost_per_token": 0.0000011,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "chat",
      "output_cost_per_token": 0.0000044,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_parallel_function_calling": false,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "o4-mini",
    "displayName": "o4-mini"
  },
  {
    "id": "azure/o4-mini-2025-04-16",
    "name": "o4-mini-2025-04-16",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 2.75e-7,
      "input_cost_per_token": 0.0000011,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "chat",
      "output_cost_per_token": 0.0000044,
      "supports_function_calling": true,
      "supports_parallel_function_calling": false,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "o4-mini-2025-04-16",
    "displayName": "o4-mini-2025-04-16"
  },
  {
    "id": "azure/text-embedding-3-large",
    "name": "text-embedding-3-large",
    "provider": "azure",
    "data": {
      "input_cost_per_token": 1.3e-7,
      "max_input_tokens": 8191,
      "max_tokens": 8191,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "provider": "azure"
    },
    "slug": "text-embedding-3-large",
    "displayName": "text-embedding-3-large"
  },
  {
    "id": "azure/text-embedding-3-small",
    "name": "text-embedding-3-small",
    "provider": "azure",
    "data": {
      "deprecation_date": "2026-04-30",
      "input_cost_per_token": 2e-8,
      "max_input_tokens": 8191,
      "max_tokens": 8191,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "provider": "azure"
    },
    "slug": "text-embedding-3-small",
    "displayName": "text-embedding-3-small"
  },
  {
    "id": "azure/text-embedding-ada-002",
    "name": "text-embedding-ada-002",
    "provider": "azure",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 8191,
      "max_tokens": 8191,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "provider": "azure"
    },
    "slug": "text-embedding-ada-002",
    "displayName": "text-embedding-ada-002"
  },
  {
    "id": "azure/us/gpt-4.1-2025-04-14",
    "name": "gpt-4.1-2025-04-14",
    "provider": "azure",
    "data": {
      "deprecation_date": "2026-11-04",
      "cache_read_input_token_cost": 5.5e-7,
      "input_cost_per_token": 0.0000022,
      "input_cost_per_token_batches": 0.0000011,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.0000088,
      "output_cost_per_token_batches": 0.0000044,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": false,
      "provider": "azure"
    },
    "slug": "gpt-4.1-2025-04-14",
    "displayName": "gpt-4.1-2025-04-14"
  },
  {
    "id": "azure/us/gpt-4.1-mini-2025-04-14",
    "name": "gpt-4.1-mini-2025-04-14",
    "provider": "azure",
    "data": {
      "deprecation_date": "2026-11-04",
      "cache_read_input_token_cost": 1.1e-7,
      "input_cost_per_token": 4.4e-7,
      "input_cost_per_token_batches": 2.2e-7,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.00000176,
      "output_cost_per_token_batches": 8.8e-7,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": false,
      "provider": "azure"
    },
    "slug": "gpt-4.1-mini-2025-04-14",
    "displayName": "gpt-4.1-mini-2025-04-14"
  },
  {
    "id": "azure/us/gpt-4.1-nano-2025-04-14",
    "name": "gpt-4.1-nano-2025-04-14",
    "provider": "azure",
    "data": {
      "deprecation_date": "2026-11-04",
      "cache_read_input_token_cost": 2.5e-8,
      "input_cost_per_token": 1.1e-7,
      "input_cost_per_token_batches": 6e-8,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 4.4e-7,
      "output_cost_per_token_batches": 2.2e-7,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-4.1-nano-2025-04-14",
    "displayName": "gpt-4.1-nano-2025-04-14"
  },
  {
    "id": "azure/us/gpt-4o-2024-08-06",
    "name": "gpt-4o-2024-08-06",
    "provider": "azure",
    "data": {
      "deprecation_date": "2026-02-27",
      "cache_read_input_token_cost": 0.000001375,
      "input_cost_per_token": 0.00000275,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.000011,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-4o-2024-08-06",
    "displayName": "gpt-4o-2024-08-06"
  },
  {
    "id": "azure/us/gpt-4o-2024-11-20",
    "name": "gpt-4o-2024-11-20",
    "provider": "azure",
    "data": {
      "deprecation_date": "2026-03-01",
      "cache_creation_input_token_cost": 0.00000138,
      "input_cost_per_token": 0.00000275,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.000011,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-4o-2024-11-20",
    "displayName": "gpt-4o-2024-11-20"
  },
  {
    "id": "azure/us/gpt-4o-mini-2024-07-18",
    "name": "gpt-4o-mini-2024-07-18",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 8.3e-8,
      "input_cost_per_token": 1.65e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 6.6e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-4o-mini-2024-07-18",
    "displayName": "gpt-4o-mini-2024-07-18"
  },
  {
    "id": "azure/us/gpt-4o-mini-realtime-preview-2024-12-17",
    "name": "gpt-4o-mini-realtime-preview-2024-12-17",
    "provider": "azure",
    "data": {
      "cache_creation_input_audio_token_cost": 3.3e-7,
      "cache_read_input_token_cost": 3.3e-7,
      "input_cost_per_audio_token": 0.000011,
      "input_cost_per_token": 6.6e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_audio_token": 0.000022,
      "output_cost_per_token": 0.00000264,
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "azure"
    },
    "slug": "gpt-4o-mini-realtime-preview-2024-12-17",
    "displayName": "gpt-4o-mini-realtime-preview-2024-12-17"
  },
  {
    "id": "azure/us/gpt-4o-realtime-preview-2024-10-01",
    "name": "gpt-4o-realtime-preview-2024-10-01",
    "provider": "azure",
    "data": {
      "cache_creation_input_audio_token_cost": 0.000022,
      "cache_read_input_token_cost": 0.00000275,
      "input_cost_per_audio_token": 0.00011,
      "input_cost_per_token": 0.0000055,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_audio_token": 0.00022,
      "output_cost_per_token": 0.000022,
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "azure"
    },
    "slug": "gpt-4o-realtime-preview-2024-10-01",
    "displayName": "gpt-4o-realtime-preview-2024-10-01"
  },
  {
    "id": "azure/us/gpt-4o-realtime-preview-2024-12-17",
    "name": "gpt-4o-realtime-preview-2024-12-17",
    "provider": "azure",
    "data": {
      "cache_read_input_audio_token_cost": 0.0000025,
      "cache_read_input_token_cost": 0.00000275,
      "input_cost_per_audio_token": 0.000044,
      "input_cost_per_token": 0.0000055,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_audio_token": 0.00008,
      "output_cost_per_token": 0.000022,
      "supported_modalities": [
        "text",
        "audio"
      ],
      "supported_output_modalities": [
        "text",
        "audio"
      ],
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "azure"
    },
    "slug": "gpt-4o-realtime-preview-2024-12-17",
    "displayName": "gpt-4o-realtime-preview-2024-12-17"
  },
  {
    "id": "azure/us/gpt-5-2025-08-07",
    "name": "gpt-5-2025-08-07",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 1.375e-7,
      "input_cost_per_token": 0.000001375,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000011,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5-2025-08-07",
    "displayName": "gpt-5-2025-08-07"
  },
  {
    "id": "azure/us/gpt-5-mini-2025-08-07",
    "name": "gpt-5-mini-2025-08-07",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 2.75e-8,
      "input_cost_per_token": 2.75e-7,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.0000022,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5-mini-2025-08-07",
    "displayName": "gpt-5-mini-2025-08-07"
  },
  {
    "id": "azure/us/gpt-5-nano-2025-08-07",
    "name": "gpt-5-nano-2025-08-07",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 5.5e-9,
      "input_cost_per_token": 5.5e-8,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 4.4e-7,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5-nano-2025-08-07",
    "displayName": "gpt-5-nano-2025-08-07"
  },
  {
    "id": "azure/us/gpt-5.1",
    "name": "gpt-5.1",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 1.4e-7,
      "input_cost_per_token": 0.00000138,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000011,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5.1",
    "displayName": "gpt-5.1"
  },
  {
    "id": "azure/us/gpt-5.1-chat",
    "name": "gpt-5.1-chat",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 1.4e-7,
      "input_cost_per_token": 0.00000138,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000011,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5.1-chat",
    "displayName": "gpt-5.1-chat"
  },
  {
    "id": "azure/us/gpt-5.1-codex",
    "name": "gpt-5.1-codex",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 1.4e-7,
      "input_cost_per_token": 0.00000138,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "responses",
      "output_cost_per_token": 0.000011,
      "supported_endpoints": [
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": false,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5.1-codex",
    "displayName": "gpt-5.1-codex"
  },
  {
    "id": "azure/us/gpt-5.1-codex-mini",
    "name": "gpt-5.1-codex-mini",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 2.8e-8,
      "input_cost_per_token": 2.75e-7,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "responses",
      "output_cost_per_token": 0.0000022,
      "supported_endpoints": [
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": false,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "gpt-5.1-codex-mini",
    "displayName": "gpt-5.1-codex-mini"
  },
  {
    "id": "azure/us/o1-2024-12-17",
    "name": "o1-2024-12-17",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 0.00000825,
      "input_cost_per_token": 0.0000165,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "chat",
      "output_cost_per_token": 0.000066,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "o1-2024-12-17",
    "displayName": "o1-2024-12-17"
  },
  {
    "id": "azure/us/o1-mini-2024-09-12",
    "name": "o1-mini-2024-09-12",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 6.05e-7,
      "input_cost_per_token": 0.00000121,
      "input_cost_per_token_batches": 6.05e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "max_tokens": 65536,
      "mode": "chat",
      "output_cost_per_token": 0.00000484,
      "output_cost_per_token_batches": 0.00000242,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_vision": false,
      "provider": "azure"
    },
    "slug": "o1-mini-2024-09-12",
    "displayName": "o1-mini-2024-09-12"
  },
  {
    "id": "azure/us/o1-preview-2024-09-12",
    "name": "o1-preview-2024-09-12",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 0.00000825,
      "input_cost_per_token": 0.0000165,
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.000066,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_vision": false,
      "provider": "azure"
    },
    "slug": "o1-preview-2024-09-12",
    "displayName": "o1-preview-2024-09-12"
  },
  {
    "id": "azure/us/o3-2025-04-16",
    "name": "o3-2025-04-16",
    "provider": "azure",
    "data": {
      "deprecation_date": "2026-04-16",
      "cache_read_input_token_cost": 5.5e-7,
      "input_cost_per_token": 0.0000022,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "chat",
      "output_cost_per_token": 0.0000088,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_parallel_function_calling": false,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "o3-2025-04-16",
    "displayName": "o3-2025-04-16"
  },
  {
    "id": "azure/us/o3-mini-2025-01-31",
    "name": "o3-mini-2025-01-31",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 6.05e-7,
      "input_cost_per_token": 0.00000121,
      "input_cost_per_token_batches": 6.05e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "chat",
      "output_cost_per_token": 0.00000484,
      "output_cost_per_token_batches": 0.00000242,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "azure"
    },
    "slug": "o3-mini-2025-01-31",
    "displayName": "o3-mini-2025-01-31"
  },
  {
    "id": "azure/us/o4-mini-2025-04-16",
    "name": "o4-mini-2025-04-16",
    "provider": "azure",
    "data": {
      "cache_read_input_token_cost": 3.1e-7,
      "input_cost_per_token": 0.00000121,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "chat",
      "output_cost_per_token": 0.00000484,
      "supports_function_calling": true,
      "supports_parallel_function_calling": false,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "o4-mini-2025-04-16",
    "displayName": "o4-mini-2025-04-16"
  },
  {
    "id": "azure_ai/Cohere-embed-v3-english",
    "name": "Cohere-embed-v3-english",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 512,
      "max_tokens": 512,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_vector_size": 1024,
      "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cohere.cohere-embed-v3-english-offer?tab=PlansAndPrice",
      "supports_embedding_image_input": true,
      "provider": "azure_ai"
    },
    "slug": "cohere-embed-v3-english",
    "displayName": "Cohere-embed-v3-english"
  },
  {
    "id": "azure_ai/Cohere-embed-v3-multilingual",
    "name": "Cohere-embed-v3-multilingual",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 512,
      "max_tokens": 512,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_vector_size": 1024,
      "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cohere.cohere-embed-v3-english-offer?tab=PlansAndPrice",
      "supports_embedding_image_input": true,
      "provider": "azure_ai"
    },
    "slug": "cohere-embed-v3-multilingual",
    "displayName": "Cohere-embed-v3-multilingual"
  },
  {
    "id": "azure_ai/Llama-3.2-11B-Vision-Instruct",
    "name": "Llama-3.2-11B-Vision-Instruct",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 3.7e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "max_tokens": 2048,
      "mode": "chat",
      "output_cost_per_token": 3.7e-7,
      "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.meta-llama-3-2-11b-vision-instruct-offer?tab=Overview",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure_ai"
    },
    "slug": "llama-3.2-11b-vision-instruct",
    "displayName": "Llama-3.2-11B-Vision-Instruct"
  },
  {
    "id": "azure_ai/Llama-3.2-90B-Vision-Instruct",
    "name": "Llama-3.2-90B-Vision-Instruct",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 0.00000204,
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "max_tokens": 2048,
      "mode": "chat",
      "output_cost_per_token": 0.00000204,
      "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.meta-llama-3-2-90b-vision-instruct-offer?tab=Overview",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure_ai"
    },
    "slug": "llama-3.2-90b-vision-instruct",
    "displayName": "Llama-3.2-90B-Vision-Instruct"
  },
  {
    "id": "azure_ai/Llama-3.3-70B-Instruct",
    "name": "Llama-3.3-70B-Instruct",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 7.1e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "max_tokens": 2048,
      "mode": "chat",
      "output_cost_per_token": 7.1e-7,
      "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.llama-3-3-70b-instruct-offer?tab=Overview",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "azure_ai"
    },
    "slug": "llama-3.3-70b-instruct",
    "displayName": "Llama-3.3-70B-Instruct"
  },
  {
    "id": "azure_ai/Llama-4-Maverick-17B-128E-Instruct-FP8",
    "name": "Llama-4-Maverick-17B-128E-Instruct-FP8",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 0.00000141,
      "max_input_tokens": 1000000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 3.5e-7,
      "source": "https://azure.microsoft.com/en-us/blog/introducing-the-llama-4-herd-in-azure-ai-foundry-and-azure-databricks/",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure_ai"
    },
    "slug": "llama-4-maverick-17b-128e-instruct-fp8",
    "displayName": "Llama-4-Maverick-17B-128E-Instruct-FP8"
  },
  {
    "id": "azure_ai/Llama-4-Scout-17B-16E-Instruct",
    "name": "Llama-4-Scout-17B-16E-Instruct",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 10000000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 7.8e-7,
      "source": "https://azure.microsoft.com/en-us/blog/introducing-the-llama-4-herd-in-azure-ai-foundry-and-azure-databricks/",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure_ai"
    },
    "slug": "llama-4-scout-17b-16e-instruct",
    "displayName": "Llama-4-Scout-17B-16E-Instruct"
  },
  {
    "id": "azure_ai/Meta-Llama-3-70B-Instruct",
    "name": "Meta-Llama-3-70B-Instruct",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 0.0000011,
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "max_tokens": 2048,
      "mode": "chat",
      "output_cost_per_token": 3.7e-7,
      "supports_tool_choice": true,
      "provider": "azure_ai"
    },
    "slug": "meta-llama-3-70b-instruct",
    "displayName": "Meta-Llama-3-70B-Instruct"
  },
  {
    "id": "azure_ai/Meta-Llama-3.1-405B-Instruct",
    "name": "Meta-Llama-3.1-405B-Instruct",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 0.00000533,
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "max_tokens": 2048,
      "mode": "chat",
      "output_cost_per_token": 0.000016,
      "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-405b-instruct-offer?tab=PlansAndPrice",
      "supports_tool_choice": true,
      "provider": "azure_ai"
    },
    "slug": "meta-llama-3.1-405b-instruct",
    "displayName": "Meta-Llama-3.1-405B-Instruct"
  },
  {
    "id": "azure_ai/Meta-Llama-3.1-70B-Instruct",
    "name": "Meta-Llama-3.1-70B-Instruct",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 0.00000268,
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "max_tokens": 2048,
      "mode": "chat",
      "output_cost_per_token": 0.00000354,
      "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-70b-instruct-offer?tab=PlansAndPrice",
      "supports_tool_choice": true,
      "provider": "azure_ai"
    },
    "slug": "meta-llama-3.1-70b-instruct",
    "displayName": "Meta-Llama-3.1-70B-Instruct"
  },
  {
    "id": "azure_ai/Meta-Llama-3.1-8B-Instruct",
    "name": "Meta-Llama-3.1-8B-Instruct",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "max_tokens": 2048,
      "mode": "chat",
      "output_cost_per_token": 6.1e-7,
      "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-8b-instruct-offer?tab=PlansAndPrice",
      "supports_tool_choice": true,
      "provider": "azure_ai"
    },
    "slug": "meta-llama-3.1-8b-instruct",
    "displayName": "Meta-Llama-3.1-8B-Instruct"
  },
  {
    "id": "azure_ai/Phi-3-medium-128k-instruct",
    "name": "Phi-3-medium-128k-instruct",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 1.7e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 6.8e-7,
      "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "azure_ai"
    },
    "slug": "phi-3-medium-128k-instruct",
    "displayName": "Phi-3-medium-128k-instruct"
  },
  {
    "id": "azure_ai/Phi-3-medium-4k-instruct",
    "name": "Phi-3-medium-4k-instruct",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 1.7e-7,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 6.8e-7,
      "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "azure_ai"
    },
    "slug": "phi-3-medium-4k-instruct",
    "displayName": "Phi-3-medium-4k-instruct"
  },
  {
    "id": "azure_ai/Phi-3-mini-128k-instruct",
    "name": "Phi-3-mini-128k-instruct",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 1.3e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 5.2e-7,
      "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "azure_ai"
    },
    "slug": "phi-3-mini-128k-instruct",
    "displayName": "Phi-3-mini-128k-instruct"
  },
  {
    "id": "azure_ai/Phi-3-mini-4k-instruct",
    "name": "Phi-3-mini-4k-instruct",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 1.3e-7,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 5.2e-7,
      "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "azure_ai"
    },
    "slug": "phi-3-mini-4k-instruct",
    "displayName": "Phi-3-mini-4k-instruct"
  },
  {
    "id": "azure_ai/Phi-3-small-128k-instruct",
    "name": "Phi-3-small-128k-instruct",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "azure_ai"
    },
    "slug": "phi-3-small-128k-instruct",
    "displayName": "Phi-3-small-128k-instruct"
  },
  {
    "id": "azure_ai/Phi-3-small-8k-instruct",
    "name": "Phi-3-small-8k-instruct",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "azure_ai"
    },
    "slug": "phi-3-small-8k-instruct",
    "displayName": "Phi-3-small-8k-instruct"
  },
  {
    "id": "azure_ai/Phi-3.5-MoE-instruct",
    "name": "Phi-3.5-MoE-instruct",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 1.6e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 6.4e-7,
      "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "azure_ai"
    },
    "slug": "phi-3.5-moe-instruct",
    "displayName": "Phi-3.5-MoE-instruct"
  },
  {
    "id": "azure_ai/Phi-3.5-mini-instruct",
    "name": "Phi-3.5-mini-instruct",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 1.3e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 5.2e-7,
      "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "azure_ai"
    },
    "slug": "phi-3.5-mini-instruct",
    "displayName": "Phi-3.5-mini-instruct"
  },
  {
    "id": "azure_ai/Phi-3.5-vision-instruct",
    "name": "Phi-3.5-vision-instruct",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 1.3e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 5.2e-7,
      "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure_ai"
    },
    "slug": "phi-3.5-vision-instruct",
    "displayName": "Phi-3.5-vision-instruct"
  },
  {
    "id": "azure_ai/Phi-4",
    "name": "Phi-4",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 1.25e-7,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 5e-7,
      "source": "https://techcommunity.microsoft.com/blog/machinelearningblog/affordable-innovation-unveiling-the-pricing-of-phi-3-slms-on-models-as-a-service/4156495",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "azure_ai"
    },
    "slug": "phi-4",
    "displayName": "Phi-4"
  },
  {
    "id": "azure_ai/Phi-4-mini-instruct",
    "name": "Phi-4-mini-instruct",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 7.5e-8,
      "max_input_tokens": 131072,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "source": "https://techcommunity.microsoft.com/blog/Azure-AI-Services-blog/announcing-new-phi-pricing-empowering-your-business-with-small-language-models/4395112",
      "supports_function_calling": true,
      "provider": "azure_ai"
    },
    "slug": "phi-4-mini-instruct",
    "displayName": "Phi-4-mini-instruct"
  },
  {
    "id": "azure_ai/Phi-4-multimodal-instruct",
    "name": "Phi-4-multimodal-instruct",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_audio_token": 0.000004,
      "input_cost_per_token": 8e-8,
      "max_input_tokens": 131072,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 3.2e-7,
      "source": "https://techcommunity.microsoft.com/blog/Azure-AI-Services-blog/announcing-new-phi-pricing-empowering-your-business-with-small-language-models/4395112",
      "supports_audio_input": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "provider": "azure_ai"
    },
    "slug": "phi-4-multimodal-instruct",
    "displayName": "Phi-4-multimodal-instruct"
  },
  {
    "id": "azure_ai/Phi-4-mini-reasoning",
    "name": "Phi-4-mini-reasoning",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 8e-8,
      "max_input_tokens": 131072,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 3.2e-7,
      "source": "https://azure.microsoft.com/en-us/pricing/details/ai-foundry-models/microsoft/",
      "supports_function_calling": true,
      "provider": "azure_ai"
    },
    "slug": "phi-4-mini-reasoning",
    "displayName": "Phi-4-mini-reasoning"
  },
  {
    "id": "azure_ai/Phi-4-reasoning",
    "name": "Phi-4-reasoning",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 1.25e-7,
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 5e-7,
      "source": "https://azure.microsoft.com/en-us/pricing/details/ai-foundry-models/microsoft/",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_reasoning": true,
      "provider": "azure_ai"
    },
    "slug": "phi-4-reasoning",
    "displayName": "Phi-4-reasoning"
  },
  {
    "id": "azure_ai/MAI-DS-R1",
    "name": "MAI-DS-R1",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 0.00000135,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.0000054,
      "source": "https://azure.microsoft.com/en-us/pricing/details/ai-foundry-models/microsoft/",
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "azure_ai"
    },
    "slug": "mai-ds-r1",
    "displayName": "MAI-DS-R1"
  },
  {
    "id": "azure_ai/deepseek-v3.2",
    "name": "deepseek-v3.2",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 5.8e-7,
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "max_tokens": 163840,
      "mode": "chat",
      "output_cost_per_token": 0.00000168,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "azure_ai"
    },
    "slug": "deepseek-v3.2",
    "displayName": "deepseek-v3.2"
  },
  {
    "id": "azure_ai/deepseek-v3.2-speciale",
    "name": "deepseek-v3.2-speciale",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 5.8e-7,
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "max_tokens": 163840,
      "mode": "chat",
      "output_cost_per_token": 0.00000168,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "azure_ai"
    },
    "slug": "deepseek-v3.2-speciale",
    "displayName": "deepseek-v3.2-speciale"
  },
  {
    "id": "azure_ai/deepseek-r1",
    "name": "deepseek-r1",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 0.00000135,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.0000054,
      "source": "https://techcommunity.microsoft.com/blog/machinelearningblog/deepseek-r1-improved-performance-higher-limits-and-transparent-pricing/4386367",
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "azure_ai"
    },
    "slug": "deepseek-r1",
    "displayName": "deepseek-r1"
  },
  {
    "id": "azure_ai/deepseek-v3",
    "name": "deepseek-v3",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 0.00000114,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.00000456,
      "source": "https://techcommunity.microsoft.com/blog/machinelearningblog/announcing-deepseek-v3-on-azure-ai-foundry-and-github/4390438",
      "supports_tool_choice": true,
      "provider": "azure_ai"
    },
    "slug": "deepseek-v3",
    "displayName": "deepseek-v3"
  },
  {
    "id": "azure_ai/deepseek-v3-0324",
    "name": "deepseek-v3-0324",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 0.00000114,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.00000456,
      "source": "https://techcommunity.microsoft.com/blog/machinelearningblog/announcing-deepseek-v3-on-azure-ai-foundry-and-github/4390438",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "azure_ai"
    },
    "slug": "deepseek-v3-0324",
    "displayName": "deepseek-v3-0324"
  },
  {
    "id": "azure_ai/embed-v-4-0",
    "name": "embed-v-4-0",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 1.2e-7,
      "max_input_tokens": 128000,
      "max_tokens": 128000,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_vector_size": 3072,
      "source": "https://azuremarketplace.microsoft.com/pt-br/marketplace/apps/cohere.cohere-embed-4-offer?tab=PlansAndPrice",
      "supported_endpoints": [
        "/v1/embeddings"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supports_embedding_image_input": true,
      "provider": "azure_ai"
    },
    "slug": "embed-v-4-0",
    "displayName": "embed-v-4-0"
  },
  {
    "id": "azure_ai/global/grok-3",
    "name": "grok-3",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "source": "https://devblogs.microsoft.com/foundry/announcing-grok-3-and-grok-3-mini-on-azure-ai-foundry/",
      "supports_function_calling": true,
      "supports_response_schema": false,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "azure_ai"
    },
    "slug": "grok-3",
    "displayName": "grok-3"
  },
  {
    "id": "azure_ai/global/grok-3-mini",
    "name": "grok-3-mini",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 2.5e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.00000127,
      "source": "https://devblogs.microsoft.com/foundry/announcing-grok-3-and-grok-3-mini-on-azure-ai-foundry/",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": false,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "azure_ai"
    },
    "slug": "grok-3-mini",
    "displayName": "grok-3-mini"
  },
  {
    "id": "azure_ai/grok-3",
    "name": "grok-3",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "source": "https://azure.microsoft.com/en-us/pricing/details/ai-foundry-models/grok/",
      "supports_function_calling": true,
      "supports_response_schema": false,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "azure_ai"
    },
    "slug": "grok-3",
    "displayName": "grok-3"
  },
  {
    "id": "azure_ai/grok-3-mini",
    "name": "grok-3-mini",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 2.5e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.00000127,
      "source": "https://azure.microsoft.com/en-us/pricing/details/ai-foundry-models/grok/",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": false,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "azure_ai"
    },
    "slug": "grok-3-mini",
    "displayName": "grok-3-mini"
  },
  {
    "id": "azure_ai/grok-4",
    "name": "grok-4",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "source": "https://azure.microsoft.com/en-us/pricing/details/ai-foundry-models/grok/",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "azure_ai"
    },
    "slug": "grok-4",
    "displayName": "grok-4"
  },
  {
    "id": "azure_ai/grok-4-fast-non-reasoning",
    "name": "grok-4-fast-non-reasoning",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 5e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "azure_ai"
    },
    "slug": "grok-4-fast-non-reasoning",
    "displayName": "grok-4-fast-non-reasoning"
  },
  {
    "id": "azure_ai/grok-4-fast-reasoning",
    "name": "grok-4-fast-reasoning",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 5e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "source": "https://azure.microsoft.com/en-us/pricing/details/ai-foundry-models/grok/",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "azure_ai"
    },
    "slug": "grok-4-fast-reasoning",
    "displayName": "grok-4-fast-reasoning"
  },
  {
    "id": "azure_ai/grok-code-fast-1",
    "name": "grok-code-fast-1",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "source": "https://azure.microsoft.com/en-us/pricing/details/ai-foundry-models/grok/",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "azure_ai"
    },
    "slug": "grok-code-fast-1",
    "displayName": "grok-code-fast-1"
  },
  {
    "id": "azure_ai/jamba-instruct",
    "name": "jamba-instruct",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 5e-7,
      "max_input_tokens": 70000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 7e-7,
      "supports_tool_choice": true,
      "provider": "azure_ai"
    },
    "slug": "jamba-instruct",
    "displayName": "jamba-instruct"
  },
  {
    "id": "azure_ai/ministral-3b",
    "name": "ministral-3b",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 4e-8,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 4e-8,
      "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.ministral-3b-2410-offer?tab=Overview",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "azure_ai"
    },
    "slug": "ministral-3b",
    "displayName": "ministral-3b"
  },
  {
    "id": "azure_ai/mistral-large",
    "name": "mistral-large",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 0.000004,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000012,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "azure_ai"
    },
    "slug": "mistral-large",
    "displayName": "mistral-large"
  },
  {
    "id": "azure_ai/mistral-large-2407",
    "name": "mistral-large-2407",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000006,
      "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-ai-large-2407-offer?tab=Overview",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "azure_ai"
    },
    "slug": "mistral-large-2407",
    "displayName": "mistral-large-2407"
  },
  {
    "id": "azure_ai/mistral-large-latest",
    "name": "mistral-large-latest",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000006,
      "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-ai-large-2407-offer?tab=Overview",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "azure_ai"
    },
    "slug": "mistral-large-latest",
    "displayName": "mistral-large-latest"
  },
  {
    "id": "azure_ai/mistral-large-3",
    "name": "mistral-large-3",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 5e-7,
      "max_input_tokens": 256000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "source": "https://azure.microsoft.com/en-us/blog/introducing-mistral-large-3-in-microsoft-foundry-open-capable-and-ready-for-production-workloads/",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure_ai"
    },
    "slug": "mistral-large-3",
    "displayName": "mistral-large-3"
  },
  {
    "id": "azure_ai/mistral-medium-2505",
    "name": "mistral-medium-2505",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 4e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "azure_ai"
    },
    "slug": "mistral-medium-2505",
    "displayName": "mistral-medium-2505"
  },
  {
    "id": "azure_ai/mistral-nemo",
    "name": "mistral-nemo",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 1.5e-7,
      "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-nemo-12b-2407?tab=PlansAndPrice",
      "supports_function_calling": true,
      "provider": "azure_ai"
    },
    "slug": "mistral-nemo",
    "displayName": "mistral-nemo"
  },
  {
    "id": "azure_ai/mistral-small",
    "name": "mistral-small",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000003,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "azure_ai"
    },
    "slug": "mistral-small",
    "displayName": "mistral-small"
  },
  {
    "id": "azure_ai/mistral-small-2503",
    "name": "mistral-small-2503",
    "provider": "azure_ai",
    "data": {
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000003,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure_ai"
    },
    "slug": "mistral-small-2503",
    "displayName": "mistral-small-2503"
  },
  {
    "id": "babbage-002",
    "name": "babbage-002",
    "provider": "text-completion-openai",
    "data": {
      "input_cost_per_token": 4e-7,
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "completion",
      "output_cost_per_token": 4e-7,
      "provider": "text-completion-openai"
    },
    "slug": "babbage-002",
    "displayName": "babbage-002"
  },
  {
    "id": "bedrock/ap-northeast-1/anthropic.claude-instant-v1",
    "name": "anthropic.claude-instant-v1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.00000223,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.00000755,
      "supports_tool_choice": true,
      "provider": "bedrock"
    },
    "slug": "anthropic.claude-instant-v1",
    "displayName": "anthropic.claude-instant-v1"
  },
  {
    "id": "bedrock/ap-northeast-1/anthropic.claude-v1",
    "name": "anthropic.claude-v1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000008,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000024,
      "supports_tool_choice": true,
      "provider": "bedrock"
    },
    "slug": "anthropic.claude-v1",
    "displayName": "anthropic.claude-v1"
  },
  {
    "id": "bedrock/ap-northeast-1/anthropic.claude-v2:1",
    "name": "anthropic.claude-v2:1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000008,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000024,
      "supports_tool_choice": true,
      "provider": "bedrock"
    },
    "slug": "anthropic.claude-v2-1",
    "displayName": "anthropic.claude-v2:1"
  },
  {
    "id": "bedrock/ap-south-1/meta.llama3-70b-instruct-v1:0",
    "name": "meta.llama3-70b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.00000318,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.0000042,
      "provider": "bedrock"
    },
    "slug": "meta.llama3-70b-instruct-v1-0",
    "displayName": "meta.llama3-70b-instruct-v1:0"
  },
  {
    "id": "bedrock/ap-south-1/meta.llama3-8b-instruct-v1:0",
    "name": "meta.llama3-8b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 3.6e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 7.2e-7,
      "provider": "bedrock"
    },
    "slug": "meta.llama3-8b-instruct-v1-0",
    "displayName": "meta.llama3-8b-instruct-v1:0"
  },
  {
    "id": "bedrock/ca-central-1/meta.llama3-70b-instruct-v1:0",
    "name": "meta.llama3-70b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.00000305,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.00000403,
      "provider": "bedrock"
    },
    "slug": "meta.llama3-70b-instruct-v1-0",
    "displayName": "meta.llama3-70b-instruct-v1:0"
  },
  {
    "id": "bedrock/ca-central-1/meta.llama3-8b-instruct-v1:0",
    "name": "meta.llama3-8b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 3.5e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 6.9e-7,
      "provider": "bedrock"
    },
    "slug": "meta.llama3-8b-instruct-v1-0",
    "displayName": "meta.llama3-8b-instruct-v1:0"
  },
  {
    "id": "bedrock/eu-central-1/anthropic.claude-instant-v1",
    "name": "anthropic.claude-instant-v1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.00000248,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.00000838,
      "supports_tool_choice": true,
      "provider": "bedrock"
    },
    "slug": "anthropic.claude-instant-v1",
    "displayName": "anthropic.claude-instant-v1"
  },
  {
    "id": "bedrock/eu-central-1/anthropic.claude-v1",
    "name": "anthropic.claude-v1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000008,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000024,
      "provider": "bedrock"
    },
    "slug": "anthropic.claude-v1",
    "displayName": "anthropic.claude-v1"
  },
  {
    "id": "bedrock/eu-central-1/anthropic.claude-v2:1",
    "name": "anthropic.claude-v2:1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000008,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000024,
      "supports_tool_choice": true,
      "provider": "bedrock"
    },
    "slug": "anthropic.claude-v2-1",
    "displayName": "anthropic.claude-v2:1"
  },
  {
    "id": "bedrock/eu-west-1/meta.llama3-70b-instruct-v1:0",
    "name": "meta.llama3-70b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.00000286,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.00000378,
      "provider": "bedrock"
    },
    "slug": "meta.llama3-70b-instruct-v1-0",
    "displayName": "meta.llama3-70b-instruct-v1:0"
  },
  {
    "id": "bedrock/eu-west-1/meta.llama3-8b-instruct-v1:0",
    "name": "meta.llama3-8b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 3.2e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 6.5e-7,
      "provider": "bedrock"
    },
    "slug": "meta.llama3-8b-instruct-v1-0",
    "displayName": "meta.llama3-8b-instruct-v1:0"
  },
  {
    "id": "bedrock/eu-west-2/meta.llama3-70b-instruct-v1:0",
    "name": "meta.llama3-70b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.00000345,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.00000455,
      "provider": "bedrock"
    },
    "slug": "meta.llama3-70b-instruct-v1-0",
    "displayName": "meta.llama3-70b-instruct-v1:0"
  },
  {
    "id": "bedrock/eu-west-2/meta.llama3-8b-instruct-v1:0",
    "name": "meta.llama3-8b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 3.9e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 7.8e-7,
      "provider": "bedrock"
    },
    "slug": "meta.llama3-8b-instruct-v1-0",
    "displayName": "meta.llama3-8b-instruct-v1:0"
  },
  {
    "id": "bedrock/eu-west-3/mistral.mistral-7b-instruct-v0:2",
    "name": "mistral.mistral-7b-instruct-v0:2",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 2.6e-7,
      "supports_tool_choice": true,
      "provider": "bedrock"
    },
    "slug": "mistral.mistral-7b-instruct-v0-2",
    "displayName": "mistral.mistral-7b-instruct-v0:2"
  },
  {
    "id": "bedrock/eu-west-3/mistral.mistral-large-2402-v1:0",
    "name": "mistral.mistral-large-2402-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.0000104,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.0000312,
      "supports_function_calling": true,
      "provider": "bedrock"
    },
    "slug": "mistral.mistral-large-2402-v1-0",
    "displayName": "mistral.mistral-large-2402-v1:0"
  },
  {
    "id": "bedrock/eu-west-3/mistral.mixtral-8x7b-instruct-v0:1",
    "name": "mistral.mixtral-8x7b-instruct-v0:1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 5.9e-7,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 9.1e-7,
      "supports_tool_choice": true,
      "provider": "bedrock"
    },
    "slug": "mistral.mixtral-8x7b-instruct-v0-1",
    "displayName": "mistral.mixtral-8x7b-instruct-v0:1"
  },
  {
    "id": "bedrock/invoke/anthropic.claude-3-5-sonnet-20240620-v1:0",
    "name": "anthropic.claude-3-5-sonnet-20240620-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "metadata": {
        "notes": "Anthropic via Invoke route does not currently support pdf input."
      },
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "anthropic.claude-3-5-sonnet-20240620-v1-0",
    "displayName": "anthropic.claude-3-5-sonnet-20240620-v1:0"
  },
  {
    "id": "bedrock/sa-east-1/meta.llama3-70b-instruct-v1:0",
    "name": "meta.llama3-70b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.00000445,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.00000588,
      "provider": "bedrock"
    },
    "slug": "meta.llama3-70b-instruct-v1-0",
    "displayName": "meta.llama3-70b-instruct-v1:0"
  },
  {
    "id": "bedrock/sa-east-1/meta.llama3-8b-instruct-v1:0",
    "name": "meta.llama3-8b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 5e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.00000101,
      "provider": "bedrock"
    },
    "slug": "meta.llama3-8b-instruct-v1-0",
    "displayName": "meta.llama3-8b-instruct-v1:0"
  },
  {
    "id": "bedrock/us-east-1/anthropic.claude-instant-v1",
    "name": "anthropic.claude-instant-v1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 8e-7,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.0000024,
      "supports_tool_choice": true,
      "provider": "bedrock"
    },
    "slug": "anthropic.claude-instant-v1",
    "displayName": "anthropic.claude-instant-v1"
  },
  {
    "id": "bedrock/us-east-1/anthropic.claude-v1",
    "name": "anthropic.claude-v1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000008,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000024,
      "supports_tool_choice": true,
      "provider": "bedrock"
    },
    "slug": "anthropic.claude-v1",
    "displayName": "anthropic.claude-v1"
  },
  {
    "id": "bedrock/us-east-1/anthropic.claude-v2:1",
    "name": "anthropic.claude-v2:1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000008,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000024,
      "supports_tool_choice": true,
      "provider": "bedrock"
    },
    "slug": "anthropic.claude-v2-1",
    "displayName": "anthropic.claude-v2:1"
  },
  {
    "id": "bedrock/us-east-1/meta.llama3-70b-instruct-v1:0",
    "name": "meta.llama3-70b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.00000265,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.0000035,
      "provider": "bedrock"
    },
    "slug": "meta.llama3-70b-instruct-v1-0",
    "displayName": "meta.llama3-70b-instruct-v1:0"
  },
  {
    "id": "bedrock/us-east-1/meta.llama3-8b-instruct-v1:0",
    "name": "meta.llama3-8b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "provider": "bedrock"
    },
    "slug": "meta.llama3-8b-instruct-v1-0",
    "displayName": "meta.llama3-8b-instruct-v1:0"
  },
  {
    "id": "bedrock/us-east-1/mistral.mistral-7b-instruct-v0:2",
    "name": "mistral.mistral-7b-instruct-v0:2",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 2e-7,
      "supports_tool_choice": true,
      "provider": "bedrock"
    },
    "slug": "mistral.mistral-7b-instruct-v0-2",
    "displayName": "mistral.mistral-7b-instruct-v0:2"
  },
  {
    "id": "bedrock/us-east-1/mistral.mistral-large-2402-v1:0",
    "name": "mistral.mistral-large-2402-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000008,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000024,
      "supports_function_calling": true,
      "provider": "bedrock"
    },
    "slug": "mistral.mistral-large-2402-v1-0",
    "displayName": "mistral.mistral-large-2402-v1:0"
  },
  {
    "id": "bedrock/us-east-1/mistral.mixtral-8x7b-instruct-v0:1",
    "name": "mistral.mixtral-8x7b-instruct-v0:1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 4.5e-7,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 7e-7,
      "supports_tool_choice": true,
      "provider": "bedrock"
    },
    "slug": "mistral.mixtral-8x7b-instruct-v0-1",
    "displayName": "mistral.mixtral-8x7b-instruct-v0:1"
  },
  {
    "id": "bedrock/us-gov-east-1/amazon.nova-pro-v1:0",
    "name": "amazon.nova-pro-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 9.6e-7,
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "max_tokens": 10000,
      "mode": "chat",
      "output_cost_per_token": 0.00000384,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "amazon.nova-pro-v1-0",
    "displayName": "amazon.nova-pro-v1:0"
  },
  {
    "id": "bedrock/us-gov-east-1/amazon.titan-embed-text-v1",
    "name": "amazon.titan-embed-text-v1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 8192,
      "max_tokens": 8192,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_vector_size": 1536,
      "provider": "bedrock"
    },
    "slug": "amazon.titan-embed-text-v1",
    "displayName": "amazon.titan-embed-text-v1"
  },
  {
    "id": "bedrock/us-gov-east-1/amazon.titan-embed-text-v2:0",
    "name": "amazon.titan-embed-text-v2:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 8192,
      "max_tokens": 8192,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_vector_size": 1024,
      "provider": "bedrock"
    },
    "slug": "amazon.titan-embed-text-v2-0",
    "displayName": "amazon.titan-embed-text-v2:0"
  },
  {
    "id": "bedrock/us-gov-east-1/amazon.titan-text-express-v1",
    "name": "amazon.titan-text-express-v1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.0000013,
      "max_input_tokens": 42000,
      "max_output_tokens": 8000,
      "max_tokens": 8000,
      "mode": "chat",
      "output_cost_per_token": 0.0000017,
      "provider": "bedrock"
    },
    "slug": "amazon.titan-text-express-v1",
    "displayName": "amazon.titan-text-express-v1"
  },
  {
    "id": "bedrock/us-gov-east-1/amazon.titan-text-lite-v1",
    "name": "amazon.titan-text-lite-v1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 42000,
      "max_output_tokens": 4000,
      "max_tokens": 4000,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "provider": "bedrock"
    },
    "slug": "amazon.titan-text-lite-v1",
    "displayName": "amazon.titan-text-lite-v1"
  },
  {
    "id": "bedrock/us-gov-east-1/amazon.titan-text-premier-v1:0",
    "name": "amazon.titan-text-premier-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 5e-7,
      "max_input_tokens": 42000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "provider": "bedrock"
    },
    "slug": "amazon.titan-text-premier-v1-0",
    "displayName": "amazon.titan-text-premier-v1:0"
  },
  {
    "id": "bedrock/us-gov-east-1/anthropic.claude-3-5-sonnet-20240620-v1:0",
    "name": "anthropic.claude-3-5-sonnet-20240620-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.0000036,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000018,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "anthropic.claude-3-5-sonnet-20240620-v1-0",
    "displayName": "anthropic.claude-3-5-sonnet-20240620-v1:0"
  },
  {
    "id": "bedrock/us-gov-east-1/anthropic.claude-3-haiku-20240307-v1:0",
    "name": "anthropic.claude-3-haiku-20240307-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "anthropic.claude-3-haiku-20240307-v1-0",
    "displayName": "anthropic.claude-3-haiku-20240307-v1:0"
  },
  {
    "id": "bedrock/us-gov-east-1/claude-sonnet-4-5-20250929-v1:0",
    "name": "claude-sonnet-4-5-20250929-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.0000033,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.0000165,
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "claude-sonnet-4-5-20250929-v1-0",
    "displayName": "claude-sonnet-4-5-20250929-v1:0"
  },
  {
    "id": "bedrock/us-gov-east-1/meta.llama3-70b-instruct-v1:0",
    "name": "meta.llama3-70b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.00000265,
      "max_input_tokens": 8000,
      "max_output_tokens": 2048,
      "max_tokens": 2048,
      "mode": "chat",
      "output_cost_per_token": 0.0000035,
      "supports_pdf_input": true,
      "provider": "bedrock"
    },
    "slug": "meta.llama3-70b-instruct-v1-0",
    "displayName": "meta.llama3-70b-instruct-v1:0"
  },
  {
    "id": "bedrock/us-gov-east-1/meta.llama3-8b-instruct-v1:0",
    "name": "meta.llama3-8b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 8000,
      "max_output_tokens": 2048,
      "max_tokens": 2048,
      "mode": "chat",
      "output_cost_per_token": 0.00000265,
      "supports_pdf_input": true,
      "provider": "bedrock"
    },
    "slug": "meta.llama3-8b-instruct-v1-0",
    "displayName": "meta.llama3-8b-instruct-v1:0"
  },
  {
    "id": "bedrock/us-gov-west-1/amazon.nova-pro-v1:0",
    "name": "amazon.nova-pro-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 9.6e-7,
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "max_tokens": 10000,
      "mode": "chat",
      "output_cost_per_token": 0.00000384,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "amazon.nova-pro-v1-0",
    "displayName": "amazon.nova-pro-v1:0"
  },
  {
    "id": "bedrock/us-gov-west-1/amazon.titan-embed-text-v1",
    "name": "amazon.titan-embed-text-v1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 8192,
      "max_tokens": 8192,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_vector_size": 1536,
      "provider": "bedrock"
    },
    "slug": "amazon.titan-embed-text-v1",
    "displayName": "amazon.titan-embed-text-v1"
  },
  {
    "id": "bedrock/us-gov-west-1/amazon.titan-embed-text-v2:0",
    "name": "amazon.titan-embed-text-v2:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 8192,
      "max_tokens": 8192,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_vector_size": 1024,
      "provider": "bedrock"
    },
    "slug": "amazon.titan-embed-text-v2-0",
    "displayName": "amazon.titan-embed-text-v2:0"
  },
  {
    "id": "bedrock/us-gov-west-1/amazon.titan-text-express-v1",
    "name": "amazon.titan-text-express-v1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.0000013,
      "max_input_tokens": 42000,
      "max_output_tokens": 8000,
      "max_tokens": 8000,
      "mode": "chat",
      "output_cost_per_token": 0.0000017,
      "provider": "bedrock"
    },
    "slug": "amazon.titan-text-express-v1",
    "displayName": "amazon.titan-text-express-v1"
  },
  {
    "id": "bedrock/us-gov-west-1/amazon.titan-text-lite-v1",
    "name": "amazon.titan-text-lite-v1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 42000,
      "max_output_tokens": 4000,
      "max_tokens": 4000,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "provider": "bedrock"
    },
    "slug": "amazon.titan-text-lite-v1",
    "displayName": "amazon.titan-text-lite-v1"
  },
  {
    "id": "bedrock/us-gov-west-1/amazon.titan-text-premier-v1:0",
    "name": "amazon.titan-text-premier-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 5e-7,
      "max_input_tokens": 42000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "provider": "bedrock"
    },
    "slug": "amazon.titan-text-premier-v1-0",
    "displayName": "amazon.titan-text-premier-v1:0"
  },
  {
    "id": "bedrock/us-gov-west-1/anthropic.claude-3-7-sonnet-20250219-v1:0",
    "name": "anthropic.claude-3-7-sonnet-20250219-v1:0",
    "provider": "bedrock",
    "data": {
      "cache_creation_input_token_cost": 0.0000045,
      "cache_read_input_token_cost": 3.6e-7,
      "input_cost_per_token": 0.0000036,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000018,
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "anthropic.claude-3-7-sonnet-20250219-v1-0",
    "displayName": "anthropic.claude-3-7-sonnet-20250219-v1:0"
  },
  {
    "id": "bedrock/us-gov-west-1/anthropic.claude-3-5-sonnet-20240620-v1:0",
    "name": "anthropic.claude-3-5-sonnet-20240620-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.0000036,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000018,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "anthropic.claude-3-5-sonnet-20240620-v1-0",
    "displayName": "anthropic.claude-3-5-sonnet-20240620-v1:0"
  },
  {
    "id": "bedrock/us-gov-west-1/anthropic.claude-3-haiku-20240307-v1:0",
    "name": "anthropic.claude-3-haiku-20240307-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "anthropic.claude-3-haiku-20240307-v1-0",
    "displayName": "anthropic.claude-3-haiku-20240307-v1:0"
  },
  {
    "id": "bedrock/us-gov-west-1/claude-sonnet-4-5-20250929-v1:0",
    "name": "claude-sonnet-4-5-20250929-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.0000033,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.0000165,
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "claude-sonnet-4-5-20250929-v1-0",
    "displayName": "claude-sonnet-4-5-20250929-v1:0"
  },
  {
    "id": "bedrock/us-gov-west-1/meta.llama3-70b-instruct-v1:0",
    "name": "meta.llama3-70b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.00000265,
      "max_input_tokens": 8000,
      "max_output_tokens": 2048,
      "max_tokens": 2048,
      "mode": "chat",
      "output_cost_per_token": 0.0000035,
      "supports_pdf_input": true,
      "provider": "bedrock"
    },
    "slug": "meta.llama3-70b-instruct-v1-0",
    "displayName": "meta.llama3-70b-instruct-v1:0"
  },
  {
    "id": "bedrock/us-gov-west-1/meta.llama3-8b-instruct-v1:0",
    "name": "meta.llama3-8b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 8000,
      "max_output_tokens": 2048,
      "max_tokens": 2048,
      "mode": "chat",
      "output_cost_per_token": 0.00000265,
      "supports_pdf_input": true,
      "provider": "bedrock"
    },
    "slug": "meta.llama3-8b-instruct-v1-0",
    "displayName": "meta.llama3-8b-instruct-v1:0"
  },
  {
    "id": "bedrock/us-west-1/meta.llama3-70b-instruct-v1:0",
    "name": "meta.llama3-70b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.00000265,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.0000035,
      "provider": "bedrock"
    },
    "slug": "meta.llama3-70b-instruct-v1-0",
    "displayName": "meta.llama3-70b-instruct-v1:0"
  },
  {
    "id": "bedrock/us-west-1/meta.llama3-8b-instruct-v1:0",
    "name": "meta.llama3-8b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "provider": "bedrock"
    },
    "slug": "meta.llama3-8b-instruct-v1-0",
    "displayName": "meta.llama3-8b-instruct-v1:0"
  },
  {
    "id": "bedrock/us-west-2/anthropic.claude-instant-v1",
    "name": "anthropic.claude-instant-v1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 8e-7,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.0000024,
      "supports_tool_choice": true,
      "provider": "bedrock"
    },
    "slug": "anthropic.claude-instant-v1",
    "displayName": "anthropic.claude-instant-v1"
  },
  {
    "id": "bedrock/us-west-2/anthropic.claude-v1",
    "name": "anthropic.claude-v1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000008,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000024,
      "supports_tool_choice": true,
      "provider": "bedrock"
    },
    "slug": "anthropic.claude-v1",
    "displayName": "anthropic.claude-v1"
  },
  {
    "id": "bedrock/us-west-2/anthropic.claude-v2:1",
    "name": "anthropic.claude-v2:1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000008,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000024,
      "supports_tool_choice": true,
      "provider": "bedrock"
    },
    "slug": "anthropic.claude-v2-1",
    "displayName": "anthropic.claude-v2:1"
  },
  {
    "id": "bedrock/us-west-2/mistral.mistral-7b-instruct-v0:2",
    "name": "mistral.mistral-7b-instruct-v0:2",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 2e-7,
      "supports_tool_choice": true,
      "provider": "bedrock"
    },
    "slug": "mistral.mistral-7b-instruct-v0-2",
    "displayName": "mistral.mistral-7b-instruct-v0:2"
  },
  {
    "id": "bedrock/us-west-2/mistral.mistral-large-2402-v1:0",
    "name": "mistral.mistral-large-2402-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000008,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000024,
      "supports_function_calling": true,
      "provider": "bedrock"
    },
    "slug": "mistral.mistral-large-2402-v1-0",
    "displayName": "mistral.mistral-large-2402-v1:0"
  },
  {
    "id": "bedrock/us-west-2/mistral.mixtral-8x7b-instruct-v0:1",
    "name": "mistral.mixtral-8x7b-instruct-v0:1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 4.5e-7,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 7e-7,
      "supports_tool_choice": true,
      "provider": "bedrock"
    },
    "slug": "mistral.mixtral-8x7b-instruct-v0-1",
    "displayName": "mistral.mixtral-8x7b-instruct-v0:1"
  },
  {
    "id": "bedrock/us.anthropic.claude-3-5-haiku-20241022-v1:0",
    "name": "us.anthropic.claude-3-5-haiku-20241022-v1:0",
    "provider": "bedrock",
    "data": {
      "cache_creation_input_token_cost": 0.000001,
      "cache_read_input_token_cost": 8e-8,
      "input_cost_per_token": 8e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000004,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "bedrock"
    },
    "slug": "us.anthropic.claude-3-5-haiku-20241022-v1-0",
    "displayName": "us.anthropic.claude-3-5-haiku-20241022-v1:0"
  },
  {
    "id": "cerebras/llama-3.3-70b",
    "name": "llama-3.3-70b",
    "provider": "cerebras",
    "data": {
      "input_cost_per_token": 8.5e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.0000012,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "cerebras"
    },
    "slug": "llama-3.3-70b",
    "displayName": "llama-3.3-70b"
  },
  {
    "id": "cerebras/llama3.1-70b",
    "name": "llama3.1-70b",
    "provider": "cerebras",
    "data": {
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "cerebras"
    },
    "slug": "llama3.1-70b",
    "displayName": "llama3.1-70b"
  },
  {
    "id": "cerebras/llama3.1-8b",
    "name": "llama3.1-8b",
    "provider": "cerebras",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 1e-7,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "cerebras"
    },
    "slug": "llama3.1-8b",
    "displayName": "llama3.1-8b"
  },
  {
    "id": "cerebras/gpt-oss-120b",
    "name": "gpt-oss-120b",
    "provider": "cerebras",
    "data": {
      "input_cost_per_token": 3.5e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 7.5e-7,
      "source": "https://www.cerebras.ai/blog/openai-gpt-oss-120b-runs-fastest-on-cerebras",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "cerebras"
    },
    "slug": "gpt-oss-120b",
    "displayName": "gpt-oss-120b"
  },
  {
    "id": "cerebras/qwen-3-32b",
    "name": "qwen-3-32b",
    "provider": "cerebras",
    "data": {
      "input_cost_per_token": 4e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 8e-7,
      "source": "https://inference-docs.cerebras.ai/support/pricing",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "cerebras"
    },
    "slug": "qwen-3-32b",
    "displayName": "qwen-3-32b"
  },
  {
    "id": "cerebras/zai-glm-4.6",
    "name": "zai-glm-4.6",
    "provider": "cerebras",
    "data": {
      "deprecation_date": "2026-01-20",
      "input_cost_per_token": 0.00000225,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.00000275,
      "source": "https://www.cerebras.ai/pricing",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "cerebras"
    },
    "slug": "zai-glm-4.6",
    "displayName": "zai-glm-4.6"
  },
  {
    "id": "cerebras/zai-glm-4.7",
    "name": "zai-glm-4.7",
    "provider": "cerebras",
    "data": {
      "input_cost_per_token": 0.00000225,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.00000275,
      "source": "https://www.cerebras.ai/pricing",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "cerebras"
    },
    "slug": "zai-glm-4.7",
    "displayName": "zai-glm-4.7"
  },
  {
    "id": "chat-bison",
    "name": "chat-bison",
    "provider": "vertex_ai-chat-models",
    "data": {
      "input_cost_per_character": 2.5e-7,
      "input_cost_per_token": 1.25e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_character": 5e-7,
      "output_cost_per_token": 1.25e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_tool_choice": true,
      "provider": "vertex_ai-chat-models"
    },
    "slug": "chat-bison",
    "displayName": "chat-bison"
  },
  {
    "id": "chat-bison-32k",
    "name": "chat-bison-32k",
    "provider": "vertex_ai-chat-models",
    "data": {
      "input_cost_per_character": 2.5e-7,
      "input_cost_per_token": 1.25e-7,
      "max_input_tokens": 32000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_character": 5e-7,
      "output_cost_per_token": 1.25e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_tool_choice": true,
      "provider": "vertex_ai-chat-models"
    },
    "slug": "chat-bison-32k",
    "displayName": "chat-bison-32k"
  },
  {
    "id": "chat-bison-32k@002",
    "name": "chat-bison-32k@002",
    "provider": "vertex_ai-chat-models",
    "data": {
      "input_cost_per_character": 2.5e-7,
      "input_cost_per_token": 1.25e-7,
      "max_input_tokens": 32000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_character": 5e-7,
      "output_cost_per_token": 1.25e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_tool_choice": true,
      "provider": "vertex_ai-chat-models"
    },
    "slug": "chat-bison-32k-002",
    "displayName": "chat-bison-32k@002"
  },
  {
    "id": "chat-bison@001",
    "name": "chat-bison@001",
    "provider": "vertex_ai-chat-models",
    "data": {
      "input_cost_per_character": 2.5e-7,
      "input_cost_per_token": 1.25e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_character": 5e-7,
      "output_cost_per_token": 1.25e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_tool_choice": true,
      "provider": "vertex_ai-chat-models"
    },
    "slug": "chat-bison-001",
    "displayName": "chat-bison@001"
  },
  {
    "id": "chat-bison@002",
    "name": "chat-bison@002",
    "provider": "vertex_ai-chat-models",
    "data": {
      "deprecation_date": "2025-04-09",
      "input_cost_per_character": 2.5e-7,
      "input_cost_per_token": 1.25e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_character": 5e-7,
      "output_cost_per_token": 1.25e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_tool_choice": true,
      "provider": "vertex_ai-chat-models"
    },
    "slug": "chat-bison-002",
    "displayName": "chat-bison@002"
  },
  {
    "id": "chatdolphin",
    "name": "chatdolphin",
    "provider": "nlp_cloud",
    "data": {
      "input_cost_per_token": 5e-7,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 5e-7,
      "provider": "nlp_cloud"
    },
    "slug": "chatdolphin",
    "displayName": "chatdolphin"
  },
  {
    "id": "chatgpt-4o-latest",
    "name": "chatgpt-4o-latest",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 0.000005,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "chatgpt-4o-latest",
    "displayName": "chatgpt-4o-latest"
  },
  {
    "id": "gpt-4o-transcribe-diarize",
    "name": "gpt-4o-transcribe-diarize",
    "provider": "openai",
    "data": {
      "input_cost_per_audio_token": 0.000006,
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 16000,
      "max_output_tokens": 2000,
      "mode": "audio_transcription",
      "output_cost_per_token": 0.00001,
      "supported_endpoints": [
        "/v1/audio/transcriptions"
      ],
      "provider": "openai"
    },
    "slug": "gpt-4o-transcribe-diarize",
    "displayName": "gpt-4o-transcribe-diarize"
  },
  {
    "id": "claude-3-5-haiku-20241022",
    "name": "claude-3-5-haiku-20241022",
    "provider": "anthropic",
    "data": {
      "cache_creation_input_token_cost": 0.000001,
      "cache_creation_input_token_cost_above_1hr": 0.000006,
      "cache_read_input_token_cost": 8e-8,
      "deprecation_date": "2025-10-01",
      "input_cost_per_token": 8e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000004,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tool_use_system_prompt_tokens": 264,
      "provider": "anthropic"
    },
    "slug": "claude-3-5-haiku-20241022",
    "displayName": "claude-3-5-haiku-20241022"
  },
  {
    "id": "claude-3-5-haiku-latest",
    "name": "claude-3-5-haiku-latest",
    "provider": "anthropic",
    "data": {
      "cache_creation_input_token_cost": 0.00000125,
      "cache_creation_input_token_cost_above_1hr": 0.000006,
      "cache_read_input_token_cost": 1e-7,
      "deprecation_date": "2025-10-01",
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000005,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tool_use_system_prompt_tokens": 264,
      "provider": "anthropic"
    },
    "slug": "claude-3-5-haiku-latest",
    "displayName": "claude-3-5-haiku-latest"
  },
  {
    "id": "claude-haiku-4-5-20251001",
    "name": "claude-haiku-4-5-20251001",
    "provider": "anthropic",
    "data": {
      "cache_creation_input_token_cost": 0.00000125,
      "cache_creation_input_token_cost_above_1hr": 0.000002,
      "cache_read_input_token_cost": 1e-7,
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000005,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_computer_use": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "anthropic"
    },
    "slug": "claude-haiku-4-5-20251001",
    "displayName": "claude-haiku-4-5-20251001"
  },
  {
    "id": "claude-haiku-4-5",
    "name": "claude-haiku-4-5",
    "provider": "anthropic",
    "data": {
      "cache_creation_input_token_cost": 0.00000125,
      "cache_creation_input_token_cost_above_1hr": 0.000002,
      "cache_read_input_token_cost": 1e-7,
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000005,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_computer_use": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "anthropic"
    },
    "slug": "claude-haiku-4-5",
    "displayName": "claude-haiku-4-5"
  },
  {
    "id": "claude-3-5-sonnet-20240620",
    "name": "claude-3-5-sonnet-20240620",
    "provider": "anthropic",
    "data": {
      "cache_creation_input_token_cost": 0.00000375,
      "cache_creation_input_token_cost_above_1hr": 0.000006,
      "cache_read_input_token_cost": 3e-7,
      "deprecation_date": "2025-06-01",
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "anthropic"
    },
    "slug": "claude-3-5-sonnet-20240620",
    "displayName": "claude-3-5-sonnet-20240620"
  },
  {
    "id": "claude-3-5-sonnet-20241022",
    "name": "claude-3-5-sonnet-20241022",
    "provider": "anthropic",
    "data": {
      "cache_creation_input_token_cost": 0.00000375,
      "cache_creation_input_token_cost_above_1hr": 0.000006,
      "cache_read_input_token_cost": 3e-7,
      "deprecation_date": "2025-10-01",
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "anthropic"
    },
    "slug": "claude-3-5-sonnet-20241022",
    "displayName": "claude-3-5-sonnet-20241022"
  },
  {
    "id": "claude-3-5-sonnet-latest",
    "name": "claude-3-5-sonnet-latest",
    "provider": "anthropic",
    "data": {
      "cache_creation_input_token_cost": 0.00000375,
      "cache_creation_input_token_cost_above_1hr": 0.000006,
      "cache_read_input_token_cost": 3e-7,
      "deprecation_date": "2025-06-01",
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "anthropic"
    },
    "slug": "claude-3-5-sonnet-latest",
    "displayName": "claude-3-5-sonnet-latest"
  },
  {
    "id": "claude-3-7-sonnet-20250219",
    "name": "claude-3-7-sonnet-20250219",
    "provider": "anthropic",
    "data": {
      "cache_creation_input_token_cost": 0.00000375,
      "cache_creation_input_token_cost_above_1hr": 0.000006,
      "cache_read_input_token_cost": 3e-7,
      "deprecation_date": "2026-02-19",
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "anthropic"
    },
    "slug": "claude-3-7-sonnet-20250219",
    "displayName": "claude-3-7-sonnet-20250219"
  },
  {
    "id": "claude-3-7-sonnet-latest",
    "name": "claude-3-7-sonnet-latest",
    "provider": "anthropic",
    "data": {
      "cache_creation_input_token_cost": 0.00000375,
      "cache_creation_input_token_cost_above_1hr": 0.000006,
      "cache_read_input_token_cost": 3e-7,
      "deprecation_date": "2025-06-01",
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "anthropic"
    },
    "slug": "claude-3-7-sonnet-latest",
    "displayName": "claude-3-7-sonnet-latest"
  },
  {
    "id": "claude-3-haiku-20240307",
    "name": "claude-3-haiku-20240307",
    "provider": "anthropic",
    "data": {
      "cache_creation_input_token_cost": 3e-7,
      "cache_creation_input_token_cost_above_1hr": 0.000006,
      "cache_read_input_token_cost": 3e-8,
      "input_cost_per_token": 2.5e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00000125,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 264,
      "provider": "anthropic"
    },
    "slug": "claude-3-haiku-20240307",
    "displayName": "claude-3-haiku-20240307"
  },
  {
    "id": "claude-3-opus-20240229",
    "name": "claude-3-opus-20240229",
    "provider": "anthropic",
    "data": {
      "cache_creation_input_token_cost": 0.00001875,
      "cache_creation_input_token_cost_above_1hr": 0.000006,
      "cache_read_input_token_cost": 0.0000015,
      "deprecation_date": "2026-05-01",
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000075,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 395,
      "provider": "anthropic"
    },
    "slug": "claude-3-opus-20240229",
    "displayName": "claude-3-opus-20240229"
  },
  {
    "id": "claude-3-opus-latest",
    "name": "claude-3-opus-latest",
    "provider": "anthropic",
    "data": {
      "cache_creation_input_token_cost": 0.00001875,
      "cache_creation_input_token_cost_above_1hr": 0.000006,
      "cache_read_input_token_cost": 0.0000015,
      "deprecation_date": "2025-03-01",
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000075,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 395,
      "provider": "anthropic"
    },
    "slug": "claude-3-opus-latest",
    "displayName": "claude-3-opus-latest"
  },
  {
    "id": "claude-4-opus-20250514",
    "name": "claude-4-opus-20250514",
    "provider": "anthropic",
    "data": {
      "cache_creation_input_token_cost": 0.00001875,
      "cache_read_input_token_cost": 0.0000015,
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.000075,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "anthropic"
    },
    "slug": "claude-4-opus-20250514",
    "displayName": "claude-4-opus-20250514"
  },
  {
    "id": "claude-4-sonnet-20250514",
    "name": "claude-4-sonnet-20250514",
    "provider": "anthropic",
    "data": {
      "cache_creation_input_token_cost": 0.00000375,
      "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
      "cache_read_input_token_cost": 3e-7,
      "cache_read_input_token_cost_above_200k_tokens": 6e-7,
      "input_cost_per_token": 0.000003,
      "input_cost_per_token_above_200k_tokens": 0.000006,
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "output_cost_per_token_above_200k_tokens": 0.0000225,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "anthropic"
    },
    "slug": "claude-4-sonnet-20250514",
    "displayName": "claude-4-sonnet-20250514"
  },
  {
    "id": "claude-sonnet-4-5",
    "name": "claude-sonnet-4-5",
    "provider": "anthropic",
    "data": {
      "cache_creation_input_token_cost": 0.00000375,
      "cache_read_input_token_cost": 3e-7,
      "input_cost_per_token": 0.000003,
      "input_cost_per_token_above_200k_tokens": 0.000006,
      "output_cost_per_token_above_200k_tokens": 0.0000225,
      "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
      "cache_read_input_token_cost_above_200k_tokens": 6e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 346,
      "provider": "anthropic"
    },
    "slug": "claude-sonnet-4-5",
    "displayName": "claude-sonnet-4-5"
  },
  {
    "id": "claude-sonnet-4-5-20250929",
    "name": "claude-sonnet-4-5-20250929",
    "provider": "anthropic",
    "data": {
      "cache_creation_input_token_cost": 0.00000375,
      "cache_read_input_token_cost": 3e-7,
      "input_cost_per_token": 0.000003,
      "input_cost_per_token_above_200k_tokens": 0.000006,
      "output_cost_per_token_above_200k_tokens": 0.0000225,
      "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
      "cache_read_input_token_cost_above_200k_tokens": 6e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tool_use_system_prompt_tokens": 346,
      "provider": "anthropic"
    },
    "slug": "claude-sonnet-4-5-20250929",
    "displayName": "claude-sonnet-4-5-20250929"
  },
  {
    "id": "claude-sonnet-4-5-20250929-v1:0",
    "name": "claude-sonnet-4-5-20250929-v1:0",
    "provider": "bedrock",
    "data": {
      "cache_creation_input_token_cost": 0.00000375,
      "cache_read_input_token_cost": 3e-7,
      "input_cost_per_token": 0.000003,
      "input_cost_per_token_above_200k_tokens": 0.000006,
      "output_cost_per_token_above_200k_tokens": 0.0000225,
      "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
      "cache_read_input_token_cost_above_200k_tokens": 6e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "bedrock"
    },
    "slug": "claude-sonnet-4-5-20250929-v1-0",
    "displayName": "claude-sonnet-4-5-20250929-v1:0"
  },
  {
    "id": "claude-opus-4-1",
    "name": "claude-opus-4-1",
    "provider": "anthropic",
    "data": {
      "cache_creation_input_token_cost": 0.00001875,
      "cache_creation_input_token_cost_above_1hr": 0.00003,
      "cache_read_input_token_cost": 0.0000015,
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.000075,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "anthropic"
    },
    "slug": "claude-opus-4-1",
    "displayName": "claude-opus-4-1"
  },
  {
    "id": "claude-opus-4-1-20250805",
    "name": "claude-opus-4-1-20250805",
    "provider": "anthropic",
    "data": {
      "cache_creation_input_token_cost": 0.00001875,
      "cache_creation_input_token_cost_above_1hr": 0.00003,
      "cache_read_input_token_cost": 0.0000015,
      "input_cost_per_token": 0.000015,
      "deprecation_date": "2026-08-05",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.000075,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "anthropic"
    },
    "slug": "claude-opus-4-1-20250805",
    "displayName": "claude-opus-4-1-20250805"
  },
  {
    "id": "claude-opus-4-20250514",
    "name": "claude-opus-4-20250514",
    "provider": "anthropic",
    "data": {
      "cache_creation_input_token_cost": 0.00001875,
      "cache_creation_input_token_cost_above_1hr": 0.00003,
      "cache_read_input_token_cost": 0.0000015,
      "input_cost_per_token": 0.000015,
      "deprecation_date": "2026-05-14",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.000075,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "anthropic"
    },
    "slug": "claude-opus-4-20250514",
    "displayName": "claude-opus-4-20250514"
  },
  {
    "id": "claude-opus-4-5-20251101",
    "name": "claude-opus-4-5-20251101",
    "provider": "anthropic",
    "data": {
      "cache_creation_input_token_cost": 0.00000625,
      "cache_creation_input_token_cost_above_1hr": 0.00001,
      "cache_read_input_token_cost": 5e-7,
      "input_cost_per_token": 0.000005,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000025,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "anthropic"
    },
    "slug": "claude-opus-4-5-20251101",
    "displayName": "claude-opus-4-5-20251101"
  },
  {
    "id": "claude-opus-4-5",
    "name": "claude-opus-4-5",
    "provider": "anthropic",
    "data": {
      "cache_creation_input_token_cost": 0.00000625,
      "cache_creation_input_token_cost_above_1hr": 0.00001,
      "cache_read_input_token_cost": 5e-7,
      "input_cost_per_token": 0.000005,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000025,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "anthropic"
    },
    "slug": "claude-opus-4-5",
    "displayName": "claude-opus-4-5"
  },
  {
    "id": "claude-sonnet-4-20250514",
    "name": "claude-sonnet-4-20250514",
    "provider": "anthropic",
    "data": {
      "deprecation_date": "2026-05-14",
      "cache_creation_input_token_cost": 0.00000375,
      "cache_creation_input_token_cost_above_1hr": 0.000006,
      "cache_read_input_token_cost": 3e-7,
      "input_cost_per_token": 0.000003,
      "input_cost_per_token_above_200k_tokens": 0.000006,
      "output_cost_per_token_above_200k_tokens": 0.0000225,
      "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
      "cache_read_input_token_cost_above_200k_tokens": 6e-7,
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "anthropic"
    },
    "slug": "claude-sonnet-4-20250514",
    "displayName": "claude-sonnet-4-20250514"
  },
  {
    "id": "cloudflare/@cf/meta/llama-2-7b-chat-fp16",
    "name": "llama-2-7b-chat-fp16",
    "provider": "cloudflare",
    "data": {
      "input_cost_per_token": 0.000001923,
      "max_input_tokens": 3072,
      "max_output_tokens": 3072,
      "max_tokens": 3072,
      "mode": "chat",
      "output_cost_per_token": 0.000001923,
      "provider": "cloudflare"
    },
    "slug": "llama-2-7b-chat-fp16",
    "displayName": "llama-2-7b-chat-fp16"
  },
  {
    "id": "cloudflare/@cf/meta/llama-2-7b-chat-int8",
    "name": "llama-2-7b-chat-int8",
    "provider": "cloudflare",
    "data": {
      "input_cost_per_token": 0.000001923,
      "max_input_tokens": 2048,
      "max_output_tokens": 2048,
      "max_tokens": 2048,
      "mode": "chat",
      "output_cost_per_token": 0.000001923,
      "provider": "cloudflare"
    },
    "slug": "llama-2-7b-chat-int8",
    "displayName": "llama-2-7b-chat-int8"
  },
  {
    "id": "cloudflare/@cf/mistral/mistral-7b-instruct-v0.1",
    "name": "mistral-7b-instruct-v0.1",
    "provider": "cloudflare",
    "data": {
      "input_cost_per_token": 0.000001923,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000001923,
      "provider": "cloudflare"
    },
    "slug": "mistral-7b-instruct-v0.1",
    "displayName": "mistral-7b-instruct-v0.1"
  },
  {
    "id": "cloudflare/@hf/thebloke/codellama-7b-instruct-awq",
    "name": "codellama-7b-instruct-awq",
    "provider": "cloudflare",
    "data": {
      "input_cost_per_token": 0.000001923,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000001923,
      "provider": "cloudflare"
    },
    "slug": "codellama-7b-instruct-awq",
    "displayName": "codellama-7b-instruct-awq"
  },
  {
    "id": "code-bison",
    "name": "code-bison",
    "provider": "vertex_ai-code-text-models",
    "data": {
      "input_cost_per_character": 2.5e-7,
      "input_cost_per_token": 1.25e-7,
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "max_tokens": 1024,
      "mode": "chat",
      "output_cost_per_character": 5e-7,
      "output_cost_per_token": 1.25e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_tool_choice": true,
      "provider": "vertex_ai-code-text-models"
    },
    "slug": "code-bison",
    "displayName": "code-bison"
  },
  {
    "id": "code-bison-32k@002",
    "name": "code-bison-32k@002",
    "provider": "vertex_ai-code-text-models",
    "data": {
      "input_cost_per_character": 2.5e-7,
      "input_cost_per_token": 1.25e-7,
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "max_tokens": 1024,
      "mode": "completion",
      "output_cost_per_character": 5e-7,
      "output_cost_per_token": 1.25e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-code-text-models"
    },
    "slug": "code-bison-32k-002",
    "displayName": "code-bison-32k@002"
  },
  {
    "id": "code-bison32k",
    "name": "code-bison32k",
    "provider": "vertex_ai-code-text-models",
    "data": {
      "input_cost_per_character": 2.5e-7,
      "input_cost_per_token": 1.25e-7,
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "max_tokens": 1024,
      "mode": "completion",
      "output_cost_per_character": 5e-7,
      "output_cost_per_token": 1.25e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-code-text-models"
    },
    "slug": "code-bison32k",
    "displayName": "code-bison32k"
  },
  {
    "id": "code-bison@001",
    "name": "code-bison@001",
    "provider": "vertex_ai-code-text-models",
    "data": {
      "input_cost_per_character": 2.5e-7,
      "input_cost_per_token": 1.25e-7,
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "max_tokens": 1024,
      "mode": "completion",
      "output_cost_per_character": 5e-7,
      "output_cost_per_token": 1.25e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-code-text-models"
    },
    "slug": "code-bison-001",
    "displayName": "code-bison@001"
  },
  {
    "id": "code-bison@002",
    "name": "code-bison@002",
    "provider": "vertex_ai-code-text-models",
    "data": {
      "input_cost_per_character": 2.5e-7,
      "input_cost_per_token": 1.25e-7,
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "max_tokens": 1024,
      "mode": "completion",
      "output_cost_per_character": 5e-7,
      "output_cost_per_token": 1.25e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-code-text-models"
    },
    "slug": "code-bison-002",
    "displayName": "code-bison@002"
  },
  {
    "id": "code-gecko",
    "name": "code-gecko",
    "provider": "vertex_ai-code-text-models",
    "data": {
      "input_cost_per_token": 1.25e-7,
      "max_input_tokens": 2048,
      "max_output_tokens": 64,
      "max_tokens": 64,
      "mode": "completion",
      "output_cost_per_token": 1.25e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-code-text-models"
    },
    "slug": "code-gecko",
    "displayName": "code-gecko"
  },
  {
    "id": "code-gecko-latest",
    "name": "code-gecko-latest",
    "provider": "vertex_ai-code-text-models",
    "data": {
      "input_cost_per_token": 1.25e-7,
      "max_input_tokens": 2048,
      "max_output_tokens": 64,
      "max_tokens": 64,
      "mode": "completion",
      "output_cost_per_token": 1.25e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-code-text-models"
    },
    "slug": "code-gecko-latest",
    "displayName": "code-gecko-latest"
  },
  {
    "id": "code-gecko@001",
    "name": "code-gecko@001",
    "provider": "vertex_ai-code-text-models",
    "data": {
      "input_cost_per_token": 1.25e-7,
      "max_input_tokens": 2048,
      "max_output_tokens": 64,
      "max_tokens": 64,
      "mode": "completion",
      "output_cost_per_token": 1.25e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-code-text-models"
    },
    "slug": "code-gecko-001",
    "displayName": "code-gecko@001"
  },
  {
    "id": "code-gecko@002",
    "name": "code-gecko@002",
    "provider": "vertex_ai-code-text-models",
    "data": {
      "input_cost_per_token": 1.25e-7,
      "max_input_tokens": 2048,
      "max_output_tokens": 64,
      "max_tokens": 64,
      "mode": "completion",
      "output_cost_per_token": 1.25e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-code-text-models"
    },
    "slug": "code-gecko-002",
    "displayName": "code-gecko@002"
  },
  {
    "id": "codechat-bison",
    "name": "codechat-bison",
    "provider": "vertex_ai-code-chat-models",
    "data": {
      "input_cost_per_character": 2.5e-7,
      "input_cost_per_token": 1.25e-7,
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "max_tokens": 1024,
      "mode": "chat",
      "output_cost_per_character": 5e-7,
      "output_cost_per_token": 1.25e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_tool_choice": true,
      "provider": "vertex_ai-code-chat-models"
    },
    "slug": "codechat-bison",
    "displayName": "codechat-bison"
  },
  {
    "id": "codechat-bison-32k",
    "name": "codechat-bison-32k",
    "provider": "vertex_ai-code-chat-models",
    "data": {
      "input_cost_per_character": 2.5e-7,
      "input_cost_per_token": 1.25e-7,
      "max_input_tokens": 32000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_character": 5e-7,
      "output_cost_per_token": 1.25e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_tool_choice": true,
      "provider": "vertex_ai-code-chat-models"
    },
    "slug": "codechat-bison-32k",
    "displayName": "codechat-bison-32k"
  },
  {
    "id": "codechat-bison-32k@002",
    "name": "codechat-bison-32k@002",
    "provider": "vertex_ai-code-chat-models",
    "data": {
      "input_cost_per_character": 2.5e-7,
      "input_cost_per_token": 1.25e-7,
      "max_input_tokens": 32000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_character": 5e-7,
      "output_cost_per_token": 1.25e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_tool_choice": true,
      "provider": "vertex_ai-code-chat-models"
    },
    "slug": "codechat-bison-32k-002",
    "displayName": "codechat-bison-32k@002"
  },
  {
    "id": "codechat-bison@001",
    "name": "codechat-bison@001",
    "provider": "vertex_ai-code-chat-models",
    "data": {
      "input_cost_per_character": 2.5e-7,
      "input_cost_per_token": 1.25e-7,
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "max_tokens": 1024,
      "mode": "chat",
      "output_cost_per_character": 5e-7,
      "output_cost_per_token": 1.25e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_tool_choice": true,
      "provider": "vertex_ai-code-chat-models"
    },
    "slug": "codechat-bison-001",
    "displayName": "codechat-bison@001"
  },
  {
    "id": "codechat-bison@002",
    "name": "codechat-bison@002",
    "provider": "vertex_ai-code-chat-models",
    "data": {
      "input_cost_per_character": 2.5e-7,
      "input_cost_per_token": 1.25e-7,
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "max_tokens": 1024,
      "mode": "chat",
      "output_cost_per_character": 5e-7,
      "output_cost_per_token": 1.25e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_tool_choice": true,
      "provider": "vertex_ai-code-chat-models"
    },
    "slug": "codechat-bison-002",
    "displayName": "codechat-bison@002"
  },
  {
    "id": "codechat-bison@latest",
    "name": "codechat-bison@latest",
    "provider": "vertex_ai-code-chat-models",
    "data": {
      "input_cost_per_character": 2.5e-7,
      "input_cost_per_token": 1.25e-7,
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "max_tokens": 1024,
      "mode": "chat",
      "output_cost_per_character": 5e-7,
      "output_cost_per_token": 1.25e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_tool_choice": true,
      "provider": "vertex_ai-code-chat-models"
    },
    "slug": "codechat-bison-latest",
    "displayName": "codechat-bison@latest"
  },
  {
    "id": "codex-mini-latest",
    "name": "codex-mini-latest",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 3.75e-7,
      "input_cost_per_token": 0.0000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "responses",
      "output_cost_per_token": 0.000006,
      "supported_endpoints": [
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "codex-mini-latest",
    "displayName": "codex-mini-latest"
  },
  {
    "id": "cohere.command-light-text-v14",
    "name": "cohere.command-light-text-v14",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "supports_tool_choice": true,
      "provider": "bedrock"
    },
    "slug": "cohere.command-light-text-v14",
    "displayName": "cohere.command-light-text-v14"
  },
  {
    "id": "cohere.command-r-plus-v1:0",
    "name": "cohere.command-r-plus-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_tool_choice": true,
      "provider": "bedrock"
    },
    "slug": "cohere.command-r-plus-v1-0",
    "displayName": "cohere.command-r-plus-v1:0"
  },
  {
    "id": "cohere.command-r-v1:0",
    "name": "cohere.command-r-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 5e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "supports_tool_choice": true,
      "provider": "bedrock"
    },
    "slug": "cohere.command-r-v1-0",
    "displayName": "cohere.command-r-v1:0"
  },
  {
    "id": "cohere.command-text-v14",
    "name": "cohere.command-text-v14",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.0000015,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "supports_tool_choice": true,
      "provider": "bedrock"
    },
    "slug": "cohere.command-text-v14",
    "displayName": "cohere.command-text-v14"
  },
  {
    "id": "cohere.embed-english-v3",
    "name": "cohere.embed-english-v3",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 512,
      "max_tokens": 512,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "supports_embedding_image_input": true,
      "provider": "bedrock"
    },
    "slug": "cohere.embed-english-v3",
    "displayName": "cohere.embed-english-v3"
  },
  {
    "id": "cohere.embed-multilingual-v3",
    "name": "cohere.embed-multilingual-v3",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 512,
      "max_tokens": 512,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "supports_embedding_image_input": true,
      "provider": "bedrock"
    },
    "slug": "cohere.embed-multilingual-v3",
    "displayName": "cohere.embed-multilingual-v3"
  },
  {
    "id": "cohere.embed-v4:0",
    "name": "cohere.embed-v4:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 1.2e-7,
      "max_input_tokens": 128000,
      "max_tokens": 128000,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_vector_size": 1536,
      "supports_embedding_image_input": true,
      "provider": "bedrock"
    },
    "slug": "cohere.embed-v4-0",
    "displayName": "cohere.embed-v4:0"
  },
  {
    "id": "cohere/embed-v4.0",
    "name": "embed-v4.0",
    "provider": "cohere",
    "data": {
      "input_cost_per_token": 1.2e-7,
      "max_input_tokens": 128000,
      "max_tokens": 128000,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_vector_size": 1536,
      "supports_embedding_image_input": true,
      "provider": "cohere"
    },
    "slug": "embed-v4.0",
    "displayName": "embed-v4.0"
  },
  {
    "id": "command",
    "name": "command",
    "provider": "cohere",
    "data": {
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "completion",
      "output_cost_per_token": 0.000002,
      "provider": "cohere"
    },
    "slug": "command",
    "displayName": "command"
  },
  {
    "id": "command-a-03-2025",
    "name": "command-a-03-2025",
    "provider": "cohere_chat",
    "data": {
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 256000,
      "max_output_tokens": 8000,
      "max_tokens": 8000,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "cohere_chat"
    },
    "slug": "command-a-03-2025",
    "displayName": "command-a-03-2025"
  },
  {
    "id": "command-light",
    "name": "command-light",
    "provider": "cohere_chat",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "supports_tool_choice": true,
      "provider": "cohere_chat"
    },
    "slug": "command-light",
    "displayName": "command-light"
  },
  {
    "id": "command-nightly",
    "name": "command-nightly",
    "provider": "cohere",
    "data": {
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "completion",
      "output_cost_per_token": 0.000002,
      "provider": "cohere"
    },
    "slug": "command-nightly",
    "displayName": "command-nightly"
  },
  {
    "id": "command-r",
    "name": "command-r",
    "provider": "cohere_chat",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "cohere_chat"
    },
    "slug": "command-r",
    "displayName": "command-r"
  },
  {
    "id": "command-r-08-2024",
    "name": "command-r-08-2024",
    "provider": "cohere_chat",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "cohere_chat"
    },
    "slug": "command-r-08-2024",
    "displayName": "command-r-08-2024"
  },
  {
    "id": "command-r-plus",
    "name": "command-r-plus",
    "provider": "cohere_chat",
    "data": {
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "cohere_chat"
    },
    "slug": "command-r-plus",
    "displayName": "command-r-plus"
  },
  {
    "id": "command-r-plus-08-2024",
    "name": "command-r-plus-08-2024",
    "provider": "cohere_chat",
    "data": {
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "cohere_chat"
    },
    "slug": "command-r-plus-08-2024",
    "displayName": "command-r-plus-08-2024"
  },
  {
    "id": "command-r7b-12-2024",
    "name": "command-r7b-12-2024",
    "provider": "cohere_chat",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 3.75e-8,
      "source": "https://docs.cohere.com/v2/docs/command-r7b",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "cohere_chat"
    },
    "slug": "command-r7b-12-2024",
    "displayName": "command-r7b-12-2024"
  },
  {
    "id": "computer-use-preview",
    "name": "computer-use-preview",
    "provider": "azure",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "max_tokens": 1024,
      "mode": "chat",
      "output_cost_per_token": 0.000012,
      "supported_endpoints": [
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": false,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "azure"
    },
    "slug": "computer-use-preview",
    "displayName": "computer-use-preview"
  },
  {
    "id": "deepseek-chat",
    "name": "deepseek-chat",
    "provider": "deepseek",
    "data": {
      "cache_read_input_token_cost": 2.8e-8,
      "input_cost_per_token": 2.8e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 4.2e-7,
      "source": "https://api-docs.deepseek.com/quick_start/pricing",
      "supported_endpoints": [
        "/v1/chat/completions"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "deepseek"
    },
    "slug": "deepseek-chat",
    "displayName": "deepseek-chat"
  },
  {
    "id": "deepseek-reasoner",
    "name": "deepseek-reasoner",
    "provider": "deepseek",
    "data": {
      "cache_read_input_token_cost": 2.8e-8,
      "input_cost_per_token": 2.8e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 65536,
      "max_tokens": 65536,
      "mode": "chat",
      "output_cost_per_token": 4.2e-7,
      "source": "https://api-docs.deepseek.com/quick_start/pricing",
      "supported_endpoints": [
        "/v1/chat/completions"
      ],
      "supports_function_calling": false,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": false,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": false,
      "provider": "deepseek"
    },
    "slug": "deepseek-reasoner",
    "displayName": "deepseek-reasoner"
  },
  {
    "id": "dashscope/qwen-coder",
    "name": "qwen-coder",
    "provider": "dashscope",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 1000000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "source": "https://www.alibabacloud.com/help/en/model-studio/models",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "dashscope"
    },
    "slug": "qwen-coder",
    "displayName": "qwen-coder"
  },
  {
    "id": "dashscope/qwen-max",
    "name": "qwen-max",
    "provider": "dashscope",
    "data": {
      "input_cost_per_token": 0.0000016,
      "max_input_tokens": 30720,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.0000064,
      "source": "https://www.alibabacloud.com/help/en/model-studio/models",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "dashscope"
    },
    "slug": "qwen-max",
    "displayName": "qwen-max"
  },
  {
    "id": "dashscope/qwen-plus",
    "name": "qwen-plus",
    "provider": "dashscope",
    "data": {
      "input_cost_per_token": 4e-7,
      "max_input_tokens": 129024,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.0000012,
      "source": "https://www.alibabacloud.com/help/en/model-studio/models",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "dashscope"
    },
    "slug": "qwen-plus",
    "displayName": "qwen-plus"
  },
  {
    "id": "dashscope/qwen-plus-2025-01-25",
    "name": "qwen-plus-2025-01-25",
    "provider": "dashscope",
    "data": {
      "input_cost_per_token": 4e-7,
      "max_input_tokens": 129024,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.0000012,
      "source": "https://www.alibabacloud.com/help/en/model-studio/models",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "dashscope"
    },
    "slug": "qwen-plus-2025-01-25",
    "displayName": "qwen-plus-2025-01-25"
  },
  {
    "id": "dashscope/qwen-plus-2025-04-28",
    "name": "qwen-plus-2025-04-28",
    "provider": "dashscope",
    "data": {
      "input_cost_per_token": 4e-7,
      "max_input_tokens": 129024,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_reasoning_token": 0.000004,
      "output_cost_per_token": 0.0000012,
      "source": "https://www.alibabacloud.com/help/en/model-studio/models",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "dashscope"
    },
    "slug": "qwen-plus-2025-04-28",
    "displayName": "qwen-plus-2025-04-28"
  },
  {
    "id": "dashscope/qwen-plus-2025-07-14",
    "name": "qwen-plus-2025-07-14",
    "provider": "dashscope",
    "data": {
      "input_cost_per_token": 4e-7,
      "max_input_tokens": 129024,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_reasoning_token": 0.000004,
      "output_cost_per_token": 0.0000012,
      "source": "https://www.alibabacloud.com/help/en/model-studio/models",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "dashscope"
    },
    "slug": "qwen-plus-2025-07-14",
    "displayName": "qwen-plus-2025-07-14"
  },
  {
    "id": "dashscope/qwen-turbo",
    "name": "qwen-turbo",
    "provider": "dashscope",
    "data": {
      "input_cost_per_token": 5e-8,
      "max_input_tokens": 129024,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_reasoning_token": 5e-7,
      "output_cost_per_token": 2e-7,
      "source": "https://www.alibabacloud.com/help/en/model-studio/models",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "dashscope"
    },
    "slug": "qwen-turbo",
    "displayName": "qwen-turbo"
  },
  {
    "id": "dashscope/qwen-turbo-2024-11-01",
    "name": "qwen-turbo-2024-11-01",
    "provider": "dashscope",
    "data": {
      "input_cost_per_token": 5e-8,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 2e-7,
      "source": "https://www.alibabacloud.com/help/en/model-studio/models",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "dashscope"
    },
    "slug": "qwen-turbo-2024-11-01",
    "displayName": "qwen-turbo-2024-11-01"
  },
  {
    "id": "dashscope/qwen-turbo-2025-04-28",
    "name": "qwen-turbo-2025-04-28",
    "provider": "dashscope",
    "data": {
      "input_cost_per_token": 5e-8,
      "max_input_tokens": 1000000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_reasoning_token": 5e-7,
      "output_cost_per_token": 2e-7,
      "source": "https://www.alibabacloud.com/help/en/model-studio/models",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "dashscope"
    },
    "slug": "qwen-turbo-2025-04-28",
    "displayName": "qwen-turbo-2025-04-28"
  },
  {
    "id": "dashscope/qwen-turbo-latest",
    "name": "qwen-turbo-latest",
    "provider": "dashscope",
    "data": {
      "input_cost_per_token": 5e-8,
      "max_input_tokens": 1000000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_reasoning_token": 5e-7,
      "output_cost_per_token": 2e-7,
      "source": "https://www.alibabacloud.com/help/en/model-studio/models",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "dashscope"
    },
    "slug": "qwen-turbo-latest",
    "displayName": "qwen-turbo-latest"
  },
  {
    "id": "dashscope/qwq-plus",
    "name": "qwq-plus",
    "provider": "dashscope",
    "data": {
      "input_cost_per_token": 8e-7,
      "max_input_tokens": 98304,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.0000024,
      "source": "https://www.alibabacloud.com/help/en/model-studio/models",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "dashscope"
    },
    "slug": "qwq-plus",
    "displayName": "qwq-plus"
  },
  {
    "id": "databricks/databricks-bge-large-en",
    "name": "databricks-bge-large-en",
    "provider": "databricks",
    "data": {
      "input_cost_per_token": 1.0003e-7,
      "input_dbu_cost_per_token": 0.000001429,
      "max_input_tokens": 512,
      "max_tokens": 512,
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_dbu_cost_per_token": 0,
      "output_vector_size": 1024,
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
      "provider": "databricks"
    },
    "slug": "databricks-bge-large-en",
    "displayName": "databricks-bge-large-en"
  },
  {
    "id": "databricks/databricks-claude-3-7-sonnet",
    "name": "databricks-claude-3-7-sonnet",
    "provider": "databricks",
    "data": {
      "input_cost_per_token": 0.0000029999900000000002,
      "input_dbu_cost_per_token": 0.000042857,
      "max_input_tokens": 200000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "mode": "chat",
      "output_cost_per_token": 0.000015000020000000002,
      "output_dbu_cost_per_token": 0.000214286,
      "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "databricks"
    },
    "slug": "databricks-claude-3-7-sonnet",
    "displayName": "databricks-claude-3-7-sonnet"
  },
  {
    "id": "databricks/databricks-claude-haiku-4-5",
    "name": "databricks-claude-haiku-4-5",
    "provider": "databricks",
    "data": {
      "input_cost_per_token": 0.00000100002,
      "input_dbu_cost_per_token": 0.000014286,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "mode": "chat",
      "output_cost_per_token": 0.00000500003,
      "output_dbu_cost_per_token": 0.000071429,
      "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "databricks"
    },
    "slug": "databricks-claude-haiku-4-5",
    "displayName": "databricks-claude-haiku-4-5"
  },
  {
    "id": "databricks/databricks-claude-opus-4",
    "name": "databricks-claude-opus-4",
    "provider": "databricks",
    "data": {
      "input_cost_per_token": 0.000015000020000000002,
      "input_dbu_cost_per_token": 0.000214286,
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "mode": "chat",
      "output_cost_per_token": 0.00007500003000000001,
      "output_dbu_cost_per_token": 0.001071429,
      "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "databricks"
    },
    "slug": "databricks-claude-opus-4",
    "displayName": "databricks-claude-opus-4"
  },
  {
    "id": "databricks/databricks-claude-opus-4-1",
    "name": "databricks-claude-opus-4-1",
    "provider": "databricks",
    "data": {
      "input_cost_per_token": 0.000015000020000000002,
      "input_dbu_cost_per_token": 0.000214286,
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "mode": "chat",
      "output_cost_per_token": 0.00007500003000000001,
      "output_dbu_cost_per_token": 0.001071429,
      "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "databricks"
    },
    "slug": "databricks-claude-opus-4-1",
    "displayName": "databricks-claude-opus-4-1"
  },
  {
    "id": "databricks/databricks-claude-opus-4-5",
    "name": "databricks-claude-opus-4-5",
    "provider": "databricks",
    "data": {
      "input_cost_per_token": 0.00000500003,
      "input_dbu_cost_per_token": 0.000071429,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "mode": "chat",
      "output_cost_per_token": 0.000025000010000000002,
      "output_dbu_cost_per_token": 0.000357143,
      "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "databricks"
    },
    "slug": "databricks-claude-opus-4-5",
    "displayName": "databricks-claude-opus-4-5"
  },
  {
    "id": "databricks/databricks-claude-sonnet-4",
    "name": "databricks-claude-sonnet-4",
    "provider": "databricks",
    "data": {
      "input_cost_per_token": 0.0000029999900000000002,
      "input_dbu_cost_per_token": 0.000042857,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "mode": "chat",
      "output_cost_per_token": 0.000015000020000000002,
      "output_dbu_cost_per_token": 0.000214286,
      "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "databricks"
    },
    "slug": "databricks-claude-sonnet-4",
    "displayName": "databricks-claude-sonnet-4"
  },
  {
    "id": "databricks/databricks-claude-sonnet-4-1",
    "name": "databricks-claude-sonnet-4-1",
    "provider": "databricks",
    "data": {
      "input_cost_per_token": 0.0000029999900000000002,
      "input_dbu_cost_per_token": 0.000042857,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "mode": "chat",
      "output_cost_per_token": 0.000015000020000000002,
      "output_dbu_cost_per_token": 0.000214286,
      "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "databricks"
    },
    "slug": "databricks-claude-sonnet-4-1",
    "displayName": "databricks-claude-sonnet-4-1"
  },
  {
    "id": "databricks/databricks-claude-sonnet-4-5",
    "name": "databricks-claude-sonnet-4-5",
    "provider": "databricks",
    "data": {
      "input_cost_per_token": 0.0000029999900000000002,
      "input_dbu_cost_per_token": 0.000042857,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "mode": "chat",
      "output_cost_per_token": 0.000015000020000000002,
      "output_dbu_cost_per_token": 0.000214286,
      "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "databricks"
    },
    "slug": "databricks-claude-sonnet-4-5",
    "displayName": "databricks-claude-sonnet-4-5"
  },
  {
    "id": "databricks/databricks-gemini-2-5-flash",
    "name": "databricks-gemini-2-5-flash",
    "provider": "databricks",
    "data": {
      "input_cost_per_token": 3.0001999999999996e-7,
      "input_dbu_cost_per_token": 0.000004285999999999999,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_tokens": 65535,
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "mode": "chat",
      "output_cost_per_token": 0.00000249998,
      "output_dbu_cost_per_token": 0.000035714,
      "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "databricks"
    },
    "slug": "databricks-gemini-2-5-flash",
    "displayName": "databricks-gemini-2-5-flash"
  },
  {
    "id": "databricks/databricks-gemini-2-5-pro",
    "name": "databricks-gemini-2-5-pro",
    "provider": "databricks",
    "data": {
      "input_cost_per_token": 0.00000124999,
      "input_dbu_cost_per_token": 0.000017857,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "max_tokens": 65536,
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "mode": "chat",
      "output_cost_per_token": 0.000009999990000000002,
      "output_dbu_cost_per_token": 0.000142857,
      "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "databricks"
    },
    "slug": "databricks-gemini-2-5-pro",
    "displayName": "databricks-gemini-2-5-pro"
  },
  {
    "id": "databricks/databricks-gemma-3-12b",
    "name": "databricks-gemma-3-12b",
    "provider": "databricks",
    "data": {
      "input_cost_per_token": 1.5000999999999998e-7,
      "input_dbu_cost_per_token": 0.0000021429999999999996,
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "mode": "chat",
      "output_cost_per_token": 5.0001e-7,
      "output_dbu_cost_per_token": 0.000007143,
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
      "provider": "databricks"
    },
    "slug": "databricks-gemma-3-12b",
    "displayName": "databricks-gemma-3-12b"
  },
  {
    "id": "databricks/databricks-gpt-5",
    "name": "databricks-gpt-5",
    "provider": "databricks",
    "data": {
      "input_cost_per_token": 0.00000124999,
      "input_dbu_cost_per_token": 0.000017857,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "mode": "chat",
      "output_cost_per_token": 0.000009999990000000002,
      "output_dbu_cost_per_token": 0.000142857,
      "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
      "provider": "databricks"
    },
    "slug": "databricks-gpt-5",
    "displayName": "databricks-gpt-5"
  },
  {
    "id": "databricks/databricks-gpt-5-1",
    "name": "databricks-gpt-5-1",
    "provider": "databricks",
    "data": {
      "input_cost_per_token": 0.00000124999,
      "input_dbu_cost_per_token": 0.000017857,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "mode": "chat",
      "output_cost_per_token": 0.000009999990000000002,
      "output_dbu_cost_per_token": 0.000142857,
      "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
      "provider": "databricks"
    },
    "slug": "databricks-gpt-5-1",
    "displayName": "databricks-gpt-5-1"
  },
  {
    "id": "databricks/databricks-gpt-5-mini",
    "name": "databricks-gpt-5-mini",
    "provider": "databricks",
    "data": {
      "input_cost_per_token": 2.4997000000000006e-7,
      "input_dbu_cost_per_token": 0.000003571,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "mode": "chat",
      "output_cost_per_token": 0.0000019999700000000004,
      "output_dbu_cost_per_token": 0.000028571,
      "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
      "provider": "databricks"
    },
    "slug": "databricks-gpt-5-mini",
    "displayName": "databricks-gpt-5-mini"
  },
  {
    "id": "databricks/databricks-gpt-5-nano",
    "name": "databricks-gpt-5-nano",
    "provider": "databricks",
    "data": {
      "input_cost_per_token": 4.998e-8,
      "input_dbu_cost_per_token": 7.14e-7,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "mode": "chat",
      "output_cost_per_token": 3.9998000000000007e-7,
      "output_dbu_cost_per_token": 0.000005714000000000001,
      "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
      "provider": "databricks"
    },
    "slug": "databricks-gpt-5-nano",
    "displayName": "databricks-gpt-5-nano"
  },
  {
    "id": "databricks/databricks-gpt-oss-120b",
    "name": "databricks-gpt-oss-120b",
    "provider": "databricks",
    "data": {
      "input_cost_per_token": 1.5000999999999998e-7,
      "input_dbu_cost_per_token": 0.0000021429999999999996,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "mode": "chat",
      "output_cost_per_token": 5.9997e-7,
      "output_dbu_cost_per_token": 0.000008571,
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
      "provider": "databricks"
    },
    "slug": "databricks-gpt-oss-120b",
    "displayName": "databricks-gpt-oss-120b"
  },
  {
    "id": "databricks/databricks-gpt-oss-20b",
    "name": "databricks-gpt-oss-20b",
    "provider": "databricks",
    "data": {
      "input_cost_per_token": 7e-8,
      "input_dbu_cost_per_token": 0.000001,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "mode": "chat",
      "output_cost_per_token": 3.0001999999999996e-7,
      "output_dbu_cost_per_token": 0.000004285999999999999,
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
      "provider": "databricks"
    },
    "slug": "databricks-gpt-oss-20b",
    "displayName": "databricks-gpt-oss-20b"
  },
  {
    "id": "databricks/databricks-gte-large-en",
    "name": "databricks-gte-large-en",
    "provider": "databricks",
    "data": {
      "input_cost_per_token": 1.2999000000000001e-7,
      "input_dbu_cost_per_token": 0.000001857,
      "max_input_tokens": 8192,
      "max_tokens": 8192,
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_dbu_cost_per_token": 0,
      "output_vector_size": 1024,
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
      "provider": "databricks"
    },
    "slug": "databricks-gte-large-en",
    "displayName": "databricks-gte-large-en"
  },
  {
    "id": "databricks/databricks-llama-2-70b-chat",
    "name": "databricks-llama-2-70b-chat",
    "provider": "databricks",
    "data": {
      "input_cost_per_token": 5.0001e-7,
      "input_dbu_cost_per_token": 0.000007143,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "mode": "chat",
      "output_cost_per_token": 0.0000015000300000000002,
      "output_dbu_cost_per_token": 0.000021429,
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
      "supports_tool_choice": true,
      "provider": "databricks"
    },
    "slug": "databricks-llama-2-70b-chat",
    "displayName": "databricks-llama-2-70b-chat"
  },
  {
    "id": "databricks/databricks-llama-4-maverick",
    "name": "databricks-llama-4-maverick",
    "provider": "databricks",
    "data": {
      "input_cost_per_token": 5.0001e-7,
      "input_dbu_cost_per_token": 0.000007143,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "metadata": {
        "notes": "Databricks documentation now provides both DBU costs (_dbu_cost_per_token) and dollar costs(_cost_per_token)."
      },
      "mode": "chat",
      "output_cost_per_token": 0.0000015000300000000002,
      "output_dbu_cost_per_token": 0.000021429,
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
      "supports_tool_choice": true,
      "provider": "databricks"
    },
    "slug": "databricks-llama-4-maverick",
    "displayName": "databricks-llama-4-maverick"
  },
  {
    "id": "databricks/databricks-meta-llama-3-1-405b-instruct",
    "name": "databricks-meta-llama-3-1-405b-instruct",
    "provider": "databricks",
    "data": {
      "input_cost_per_token": 0.00000500003,
      "input_dbu_cost_per_token": 0.000071429,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "mode": "chat",
      "output_cost_per_token": 0.000015000020000000002,
      "output_dbu_cost_per_token": 0.000214286,
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
      "supports_tool_choice": true,
      "provider": "databricks"
    },
    "slug": "databricks-meta-llama-3-1-405b-instruct",
    "displayName": "databricks-meta-llama-3-1-405b-instruct"
  },
  {
    "id": "databricks/databricks-meta-llama-3-1-8b-instruct",
    "name": "databricks-meta-llama-3-1-8b-instruct",
    "provider": "databricks",
    "data": {
      "input_cost_per_token": 1.5000999999999998e-7,
      "input_dbu_cost_per_token": 0.0000021429999999999996,
      "max_input_tokens": 200000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "mode": "chat",
      "output_cost_per_token": 4.5003000000000007e-7,
      "output_dbu_cost_per_token": 0.000006429000000000001,
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
      "provider": "databricks"
    },
    "slug": "databricks-meta-llama-3-1-8b-instruct",
    "displayName": "databricks-meta-llama-3-1-8b-instruct"
  },
  {
    "id": "databricks/databricks-meta-llama-3-3-70b-instruct",
    "name": "databricks-meta-llama-3-3-70b-instruct",
    "provider": "databricks",
    "data": {
      "input_cost_per_token": 5.0001e-7,
      "input_dbu_cost_per_token": 0.000007143,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "mode": "chat",
      "output_cost_per_token": 0.0000015000300000000002,
      "output_dbu_cost_per_token": 0.000021429,
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
      "supports_tool_choice": true,
      "provider": "databricks"
    },
    "slug": "databricks-meta-llama-3-3-70b-instruct",
    "displayName": "databricks-meta-llama-3-3-70b-instruct"
  },
  {
    "id": "databricks/databricks-meta-llama-3-70b-instruct",
    "name": "databricks-meta-llama-3-70b-instruct",
    "provider": "databricks",
    "data": {
      "input_cost_per_token": 0.00000100002,
      "input_dbu_cost_per_token": 0.000014286,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "mode": "chat",
      "output_cost_per_token": 0.0000029999900000000002,
      "output_dbu_cost_per_token": 0.000042857,
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
      "supports_tool_choice": true,
      "provider": "databricks"
    },
    "slug": "databricks-meta-llama-3-70b-instruct",
    "displayName": "databricks-meta-llama-3-70b-instruct"
  },
  {
    "id": "databricks/databricks-mixtral-8x7b-instruct",
    "name": "databricks-mixtral-8x7b-instruct",
    "provider": "databricks",
    "data": {
      "input_cost_per_token": 5.0001e-7,
      "input_dbu_cost_per_token": 0.000007143,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "mode": "chat",
      "output_cost_per_token": 0.00000100002,
      "output_dbu_cost_per_token": 0.000014286,
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
      "supports_tool_choice": true,
      "provider": "databricks"
    },
    "slug": "databricks-mixtral-8x7b-instruct",
    "displayName": "databricks-mixtral-8x7b-instruct"
  },
  {
    "id": "databricks/databricks-mpt-30b-instruct",
    "name": "databricks-mpt-30b-instruct",
    "provider": "databricks",
    "data": {
      "input_cost_per_token": 0.00000100002,
      "input_dbu_cost_per_token": 0.000014286,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "mode": "chat",
      "output_cost_per_token": 0.00000100002,
      "output_dbu_cost_per_token": 0.000014286,
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
      "supports_tool_choice": true,
      "provider": "databricks"
    },
    "slug": "databricks-mpt-30b-instruct",
    "displayName": "databricks-mpt-30b-instruct"
  },
  {
    "id": "databricks/databricks-mpt-7b-instruct",
    "name": "databricks-mpt-7b-instruct",
    "provider": "databricks",
    "data": {
      "input_cost_per_token": 5.0001e-7,
      "input_dbu_cost_per_token": 0.000007143,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "mode": "chat",
      "output_cost_per_token": 0,
      "output_dbu_cost_per_token": 0,
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
      "supports_tool_choice": true,
      "provider": "databricks"
    },
    "slug": "databricks-mpt-7b-instruct",
    "displayName": "databricks-mpt-7b-instruct"
  },
  {
    "id": "davinci-002",
    "name": "davinci-002",
    "provider": "text-completion-openai",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "completion",
      "output_cost_per_token": 0.000002,
      "provider": "text-completion-openai"
    },
    "slug": "davinci-002",
    "displayName": "davinci-002"
  },
  {
    "id": "deepinfra/Gryphe/MythoMax-L2-13b",
    "name": "MythoMax-L2-13b",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 8e-8,
      "output_cost_per_token": 9e-8,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "mythomax-l2-13b",
    "displayName": "MythoMax-L2-13b"
  },
  {
    "id": "deepinfra/NousResearch/Hermes-3-Llama-3.1-405B",
    "name": "Hermes-3-Llama-3.1-405B",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000001,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "hermes-3-llama-3.1-405b",
    "displayName": "Hermes-3-Llama-3.1-405B"
  },
  {
    "id": "deepinfra/NousResearch/Hermes-3-Llama-3.1-70B",
    "name": "Hermes-3-Llama-3.1-70B",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 3e-7,
      "output_cost_per_token": 3e-7,
      "mode": "chat",
      "supports_tool_choice": false,
      "provider": "deepinfra"
    },
    "slug": "hermes-3-llama-3.1-70b",
    "displayName": "Hermes-3-Llama-3.1-70B"
  },
  {
    "id": "deepinfra/Qwen/QwQ-32B",
    "name": "QwQ-32B",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 1.5e-7,
      "output_cost_per_token": 4e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "qwq-32b",
    "displayName": "QwQ-32B"
  },
  {
    "id": "deepinfra/Qwen/Qwen2.5-72B-Instruct",
    "name": "Qwen2.5-72B-Instruct",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 1.2e-7,
      "output_cost_per_token": 3.9e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "qwen2.5-72b-instruct",
    "displayName": "Qwen2.5-72B-Instruct"
  },
  {
    "id": "deepinfra/Qwen/Qwen2.5-7B-Instruct",
    "name": "Qwen2.5-7B-Instruct",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 4e-8,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "supports_tool_choice": false,
      "provider": "deepinfra"
    },
    "slug": "qwen2.5-7b-instruct",
    "displayName": "Qwen2.5-7B-Instruct"
  },
  {
    "id": "deepinfra/Qwen/Qwen2.5-VL-32B-Instruct",
    "name": "Qwen2.5-VL-32B-Instruct",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 6e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "deepinfra"
    },
    "slug": "qwen2.5-vl-32b-instruct",
    "displayName": "Qwen2.5-VL-32B-Instruct"
  },
  {
    "id": "deepinfra/Qwen/Qwen3-14B",
    "name": "Qwen3-14B",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 40960,
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_token": 6e-8,
      "output_cost_per_token": 2.4e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "qwen3-14b",
    "displayName": "Qwen3-14B"
  },
  {
    "id": "deepinfra/Qwen/Qwen3-235B-A22B",
    "name": "Qwen3-235B-A22B",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 40960,
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_token": 1.8e-7,
      "output_cost_per_token": 5.4e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "qwen3-235b-a22b",
    "displayName": "Qwen3-235B-A22B"
  },
  {
    "id": "deepinfra/Qwen/Qwen3-235B-A22B-Instruct-2507",
    "name": "Qwen3-235B-A22B-Instruct-2507",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 262144,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_token": 9e-8,
      "output_cost_per_token": 6e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "qwen3-235b-a22b-instruct-2507",
    "displayName": "Qwen3-235B-A22B-Instruct-2507"
  },
  {
    "id": "deepinfra/Qwen/Qwen3-235B-A22B-Thinking-2507",
    "name": "Qwen3-235B-A22B-Thinking-2507",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 262144,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_token": 3e-7,
      "output_cost_per_token": 0.0000029,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "qwen3-235b-a22b-thinking-2507",
    "displayName": "Qwen3-235B-A22B-Thinking-2507"
  },
  {
    "id": "deepinfra/Qwen/Qwen3-30B-A3B",
    "name": "Qwen3-30B-A3B",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 40960,
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_token": 8e-8,
      "output_cost_per_token": 2.9e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "qwen3-30b-a3b",
    "displayName": "Qwen3-30B-A3B"
  },
  {
    "id": "deepinfra/Qwen/Qwen3-32B",
    "name": "Qwen3-32B",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 40960,
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 2.8e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "qwen3-32b",
    "displayName": "Qwen3-32B"
  },
  {
    "id": "deepinfra/Qwen/Qwen3-Coder-480B-A35B-Instruct",
    "name": "Qwen3-Coder-480B-A35B-Instruct",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 262144,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_token": 4e-7,
      "output_cost_per_token": 0.0000016,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "qwen3-coder-480b-a35b-instruct",
    "displayName": "Qwen3-Coder-480B-A35B-Instruct"
  },
  {
    "id": "deepinfra/Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo",
    "name": "Qwen3-Coder-480B-A35B-Instruct-Turbo",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 262144,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_token": 2.9e-7,
      "output_cost_per_token": 0.0000012,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "qwen3-coder-480b-a35b-instruct-turbo",
    "displayName": "Qwen3-Coder-480B-A35B-Instruct-Turbo"
  },
  {
    "id": "deepinfra/Qwen/Qwen3-Next-80B-A3B-Instruct",
    "name": "Qwen3-Next-80B-A3B-Instruct",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 262144,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_token": 1.4e-7,
      "output_cost_per_token": 0.0000014,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "qwen3-next-80b-a3b-instruct",
    "displayName": "Qwen3-Next-80B-A3B-Instruct"
  },
  {
    "id": "deepinfra/Qwen/Qwen3-Next-80B-A3B-Thinking",
    "name": "Qwen3-Next-80B-A3B-Thinking",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 262144,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_token": 1.4e-7,
      "output_cost_per_token": 0.0000014,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "qwen3-next-80b-a3b-thinking",
    "displayName": "Qwen3-Next-80B-A3B-Thinking"
  },
  {
    "id": "deepinfra/Sao10K/L3-8B-Lunaris-v1-Turbo",
    "name": "L3-8B-Lunaris-v1-Turbo",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 4e-8,
      "output_cost_per_token": 5e-8,
      "mode": "chat",
      "supports_tool_choice": false,
      "provider": "deepinfra"
    },
    "slug": "l3-8b-lunaris-v1-turbo",
    "displayName": "L3-8B-Lunaris-v1-Turbo"
  },
  {
    "id": "deepinfra/Sao10K/L3.1-70B-Euryale-v2.2",
    "name": "L3.1-70B-Euryale-v2.2",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 6.5e-7,
      "output_cost_per_token": 7.5e-7,
      "mode": "chat",
      "supports_tool_choice": false,
      "provider": "deepinfra"
    },
    "slug": "l3.1-70b-euryale-v2.2",
    "displayName": "L3.1-70B-Euryale-v2.2"
  },
  {
    "id": "deepinfra/Sao10K/L3.3-70B-Euryale-v2.3",
    "name": "L3.3-70B-Euryale-v2.3",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 6.5e-7,
      "output_cost_per_token": 7.5e-7,
      "mode": "chat",
      "supports_tool_choice": false,
      "provider": "deepinfra"
    },
    "slug": "l3.3-70b-euryale-v2.3",
    "displayName": "L3.3-70B-Euryale-v2.3"
  },
  {
    "id": "deepinfra/allenai/olmOCR-7B-0725-FP8",
    "name": "olmOCR-7B-0725-FP8",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 2.7e-7,
      "output_cost_per_token": 0.0000015,
      "mode": "chat",
      "supports_tool_choice": false,
      "provider": "deepinfra"
    },
    "slug": "olmocr-7b-0725-fp8",
    "displayName": "olmOCR-7B-0725-FP8"
  },
  {
    "id": "deepinfra/anthropic/claude-3-7-sonnet-latest",
    "name": "claude-3-7-sonnet-latest",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 200000,
      "max_input_tokens": 200000,
      "max_output_tokens": 200000,
      "input_cost_per_token": 0.0000033,
      "output_cost_per_token": 0.0000165,
      "cache_read_input_token_cost": 3.3e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "claude-3-7-sonnet-latest",
    "displayName": "claude-3-7-sonnet-latest"
  },
  {
    "id": "deepinfra/anthropic/claude-4-opus",
    "name": "claude-4-opus",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 200000,
      "max_input_tokens": 200000,
      "max_output_tokens": 200000,
      "input_cost_per_token": 0.0000165,
      "output_cost_per_token": 0.0000825,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "claude-4-opus",
    "displayName": "claude-4-opus"
  },
  {
    "id": "deepinfra/anthropic/claude-4-sonnet",
    "name": "claude-4-sonnet",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 200000,
      "max_input_tokens": 200000,
      "max_output_tokens": 200000,
      "input_cost_per_token": 0.0000033,
      "output_cost_per_token": 0.0000165,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "claude-4-sonnet",
    "displayName": "claude-4-sonnet"
  },
  {
    "id": "deepinfra/deepseek-ai/DeepSeek-R1",
    "name": "DeepSeek-R1",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 163840,
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_token": 7e-7,
      "output_cost_per_token": 0.0000024,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "deepseek-r1",
    "displayName": "DeepSeek-R1"
  },
  {
    "id": "deepinfra/deepseek-ai/DeepSeek-R1-0528",
    "name": "DeepSeek-R1-0528",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 163840,
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 0.00000215,
      "cache_read_input_token_cost": 4e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "deepseek-r1-0528",
    "displayName": "DeepSeek-R1-0528"
  },
  {
    "id": "deepinfra/deepseek-ai/DeepSeek-R1-0528-Turbo",
    "name": "DeepSeek-R1-0528-Turbo",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000003,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "deepseek-r1-0528-turbo",
    "displayName": "DeepSeek-R1-0528-Turbo"
  },
  {
    "id": "deepinfra/deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "name": "DeepSeek-R1-Distill-Llama-70B",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 6e-7,
      "mode": "chat",
      "supports_tool_choice": false,
      "provider": "deepinfra"
    },
    "slug": "deepseek-r1-distill-llama-70b",
    "displayName": "DeepSeek-R1-Distill-Llama-70B"
  },
  {
    "id": "deepinfra/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
    "name": "DeepSeek-R1-Distill-Qwen-32B",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 2.7e-7,
      "output_cost_per_token": 2.7e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "deepseek-r1-distill-qwen-32b",
    "displayName": "DeepSeek-R1-Distill-Qwen-32B"
  },
  {
    "id": "deepinfra/deepseek-ai/DeepSeek-R1-Turbo",
    "name": "DeepSeek-R1-Turbo",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 40960,
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000003,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "deepseek-r1-turbo",
    "displayName": "DeepSeek-R1-Turbo"
  },
  {
    "id": "deepinfra/deepseek-ai/DeepSeek-V3",
    "name": "DeepSeek-V3",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 163840,
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_token": 3.8e-7,
      "output_cost_per_token": 8.9e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "deepseek-v3",
    "displayName": "DeepSeek-V3"
  },
  {
    "id": "deepinfra/deepseek-ai/DeepSeek-V3-0324",
    "name": "DeepSeek-V3-0324",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 163840,
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_token": 2.5e-7,
      "output_cost_per_token": 8.8e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "deepseek-v3-0324",
    "displayName": "DeepSeek-V3-0324"
  },
  {
    "id": "deepinfra/deepseek-ai/DeepSeek-V3.1",
    "name": "DeepSeek-V3.1",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 163840,
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_token": 2.7e-7,
      "output_cost_per_token": 0.000001,
      "cache_read_input_token_cost": 2.16e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "supports_reasoning": true,
      "provider": "deepinfra"
    },
    "slug": "deepseek-v3.1",
    "displayName": "DeepSeek-V3.1"
  },
  {
    "id": "deepinfra/deepseek-ai/DeepSeek-V3.1-Terminus",
    "name": "DeepSeek-V3.1-Terminus",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 163840,
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_token": 2.7e-7,
      "output_cost_per_token": 0.000001,
      "cache_read_input_token_cost": 2.16e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "deepseek-v3.1-terminus",
    "displayName": "DeepSeek-V3.1-Terminus"
  },
  {
    "id": "deepinfra/google/gemini-2.0-flash-001",
    "name": "gemini-2.0-flash-001",
    "provider": "deepinfra",
    "data": {
      "deprecation_date": "2026-03-31",
      "max_tokens": 1000000,
      "max_input_tokens": 1000000,
      "max_output_tokens": 1000000,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 4e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "gemini-2.0-flash-001",
    "displayName": "gemini-2.0-flash-001"
  },
  {
    "id": "deepinfra/google/gemini-2.5-flash",
    "name": "gemini-2.5-flash",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 1000000,
      "max_input_tokens": 1000000,
      "max_output_tokens": 1000000,
      "input_cost_per_token": 3e-7,
      "output_cost_per_token": 0.0000025,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "gemini-2.5-flash",
    "displayName": "gemini-2.5-flash"
  },
  {
    "id": "deepinfra/google/gemini-2.5-pro",
    "name": "gemini-2.5-pro",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 1000000,
      "max_input_tokens": 1000000,
      "max_output_tokens": 1000000,
      "input_cost_per_token": 0.00000125,
      "output_cost_per_token": 0.00001,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "gemini-2.5-pro",
    "displayName": "gemini-2.5-pro"
  },
  {
    "id": "deepinfra/google/gemma-3-12b-it",
    "name": "gemma-3-12b-it",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 5e-8,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "gemma-3-12b-it",
    "displayName": "gemma-3-12b-it"
  },
  {
    "id": "deepinfra/google/gemma-3-27b-it",
    "name": "gemma-3-27b-it",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 9e-8,
      "output_cost_per_token": 1.6e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "gemma-3-27b-it",
    "displayName": "gemma-3-27b-it"
  },
  {
    "id": "deepinfra/google/gemma-3-4b-it",
    "name": "gemma-3-4b-it",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 4e-8,
      "output_cost_per_token": 8e-8,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "gemma-3-4b-it",
    "displayName": "gemma-3-4b-it"
  },
  {
    "id": "deepinfra/meta-llama/Llama-3.2-11B-Vision-Instruct",
    "name": "Llama-3.2-11B-Vision-Instruct",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 4.9e-8,
      "output_cost_per_token": 4.9e-8,
      "mode": "chat",
      "supports_tool_choice": false,
      "provider": "deepinfra"
    },
    "slug": "llama-3.2-11b-vision-instruct",
    "displayName": "Llama-3.2-11B-Vision-Instruct"
  },
  {
    "id": "deepinfra/meta-llama/Llama-3.2-3B-Instruct",
    "name": "Llama-3.2-3B-Instruct",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 2e-8,
      "output_cost_per_token": 2e-8,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "llama-3.2-3b-instruct",
    "displayName": "Llama-3.2-3B-Instruct"
  },
  {
    "id": "deepinfra/meta-llama/Llama-3.3-70B-Instruct",
    "name": "Llama-3.3-70B-Instruct",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 2.3e-7,
      "output_cost_per_token": 4e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "llama-3.3-70b-instruct",
    "displayName": "Llama-3.3-70B-Instruct"
  },
  {
    "id": "deepinfra/meta-llama/Llama-3.3-70B-Instruct-Turbo",
    "name": "Llama-3.3-70B-Instruct-Turbo",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 1.3e-7,
      "output_cost_per_token": 3.9e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "llama-3.3-70b-instruct-turbo",
    "displayName": "Llama-3.3-70B-Instruct-Turbo"
  },
  {
    "id": "deepinfra/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
    "name": "Llama-4-Maverick-17B-128E-Instruct-FP8",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 1048576,
      "max_input_tokens": 1048576,
      "max_output_tokens": 1048576,
      "input_cost_per_token": 1.5e-7,
      "output_cost_per_token": 6e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "llama-4-maverick-17b-128e-instruct-fp8",
    "displayName": "Llama-4-Maverick-17B-128E-Instruct-FP8"
  },
  {
    "id": "deepinfra/meta-llama/Llama-4-Scout-17B-16E-Instruct",
    "name": "Llama-4-Scout-17B-16E-Instruct",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 327680,
      "max_input_tokens": 327680,
      "max_output_tokens": 327680,
      "input_cost_per_token": 8e-8,
      "output_cost_per_token": 3e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "llama-4-scout-17b-16e-instruct",
    "displayName": "Llama-4-Scout-17B-16E-Instruct"
  },
  {
    "id": "deepinfra/meta-llama/Llama-Guard-3-8B",
    "name": "Llama-Guard-3-8B",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 5.5e-8,
      "output_cost_per_token": 5.5e-8,
      "mode": "chat",
      "supports_tool_choice": false,
      "provider": "deepinfra"
    },
    "slug": "llama-guard-3-8b",
    "displayName": "Llama-Guard-3-8B"
  },
  {
    "id": "deepinfra/meta-llama/Llama-Guard-4-12B",
    "name": "Llama-Guard-4-12B",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 163840,
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_token": 1.8e-7,
      "output_cost_per_token": 1.8e-7,
      "mode": "chat",
      "supports_tool_choice": false,
      "provider": "deepinfra"
    },
    "slug": "llama-guard-4-12b",
    "displayName": "Llama-Guard-4-12B"
  },
  {
    "id": "deepinfra/meta-llama/Meta-Llama-3-8B-Instruct",
    "name": "Meta-Llama-3-8B-Instruct",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 3e-8,
      "output_cost_per_token": 6e-8,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "meta-llama-3-8b-instruct",
    "displayName": "Meta-Llama-3-8B-Instruct"
  },
  {
    "id": "deepinfra/meta-llama/Meta-Llama-3.1-70B-Instruct",
    "name": "Meta-Llama-3.1-70B-Instruct",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 4e-7,
      "output_cost_per_token": 4e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "meta-llama-3.1-70b-instruct",
    "displayName": "Meta-Llama-3.1-70B-Instruct"
  },
  {
    "id": "deepinfra/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
    "name": "Meta-Llama-3.1-70B-Instruct-Turbo",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 2.8e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "meta-llama-3.1-70b-instruct-turbo",
    "displayName": "Meta-Llama-3.1-70B-Instruct-Turbo"
  },
  {
    "id": "deepinfra/meta-llama/Meta-Llama-3.1-8B-Instruct",
    "name": "Meta-Llama-3.1-8B-Instruct",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 3e-8,
      "output_cost_per_token": 5e-8,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "meta-llama-3.1-8b-instruct",
    "displayName": "Meta-Llama-3.1-8B-Instruct"
  },
  {
    "id": "deepinfra/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
    "name": "Meta-Llama-3.1-8B-Instruct-Turbo",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 2e-8,
      "output_cost_per_token": 3e-8,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "meta-llama-3.1-8b-instruct-turbo",
    "displayName": "Meta-Llama-3.1-8B-Instruct-Turbo"
  },
  {
    "id": "deepinfra/microsoft/WizardLM-2-8x22B",
    "name": "WizardLM-2-8x22B",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 65536,
      "max_input_tokens": 65536,
      "max_output_tokens": 65536,
      "input_cost_per_token": 4.8e-7,
      "output_cost_per_token": 4.8e-7,
      "mode": "chat",
      "supports_tool_choice": false,
      "provider": "deepinfra"
    },
    "slug": "wizardlm-2-8x22b",
    "displayName": "WizardLM-2-8x22B"
  },
  {
    "id": "deepinfra/microsoft/phi-4",
    "name": "phi-4",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 7e-8,
      "output_cost_per_token": 1.4e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "phi-4",
    "displayName": "phi-4"
  },
  {
    "id": "deepinfra/mistralai/Mistral-Nemo-Instruct-2407",
    "name": "Mistral-Nemo-Instruct-2407",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 2e-8,
      "output_cost_per_token": 4e-8,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "mistral-nemo-instruct-2407",
    "displayName": "Mistral-Nemo-Instruct-2407"
  },
  {
    "id": "deepinfra/mistralai/Mistral-Small-24B-Instruct-2501",
    "name": "Mistral-Small-24B-Instruct-2501",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 5e-8,
      "output_cost_per_token": 8e-8,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "mistral-small-24b-instruct-2501",
    "displayName": "Mistral-Small-24B-Instruct-2501"
  },
  {
    "id": "deepinfra/mistralai/Mistral-Small-3.2-24B-Instruct-2506",
    "name": "Mistral-Small-3.2-24B-Instruct-2506",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 7.5e-8,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "mistral-small-3.2-24b-instruct-2506",
    "displayName": "Mistral-Small-3.2-24B-Instruct-2506"
  },
  {
    "id": "deepinfra/mistralai/Mixtral-8x7B-Instruct-v0.1",
    "name": "Mixtral-8x7B-Instruct-v0.1",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 4e-7,
      "output_cost_per_token": 4e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "mixtral-8x7b-instruct-v0.1",
    "displayName": "Mixtral-8x7B-Instruct-v0.1"
  },
  {
    "id": "deepinfra/moonshotai/Kimi-K2-Instruct",
    "name": "Kimi-K2-Instruct",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 0.000002,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "kimi-k2-instruct",
    "displayName": "Kimi-K2-Instruct"
  },
  {
    "id": "deepinfra/moonshotai/Kimi-K2-Instruct-0905",
    "name": "Kimi-K2-Instruct-0905",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 262144,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 0.000002,
      "cache_read_input_token_cost": 4e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "kimi-k2-instruct-0905",
    "displayName": "Kimi-K2-Instruct-0905"
  },
  {
    "id": "deepinfra/nvidia/Llama-3.1-Nemotron-70B-Instruct",
    "name": "Llama-3.1-Nemotron-70B-Instruct",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 6e-7,
      "output_cost_per_token": 6e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "llama-3.1-nemotron-70b-instruct",
    "displayName": "Llama-3.1-Nemotron-70B-Instruct"
  },
  {
    "id": "deepinfra/nvidia/Llama-3.3-Nemotron-Super-49B-v1.5",
    "name": "Llama-3.3-Nemotron-Super-49B-v1.5",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 4e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "llama-3.3-nemotron-super-49b-v1.5",
    "displayName": "Llama-3.3-Nemotron-Super-49B-v1.5"
  },
  {
    "id": "deepinfra/nvidia/NVIDIA-Nemotron-Nano-9B-v2",
    "name": "NVIDIA-Nemotron-Nano-9B-v2",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 4e-8,
      "output_cost_per_token": 1.6e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "nvidia-nemotron-nano-9b-v2",
    "displayName": "NVIDIA-Nemotron-Nano-9B-v2"
  },
  {
    "id": "deepinfra/openai/gpt-oss-120b",
    "name": "gpt-oss-120b",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 5e-8,
      "output_cost_per_token": 4.5e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "gpt-oss-120b",
    "displayName": "gpt-oss-120b"
  },
  {
    "id": "deepinfra/openai/gpt-oss-20b",
    "name": "gpt-oss-20b",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 4e-8,
      "output_cost_per_token": 1.5e-7,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "gpt-oss-20b",
    "displayName": "gpt-oss-20b"
  },
  {
    "id": "deepinfra/zai-org/GLM-4.5",
    "name": "GLM-4.5",
    "provider": "deepinfra",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 4e-7,
      "output_cost_per_token": 0.0000016,
      "mode": "chat",
      "supports_tool_choice": true,
      "provider": "deepinfra"
    },
    "slug": "glm-4.5",
    "displayName": "GLM-4.5"
  },
  {
    "id": "deepseek/deepseek-chat",
    "name": "deepseek-chat",
    "provider": "deepseek",
    "data": {
      "cache_creation_input_token_cost": 0,
      "cache_read_input_token_cost": 2.8e-8,
      "input_cost_per_token": 2.8e-7,
      "input_cost_per_token_cache_hit": 2.8e-8,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 4.2e-7,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_tool_choice": true,
      "provider": "deepseek"
    },
    "slug": "deepseek-chat",
    "displayName": "deepseek-chat"
  },
  {
    "id": "deepseek/deepseek-coder",
    "name": "deepseek-coder",
    "provider": "deepseek",
    "data": {
      "input_cost_per_token": 1.4e-7,
      "input_cost_per_token_cache_hit": 1.4e-8,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 2.8e-7,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_tool_choice": true,
      "provider": "deepseek"
    },
    "slug": "deepseek-coder",
    "displayName": "deepseek-coder"
  },
  {
    "id": "deepseek/deepseek-r1",
    "name": "deepseek-r1",
    "provider": "deepseek",
    "data": {
      "input_cost_per_token": 5.5e-7,
      "input_cost_per_token_cache_hit": 1.4e-7,
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.00000219,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "deepseek"
    },
    "slug": "deepseek-r1",
    "displayName": "deepseek-r1"
  },
  {
    "id": "deepseek/deepseek-reasoner",
    "name": "deepseek-reasoner",
    "provider": "deepseek",
    "data": {
      "cache_read_input_token_cost": 2.8e-8,
      "input_cost_per_token": 2.8e-7,
      "input_cost_per_token_cache_hit": 2.8e-8,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 4.2e-7,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "deepseek"
    },
    "slug": "deepseek-reasoner",
    "displayName": "deepseek-reasoner"
  },
  {
    "id": "deepseek/deepseek-v3",
    "name": "deepseek-v3",
    "provider": "deepseek",
    "data": {
      "cache_creation_input_token_cost": 0,
      "cache_read_input_token_cost": 7e-8,
      "input_cost_per_token": 2.7e-7,
      "input_cost_per_token_cache_hit": 7e-8,
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.0000011,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_tool_choice": true,
      "provider": "deepseek"
    },
    "slug": "deepseek-v3",
    "displayName": "deepseek-v3"
  },
  {
    "id": "deepseek/deepseek-v3.2",
    "name": "deepseek-v3.2",
    "provider": "deepseek",
    "data": {
      "input_cost_per_token": 2.8e-7,
      "input_cost_per_token_cache_hit": 2.8e-8,
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "max_tokens": 163840,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "deepseek"
    },
    "slug": "deepseek-v3.2",
    "displayName": "deepseek-v3.2"
  },
  {
    "id": "deepseek.v3-v1:0",
    "name": "deepseek.v3-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 5.8e-7,
      "max_input_tokens": 163840,
      "max_output_tokens": 81920,
      "max_tokens": 81920,
      "mode": "chat",
      "output_cost_per_token": 0.00000168,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "bedrock_converse"
    },
    "slug": "deepseek.v3-v1-0",
    "displayName": "deepseek.v3-v1:0"
  },
  {
    "id": "dolphin",
    "name": "dolphin",
    "provider": "nlp_cloud",
    "data": {
      "input_cost_per_token": 5e-7,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "completion",
      "output_cost_per_token": 5e-7,
      "provider": "nlp_cloud"
    },
    "slug": "dolphin",
    "displayName": "dolphin"
  },
  {
    "id": "embed-english-light-v2.0",
    "name": "embed-english-light-v2.0",
    "provider": "cohere",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 1024,
      "max_tokens": 1024,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "provider": "cohere"
    },
    "slug": "embed-english-light-v2.0",
    "displayName": "embed-english-light-v2.0"
  },
  {
    "id": "embed-english-light-v3.0",
    "name": "embed-english-light-v3.0",
    "provider": "cohere",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 1024,
      "max_tokens": 1024,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "provider": "cohere"
    },
    "slug": "embed-english-light-v3.0",
    "displayName": "embed-english-light-v3.0"
  },
  {
    "id": "embed-english-v2.0",
    "name": "embed-english-v2.0",
    "provider": "cohere",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 4096,
      "max_tokens": 4096,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "provider": "cohere"
    },
    "slug": "embed-english-v2.0",
    "displayName": "embed-english-v2.0"
  },
  {
    "id": "embed-english-v3.0",
    "name": "embed-english-v3.0",
    "provider": "cohere",
    "data": {
      "input_cost_per_image": 0.0001,
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 1024,
      "max_tokens": 1024,
      "metadata": {
        "notes": "'supports_image_input' is a deprecated field. Use 'supports_embedding_image_input' instead."
      },
      "mode": "embedding",
      "output_cost_per_token": 0,
      "supports_embedding_image_input": true,
      "supports_image_input": true,
      "provider": "cohere"
    },
    "slug": "embed-english-v3.0",
    "displayName": "embed-english-v3.0"
  },
  {
    "id": "embed-multilingual-v2.0",
    "name": "embed-multilingual-v2.0",
    "provider": "cohere",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 768,
      "max_tokens": 768,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "provider": "cohere"
    },
    "slug": "embed-multilingual-v2.0",
    "displayName": "embed-multilingual-v2.0"
  },
  {
    "id": "embed-multilingual-v3.0",
    "name": "embed-multilingual-v3.0",
    "provider": "cohere",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 1024,
      "max_tokens": 1024,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "supports_embedding_image_input": true,
      "provider": "cohere"
    },
    "slug": "embed-multilingual-v3.0",
    "displayName": "embed-multilingual-v3.0"
  },
  {
    "id": "embed-multilingual-light-v3.0",
    "name": "embed-multilingual-light-v3.0",
    "provider": "cohere",
    "data": {
      "input_cost_per_token": 0.0001,
      "max_input_tokens": 1024,
      "max_tokens": 1024,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "supports_embedding_image_input": true,
      "provider": "cohere"
    },
    "slug": "embed-multilingual-light-v3.0",
    "displayName": "embed-multilingual-light-v3.0"
  },
  {
    "id": "eu.amazon.nova-lite-v1:0",
    "name": "eu.amazon.nova-lite-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 7.8e-8,
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "max_tokens": 10000,
      "mode": "chat",
      "output_cost_per_token": 3.12e-7,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "provider": "bedrock_converse"
    },
    "slug": "eu.amazon.nova-lite-v1-0",
    "displayName": "eu.amazon.nova-lite-v1:0"
  },
  {
    "id": "eu.amazon.nova-micro-v1:0",
    "name": "eu.amazon.nova-micro-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 4.6e-8,
      "max_input_tokens": 128000,
      "max_output_tokens": 10000,
      "max_tokens": 10000,
      "mode": "chat",
      "output_cost_per_token": 1.84e-7,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "provider": "bedrock_converse"
    },
    "slug": "eu.amazon.nova-micro-v1-0",
    "displayName": "eu.amazon.nova-micro-v1:0"
  },
  {
    "id": "eu.amazon.nova-pro-v1:0",
    "name": "eu.amazon.nova-pro-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 0.00000105,
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "max_tokens": 10000,
      "mode": "chat",
      "output_cost_per_token": 0.0000042,
      "source": "https://aws.amazon.com/bedrock/pricing/",
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "provider": "bedrock_converse"
    },
    "slug": "eu.amazon.nova-pro-v1-0",
    "displayName": "eu.amazon.nova-pro-v1:0"
  },
  {
    "id": "eu.anthropic.claude-3-5-haiku-20241022-v1:0",
    "name": "eu.anthropic.claude-3-5-haiku-20241022-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 2.5e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.00000125,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "bedrock"
    },
    "slug": "eu.anthropic.claude-3-5-haiku-20241022-v1-0",
    "displayName": "eu.anthropic.claude-3-5-haiku-20241022-v1:0"
  },
  {
    "id": "eu.anthropic.claude-haiku-4-5-20251001-v1:0",
    "name": "eu.anthropic.claude-haiku-4-5-20251001-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_creation_input_token_cost": 0.000001375,
      "cache_read_input_token_cost": 1.1e-7,
      "input_cost_per_token": 0.0000011,
      "deprecation_date": "2026-10-15",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.0000055,
      "source": "https://aws.amazon.com/about-aws/whats-new/2025/10/claude-4-5-haiku-anthropic-amazon-bedrock",
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 346,
      "provider": "bedrock_converse"
    },
    "slug": "eu.anthropic.claude-haiku-4-5-20251001-v1-0",
    "displayName": "eu.anthropic.claude-haiku-4-5-20251001-v1:0"
  },
  {
    "id": "eu.anthropic.claude-3-5-sonnet-20240620-v1:0",
    "name": "eu.anthropic.claude-3-5-sonnet-20240620-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "eu.anthropic.claude-3-5-sonnet-20240620-v1-0",
    "displayName": "eu.anthropic.claude-3-5-sonnet-20240620-v1:0"
  },
  {
    "id": "eu.anthropic.claude-3-5-sonnet-20241022-v2:0",
    "name": "eu.anthropic.claude-3-5-sonnet-20241022-v2:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "eu.anthropic.claude-3-5-sonnet-20241022-v2-0",
    "displayName": "eu.anthropic.claude-3-5-sonnet-20241022-v2:0"
  },
  {
    "id": "eu.anthropic.claude-3-7-sonnet-20250219-v1:0",
    "name": "eu.anthropic.claude-3-7-sonnet-20250219-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "eu.anthropic.claude-3-7-sonnet-20250219-v1-0",
    "displayName": "eu.anthropic.claude-3-7-sonnet-20250219-v1:0"
  },
  {
    "id": "eu.anthropic.claude-3-haiku-20240307-v1:0",
    "name": "eu.anthropic.claude-3-haiku-20240307-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 2.5e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00000125,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "eu.anthropic.claude-3-haiku-20240307-v1-0",
    "displayName": "eu.anthropic.claude-3-haiku-20240307-v1:0"
  },
  {
    "id": "eu.anthropic.claude-3-opus-20240229-v1:0",
    "name": "eu.anthropic.claude-3-opus-20240229-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000075,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "eu.anthropic.claude-3-opus-20240229-v1-0",
    "displayName": "eu.anthropic.claude-3-opus-20240229-v1:0"
  },
  {
    "id": "eu.anthropic.claude-3-sonnet-20240229-v1:0",
    "name": "eu.anthropic.claude-3-sonnet-20240229-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "eu.anthropic.claude-3-sonnet-20240229-v1-0",
    "displayName": "eu.anthropic.claude-3-sonnet-20240229-v1:0"
  },
  {
    "id": "eu.anthropic.claude-opus-4-1-20250805-v1:0",
    "name": "eu.anthropic.claude-opus-4-1-20250805-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_creation_input_token_cost": 0.00001875,
      "cache_read_input_token_cost": 0.0000015,
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.000075,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "bedrock_converse"
    },
    "slug": "eu.anthropic.claude-opus-4-1-20250805-v1-0",
    "displayName": "eu.anthropic.claude-opus-4-1-20250805-v1:0"
  },
  {
    "id": "eu.anthropic.claude-opus-4-20250514-v1:0",
    "name": "eu.anthropic.claude-opus-4-20250514-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_creation_input_token_cost": 0.00001875,
      "cache_read_input_token_cost": 0.0000015,
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.000075,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "bedrock_converse"
    },
    "slug": "eu.anthropic.claude-opus-4-20250514-v1-0",
    "displayName": "eu.anthropic.claude-opus-4-20250514-v1:0"
  },
  {
    "id": "eu.anthropic.claude-sonnet-4-20250514-v1:0",
    "name": "eu.anthropic.claude-sonnet-4-20250514-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_creation_input_token_cost": 0.00000375,
      "cache_read_input_token_cost": 3e-7,
      "input_cost_per_token": 0.000003,
      "input_cost_per_token_above_200k_tokens": 0.000006,
      "output_cost_per_token_above_200k_tokens": 0.0000225,
      "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
      "cache_read_input_token_cost_above_200k_tokens": 6e-7,
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "bedrock_converse"
    },
    "slug": "eu.anthropic.claude-sonnet-4-20250514-v1-0",
    "displayName": "eu.anthropic.claude-sonnet-4-20250514-v1:0"
  },
  {
    "id": "eu.anthropic.claude-sonnet-4-5-20250929-v1:0",
    "name": "eu.anthropic.claude-sonnet-4-5-20250929-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_creation_input_token_cost": 0.000004125,
      "cache_read_input_token_cost": 3.3e-7,
      "input_cost_per_token": 0.0000033,
      "input_cost_per_token_above_200k_tokens": 0.0000066,
      "output_cost_per_token_above_200k_tokens": 0.00002475,
      "cache_creation_input_token_cost_above_200k_tokens": 0.00000825,
      "cache_read_input_token_cost_above_200k_tokens": 6.6e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.0000165,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 346,
      "provider": "bedrock_converse"
    },
    "slug": "eu.anthropic.claude-sonnet-4-5-20250929-v1-0",
    "displayName": "eu.anthropic.claude-sonnet-4-5-20250929-v1:0"
  },
  {
    "id": "eu.meta.llama3-2-1b-instruct-v1:0",
    "name": "eu.meta.llama3-2-1b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 1.3e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 1.3e-7,
      "supports_function_calling": true,
      "supports_tool_choice": false,
      "provider": "bedrock"
    },
    "slug": "eu.meta.llama3-2-1b-instruct-v1-0",
    "displayName": "eu.meta.llama3-2-1b-instruct-v1:0"
  },
  {
    "id": "eu.meta.llama3-2-3b-instruct-v1:0",
    "name": "eu.meta.llama3-2-3b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 1.9e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 1.9e-7,
      "supports_function_calling": true,
      "supports_tool_choice": false,
      "provider": "bedrock"
    },
    "slug": "eu.meta.llama3-2-3b-instruct-v1-0",
    "displayName": "eu.meta.llama3-2-3b-instruct-v1:0"
  },
  {
    "id": "eu.mistral.pixtral-large-2502-v1:0",
    "name": "eu.mistral.pixtral-large-2502-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000006,
      "supports_function_calling": true,
      "supports_tool_choice": false,
      "provider": "bedrock_converse"
    },
    "slug": "eu.mistral.pixtral-large-2502-v1-0",
    "displayName": "eu.mistral.pixtral-large-2502-v1:0"
  },
  {
    "id": "fireworks_ai/WhereIsAI/UAE-Large-V1",
    "name": "UAE-Large-V1",
    "provider": "fireworks_ai-embedding-models",
    "data": {
      "input_cost_per_token": 1.6e-8,
      "max_input_tokens": 512,
      "max_tokens": 512,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "source": "https://fireworks.ai/pricing",
      "provider": "fireworks_ai-embedding-models"
    },
    "slug": "uae-large-v1",
    "displayName": "UAE-Large-V1"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-instruct",
    "name": "deepseek-coder-v2-instruct",
    "provider": "fireworks_ai",
    "data": {
      "input_cost_per_token": 0.0000012,
      "max_input_tokens": 65536,
      "max_output_tokens": 65536,
      "max_tokens": 65536,
      "mode": "chat",
      "output_cost_per_token": 0.0000012,
      "source": "https://fireworks.ai/pricing",
      "supports_function_calling": false,
      "supports_response_schema": true,
      "supports_tool_choice": false,
      "provider": "fireworks_ai"
    },
    "slug": "deepseek-coder-v2-instruct",
    "displayName": "deepseek-coder-v2-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/deepseek-r1",
    "name": "deepseek-r1",
    "provider": "fireworks_ai",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 128000,
      "max_output_tokens": 20480,
      "max_tokens": 20480,
      "mode": "chat",
      "output_cost_per_token": 0.000008,
      "source": "https://fireworks.ai/pricing",
      "supports_response_schema": true,
      "supports_tool_choice": false,
      "provider": "fireworks_ai"
    },
    "slug": "deepseek-r1",
    "displayName": "deepseek-r1"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/deepseek-r1-0528",
    "name": "deepseek-r1-0528",
    "provider": "fireworks_ai",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 160000,
      "max_output_tokens": 160000,
      "max_tokens": 160000,
      "mode": "chat",
      "output_cost_per_token": 0.000008,
      "source": "https://fireworks.ai/pricing",
      "supports_response_schema": true,
      "supports_tool_choice": false,
      "provider": "fireworks_ai"
    },
    "slug": "deepseek-r1-0528",
    "displayName": "deepseek-r1-0528"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/deepseek-r1-basic",
    "name": "deepseek-r1-basic",
    "provider": "fireworks_ai",
    "data": {
      "input_cost_per_token": 5.5e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 20480,
      "max_tokens": 20480,
      "mode": "chat",
      "output_cost_per_token": 0.00000219,
      "source": "https://fireworks.ai/pricing",
      "supports_response_schema": true,
      "supports_tool_choice": false,
      "provider": "fireworks_ai"
    },
    "slug": "deepseek-r1-basic",
    "displayName": "deepseek-r1-basic"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/deepseek-v3",
    "name": "deepseek-v3",
    "provider": "fireworks_ai",
    "data": {
      "input_cost_per_token": 9e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 9e-7,
      "source": "https://fireworks.ai/pricing",
      "supports_response_schema": true,
      "supports_tool_choice": false,
      "provider": "fireworks_ai"
    },
    "slug": "deepseek-v3",
    "displayName": "deepseek-v3"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/deepseek-v3-0324",
    "name": "deepseek-v3-0324",
    "provider": "fireworks_ai",
    "data": {
      "input_cost_per_token": 9e-7,
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "max_tokens": 163840,
      "mode": "chat",
      "output_cost_per_token": 9e-7,
      "source": "https://fireworks.ai/models/fireworks/deepseek-v3-0324",
      "supports_response_schema": true,
      "supports_tool_choice": false,
      "provider": "fireworks_ai"
    },
    "slug": "deepseek-v3-0324",
    "displayName": "deepseek-v3-0324"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/deepseek-v3p1",
    "name": "deepseek-v3p1",
    "provider": "fireworks_ai",
    "data": {
      "input_cost_per_token": 5.6e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.00000168,
      "source": "https://fireworks.ai/pricing",
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "fireworks_ai"
    },
    "slug": "deepseek-v3p1",
    "displayName": "deepseek-v3p1"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/deepseek-v3p1-terminus",
    "name": "deepseek-v3p1-terminus",
    "provider": "fireworks_ai",
    "data": {
      "input_cost_per_token": 5.6e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.00000168,
      "source": "https://fireworks.ai/pricing",
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "fireworks_ai"
    },
    "slug": "deepseek-v3p1-terminus",
    "displayName": "deepseek-v3p1-terminus"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/deepseek-v3p2",
    "name": "deepseek-v3p2",
    "provider": "fireworks_ai",
    "data": {
      "input_cost_per_token": 5.6e-7,
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "max_tokens": 163840,
      "mode": "chat",
      "output_cost_per_token": 0.00000168,
      "source": "https://fireworks.ai/models/fireworks/deepseek-v3p2",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "fireworks_ai"
    },
    "slug": "deepseek-v3p2",
    "displayName": "deepseek-v3p2"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/firefunction-v2",
    "name": "firefunction-v2",
    "provider": "fireworks_ai",
    "data": {
      "input_cost_per_token": 9e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 9e-7,
      "source": "https://fireworks.ai/pricing",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "fireworks_ai"
    },
    "slug": "firefunction-v2",
    "displayName": "firefunction-v2"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/glm-4p5",
    "name": "glm-4p5",
    "provider": "fireworks_ai",
    "data": {
      "input_cost_per_token": 5.5e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 96000,
      "max_tokens": 96000,
      "mode": "chat",
      "output_cost_per_token": 0.00000219,
      "source": "https://fireworks.ai/models/fireworks/glm-4p5",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "fireworks_ai"
    },
    "slug": "glm-4p5",
    "displayName": "glm-4p5"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/glm-4p5-air",
    "name": "glm-4p5-air",
    "provider": "fireworks_ai",
    "data": {
      "input_cost_per_token": 2.2e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 96000,
      "max_tokens": 96000,
      "mode": "chat",
      "output_cost_per_token": 8.8e-7,
      "source": "https://artificialanalysis.ai/models/glm-4-5-air",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "fireworks_ai"
    },
    "slug": "glm-4p5-air",
    "displayName": "glm-4p5-air"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/glm-4p6",
    "name": "glm-4p6",
    "provider": "fireworks_ai",
    "data": {
      "input_cost_per_token": 5.5e-7,
      "output_cost_per_token": 0.00000219,
      "max_input_tokens": 202800,
      "max_output_tokens": 202800,
      "max_tokens": 202800,
      "mode": "chat",
      "source": "https://fireworks.ai/pricing",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "fireworks_ai"
    },
    "slug": "glm-4p6",
    "displayName": "glm-4p6"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/gpt-oss-120b",
    "name": "gpt-oss-120b",
    "provider": "fireworks_ai",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "source": "https://fireworks.ai/pricing",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "fireworks_ai"
    },
    "slug": "gpt-oss-120b",
    "displayName": "gpt-oss-120b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/gpt-oss-20b",
    "name": "gpt-oss-20b",
    "provider": "fireworks_ai",
    "data": {
      "input_cost_per_token": 5e-8,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 2e-7,
      "source": "https://fireworks.ai/pricing",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "fireworks_ai"
    },
    "slug": "gpt-oss-20b",
    "displayName": "gpt-oss-20b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/kimi-k2-instruct",
    "name": "kimi-k2-instruct",
    "provider": "fireworks_ai",
    "data": {
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.0000025,
      "source": "https://fireworks.ai/models/fireworks/kimi-k2-instruct",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "fireworks_ai"
    },
    "slug": "kimi-k2-instruct",
    "displayName": "kimi-k2-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/kimi-k2-instruct-0905",
    "name": "kimi-k2-instruct-0905",
    "provider": "fireworks_ai",
    "data": {
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 262144,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.0000025,
      "source": "https://app.fireworks.ai/models/fireworks/kimi-k2-instruct-0905",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "fireworks_ai"
    },
    "slug": "kimi-k2-instruct-0905",
    "displayName": "kimi-k2-instruct-0905"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/kimi-k2-thinking",
    "name": "kimi-k2-thinking",
    "provider": "fireworks_ai",
    "data": {
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "max_tokens": 262144,
      "mode": "chat",
      "output_cost_per_token": 0.0000025,
      "source": "https://fireworks.ai/pricing",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "fireworks_ai"
    },
    "slug": "kimi-k2-thinking",
    "displayName": "kimi-k2-thinking"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/llama-v3p1-405b-instruct",
    "name": "llama-v3p1-405b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.000003,
      "source": "https://fireworks.ai/pricing",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "fireworks_ai"
    },
    "slug": "llama-v3p1-405b-instruct",
    "displayName": "llama-v3p1-405b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/llama-v3p1-8b-instruct",
    "name": "llama-v3p1-8b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 1e-7,
      "source": "https://fireworks.ai/pricing",
      "supports_function_calling": false,
      "supports_response_schema": true,
      "supports_tool_choice": false,
      "provider": "fireworks_ai"
    },
    "slug": "llama-v3p1-8b-instruct",
    "displayName": "llama-v3p1-8b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/llama-v3p2-11b-vision-instruct",
    "name": "llama-v3p2-11b-vision-instruct",
    "provider": "fireworks_ai",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 2e-7,
      "source": "https://fireworks.ai/pricing",
      "supports_function_calling": false,
      "supports_response_schema": true,
      "supports_tool_choice": false,
      "supports_vision": true,
      "provider": "fireworks_ai"
    },
    "slug": "llama-v3p2-11b-vision-instruct",
    "displayName": "llama-v3p2-11b-vision-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/llama-v3p2-1b-instruct",
    "name": "llama-v3p2-1b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 1e-7,
      "source": "https://fireworks.ai/pricing",
      "supports_function_calling": false,
      "supports_response_schema": true,
      "supports_tool_choice": false,
      "provider": "fireworks_ai"
    },
    "slug": "llama-v3p2-1b-instruct",
    "displayName": "llama-v3p2-1b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/llama-v3p2-3b-instruct",
    "name": "llama-v3p2-3b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 1e-7,
      "source": "https://fireworks.ai/pricing",
      "supports_function_calling": false,
      "supports_response_schema": true,
      "supports_tool_choice": false,
      "provider": "fireworks_ai"
    },
    "slug": "llama-v3p2-3b-instruct",
    "displayName": "llama-v3p2-3b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/llama-v3p2-90b-vision-instruct",
    "name": "llama-v3p2-90b-vision-instruct",
    "provider": "fireworks_ai",
    "data": {
      "input_cost_per_token": 9e-7,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 9e-7,
      "source": "https://fireworks.ai/pricing",
      "supports_response_schema": true,
      "supports_tool_choice": false,
      "supports_vision": true,
      "provider": "fireworks_ai"
    },
    "slug": "llama-v3p2-90b-vision-instruct",
    "displayName": "llama-v3p2-90b-vision-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/llama4-maverick-instruct-basic",
    "name": "llama4-maverick-instruct-basic",
    "provider": "fireworks_ai",
    "data": {
      "input_cost_per_token": 2.2e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 8.8e-7,
      "source": "https://fireworks.ai/pricing",
      "supports_response_schema": true,
      "supports_tool_choice": false,
      "provider": "fireworks_ai"
    },
    "slug": "llama4-maverick-instruct-basic",
    "displayName": "llama4-maverick-instruct-basic"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/llama4-scout-instruct-basic",
    "name": "llama4-scout-instruct-basic",
    "provider": "fireworks_ai",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "source": "https://fireworks.ai/pricing",
      "supports_response_schema": true,
      "supports_tool_choice": false,
      "provider": "fireworks_ai"
    },
    "slug": "llama4-scout-instruct-basic",
    "displayName": "llama4-scout-instruct-basic"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct-hf",
    "name": "mixtral-8x22b-instruct-hf",
    "provider": "fireworks_ai",
    "data": {
      "input_cost_per_token": 0.0000012,
      "max_input_tokens": 65536,
      "max_output_tokens": 65536,
      "max_tokens": 65536,
      "mode": "chat",
      "output_cost_per_token": 0.0000012,
      "source": "https://fireworks.ai/pricing",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "fireworks_ai"
    },
    "slug": "mixtral-8x22b-instruct-hf",
    "displayName": "mixtral-8x22b-instruct-hf"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2-72b-instruct",
    "name": "qwen2-72b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "input_cost_per_token": 9e-7,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 9e-7,
      "source": "https://fireworks.ai/pricing",
      "supports_function_calling": false,
      "supports_response_schema": true,
      "supports_tool_choice": false,
      "provider": "fireworks_ai"
    },
    "slug": "qwen2-72b-instruct",
    "displayName": "qwen2-72b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct",
    "name": "qwen2p5-coder-32b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "input_cost_per_token": 9e-7,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 9e-7,
      "source": "https://fireworks.ai/pricing",
      "supports_function_calling": false,
      "supports_response_schema": true,
      "supports_tool_choice": false,
      "provider": "fireworks_ai"
    },
    "slug": "qwen2p5-coder-32b-instruct",
    "displayName": "qwen2p5-coder-32b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/yi-large",
    "name": "yi-large",
    "provider": "fireworks_ai",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.000003,
      "source": "https://fireworks.ai/pricing",
      "supports_function_calling": false,
      "supports_response_schema": true,
      "supports_tool_choice": false,
      "provider": "fireworks_ai"
    },
    "slug": "yi-large",
    "displayName": "yi-large"
  },
  {
    "id": "fireworks_ai/thenlper/gte-large",
    "name": "gte-large",
    "provider": "fireworks_ai-embedding-models",
    "data": {
      "input_cost_per_token": 1.6e-8,
      "max_input_tokens": 512,
      "max_tokens": 512,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "source": "https://fireworks.ai/pricing",
      "provider": "fireworks_ai-embedding-models"
    },
    "slug": "gte-large",
    "displayName": "gte-large"
  },
  {
    "id": "friendliai/meta-llama-3.1-70b-instruct",
    "name": "meta-llama-3.1-70b-instruct",
    "provider": "friendliai",
    "data": {
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "friendliai"
    },
    "slug": "meta-llama-3.1-70b-instruct",
    "displayName": "meta-llama-3.1-70b-instruct"
  },
  {
    "id": "friendliai/meta-llama-3.1-8b-instruct",
    "name": "meta-llama-3.1-8b-instruct",
    "provider": "friendliai",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 1e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "friendliai"
    },
    "slug": "meta-llama-3.1-8b-instruct",
    "displayName": "meta-llama-3.1-8b-instruct"
  },
  {
    "id": "ft:babbage-002",
    "name": "ft:babbage-002",
    "provider": "text-completion-openai",
    "data": {
      "input_cost_per_token": 0.0000016,
      "input_cost_per_token_batches": 2e-7,
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "completion",
      "output_cost_per_token": 0.0000016,
      "output_cost_per_token_batches": 2e-7,
      "provider": "text-completion-openai"
    },
    "slug": "ft-babbage-002",
    "displayName": "ft:babbage-002"
  },
  {
    "id": "ft:davinci-002",
    "name": "ft:davinci-002",
    "provider": "text-completion-openai",
    "data": {
      "input_cost_per_token": 0.000012,
      "input_cost_per_token_batches": 0.000001,
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "completion",
      "output_cost_per_token": 0.000012,
      "output_cost_per_token_batches": 0.000001,
      "provider": "text-completion-openai"
    },
    "slug": "ft-davinci-002",
    "displayName": "ft:davinci-002"
  },
  {
    "id": "ft:gpt-3.5-turbo",
    "name": "ft:gpt-3.5-turbo",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 0.000003,
      "input_cost_per_token_batches": 0.0000015,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000006,
      "output_cost_per_token_batches": 0.000003,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "ft-gpt-3.5-turbo",
    "displayName": "ft:gpt-3.5-turbo"
  },
  {
    "id": "ft:gpt-3.5-turbo-0125",
    "name": "ft:gpt-3.5-turbo-0125",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000006,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "ft-gpt-3.5-turbo-0125",
    "displayName": "ft:gpt-3.5-turbo-0125"
  },
  {
    "id": "ft:gpt-3.5-turbo-0613",
    "name": "ft:gpt-3.5-turbo-0613",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000006,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "ft-gpt-3.5-turbo-0613",
    "displayName": "ft:gpt-3.5-turbo-0613"
  },
  {
    "id": "ft:gpt-3.5-turbo-1106",
    "name": "ft:gpt-3.5-turbo-1106",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000006,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "ft-gpt-3.5-turbo-1106",
    "displayName": "ft:gpt-3.5-turbo-1106"
  },
  {
    "id": "ft:gpt-4-0613",
    "name": "ft:gpt-4-0613",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 0.00003,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00006,
      "source": "OpenAI needs to add pricing for this ft model, will be updated when added by OpenAI. Defaulting to base model pricing",
      "supports_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "ft-gpt-4-0613",
    "displayName": "ft:gpt-4-0613"
  },
  {
    "id": "ft:gpt-4o-2024-08-06",
    "name": "ft:gpt-4o-2024-08-06",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 0.000001875,
      "input_cost_per_token": 0.00000375,
      "input_cost_per_token_batches": 0.000001875,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "output_cost_per_token_batches": 0.0000075,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "ft-gpt-4o-2024-08-06",
    "displayName": "ft:gpt-4o-2024-08-06"
  },
  {
    "id": "ft:gpt-4o-2024-11-20",
    "name": "ft:gpt-4o-2024-11-20",
    "provider": "openai",
    "data": {
      "cache_creation_input_token_cost": 0.000001875,
      "input_cost_per_token": 0.00000375,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "ft-gpt-4o-2024-11-20",
    "displayName": "ft:gpt-4o-2024-11-20"
  },
  {
    "id": "ft:gpt-4o-mini-2024-07-18",
    "name": "ft:gpt-4o-mini-2024-07-18",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 1.5e-7,
      "input_cost_per_token": 3e-7,
      "input_cost_per_token_batches": 1.5e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.0000012,
      "output_cost_per_token_batches": 6e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "ft-gpt-4o-mini-2024-07-18",
    "displayName": "ft:gpt-4o-mini-2024-07-18"
  },
  {
    "id": "ft:gpt-4.1-2025-04-14",
    "name": "ft:gpt-4.1-2025-04-14",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 7.5e-7,
      "input_cost_per_token": 0.000003,
      "input_cost_per_token_batches": 0.0000015,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.000012,
      "output_cost_per_token_batches": 0.000006,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "ft-gpt-4.1-2025-04-14",
    "displayName": "ft:gpt-4.1-2025-04-14"
  },
  {
    "id": "ft:gpt-4.1-mini-2025-04-14",
    "name": "ft:gpt-4.1-mini-2025-04-14",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 2e-7,
      "input_cost_per_token": 8e-7,
      "input_cost_per_token_batches": 4e-7,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.0000032,
      "output_cost_per_token_batches": 0.0000016,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "ft-gpt-4.1-mini-2025-04-14",
    "displayName": "ft:gpt-4.1-mini-2025-04-14"
  },
  {
    "id": "ft:gpt-4.1-nano-2025-04-14",
    "name": "ft:gpt-4.1-nano-2025-04-14",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 5e-8,
      "input_cost_per_token": 2e-7,
      "input_cost_per_token_batches": 1e-7,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 8e-7,
      "output_cost_per_token_batches": 4e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "ft-gpt-4.1-nano-2025-04-14",
    "displayName": "ft:gpt-4.1-nano-2025-04-14"
  },
  {
    "id": "ft:o4-mini-2025-04-16",
    "name": "ft:o4-mini-2025-04-16",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 0.000001,
      "input_cost_per_token": 0.000004,
      "input_cost_per_token_batches": 0.000002,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "chat",
      "output_cost_per_token": 0.000016,
      "output_cost_per_token_batches": 0.000008,
      "supports_function_calling": true,
      "supports_parallel_function_calling": false,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "ft-o4-mini-2025-04-16",
    "displayName": "ft:o4-mini-2025-04-16"
  },
  {
    "id": "gemini-1.0-pro",
    "name": "gemini-1.0-pro",
    "provider": "vertex_ai-language-models",
    "data": {
      "input_cost_per_character": 1.25e-7,
      "input_cost_per_image": 0.0025,
      "input_cost_per_token": 5e-7,
      "input_cost_per_video_per_second": 0.002,
      "max_input_tokens": 32760,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_character": 3.75e-7,
      "output_cost_per_token": 0.0000015,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#google_models",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-1.0-pro",
    "displayName": "gemini-1.0-pro"
  },
  {
    "id": "gemini-1.0-pro-001",
    "name": "gemini-1.0-pro-001",
    "provider": "vertex_ai-language-models",
    "data": {
      "deprecation_date": "2025-04-09",
      "input_cost_per_character": 1.25e-7,
      "input_cost_per_image": 0.0025,
      "input_cost_per_token": 5e-7,
      "input_cost_per_video_per_second": 0.002,
      "max_input_tokens": 32760,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_character": 3.75e-7,
      "output_cost_per_token": 0.0000015,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-1.0-pro-001",
    "displayName": "gemini-1.0-pro-001"
  },
  {
    "id": "gemini-1.0-pro-002",
    "name": "gemini-1.0-pro-002",
    "provider": "vertex_ai-language-models",
    "data": {
      "deprecation_date": "2025-04-09",
      "input_cost_per_character": 1.25e-7,
      "input_cost_per_image": 0.0025,
      "input_cost_per_token": 5e-7,
      "input_cost_per_video_per_second": 0.002,
      "max_input_tokens": 32760,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_character": 3.75e-7,
      "output_cost_per_token": 0.0000015,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-1.0-pro-002",
    "displayName": "gemini-1.0-pro-002"
  },
  {
    "id": "gemini-1.0-pro-vision",
    "name": "gemini-1.0-pro-vision",
    "provider": "vertex_ai-vision-models",
    "data": {
      "input_cost_per_image": 0.0025,
      "input_cost_per_token": 5e-7,
      "max_images_per_prompt": 16,
      "max_input_tokens": 16384,
      "max_output_tokens": 2048,
      "max_tokens": 2048,
      "max_video_length": 2,
      "max_videos_per_prompt": 1,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "vertex_ai-vision-models"
    },
    "slug": "gemini-1.0-pro-vision",
    "displayName": "gemini-1.0-pro-vision"
  },
  {
    "id": "gemini-1.0-pro-vision-001",
    "name": "gemini-1.0-pro-vision-001",
    "provider": "vertex_ai-vision-models",
    "data": {
      "deprecation_date": "2025-04-09",
      "input_cost_per_image": 0.0025,
      "input_cost_per_token": 5e-7,
      "max_images_per_prompt": 16,
      "max_input_tokens": 16384,
      "max_output_tokens": 2048,
      "max_tokens": 2048,
      "max_video_length": 2,
      "max_videos_per_prompt": 1,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "vertex_ai-vision-models"
    },
    "slug": "gemini-1.0-pro-vision-001",
    "displayName": "gemini-1.0-pro-vision-001"
  },
  {
    "id": "gemini-1.0-ultra",
    "name": "gemini-1.0-ultra",
    "provider": "vertex_ai-language-models",
    "data": {
      "input_cost_per_character": 1.25e-7,
      "input_cost_per_image": 0.0025,
      "input_cost_per_token": 5e-7,
      "input_cost_per_video_per_second": 0.002,
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "max_tokens": 2048,
      "mode": "chat",
      "output_cost_per_character": 3.75e-7,
      "output_cost_per_token": 0.0000015,
      "source": "As of Jun, 2024. There is no available doc on vertex ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got max_tokens info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-1.0-ultra",
    "displayName": "gemini-1.0-ultra"
  },
  {
    "id": "gemini-1.0-ultra-001",
    "name": "gemini-1.0-ultra-001",
    "provider": "vertex_ai-language-models",
    "data": {
      "input_cost_per_character": 1.25e-7,
      "input_cost_per_image": 0.0025,
      "input_cost_per_token": 5e-7,
      "input_cost_per_video_per_second": 0.002,
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "max_tokens": 2048,
      "mode": "chat",
      "output_cost_per_character": 3.75e-7,
      "output_cost_per_token": 0.0000015,
      "source": "As of Jun, 2024. There is no available doc on vertex ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got max_tokens info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-1.0-ultra-001",
    "displayName": "gemini-1.0-ultra-001"
  },
  {
    "id": "gemini-1.5-flash",
    "name": "gemini-1.5-flash",
    "provider": "vertex_ai-language-models",
    "data": {
      "deprecation_date": "2025-09-29",
      "input_cost_per_audio_per_second": 0.000002,
      "input_cost_per_audio_per_second_above_128k_tokens": 0.000004,
      "input_cost_per_character": 1.875e-8,
      "input_cost_per_character_above_128k_tokens": 2.5e-7,
      "input_cost_per_image": 0.00002,
      "input_cost_per_image_above_128k_tokens": 0.00004,
      "input_cost_per_token": 7.5e-8,
      "input_cost_per_token_above_128k_tokens": 0.000001,
      "input_cost_per_video_per_second": 0.00002,
      "input_cost_per_video_per_second_above_128k_tokens": 0.00004,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "max_pdf_size_mb": 30,
      "max_tokens": 8192,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_character": 7.5e-8,
      "output_cost_per_character_above_128k_tokens": 1.5e-7,
      "output_cost_per_token": 3e-7,
      "output_cost_per_token_above_128k_tokens": 6e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-1.5-flash",
    "displayName": "gemini-1.5-flash"
  },
  {
    "id": "gemini-1.5-flash-001",
    "name": "gemini-1.5-flash-001",
    "provider": "vertex_ai-language-models",
    "data": {
      "deprecation_date": "2025-05-24",
      "input_cost_per_audio_per_second": 0.000002,
      "input_cost_per_audio_per_second_above_128k_tokens": 0.000004,
      "input_cost_per_character": 1.875e-8,
      "input_cost_per_character_above_128k_tokens": 2.5e-7,
      "input_cost_per_image": 0.00002,
      "input_cost_per_image_above_128k_tokens": 0.00004,
      "input_cost_per_token": 7.5e-8,
      "input_cost_per_token_above_128k_tokens": 0.000001,
      "input_cost_per_video_per_second": 0.00002,
      "input_cost_per_video_per_second_above_128k_tokens": 0.00004,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "max_pdf_size_mb": 30,
      "max_tokens": 8192,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_character": 7.5e-8,
      "output_cost_per_character_above_128k_tokens": 1.5e-7,
      "output_cost_per_token": 3e-7,
      "output_cost_per_token_above_128k_tokens": 6e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-1.5-flash-001",
    "displayName": "gemini-1.5-flash-001"
  },
  {
    "id": "gemini-1.5-flash-002",
    "name": "gemini-1.5-flash-002",
    "provider": "vertex_ai-language-models",
    "data": {
      "deprecation_date": "2025-09-24",
      "input_cost_per_audio_per_second": 0.000002,
      "input_cost_per_audio_per_second_above_128k_tokens": 0.000004,
      "input_cost_per_character": 1.875e-8,
      "input_cost_per_character_above_128k_tokens": 2.5e-7,
      "input_cost_per_image": 0.00002,
      "input_cost_per_image_above_128k_tokens": 0.00004,
      "input_cost_per_token": 7.5e-8,
      "input_cost_per_token_above_128k_tokens": 0.000001,
      "input_cost_per_video_per_second": 0.00002,
      "input_cost_per_video_per_second_above_128k_tokens": 0.00004,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_pdf_size_mb": 30,
      "max_tokens": 8192,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_character": 7.5e-8,
      "output_cost_per_character_above_128k_tokens": 1.5e-7,
      "output_cost_per_token": 3e-7,
      "output_cost_per_token_above_128k_tokens": 6e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-flash",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-1.5-flash-002",
    "displayName": "gemini-1.5-flash-002"
  },
  {
    "id": "gemini-1.5-flash-preview-0514",
    "name": "gemini-1.5-flash-preview-0514",
    "provider": "vertex_ai-language-models",
    "data": {
      "deprecation_date": "2025-09-29",
      "input_cost_per_audio_per_second": 0.000002,
      "input_cost_per_audio_per_second_above_128k_tokens": 0.000004,
      "input_cost_per_character": 1.875e-8,
      "input_cost_per_character_above_128k_tokens": 2.5e-7,
      "input_cost_per_image": 0.00002,
      "input_cost_per_image_above_128k_tokens": 0.00004,
      "input_cost_per_token": 7.5e-8,
      "input_cost_per_token_above_128k_tokens": 0.000001,
      "input_cost_per_video_per_second": 0.00002,
      "input_cost_per_video_per_second_above_128k_tokens": 0.00004,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "max_pdf_size_mb": 30,
      "max_tokens": 8192,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_character": 1.875e-8,
      "output_cost_per_character_above_128k_tokens": 3.75e-8,
      "output_cost_per_token": 4.6875e-9,
      "output_cost_per_token_above_128k_tokens": 9.375e-9,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-1.5-flash-preview-0514",
    "displayName": "gemini-1.5-flash-preview-0514"
  },
  {
    "id": "gemini-1.5-pro",
    "name": "gemini-1.5-pro",
    "provider": "vertex_ai-language-models",
    "data": {
      "deprecation_date": "2025-09-29",
      "input_cost_per_audio_per_second": 0.00003125,
      "input_cost_per_audio_per_second_above_128k_tokens": 0.0000625,
      "input_cost_per_character": 3.125e-7,
      "input_cost_per_character_above_128k_tokens": 6.25e-7,
      "input_cost_per_image": 0.00032875,
      "input_cost_per_image_above_128k_tokens": 0.0006575,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_above_128k_tokens": 0.0000025,
      "input_cost_per_video_per_second": 0.00032875,
      "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_character": 0.00000125,
      "output_cost_per_character_above_128k_tokens": 0.0000025,
      "output_cost_per_token": 0.000005,
      "output_cost_per_token_above_128k_tokens": 0.00001,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-1.5-pro",
    "displayName": "gemini-1.5-pro"
  },
  {
    "id": "gemini-1.5-pro-001",
    "name": "gemini-1.5-pro-001",
    "provider": "vertex_ai-language-models",
    "data": {
      "deprecation_date": "2025-05-24",
      "input_cost_per_audio_per_second": 0.00003125,
      "input_cost_per_audio_per_second_above_128k_tokens": 0.0000625,
      "input_cost_per_character": 3.125e-7,
      "input_cost_per_character_above_128k_tokens": 6.25e-7,
      "input_cost_per_image": 0.00032875,
      "input_cost_per_image_above_128k_tokens": 0.0006575,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_above_128k_tokens": 0.0000025,
      "input_cost_per_video_per_second": 0.00032875,
      "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_character": 0.00000125,
      "output_cost_per_character_above_128k_tokens": 0.0000025,
      "output_cost_per_token": 0.000005,
      "output_cost_per_token_above_128k_tokens": 0.00001,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-1.5-pro-001",
    "displayName": "gemini-1.5-pro-001"
  },
  {
    "id": "gemini-1.5-pro-002",
    "name": "gemini-1.5-pro-002",
    "provider": "vertex_ai-language-models",
    "data": {
      "deprecation_date": "2025-09-24",
      "input_cost_per_audio_per_second": 0.00003125,
      "input_cost_per_audio_per_second_above_128k_tokens": 0.0000625,
      "input_cost_per_character": 3.125e-7,
      "input_cost_per_character_above_128k_tokens": 6.25e-7,
      "input_cost_per_image": 0.00032875,
      "input_cost_per_image_above_128k_tokens": 0.0006575,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_above_128k_tokens": 0.0000025,
      "input_cost_per_video_per_second": 0.00032875,
      "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_character": 0.00000125,
      "output_cost_per_character_above_128k_tokens": 0.0000025,
      "output_cost_per_token": 0.000005,
      "output_cost_per_token_above_128k_tokens": 0.00001,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-pro",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-1.5-pro-002",
    "displayName": "gemini-1.5-pro-002"
  },
  {
    "id": "gemini-1.5-pro-preview-0215",
    "name": "gemini-1.5-pro-preview-0215",
    "provider": "vertex_ai-language-models",
    "data": {
      "deprecation_date": "2025-09-29",
      "input_cost_per_audio_per_second": 0.00003125,
      "input_cost_per_audio_per_second_above_128k_tokens": 0.0000625,
      "input_cost_per_character": 3.125e-7,
      "input_cost_per_character_above_128k_tokens": 6.25e-7,
      "input_cost_per_image": 0.00032875,
      "input_cost_per_image_above_128k_tokens": 0.0006575,
      "input_cost_per_token": 7.8125e-8,
      "input_cost_per_token_above_128k_tokens": 1.5625e-7,
      "input_cost_per_video_per_second": 0.00032875,
      "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_character": 0.00000125,
      "output_cost_per_character_above_128k_tokens": 0.0000025,
      "output_cost_per_token": 3.125e-7,
      "output_cost_per_token_above_128k_tokens": 6.25e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-1.5-pro-preview-0215",
    "displayName": "gemini-1.5-pro-preview-0215"
  },
  {
    "id": "gemini-1.5-pro-preview-0409",
    "name": "gemini-1.5-pro-preview-0409",
    "provider": "vertex_ai-language-models",
    "data": {
      "deprecation_date": "2025-09-29",
      "input_cost_per_audio_per_second": 0.00003125,
      "input_cost_per_audio_per_second_above_128k_tokens": 0.0000625,
      "input_cost_per_character": 3.125e-7,
      "input_cost_per_character_above_128k_tokens": 6.25e-7,
      "input_cost_per_image": 0.00032875,
      "input_cost_per_image_above_128k_tokens": 0.0006575,
      "input_cost_per_token": 7.8125e-8,
      "input_cost_per_token_above_128k_tokens": 1.5625e-7,
      "input_cost_per_video_per_second": 0.00032875,
      "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_character": 0.00000125,
      "output_cost_per_character_above_128k_tokens": 0.0000025,
      "output_cost_per_token": 3.125e-7,
      "output_cost_per_token_above_128k_tokens": 6.25e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-1.5-pro-preview-0409",
    "displayName": "gemini-1.5-pro-preview-0409"
  },
  {
    "id": "gemini-1.5-pro-preview-0514",
    "name": "gemini-1.5-pro-preview-0514",
    "provider": "vertex_ai-language-models",
    "data": {
      "deprecation_date": "2025-09-29",
      "input_cost_per_audio_per_second": 0.00003125,
      "input_cost_per_audio_per_second_above_128k_tokens": 0.0000625,
      "input_cost_per_character": 3.125e-7,
      "input_cost_per_character_above_128k_tokens": 6.25e-7,
      "input_cost_per_image": 0.00032875,
      "input_cost_per_image_above_128k_tokens": 0.0006575,
      "input_cost_per_token": 7.8125e-8,
      "input_cost_per_token_above_128k_tokens": 1.5625e-7,
      "input_cost_per_video_per_second": 0.00032875,
      "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_character": 0.00000125,
      "output_cost_per_character_above_128k_tokens": 0.0000025,
      "output_cost_per_token": 3.125e-7,
      "output_cost_per_token_above_128k_tokens": 6.25e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-1.5-pro-preview-0514",
    "displayName": "gemini-1.5-pro-preview-0514"
  },
  {
    "id": "gemini-2.0-flash",
    "name": "gemini-2.0-flash",
    "provider": "vertex_ai-language-models",
    "data": {
      "cache_read_input_token_cost": 2.5e-8,
      "deprecation_date": "2026-03-31",
      "input_cost_per_audio_token": 7e-7,
      "input_cost_per_token": 1e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_pdf_size_mb": 30,
      "max_tokens": 8192,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "source": "https://ai.google.dev/pricing#2_0flash",
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-2.0-flash",
    "displayName": "gemini-2.0-flash"
  },
  {
    "id": "gemini-2.0-flash-001",
    "name": "gemini-2.0-flash-001",
    "provider": "vertex_ai-language-models",
    "data": {
      "cache_read_input_token_cost": 3.75e-8,
      "deprecation_date": "2026-03-31",
      "input_cost_per_audio_token": 0.000001,
      "input_cost_per_token": 1.5e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_pdf_size_mb": 30,
      "max_tokens": 8192,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-2.0-flash-001",
    "displayName": "gemini-2.0-flash-001"
  },
  {
    "id": "gemini-2.0-flash-exp",
    "name": "gemini-2.0-flash-exp",
    "provider": "vertex_ai-language-models",
    "data": {
      "cache_read_input_token_cost": 3.75e-8,
      "input_cost_per_audio_per_second": 0,
      "input_cost_per_audio_per_second_above_128k_tokens": 0,
      "input_cost_per_character": 0,
      "input_cost_per_character_above_128k_tokens": 0,
      "input_cost_per_image": 0,
      "input_cost_per_image_above_128k_tokens": 0,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_token_above_128k_tokens": 0,
      "input_cost_per_video_per_second": 0,
      "input_cost_per_video_per_second_above_128k_tokens": 0,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_pdf_size_mb": 30,
      "max_tokens": 8192,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_character": 0,
      "output_cost_per_character_above_128k_tokens": 0,
      "output_cost_per_token": 6e-7,
      "output_cost_per_token_above_128k_tokens": 0,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-2.0-flash-exp",
    "displayName": "gemini-2.0-flash-exp"
  },
  {
    "id": "gemini-2.0-flash-lite",
    "name": "gemini-2.0-flash-lite",
    "provider": "vertex_ai-language-models",
    "data": {
      "cache_read_input_token_cost": 1.875e-8,
      "deprecation_date": "2026-03-31",
      "input_cost_per_audio_token": 7.5e-8,
      "input_cost_per_token": 7.5e-8,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_pdf_size_mb": 50,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-2.0-flash-lite",
    "displayName": "gemini-2.0-flash-lite"
  },
  {
    "id": "gemini-2.0-flash-lite-001",
    "name": "gemini-2.0-flash-lite-001",
    "provider": "vertex_ai-language-models",
    "data": {
      "cache_read_input_token_cost": 1.875e-8,
      "deprecation_date": "2026-03-31",
      "input_cost_per_audio_token": 7.5e-8,
      "input_cost_per_token": 7.5e-8,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_pdf_size_mb": 50,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-2.0-flash-lite-001",
    "displayName": "gemini-2.0-flash-lite-001"
  },
  {
    "id": "gemini-2.0-flash-live-preview-04-09",
    "name": "gemini-2.0-flash-live-preview-04-09",
    "provider": "vertex_ai-language-models",
    "data": {
      "cache_read_input_token_cost": 7.5e-8,
      "input_cost_per_audio_token": 0.000003,
      "input_cost_per_image": 0.000003,
      "input_cost_per_token": 5e-7,
      "input_cost_per_video_per_second": 0.000003,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_audio_token": 0.000012,
      "output_cost_per_token": 0.000002,
      "rpm": 10,
      "source": "https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini#gemini-2-0-flash-live-preview-04-09",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text",
        "audio"
      ],
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tpm": 250000,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-2.0-flash-live-preview-04-09",
    "displayName": "gemini-2.0-flash-live-preview-04-09"
  },
  {
    "id": "gemini-2.0-flash-preview-image-generation",
    "name": "gemini-2.0-flash-preview-image-generation",
    "provider": "vertex_ai-language-models",
    "data": {
      "deprecation_date": "2025-11-14",
      "cache_read_input_token_cost": 2.5e-8,
      "input_cost_per_audio_token": 7e-7,
      "input_cost_per_token": 1e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_pdf_size_mb": 30,
      "max_tokens": 8192,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "source": "https://ai.google.dev/pricing#2_0flash",
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-2.0-flash-preview-image-generation",
    "displayName": "gemini-2.0-flash-preview-image-generation"
  },
  {
    "id": "gemini-2.0-pro-exp-02-05",
    "name": "gemini-2.0-pro-exp-02-05",
    "provider": "vertex_ai-language-models",
    "data": {
      "cache_read_input_token_cost": 3.125e-7,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_above_200k_tokens": 0.0000025,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "max_pdf_size_mb": 30,
      "max_tokens": 8192,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_above_200k_tokens": 0.000015,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_input": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_video_input": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-2.0-pro-exp-02-05",
    "displayName": "gemini-2.0-pro-exp-02-05"
  },
  {
    "id": "gemini-2.5-flash",
    "name": "gemini-2.5-flash",
    "provider": "vertex_ai-language-models",
    "data": {
      "cache_read_input_token_cost": 3e-8,
      "input_cost_per_audio_token": 0.000001,
      "input_cost_per_token": 3e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_reasoning_token": 0.0000025,
      "output_cost_per_token": 0.0000025,
      "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-2.5-flash",
    "displayName": "gemini-2.5-flash"
  },
  {
    "id": "gemini-2.5-flash-image",
    "name": "gemini-2.5-flash-image",
    "provider": "vertex_ai-language-models",
    "data": {
      "cache_read_input_token_cost": 3e-8,
      "input_cost_per_audio_token": 0.000001,
      "input_cost_per_token": 3e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "max_pdf_size_mb": 30,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "image_generation",
      "output_cost_per_image": 0.039,
      "output_cost_per_image_token": 0.00003,
      "output_cost_per_reasoning_token": 0.0000025,
      "output_cost_per_token": 0.0000025,
      "rpm": 100000,
      "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-flash-image",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "supports_web_search": false,
      "tpm": 8000000,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-2.5-flash-image",
    "displayName": "gemini-2.5-flash-image"
  },
  {
    "id": "gemini-2.5-flash-image-preview",
    "name": "gemini-2.5-flash-image-preview",
    "provider": "vertex_ai-language-models",
    "data": {
      "deprecation_date": "2026-01-15",
      "cache_read_input_token_cost": 7.5e-8,
      "input_cost_per_audio_token": 0.000001,
      "input_cost_per_image_token": 3e-7,
      "input_cost_per_token": 3e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "image_generation",
      "output_cost_per_image": 0.039,
      "output_cost_per_image_token": 0.00003,
      "output_cost_per_reasoning_token": 0.00003,
      "output_cost_per_token": 0.00003,
      "rpm": 100000,
      "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tpm": 8000000,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-2.5-flash-image-preview",
    "displayName": "gemini-2.5-flash-image-preview"
  },
  {
    "id": "gemini-3-pro-image-preview",
    "name": "gemini-3-pro-image-preview",
    "provider": "vertex_ai-language-models",
    "data": {
      "input_cost_per_image": 0.0011,
      "input_cost_per_token": 0.000002,
      "input_cost_per_token_batches": 0.000001,
      "max_input_tokens": 65536,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "image_generation",
      "output_cost_per_image": 0.134,
      "output_cost_per_image_token": 0.00012,
      "output_cost_per_token": 0.000012,
      "output_cost_per_token_batches": 0.000006,
      "source": "https://ai.google.dev/gemini-api/docs/pricing",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_function_calling": false,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-3-pro-image-preview",
    "displayName": "gemini-3-pro-image-preview"
  },
  {
    "id": "deep-research-pro-preview-12-2025",
    "name": "deep-research-pro-preview-12-2025",
    "provider": "vertex_ai-language-models",
    "data": {
      "input_cost_per_image": 0.0011,
      "input_cost_per_token": 0.000002,
      "input_cost_per_token_batches": 0.000001,
      "max_input_tokens": 65536,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "image_generation",
      "output_cost_per_image": 0.134,
      "output_cost_per_image_token": 0.00012,
      "output_cost_per_token": 0.000012,
      "output_cost_per_token_batches": 0.000006,
      "source": "https://ai.google.dev/gemini-api/docs/pricing",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_function_calling": false,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "deep-research-pro-preview-12-2025",
    "displayName": "deep-research-pro-preview-12-2025"
  },
  {
    "id": "gemini-2.5-flash-lite",
    "name": "gemini-2.5-flash-lite",
    "provider": "vertex_ai-language-models",
    "data": {
      "cache_read_input_token_cost": 1e-8,
      "input_cost_per_audio_token": 3e-7,
      "input_cost_per_token": 1e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_reasoning_token": 4e-7,
      "output_cost_per_token": 4e-7,
      "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-2.5-flash-lite",
    "displayName": "gemini-2.5-flash-lite"
  },
  {
    "id": "gemini-2.5-flash-lite-preview-09-2025",
    "name": "gemini-2.5-flash-lite-preview-09-2025",
    "provider": "vertex_ai-language-models",
    "data": {
      "cache_read_input_token_cost": 1e-8,
      "input_cost_per_audio_token": 3e-7,
      "input_cost_per_token": 1e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_reasoning_token": 4e-7,
      "output_cost_per_token": 4e-7,
      "source": "https://developers.googleblog.com/en/continuing-to-bring-you-our-latest-models-with-an-improved-gemini-2-5-flash-and-flash-lite-release/",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-2.5-flash-lite-preview-09-2025",
    "displayName": "gemini-2.5-flash-lite-preview-09-2025"
  },
  {
    "id": "gemini-2.5-flash-preview-09-2025",
    "name": "gemini-2.5-flash-preview-09-2025",
    "provider": "vertex_ai-language-models",
    "data": {
      "cache_read_input_token_cost": 7.5e-8,
      "input_cost_per_audio_token": 0.000001,
      "input_cost_per_token": 3e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_reasoning_token": 0.0000025,
      "output_cost_per_token": 0.0000025,
      "source": "https://developers.googleblog.com/en/continuing-to-bring-you-our-latest-models-with-an-improved-gemini-2-5-flash-and-flash-lite-release/",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-2.5-flash-preview-09-2025",
    "displayName": "gemini-2.5-flash-preview-09-2025"
  },
  {
    "id": "gemini-live-2.5-flash-preview-native-audio-09-2025",
    "name": "gemini-live-2.5-flash-preview-native-audio-09-2025",
    "provider": "vertex_ai-language-models",
    "data": {
      "cache_read_input_token_cost": 7.5e-8,
      "input_cost_per_audio_token": 0.000003,
      "input_cost_per_token": 3e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_audio_token": 0.000012,
      "output_cost_per_token": 0.000002,
      "source": "https://ai.google.dev/gemini-api/docs/pricing",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text",
        "audio"
      ],
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-live-2.5-flash-preview-native-audio-09-2025",
    "displayName": "gemini-live-2.5-flash-preview-native-audio-09-2025"
  },
  {
    "id": "gemini/gemini-live-2.5-flash-preview-native-audio-09-2025",
    "name": "gemini-live-2.5-flash-preview-native-audio-09-2025",
    "provider": "gemini",
    "data": {
      "cache_read_input_token_cost": 7.5e-8,
      "input_cost_per_audio_token": 0.000003,
      "input_cost_per_token": 3e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_audio_token": 0.000012,
      "output_cost_per_token": 0.000002,
      "rpm": 100000,
      "source": "https://ai.google.dev/gemini-api/docs/pricing",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text",
        "audio"
      ],
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tpm": 8000000,
      "provider": "gemini"
    },
    "slug": "gemini-live-2.5-flash-preview-native-audio-09-2025",
    "displayName": "gemini-live-2.5-flash-preview-native-audio-09-2025"
  },
  {
    "id": "gemini-2.5-flash-lite-preview-06-17",
    "name": "gemini-2.5-flash-lite-preview-06-17",
    "provider": "vertex_ai-language-models",
    "data": {
      "deprecation_date": "2025-11-18",
      "cache_read_input_token_cost": 2.5e-8,
      "input_cost_per_audio_token": 5e-7,
      "input_cost_per_token": 1e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_reasoning_token": 4e-7,
      "output_cost_per_token": 4e-7,
      "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-2.5-flash-lite-preview-06-17",
    "displayName": "gemini-2.5-flash-lite-preview-06-17"
  },
  {
    "id": "gemini-2.5-flash-preview-04-17",
    "name": "gemini-2.5-flash-preview-04-17",
    "provider": "vertex_ai-language-models",
    "data": {
      "cache_read_input_token_cost": 3.75e-8,
      "input_cost_per_audio_token": 0.000001,
      "input_cost_per_token": 1.5e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_reasoning_token": 0.0000035,
      "output_cost_per_token": 6e-7,
      "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-2.5-flash-preview-04-17",
    "displayName": "gemini-2.5-flash-preview-04-17"
  },
  {
    "id": "gemini-2.5-flash-preview-05-20",
    "name": "gemini-2.5-flash-preview-05-20",
    "provider": "vertex_ai-language-models",
    "data": {
      "deprecation_date": "2025-11-18",
      "cache_read_input_token_cost": 7.5e-8,
      "input_cost_per_audio_token": 0.000001,
      "input_cost_per_token": 3e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_reasoning_token": 0.0000025,
      "output_cost_per_token": 0.0000025,
      "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-2.5-flash-preview-05-20",
    "displayName": "gemini-2.5-flash-preview-05-20"
  },
  {
    "id": "gemini-2.5-pro",
    "name": "gemini-2.5-pro",
    "provider": "vertex_ai-language-models",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "cache_read_input_token_cost_above_200k_tokens": 2.5e-7,
      "cache_creation_input_token_cost_above_200k_tokens": 2.5e-7,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_above_200k_tokens": 0.0000025,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_above_200k_tokens": 0.000015,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_input": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_video_input": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-2.5-pro",
    "displayName": "gemini-2.5-pro"
  },
  {
    "id": "gemini-3-pro-preview",
    "name": "gemini-3-pro-preview",
    "provider": "vertex_ai-language-models",
    "data": {
      "cache_read_input_token_cost": 2e-7,
      "cache_read_input_token_cost_above_200k_tokens": 4e-7,
      "cache_creation_input_token_cost_above_200k_tokens": 2.5e-7,
      "input_cost_per_token": 0.000002,
      "input_cost_per_token_above_200k_tokens": 0.000004,
      "input_cost_per_token_batches": 0.000001,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 0.000012,
      "output_cost_per_token_above_200k_tokens": 0.000018,
      "output_cost_per_token_batches": 0.000006,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_input": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_video_input": true,
      "supports_vision": true,
      "supports_web_search": true,
      "supports_native_streaming": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-3-pro-preview",
    "displayName": "gemini-3-pro-preview"
  },
  {
    "id": "vertex_ai/gemini-3-pro-preview",
    "name": "gemini-3-pro-preview",
    "provider": "vertex_ai",
    "data": {
      "cache_read_input_token_cost": 2e-7,
      "cache_read_input_token_cost_above_200k_tokens": 4e-7,
      "cache_creation_input_token_cost_above_200k_tokens": 2.5e-7,
      "input_cost_per_token": 0.000002,
      "input_cost_per_token_above_200k_tokens": 0.000004,
      "input_cost_per_token_batches": 0.000001,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 0.000012,
      "output_cost_per_token_above_200k_tokens": 0.000018,
      "output_cost_per_token_batches": 0.000006,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_input": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_video_input": true,
      "supports_vision": true,
      "supports_web_search": true,
      "supports_native_streaming": true,
      "provider": "vertex_ai"
    },
    "slug": "gemini-3-pro-preview",
    "displayName": "gemini-3-pro-preview"
  },
  {
    "id": "vertex_ai/gemini-3-flash-preview",
    "name": "gemini-3-flash-preview",
    "provider": "vertex_ai",
    "data": {
      "cache_read_input_token_cost": 5e-8,
      "input_cost_per_token": 5e-7,
      "input_cost_per_audio_token": 0.000001,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 0.000003,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_input": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_video_input": true,
      "supports_vision": true,
      "supports_web_search": true,
      "supports_native_streaming": true,
      "provider": "vertex_ai"
    },
    "slug": "gemini-3-flash-preview",
    "displayName": "gemini-3-flash-preview"
  },
  {
    "id": "gemini-2.5-pro-exp-03-25",
    "name": "gemini-2.5-pro-exp-03-25",
    "provider": "vertex_ai-language-models",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "cache_read_input_token_cost_above_200k_tokens": 2.5e-7,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_above_200k_tokens": 0.0000025,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_above_200k_tokens": 0.000015,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_input": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_video_input": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-2.5-pro-exp-03-25",
    "displayName": "gemini-2.5-pro-exp-03-25"
  },
  {
    "id": "gemini-2.5-pro-preview-03-25",
    "name": "gemini-2.5-pro-preview-03-25",
    "provider": "vertex_ai-language-models",
    "data": {
      "deprecation_date": "2025-12-02",
      "cache_read_input_token_cost": 1.25e-7,
      "cache_read_input_token_cost_above_200k_tokens": 2.5e-7,
      "input_cost_per_audio_token": 0.00000125,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_above_200k_tokens": 0.0000025,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_above_200k_tokens": 0.000015,
      "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-2.5-pro-preview-03-25",
    "displayName": "gemini-2.5-pro-preview-03-25"
  },
  {
    "id": "gemini-2.5-pro-preview-05-06",
    "name": "gemini-2.5-pro-preview-05-06",
    "provider": "vertex_ai-language-models",
    "data": {
      "deprecation_date": "2025-12-02",
      "cache_read_input_token_cost": 1.25e-7,
      "cache_read_input_token_cost_above_200k_tokens": 2.5e-7,
      "input_cost_per_audio_token": 0.00000125,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_above_200k_tokens": 0.0000025,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_above_200k_tokens": 0.000015,
      "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supported_regions": [
        "global"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-2.5-pro-preview-05-06",
    "displayName": "gemini-2.5-pro-preview-05-06"
  },
  {
    "id": "gemini-2.5-pro-preview-06-05",
    "name": "gemini-2.5-pro-preview-06-05",
    "provider": "vertex_ai-language-models",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "cache_read_input_token_cost_above_200k_tokens": 2.5e-7,
      "input_cost_per_audio_token": 0.00000125,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_above_200k_tokens": 0.0000025,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_above_200k_tokens": 0.000015,
      "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-2.5-pro-preview-06-05",
    "displayName": "gemini-2.5-pro-preview-06-05"
  },
  {
    "id": "gemini-2.5-pro-preview-tts",
    "name": "gemini-2.5-pro-preview-tts",
    "provider": "vertex_ai-language-models",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "cache_read_input_token_cost_above_200k_tokens": 2.5e-7,
      "input_cost_per_audio_token": 7e-7,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_above_200k_tokens": 0.0000025,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_above_200k_tokens": 0.000015,
      "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview",
      "supported_modalities": [
        "text"
      ],
      "supported_output_modalities": [
        "audio"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-2.5-pro-preview-tts",
    "displayName": "gemini-2.5-pro-preview-tts"
  },
  {
    "id": "gemini-robotics-er-1.5-preview",
    "name": "gemini-robotics-er-1.5-preview",
    "provider": "vertex_ai-language-models",
    "data": {
      "cache_read_input_token_cost": 0,
      "input_cost_per_token": 3e-7,
      "input_cost_per_audio_token": 0.000001,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_tokens": 65535,
      "mode": "chat",
      "output_cost_per_token": 0.0000025,
      "output_cost_per_reasoning_token": 0.0000025,
      "source": "https://ai.google.dev/gemini-api/docs/models#gemini-robotics-er-1-5-preview",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions"
      ],
      "supported_modalities": [
        "text",
        "image",
        "video",
        "audio"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": false,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-robotics-er-1.5-preview",
    "displayName": "gemini-robotics-er-1.5-preview"
  },
  {
    "id": "gemini/gemini-robotics-er-1.5-preview",
    "name": "gemini-robotics-er-1.5-preview",
    "provider": "gemini",
    "data": {
      "cache_read_input_token_cost": 0,
      "input_cost_per_token": 3e-7,
      "input_cost_per_audio_token": 0.000001,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_tokens": 65535,
      "mode": "chat",
      "output_cost_per_token": 0.0000025,
      "output_cost_per_reasoning_token": 0.0000025,
      "source": "https://ai.google.dev/gemini-api/docs/models#gemini-robotics-er-1-5-preview",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions"
      ],
      "supported_modalities": [
        "text",
        "image",
        "video",
        "audio"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": false,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "gemini"
    },
    "slug": "gemini-robotics-er-1.5-preview",
    "displayName": "gemini-robotics-er-1.5-preview"
  },
  {
    "id": "gemini-2.5-computer-use-preview-10-2025",
    "name": "gemini-2.5-computer-use-preview-10-2025",
    "provider": "vertex_ai-language-models",
    "data": {
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_above_200k_tokens": 0.0000025,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_above_200k_tokens": 0.000015,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/computer-use",
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-2.5-computer-use-preview-10-2025",
    "displayName": "gemini-2.5-computer-use-preview-10-2025"
  },
  {
    "id": "gemini-embedding-001",
    "name": "gemini-embedding-001",
    "provider": "vertex_ai-embedding-models",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 2048,
      "max_tokens": 2048,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_vector_size": 3072,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models",
      "provider": "vertex_ai-embedding-models"
    },
    "slug": "gemini-embedding-001",
    "displayName": "gemini-embedding-001"
  },
  {
    "id": "gemini-pro",
    "name": "gemini-pro",
    "provider": "vertex_ai-language-models",
    "data": {
      "input_cost_per_character": 1.25e-7,
      "input_cost_per_image": 0.0025,
      "input_cost_per_token": 5e-7,
      "input_cost_per_video_per_second": 0.002,
      "max_input_tokens": 32760,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_character": 3.75e-7,
      "output_cost_per_token": 0.0000015,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-pro",
    "displayName": "gemini-pro"
  },
  {
    "id": "gemini-pro-vision",
    "name": "gemini-pro-vision",
    "provider": "vertex_ai-vision-models",
    "data": {
      "input_cost_per_image": 0.0025,
      "input_cost_per_token": 5e-7,
      "max_images_per_prompt": 16,
      "max_input_tokens": 16384,
      "max_output_tokens": 2048,
      "max_tokens": 2048,
      "max_video_length": 2,
      "max_videos_per_prompt": 1,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "vertex_ai-vision-models"
    },
    "slug": "gemini-pro-vision",
    "displayName": "gemini-pro-vision"
  },
  {
    "id": "gemini/gemini-embedding-001",
    "name": "gemini-embedding-001",
    "provider": "gemini",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 2048,
      "max_tokens": 2048,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_vector_size": 3072,
      "rpm": 10000,
      "source": "https://ai.google.dev/gemini-api/docs/embeddings#model-versions",
      "tpm": 10000000,
      "provider": "gemini"
    },
    "slug": "gemini-embedding-001",
    "displayName": "gemini-embedding-001"
  },
  {
    "id": "gemini/gemini-1.5-flash",
    "name": "gemini-1.5-flash",
    "provider": "gemini",
    "data": {
      "deprecation_date": "2025-09-29",
      "input_cost_per_token": 7.5e-8,
      "input_cost_per_token_above_128k_tokens": 1.5e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_pdf_size_mb": 30,
      "max_tokens": 8192,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "output_cost_per_token_above_128k_tokens": 6e-7,
      "rpm": 2000,
      "source": "https://ai.google.dev/pricing",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tpm": 4000000,
      "provider": "gemini"
    },
    "slug": "gemini-1.5-flash",
    "displayName": "gemini-1.5-flash"
  },
  {
    "id": "gemini/gemini-1.5-flash-001",
    "name": "gemini-1.5-flash-001",
    "provider": "gemini",
    "data": {
      "cache_creation_input_token_cost": 0.000001,
      "cache_read_input_token_cost": 1.875e-8,
      "deprecation_date": "2025-05-24",
      "input_cost_per_token": 7.5e-8,
      "input_cost_per_token_above_128k_tokens": 1.5e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_pdf_size_mb": 30,
      "max_tokens": 8192,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "output_cost_per_token_above_128k_tokens": 6e-7,
      "rpm": 2000,
      "source": "https://ai.google.dev/pricing",
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tpm": 4000000,
      "provider": "gemini"
    },
    "slug": "gemini-1.5-flash-001",
    "displayName": "gemini-1.5-flash-001"
  },
  {
    "id": "gemini/gemini-1.5-flash-002",
    "name": "gemini-1.5-flash-002",
    "provider": "gemini",
    "data": {
      "cache_creation_input_token_cost": 0.000001,
      "cache_read_input_token_cost": 1.875e-8,
      "deprecation_date": "2025-09-24",
      "input_cost_per_token": 7.5e-8,
      "input_cost_per_token_above_128k_tokens": 1.5e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_pdf_size_mb": 30,
      "max_tokens": 8192,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "output_cost_per_token_above_128k_tokens": 6e-7,
      "rpm": 2000,
      "source": "https://ai.google.dev/pricing",
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tpm": 4000000,
      "provider": "gemini"
    },
    "slug": "gemini-1.5-flash-002",
    "displayName": "gemini-1.5-flash-002"
  },
  {
    "id": "gemini/gemini-1.5-flash-latest",
    "name": "gemini-1.5-flash-latest",
    "provider": "gemini",
    "data": {
      "deprecation_date": "2025-09-29",
      "input_cost_per_token": 7.5e-8,
      "input_cost_per_token_above_128k_tokens": 1.5e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_pdf_size_mb": 30,
      "max_tokens": 8192,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "output_cost_per_token_above_128k_tokens": 6e-7,
      "rpm": 2000,
      "source": "https://ai.google.dev/pricing",
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tpm": 4000000,
      "provider": "gemini"
    },
    "slug": "gemini-1.5-flash-latest",
    "displayName": "gemini-1.5-flash-latest"
  },
  {
    "id": "gemini/gemini-1.5-pro",
    "name": "gemini-1.5-pro",
    "provider": "gemini",
    "data": {
      "deprecation_date": "2025-09-29",
      "input_cost_per_token": 0.0000035,
      "input_cost_per_token_above_128k_tokens": 0.000007,
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.0000105,
      "output_cost_per_token_above_128k_tokens": 0.000021,
      "rpm": 1000,
      "source": "https://ai.google.dev/pricing",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tpm": 4000000,
      "provider": "gemini"
    },
    "slug": "gemini-1.5-pro",
    "displayName": "gemini-1.5-pro"
  },
  {
    "id": "gemini/gemini-1.5-pro-001",
    "name": "gemini-1.5-pro-001",
    "provider": "gemini",
    "data": {
      "deprecation_date": "2025-05-24",
      "input_cost_per_token": 0.0000035,
      "input_cost_per_token_above_128k_tokens": 0.000007,
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.0000105,
      "output_cost_per_token_above_128k_tokens": 0.000021,
      "rpm": 1000,
      "source": "https://ai.google.dev/pricing",
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tpm": 4000000,
      "provider": "gemini"
    },
    "slug": "gemini-1.5-pro-001",
    "displayName": "gemini-1.5-pro-001"
  },
  {
    "id": "gemini/gemini-1.5-pro-002",
    "name": "gemini-1.5-pro-002",
    "provider": "gemini",
    "data": {
      "deprecation_date": "2025-09-24",
      "input_cost_per_token": 0.0000035,
      "input_cost_per_token_above_128k_tokens": 0.000007,
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.0000105,
      "output_cost_per_token_above_128k_tokens": 0.000021,
      "rpm": 1000,
      "source": "https://ai.google.dev/pricing",
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tpm": 4000000,
      "provider": "gemini"
    },
    "slug": "gemini-1.5-pro-002",
    "displayName": "gemini-1.5-pro-002"
  },
  {
    "id": "gemini/gemini-1.5-pro-exp-0801",
    "name": "gemini-1.5-pro-exp-0801",
    "provider": "gemini",
    "data": {
      "deprecation_date": "2025-09-29",
      "input_cost_per_token": 0.0000035,
      "input_cost_per_token_above_128k_tokens": 0.000007,
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.0000105,
      "output_cost_per_token_above_128k_tokens": 0.000021,
      "rpm": 1000,
      "source": "https://ai.google.dev/pricing",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tpm": 4000000,
      "provider": "gemini"
    },
    "slug": "gemini-1.5-pro-exp-0801",
    "displayName": "gemini-1.5-pro-exp-0801"
  },
  {
    "id": "gemini/gemini-1.5-pro-latest",
    "name": "gemini-1.5-pro-latest",
    "provider": "gemini",
    "data": {
      "deprecation_date": "2025-09-29",
      "input_cost_per_token": 0.0000035,
      "input_cost_per_token_above_128k_tokens": 0.000007,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.00000105,
      "output_cost_per_token_above_128k_tokens": 0.000021,
      "rpm": 1000,
      "source": "https://ai.google.dev/pricing",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tpm": 4000000,
      "provider": "gemini"
    },
    "slug": "gemini-1.5-pro-latest",
    "displayName": "gemini-1.5-pro-latest"
  },
  {
    "id": "gemini/gemini-2.0-flash",
    "name": "gemini-2.0-flash",
    "provider": "gemini",
    "data": {
      "cache_read_input_token_cost": 2.5e-8,
      "deprecation_date": "2026-03-31",
      "input_cost_per_audio_token": 7e-7,
      "input_cost_per_token": 1e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_pdf_size_mb": 30,
      "max_tokens": 8192,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "rpm": 10000,
      "source": "https://ai.google.dev/pricing#2_0flash",
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tpm": 10000000,
      "provider": "gemini"
    },
    "slug": "gemini-2.0-flash",
    "displayName": "gemini-2.0-flash"
  },
  {
    "id": "gemini/gemini-2.0-flash-001",
    "name": "gemini-2.0-flash-001",
    "provider": "gemini",
    "data": {
      "cache_read_input_token_cost": 2.5e-8,
      "deprecation_date": "2026-03-31",
      "input_cost_per_audio_token": 7e-7,
      "input_cost_per_token": 1e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_pdf_size_mb": 30,
      "max_tokens": 8192,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "rpm": 10000,
      "source": "https://ai.google.dev/pricing#2_0flash",
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tpm": 10000000,
      "provider": "gemini"
    },
    "slug": "gemini-2.0-flash-001",
    "displayName": "gemini-2.0-flash-001"
  },
  {
    "id": "gemini/gemini-2.0-flash-lite",
    "name": "gemini-2.0-flash-lite",
    "provider": "gemini",
    "data": {
      "cache_read_input_token_cost": 1.875e-8,
      "deprecation_date": "2026-03-31",
      "input_cost_per_audio_token": 7.5e-8,
      "input_cost_per_token": 7.5e-8,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_pdf_size_mb": 50,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "rpm": 4000,
      "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.0-flash-lite",
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tpm": 4000000,
      "provider": "gemini"
    },
    "slug": "gemini-2.0-flash-lite",
    "displayName": "gemini-2.0-flash-lite"
  },
  {
    "id": "gemini/gemini-2.0-flash-lite-preview-02-05",
    "name": "gemini-2.0-flash-lite-preview-02-05",
    "provider": "gemini",
    "data": {
      "deprecation_date": "2025-12-02",
      "cache_read_input_token_cost": 1.875e-8,
      "input_cost_per_audio_token": 7.5e-8,
      "input_cost_per_token": 7.5e-8,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_pdf_size_mb": 30,
      "max_tokens": 8192,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "rpm": 60000,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash-lite",
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tpm": 10000000,
      "provider": "gemini"
    },
    "slug": "gemini-2.0-flash-lite-preview-02-05",
    "displayName": "gemini-2.0-flash-lite-preview-02-05"
  },
  {
    "id": "gemini/gemini-2.0-flash-live-001",
    "name": "gemini-2.0-flash-live-001",
    "provider": "gemini",
    "data": {
      "deprecation_date": "2025-12-09",
      "cache_read_input_token_cost": 7.5e-8,
      "input_cost_per_audio_token": 0.0000021,
      "input_cost_per_image": 0.0000021,
      "input_cost_per_token": 3.5e-7,
      "input_cost_per_video_per_second": 0.0000021,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_audio_token": 0.0000085,
      "output_cost_per_token": 0.0000015,
      "rpm": 10,
      "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2-0-flash-live-001",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text",
        "audio"
      ],
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tpm": 250000,
      "provider": "gemini"
    },
    "slug": "gemini-2.0-flash-live-001",
    "displayName": "gemini-2.0-flash-live-001"
  },
  {
    "id": "gemini/gemini-2.0-flash-preview-image-generation",
    "name": "gemini-2.0-flash-preview-image-generation",
    "provider": "gemini",
    "data": {
      "deprecation_date": "2025-11-14",
      "cache_read_input_token_cost": 2.5e-8,
      "input_cost_per_audio_token": 7e-7,
      "input_cost_per_token": 1e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_pdf_size_mb": 30,
      "max_tokens": 8192,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "rpm": 10000,
      "source": "https://ai.google.dev/pricing#2_0flash",
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tpm": 10000000,
      "provider": "gemini"
    },
    "slug": "gemini-2.0-flash-preview-image-generation",
    "displayName": "gemini-2.0-flash-preview-image-generation"
  },
  {
    "id": "gemini/gemini-2.5-flash",
    "name": "gemini-2.5-flash",
    "provider": "gemini",
    "data": {
      "cache_read_input_token_cost": 3e-8,
      "input_cost_per_audio_token": 0.000001,
      "input_cost_per_token": 3e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_reasoning_token": 0.0000025,
      "output_cost_per_token": 0.0000025,
      "rpm": 100000,
      "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tpm": 8000000,
      "provider": "gemini"
    },
    "slug": "gemini-2.5-flash",
    "displayName": "gemini-2.5-flash"
  },
  {
    "id": "gemini/gemini-2.5-flash-image",
    "name": "gemini-2.5-flash-image",
    "provider": "vertex_ai-language-models",
    "data": {
      "cache_read_input_token_cost": 3e-8,
      "input_cost_per_audio_token": 0.000001,
      "input_cost_per_token": 3e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "supports_reasoning": false,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "max_pdf_size_mb": 30,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "image_generation",
      "output_cost_per_image": 0.039,
      "output_cost_per_image_token": 0.00003,
      "output_cost_per_reasoning_token": 0.0000025,
      "output_cost_per_token": 0.0000025,
      "rpm": 100000,
      "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-flash-image",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tpm": 8000000,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-2.5-flash-image",
    "displayName": "gemini-2.5-flash-image"
  },
  {
    "id": "gemini/gemini-2.5-flash-image-preview",
    "name": "gemini-2.5-flash-image-preview",
    "provider": "gemini",
    "data": {
      "deprecation_date": "2026-01-15",
      "cache_read_input_token_cost": 7.5e-8,
      "input_cost_per_audio_token": 0.000001,
      "input_cost_per_token": 3e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "image_generation",
      "output_cost_per_image": 0.039,
      "output_cost_per_image_token": 0.00003,
      "output_cost_per_reasoning_token": 0.00003,
      "output_cost_per_token": 0.00003,
      "rpm": 100000,
      "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tpm": 8000000,
      "provider": "gemini"
    },
    "slug": "gemini-2.5-flash-image-preview",
    "displayName": "gemini-2.5-flash-image-preview"
  },
  {
    "id": "gemini/gemini-3-pro-image-preview",
    "name": "gemini-3-pro-image-preview",
    "provider": "gemini",
    "data": {
      "input_cost_per_image": 0.0011,
      "input_cost_per_token": 0.000002,
      "input_cost_per_token_batches": 0.000001,
      "max_input_tokens": 65536,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "image_generation",
      "output_cost_per_image": 0.134,
      "output_cost_per_image_token": 0.00012,
      "output_cost_per_token": 0.000012,
      "rpm": 1000,
      "tpm": 4000000,
      "output_cost_per_token_batches": 0.000006,
      "source": "https://ai.google.dev/gemini-api/docs/pricing",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_function_calling": false,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "gemini"
    },
    "slug": "gemini-3-pro-image-preview",
    "displayName": "gemini-3-pro-image-preview"
  },
  {
    "id": "gemini/deep-research-pro-preview-12-2025",
    "name": "deep-research-pro-preview-12-2025",
    "provider": "gemini",
    "data": {
      "input_cost_per_image": 0.0011,
      "input_cost_per_token": 0.000002,
      "input_cost_per_token_batches": 0.000001,
      "max_input_tokens": 65536,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "image_generation",
      "output_cost_per_image": 0.134,
      "output_cost_per_image_token": 0.00012,
      "output_cost_per_token": 0.000012,
      "rpm": 1000,
      "tpm": 4000000,
      "output_cost_per_token_batches": 0.000006,
      "source": "https://ai.google.dev/gemini-api/docs/pricing",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_function_calling": false,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "gemini"
    },
    "slug": "deep-research-pro-preview-12-2025",
    "displayName": "deep-research-pro-preview-12-2025"
  },
  {
    "id": "gemini/gemini-2.5-flash-lite",
    "name": "gemini-2.5-flash-lite",
    "provider": "gemini",
    "data": {
      "cache_read_input_token_cost": 1e-8,
      "input_cost_per_audio_token": 3e-7,
      "input_cost_per_token": 1e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_reasoning_token": 4e-7,
      "output_cost_per_token": 4e-7,
      "rpm": 15,
      "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-lite",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tpm": 250000,
      "provider": "gemini"
    },
    "slug": "gemini-2.5-flash-lite",
    "displayName": "gemini-2.5-flash-lite"
  },
  {
    "id": "gemini/gemini-2.5-flash-lite-preview-09-2025",
    "name": "gemini-2.5-flash-lite-preview-09-2025",
    "provider": "gemini",
    "data": {
      "cache_read_input_token_cost": 1e-8,
      "input_cost_per_audio_token": 3e-7,
      "input_cost_per_token": 1e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_reasoning_token": 4e-7,
      "output_cost_per_token": 4e-7,
      "rpm": 15,
      "source": "https://developers.googleblog.com/en/continuing-to-bring-you-our-latest-models-with-an-improved-gemini-2-5-flash-and-flash-lite-release/",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tpm": 250000,
      "provider": "gemini"
    },
    "slug": "gemini-2.5-flash-lite-preview-09-2025",
    "displayName": "gemini-2.5-flash-lite-preview-09-2025"
  },
  {
    "id": "gemini/gemini-2.5-flash-preview-09-2025",
    "name": "gemini-2.5-flash-preview-09-2025",
    "provider": "gemini",
    "data": {
      "cache_read_input_token_cost": 7.5e-8,
      "input_cost_per_audio_token": 0.000001,
      "input_cost_per_token": 3e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_reasoning_token": 0.0000025,
      "output_cost_per_token": 0.0000025,
      "rpm": 15,
      "source": "https://developers.googleblog.com/en/continuing-to-bring-you-our-latest-models-with-an-improved-gemini-2-5-flash-and-flash-lite-release/",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tpm": 250000,
      "provider": "gemini"
    },
    "slug": "gemini-2.5-flash-preview-09-2025",
    "displayName": "gemini-2.5-flash-preview-09-2025"
  },
  {
    "id": "gemini/gemini-flash-latest",
    "name": "gemini-flash-latest",
    "provider": "gemini",
    "data": {
      "cache_read_input_token_cost": 7.5e-8,
      "input_cost_per_audio_token": 0.000001,
      "input_cost_per_token": 3e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_reasoning_token": 0.0000025,
      "output_cost_per_token": 0.0000025,
      "rpm": 15,
      "source": "https://developers.googleblog.com/en/continuing-to-bring-you-our-latest-models-with-an-improved-gemini-2-5-flash-and-flash-lite-release/",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tpm": 250000,
      "provider": "gemini"
    },
    "slug": "gemini-flash-latest",
    "displayName": "gemini-flash-latest"
  },
  {
    "id": "gemini/gemini-flash-lite-latest",
    "name": "gemini-flash-lite-latest",
    "provider": "gemini",
    "data": {
      "cache_read_input_token_cost": 2.5e-8,
      "input_cost_per_audio_token": 3e-7,
      "input_cost_per_token": 1e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_reasoning_token": 4e-7,
      "output_cost_per_token": 4e-7,
      "rpm": 15,
      "source": "https://developers.googleblog.com/en/continuing-to-bring-you-our-latest-models-with-an-improved-gemini-2-5-flash-and-flash-lite-release/",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tpm": 250000,
      "provider": "gemini"
    },
    "slug": "gemini-flash-lite-latest",
    "displayName": "gemini-flash-lite-latest"
  },
  {
    "id": "gemini/gemini-2.5-flash-lite-preview-06-17",
    "name": "gemini-2.5-flash-lite-preview-06-17",
    "provider": "gemini",
    "data": {
      "deprecation_date": "2025-11-18",
      "cache_read_input_token_cost": 2.5e-8,
      "input_cost_per_audio_token": 5e-7,
      "input_cost_per_token": 1e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_reasoning_token": 4e-7,
      "output_cost_per_token": 4e-7,
      "rpm": 15,
      "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-lite",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tpm": 250000,
      "provider": "gemini"
    },
    "slug": "gemini-2.5-flash-lite-preview-06-17",
    "displayName": "gemini-2.5-flash-lite-preview-06-17"
  },
  {
    "id": "gemini/gemini-2.5-flash-preview-04-17",
    "name": "gemini-2.5-flash-preview-04-17",
    "provider": "gemini",
    "data": {
      "cache_read_input_token_cost": 3.75e-8,
      "input_cost_per_audio_token": 0.000001,
      "input_cost_per_token": 1.5e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_reasoning_token": 0.0000035,
      "output_cost_per_token": 6e-7,
      "rpm": 10,
      "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tpm": 250000,
      "provider": "gemini"
    },
    "slug": "gemini-2.5-flash-preview-04-17",
    "displayName": "gemini-2.5-flash-preview-04-17"
  },
  {
    "id": "gemini/gemini-2.5-flash-preview-05-20",
    "name": "gemini-2.5-flash-preview-05-20",
    "provider": "gemini",
    "data": {
      "deprecation_date": "2025-11-18",
      "cache_read_input_token_cost": 7.5e-8,
      "input_cost_per_audio_token": 0.000001,
      "input_cost_per_token": 3e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_reasoning_token": 0.0000025,
      "output_cost_per_token": 0.0000025,
      "rpm": 10,
      "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tpm": 250000,
      "provider": "gemini"
    },
    "slug": "gemini-2.5-flash-preview-05-20",
    "displayName": "gemini-2.5-flash-preview-05-20"
  },
  {
    "id": "gemini/gemini-2.5-flash-preview-tts",
    "name": "gemini-2.5-flash-preview-tts",
    "provider": "gemini",
    "data": {
      "cache_read_input_token_cost": 3.75e-8,
      "input_cost_per_audio_token": 0.000001,
      "input_cost_per_token": 1.5e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_reasoning_token": 0.0000035,
      "output_cost_per_token": 6e-7,
      "rpm": 10,
      "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions"
      ],
      "supported_modalities": [
        "text"
      ],
      "supported_output_modalities": [
        "audio"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tpm": 250000,
      "provider": "gemini"
    },
    "slug": "gemini-2.5-flash-preview-tts",
    "displayName": "gemini-2.5-flash-preview-tts"
  },
  {
    "id": "gemini/gemini-2.5-pro",
    "name": "gemini-2.5-pro",
    "provider": "gemini",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "cache_read_input_token_cost_above_200k_tokens": 2.5e-7,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_above_200k_tokens": 0.0000025,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_above_200k_tokens": 0.000015,
      "rpm": 2000,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_input": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_video_input": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tpm": 800000,
      "provider": "gemini"
    },
    "slug": "gemini-2.5-pro",
    "displayName": "gemini-2.5-pro"
  },
  {
    "id": "gemini/gemini-2.5-computer-use-preview-10-2025",
    "name": "gemini-2.5-computer-use-preview-10-2025",
    "provider": "gemini",
    "data": {
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_above_200k_tokens": 0.0000025,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_above_200k_tokens": 0.000015,
      "rpm": 2000,
      "source": "https://ai.google.dev/gemini-api/docs/computer-use",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tpm": 800000,
      "provider": "gemini"
    },
    "slug": "gemini-2.5-computer-use-preview-10-2025",
    "displayName": "gemini-2.5-computer-use-preview-10-2025"
  },
  {
    "id": "gemini/gemini-3-pro-preview",
    "name": "gemini-3-pro-preview",
    "provider": "gemini",
    "data": {
      "cache_read_input_token_cost": 2e-7,
      "cache_read_input_token_cost_above_200k_tokens": 4e-7,
      "input_cost_per_token": 0.000002,
      "input_cost_per_token_above_200k_tokens": 0.000004,
      "input_cost_per_token_batches": 0.000001,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 0.000012,
      "output_cost_per_token_above_200k_tokens": 0.000018,
      "output_cost_per_token_batches": 0.000006,
      "rpm": 2000,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_input": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_video_input": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tpm": 800000,
      "provider": "gemini"
    },
    "slug": "gemini-3-pro-preview",
    "displayName": "gemini-3-pro-preview"
  },
  {
    "id": "gemini/gemini-3-flash-preview",
    "name": "gemini-3-flash-preview",
    "provider": "gemini",
    "data": {
      "cache_read_input_token_cost": 5e-8,
      "input_cost_per_audio_token": 0.000001,
      "input_cost_per_token": 5e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_reasoning_token": 0.000003,
      "output_cost_per_token": 0.000003,
      "rpm": 2000,
      "source": "https://ai.google.dev/pricing/gemini-3",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "supports_web_search": true,
      "supports_native_streaming": true,
      "tpm": 800000,
      "provider": "gemini"
    },
    "slug": "gemini-3-flash-preview",
    "displayName": "gemini-3-flash-preview"
  },
  {
    "id": "gemini-3-flash-preview",
    "name": "gemini-3-flash-preview",
    "provider": "vertex_ai-language-models",
    "data": {
      "cache_read_input_token_cost": 5e-8,
      "input_cost_per_audio_token": 0.000001,
      "input_cost_per_token": 5e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_reasoning_token": 0.000003,
      "output_cost_per_token": 0.000003,
      "source": "https://ai.google.dev/pricing/gemini-3",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "supports_web_search": true,
      "supports_native_streaming": true,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-3-flash-preview",
    "displayName": "gemini-3-flash-preview"
  },
  {
    "id": "gemini/gemini-2.5-pro-preview-03-25",
    "name": "gemini-2.5-pro-preview-03-25",
    "provider": "gemini",
    "data": {
      "deprecation_date": "2025-12-02",
      "cache_read_input_token_cost": 1.25e-7,
      "cache_read_input_token_cost_above_200k_tokens": 2.5e-7,
      "input_cost_per_audio_token": 7e-7,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_above_200k_tokens": 0.0000025,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_above_200k_tokens": 0.000015,
      "rpm": 10000,
      "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview",
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tpm": 10000000,
      "provider": "gemini"
    },
    "slug": "gemini-2.5-pro-preview-03-25",
    "displayName": "gemini-2.5-pro-preview-03-25"
  },
  {
    "id": "gemini/gemini-2.5-pro-preview-05-06",
    "name": "gemini-2.5-pro-preview-05-06",
    "provider": "gemini",
    "data": {
      "deprecation_date": "2025-12-02",
      "cache_read_input_token_cost": 1.25e-7,
      "cache_read_input_token_cost_above_200k_tokens": 2.5e-7,
      "input_cost_per_audio_token": 7e-7,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_above_200k_tokens": 0.0000025,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_above_200k_tokens": 0.000015,
      "rpm": 10000,
      "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview",
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tpm": 10000000,
      "provider": "gemini"
    },
    "slug": "gemini-2.5-pro-preview-05-06",
    "displayName": "gemini-2.5-pro-preview-05-06"
  },
  {
    "id": "gemini/gemini-2.5-pro-preview-06-05",
    "name": "gemini-2.5-pro-preview-06-05",
    "provider": "gemini",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "cache_read_input_token_cost_above_200k_tokens": 2.5e-7,
      "input_cost_per_audio_token": 7e-7,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_above_200k_tokens": 0.0000025,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_above_200k_tokens": 0.000015,
      "rpm": 10000,
      "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview",
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tpm": 10000000,
      "provider": "gemini"
    },
    "slug": "gemini-2.5-pro-preview-06-05",
    "displayName": "gemini-2.5-pro-preview-06-05"
  },
  {
    "id": "gemini/gemini-2.5-pro-preview-tts",
    "name": "gemini-2.5-pro-preview-tts",
    "provider": "gemini",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "cache_read_input_token_cost_above_200k_tokens": 2.5e-7,
      "input_cost_per_audio_token": 7e-7,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_above_200k_tokens": 0.0000025,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_above_200k_tokens": 0.000015,
      "rpm": 10000,
      "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview",
      "supported_modalities": [
        "text"
      ],
      "supported_output_modalities": [
        "audio"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tpm": 10000000,
      "provider": "gemini"
    },
    "slug": "gemini-2.5-pro-preview-tts",
    "displayName": "gemini-2.5-pro-preview-tts"
  },
  {
    "id": "gemini/gemini-gemma-2-27b-it",
    "name": "gemini-gemma-2-27b-it",
    "provider": "gemini",
    "data": {
      "input_cost_per_token": 3.5e-7,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.00000105,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "gemini"
    },
    "slug": "gemini-gemma-2-27b-it",
    "displayName": "gemini-gemma-2-27b-it"
  },
  {
    "id": "gemini/gemini-gemma-2-9b-it",
    "name": "gemini-gemma-2-9b-it",
    "provider": "gemini",
    "data": {
      "input_cost_per_token": 3.5e-7,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.00000105,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "gemini"
    },
    "slug": "gemini-gemma-2-9b-it",
    "displayName": "gemini-gemma-2-9b-it"
  },
  {
    "id": "gemini/gemini-pro",
    "name": "gemini-pro",
    "provider": "gemini",
    "data": {
      "input_cost_per_token": 3.5e-7,
      "input_cost_per_token_above_128k_tokens": 7e-7,
      "max_input_tokens": 32760,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.00000105,
      "output_cost_per_token_above_128k_tokens": 0.0000021,
      "rpd": 30000,
      "rpm": 360,
      "source": "https://ai.google.dev/gemini-api/docs/models/gemini",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "tpm": 120000,
      "provider": "gemini"
    },
    "slug": "gemini-pro",
    "displayName": "gemini-pro"
  },
  {
    "id": "gemini/gemini-pro-vision",
    "name": "gemini-pro-vision",
    "provider": "gemini",
    "data": {
      "input_cost_per_token": 3.5e-7,
      "input_cost_per_token_above_128k_tokens": 7e-7,
      "max_input_tokens": 30720,
      "max_output_tokens": 2048,
      "max_tokens": 2048,
      "mode": "chat",
      "output_cost_per_token": 0.00000105,
      "output_cost_per_token_above_128k_tokens": 0.0000021,
      "rpd": 30000,
      "rpm": 360,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tpm": 120000,
      "provider": "gemini"
    },
    "slug": "gemini-pro-vision",
    "displayName": "gemini-pro-vision"
  },
  {
    "id": "gmi/anthropic/claude-opus-4.5",
    "name": "claude-opus-4.5",
    "provider": "gmi",
    "data": {
      "input_cost_per_token": 0.000005,
      "max_input_tokens": 409600,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.000025,
      "supports_function_calling": true,
      "supports_vision": true,
      "provider": "gmi"
    },
    "slug": "claude-opus-4.5",
    "displayName": "claude-opus-4.5"
  },
  {
    "id": "gmi/anthropic/claude-sonnet-4.5",
    "name": "claude-sonnet-4.5",
    "provider": "gmi",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 409600,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_function_calling": true,
      "supports_vision": true,
      "provider": "gmi"
    },
    "slug": "claude-sonnet-4.5",
    "displayName": "claude-sonnet-4.5"
  },
  {
    "id": "gmi/anthropic/claude-sonnet-4",
    "name": "claude-sonnet-4",
    "provider": "gmi",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 409600,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_function_calling": true,
      "supports_vision": true,
      "provider": "gmi"
    },
    "slug": "claude-sonnet-4",
    "displayName": "claude-sonnet-4"
  },
  {
    "id": "gmi/anthropic/claude-opus-4",
    "name": "claude-opus-4",
    "provider": "gmi",
    "data": {
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 409600,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.000075,
      "supports_function_calling": true,
      "supports_vision": true,
      "provider": "gmi"
    },
    "slug": "claude-opus-4",
    "displayName": "claude-opus-4"
  },
  {
    "id": "gmi/openai/gpt-5.2",
    "name": "gpt-5.2",
    "provider": "gmi",
    "data": {
      "input_cost_per_token": 0.00000175,
      "max_input_tokens": 409600,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.000014,
      "supports_function_calling": true,
      "provider": "gmi"
    },
    "slug": "gpt-5.2",
    "displayName": "gpt-5.2"
  },
  {
    "id": "gmi/openai/gpt-5.1",
    "name": "gpt-5.1",
    "provider": "gmi",
    "data": {
      "input_cost_per_token": 0.00000125,
      "max_input_tokens": 409600,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supports_function_calling": true,
      "provider": "gmi"
    },
    "slug": "gpt-5.1",
    "displayName": "gpt-5.1"
  },
  {
    "id": "gmi/openai/gpt-5",
    "name": "gpt-5",
    "provider": "gmi",
    "data": {
      "input_cost_per_token": 0.00000125,
      "max_input_tokens": 409600,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supports_function_calling": true,
      "provider": "gmi"
    },
    "slug": "gpt-5",
    "displayName": "gpt-5"
  },
  {
    "id": "gmi/openai/gpt-4o",
    "name": "gpt-4o",
    "provider": "gmi",
    "data": {
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supports_function_calling": true,
      "supports_vision": true,
      "provider": "gmi"
    },
    "slug": "gpt-4o",
    "displayName": "gpt-4o"
  },
  {
    "id": "gmi/openai/gpt-4o-mini",
    "name": "gpt-4o-mini",
    "provider": "gmi",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "supports_function_calling": true,
      "supports_vision": true,
      "provider": "gmi"
    },
    "slug": "gpt-4o-mini",
    "displayName": "gpt-4o-mini"
  },
  {
    "id": "gmi/deepseek-ai/DeepSeek-V3.2",
    "name": "DeepSeek-V3.2",
    "provider": "gmi",
    "data": {
      "input_cost_per_token": 2.8e-7,
      "max_input_tokens": 163840,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "supports_function_calling": true,
      "provider": "gmi"
    },
    "slug": "deepseek-v3.2",
    "displayName": "DeepSeek-V3.2"
  },
  {
    "id": "gmi/deepseek-ai/DeepSeek-V3-0324",
    "name": "DeepSeek-V3-0324",
    "provider": "gmi",
    "data": {
      "input_cost_per_token": 2.8e-7,
      "max_input_tokens": 163840,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 8.8e-7,
      "supports_function_calling": true,
      "provider": "gmi"
    },
    "slug": "deepseek-v3-0324",
    "displayName": "DeepSeek-V3-0324"
  },
  {
    "id": "gmi/google/gemini-3-pro-preview",
    "name": "gemini-3-pro-preview",
    "provider": "gmi",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "max_tokens": 65536,
      "mode": "chat",
      "output_cost_per_token": 0.000012,
      "supports_function_calling": true,
      "supports_vision": true,
      "provider": "gmi"
    },
    "slug": "gemini-3-pro-preview",
    "displayName": "gemini-3-pro-preview"
  },
  {
    "id": "gmi/google/gemini-3-flash-preview",
    "name": "gemini-3-flash-preview",
    "provider": "gmi",
    "data": {
      "input_cost_per_token": 5e-7,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "max_tokens": 65536,
      "mode": "chat",
      "output_cost_per_token": 0.000003,
      "supports_function_calling": true,
      "supports_vision": true,
      "provider": "gmi"
    },
    "slug": "gemini-3-flash-preview",
    "displayName": "gemini-3-flash-preview"
  },
  {
    "id": "gmi/moonshotai/Kimi-K2-Thinking",
    "name": "Kimi-K2-Thinking",
    "provider": "gmi",
    "data": {
      "input_cost_per_token": 8e-7,
      "max_input_tokens": 262144,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.0000012,
      "provider": "gmi"
    },
    "slug": "kimi-k2-thinking",
    "displayName": "Kimi-K2-Thinking"
  },
  {
    "id": "gmi/MiniMaxAI/MiniMax-M2.1",
    "name": "MiniMax-M2.1",
    "provider": "gmi",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 196608,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.0000012,
      "provider": "gmi"
    },
    "slug": "minimax-m2.1",
    "displayName": "MiniMax-M2.1"
  },
  {
    "id": "gmi/Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
    "name": "Qwen3-VL-235B-A22B-Instruct-FP8",
    "provider": "gmi",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 262144,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.0000014,
      "supports_vision": true,
      "provider": "gmi"
    },
    "slug": "qwen3-vl-235b-a22b-instruct-fp8",
    "displayName": "Qwen3-VL-235B-A22B-Instruct-FP8"
  },
  {
    "id": "gmi/zai-org/GLM-4.7-FP8",
    "name": "GLM-4.7-FP8",
    "provider": "gmi",
    "data": {
      "input_cost_per_token": 4e-7,
      "max_input_tokens": 202752,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "provider": "gmi"
    },
    "slug": "glm-4.7-fp8",
    "displayName": "GLM-4.7-FP8"
  },
  {
    "id": "google.gemma-3-12b-it",
    "name": "google.gemma-3-12b-it",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 9e-8,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 2.9e-7,
      "supports_system_messages": true,
      "supports_vision": true,
      "provider": "bedrock_converse"
    },
    "slug": "google.gemma-3-12b-it",
    "displayName": "google.gemma-3-12b-it"
  },
  {
    "id": "google.gemma-3-27b-it",
    "name": "google.gemma-3-27b-it",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 2.3e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 3.8e-7,
      "supports_system_messages": true,
      "supports_vision": true,
      "provider": "bedrock_converse"
    },
    "slug": "google.gemma-3-27b-it",
    "displayName": "google.gemma-3-27b-it"
  },
  {
    "id": "google.gemma-3-4b-it",
    "name": "google.gemma-3-4b-it",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 4e-8,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 8e-8,
      "supports_system_messages": true,
      "supports_vision": true,
      "provider": "bedrock_converse"
    },
    "slug": "google.gemma-3-4b-it",
    "displayName": "google.gemma-3-4b-it"
  },
  {
    "id": "global.anthropic.claude-sonnet-4-5-20250929-v1:0",
    "name": "global.anthropic.claude-sonnet-4-5-20250929-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_creation_input_token_cost": 0.00000375,
      "cache_read_input_token_cost": 3e-7,
      "input_cost_per_token": 0.000003,
      "input_cost_per_token_above_200k_tokens": 0.000006,
      "output_cost_per_token_above_200k_tokens": 0.0000225,
      "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
      "cache_read_input_token_cost_above_200k_tokens": 6e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 346,
      "provider": "bedrock_converse"
    },
    "slug": "global.anthropic.claude-sonnet-4-5-20250929-v1-0",
    "displayName": "global.anthropic.claude-sonnet-4-5-20250929-v1:0"
  },
  {
    "id": "global.anthropic.claude-sonnet-4-20250514-v1:0",
    "name": "global.anthropic.claude-sonnet-4-20250514-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_creation_input_token_cost": 0.00000375,
      "cache_read_input_token_cost": 3e-7,
      "input_cost_per_token": 0.000003,
      "input_cost_per_token_above_200k_tokens": 0.000006,
      "output_cost_per_token_above_200k_tokens": 0.0000225,
      "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
      "cache_read_input_token_cost_above_200k_tokens": 6e-7,
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "bedrock_converse"
    },
    "slug": "global.anthropic.claude-sonnet-4-20250514-v1-0",
    "displayName": "global.anthropic.claude-sonnet-4-20250514-v1:0"
  },
  {
    "id": "global.anthropic.claude-haiku-4-5-20251001-v1:0",
    "name": "global.anthropic.claude-haiku-4-5-20251001-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_creation_input_token_cost": 0.00000125,
      "cache_read_input_token_cost": 1e-7,
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000005,
      "source": "https://aws.amazon.com/about-aws/whats-new/2025/10/claude-4-5-haiku-anthropic-amazon-bedrock",
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 346,
      "provider": "bedrock_converse"
    },
    "slug": "global.anthropic.claude-haiku-4-5-20251001-v1-0",
    "displayName": "global.anthropic.claude-haiku-4-5-20251001-v1:0"
  },
  {
    "id": "global.amazon.nova-2-lite-v1:0",
    "name": "global.amazon.nova-2-lite-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_read_input_token_cost": 7.5e-8,
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.0000025,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_video_input": true,
      "supports_vision": true,
      "provider": "bedrock_converse"
    },
    "slug": "global.amazon.nova-2-lite-v1-0",
    "displayName": "global.amazon.nova-2-lite-v1:0"
  },
  {
    "id": "gpt-3.5-turbo",
    "name": "gpt-3.5-turbo",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 5e-7,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "gpt-3.5-turbo",
    "displayName": "gpt-3.5-turbo"
  },
  {
    "id": "gpt-3.5-turbo-0125",
    "name": "gpt-3.5-turbo-0125",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 5e-7,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "gpt-3.5-turbo-0125",
    "displayName": "gpt-3.5-turbo-0125"
  },
  {
    "id": "gpt-3.5-turbo-0301",
    "name": "gpt-3.5-turbo-0301",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 0.0000015,
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "gpt-3.5-turbo-0301",
    "displayName": "gpt-3.5-turbo-0301"
  },
  {
    "id": "gpt-3.5-turbo-0613",
    "name": "gpt-3.5-turbo-0613",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 0.0000015,
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "gpt-3.5-turbo-0613",
    "displayName": "gpt-3.5-turbo-0613"
  },
  {
    "id": "gpt-3.5-turbo-1106",
    "name": "gpt-3.5-turbo-1106",
    "provider": "openai",
    "data": {
      "deprecation_date": "2026-09-28",
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "gpt-3.5-turbo-1106",
    "displayName": "gpt-3.5-turbo-1106"
  },
  {
    "id": "gpt-3.5-turbo-16k",
    "name": "gpt-3.5-turbo-16k",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000004,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "gpt-3.5-turbo-16k",
    "displayName": "gpt-3.5-turbo-16k"
  },
  {
    "id": "gpt-3.5-turbo-16k-0613",
    "name": "gpt-3.5-turbo-16k-0613",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000004,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "gpt-3.5-turbo-16k-0613",
    "displayName": "gpt-3.5-turbo-16k-0613"
  },
  {
    "id": "gpt-3.5-turbo-instruct",
    "name": "gpt-3.5-turbo-instruct",
    "provider": "text-completion-openai",
    "data": {
      "input_cost_per_token": 0.0000015,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "completion",
      "output_cost_per_token": 0.000002,
      "provider": "text-completion-openai"
    },
    "slug": "gpt-3.5-turbo-instruct",
    "displayName": "gpt-3.5-turbo-instruct"
  },
  {
    "id": "gpt-3.5-turbo-instruct-0914",
    "name": "gpt-3.5-turbo-instruct-0914",
    "provider": "text-completion-openai",
    "data": {
      "input_cost_per_token": 0.0000015,
      "max_input_tokens": 8192,
      "max_output_tokens": 4097,
      "max_tokens": 4097,
      "mode": "completion",
      "output_cost_per_token": 0.000002,
      "provider": "text-completion-openai"
    },
    "slug": "gpt-3.5-turbo-instruct-0914",
    "displayName": "gpt-3.5-turbo-instruct-0914"
  },
  {
    "id": "gpt-4",
    "name": "gpt-4",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 0.00003,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00006,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "gpt-4",
    "displayName": "gpt-4"
  },
  {
    "id": "gpt-4-0125-preview",
    "name": "gpt-4-0125-preview",
    "provider": "openai",
    "data": {
      "deprecation_date": "2026-03-26",
      "input_cost_per_token": 0.00001,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00003,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "gpt-4-0125-preview",
    "displayName": "gpt-4-0125-preview"
  },
  {
    "id": "gpt-4-0314",
    "name": "gpt-4-0314",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 0.00003,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00006,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "gpt-4-0314",
    "displayName": "gpt-4-0314"
  },
  {
    "id": "gpt-4-0613",
    "name": "gpt-4-0613",
    "provider": "openai",
    "data": {
      "deprecation_date": "2025-06-06",
      "input_cost_per_token": 0.00003,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00006,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "gpt-4-0613",
    "displayName": "gpt-4-0613"
  },
  {
    "id": "gpt-4-1106-preview",
    "name": "gpt-4-1106-preview",
    "provider": "openai",
    "data": {
      "deprecation_date": "2026-03-26",
      "input_cost_per_token": 0.00001,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00003,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "gpt-4-1106-preview",
    "displayName": "gpt-4-1106-preview"
  },
  {
    "id": "gpt-4-1106-vision-preview",
    "name": "gpt-4-1106-vision-preview",
    "provider": "openai",
    "data": {
      "deprecation_date": "2024-12-06",
      "input_cost_per_token": 0.00001,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00003,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-4-1106-vision-preview",
    "displayName": "gpt-4-1106-vision-preview"
  },
  {
    "id": "gpt-4-32k",
    "name": "gpt-4-32k",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 0.00006,
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00012,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "gpt-4-32k",
    "displayName": "gpt-4-32k"
  },
  {
    "id": "gpt-4-32k-0314",
    "name": "gpt-4-32k-0314",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 0.00006,
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00012,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "gpt-4-32k-0314",
    "displayName": "gpt-4-32k-0314"
  },
  {
    "id": "gpt-4-32k-0613",
    "name": "gpt-4-32k-0613",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 0.00006,
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00012,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "gpt-4-32k-0613",
    "displayName": "gpt-4-32k-0613"
  },
  {
    "id": "gpt-4-turbo",
    "name": "gpt-4-turbo",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 0.00001,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00003,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-4-turbo",
    "displayName": "gpt-4-turbo"
  },
  {
    "id": "gpt-4-turbo-2024-04-09",
    "name": "gpt-4-turbo-2024-04-09",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 0.00001,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00003,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-4-turbo-2024-04-09",
    "displayName": "gpt-4-turbo-2024-04-09"
  },
  {
    "id": "gpt-4-turbo-preview",
    "name": "gpt-4-turbo-preview",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 0.00001,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00003,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "gpt-4-turbo-preview",
    "displayName": "gpt-4-turbo-preview"
  },
  {
    "id": "gpt-4-vision-preview",
    "name": "gpt-4-vision-preview",
    "provider": "openai",
    "data": {
      "deprecation_date": "2024-12-06",
      "input_cost_per_token": 0.00001,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00003,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-4-vision-preview",
    "displayName": "gpt-4-vision-preview"
  },
  {
    "id": "gpt-4.1",
    "name": "gpt-4.1",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 5e-7,
      "cache_read_input_token_cost_priority": 8.75e-7,
      "input_cost_per_token": 0.000002,
      "input_cost_per_token_batches": 0.000001,
      "input_cost_per_token_priority": 0.0000035,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.000008,
      "output_cost_per_token_batches": 0.000004,
      "output_cost_per_token_priority": 0.000014,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_service_tier": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-4.1",
    "displayName": "gpt-4.1"
  },
  {
    "id": "gpt-4.1-2025-04-14",
    "name": "gpt-4.1-2025-04-14",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 5e-7,
      "input_cost_per_token": 0.000002,
      "input_cost_per_token_batches": 0.000001,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.000008,
      "output_cost_per_token_batches": 0.000004,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_service_tier": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-4.1-2025-04-14",
    "displayName": "gpt-4.1-2025-04-14"
  },
  {
    "id": "gpt-4.1-mini",
    "name": "gpt-4.1-mini",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 1e-7,
      "cache_read_input_token_cost_priority": 1.75e-7,
      "input_cost_per_token": 4e-7,
      "input_cost_per_token_batches": 2e-7,
      "input_cost_per_token_priority": 7e-7,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.0000016,
      "output_cost_per_token_batches": 8e-7,
      "output_cost_per_token_priority": 0.0000028,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_service_tier": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-4.1-mini",
    "displayName": "gpt-4.1-mini"
  },
  {
    "id": "gpt-4.1-mini-2025-04-14",
    "name": "gpt-4.1-mini-2025-04-14",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 1e-7,
      "input_cost_per_token": 4e-7,
      "input_cost_per_token_batches": 2e-7,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.0000016,
      "output_cost_per_token_batches": 8e-7,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_service_tier": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-4.1-mini-2025-04-14",
    "displayName": "gpt-4.1-mini-2025-04-14"
  },
  {
    "id": "gpt-4.1-nano",
    "name": "gpt-4.1-nano",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 2.5e-8,
      "cache_read_input_token_cost_priority": 5e-8,
      "input_cost_per_token": 1e-7,
      "input_cost_per_token_batches": 5e-8,
      "input_cost_per_token_priority": 2e-7,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "output_cost_per_token_batches": 2e-7,
      "output_cost_per_token_priority": 8e-7,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_service_tier": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-4.1-nano",
    "displayName": "gpt-4.1-nano"
  },
  {
    "id": "gpt-4.1-nano-2025-04-14",
    "name": "gpt-4.1-nano-2025-04-14",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 2.5e-8,
      "input_cost_per_token": 1e-7,
      "input_cost_per_token_batches": 5e-8,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "output_cost_per_token_batches": 2e-7,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_service_tier": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-4.1-nano-2025-04-14",
    "displayName": "gpt-4.1-nano-2025-04-14"
  },
  {
    "id": "gpt-4.5-preview",
    "name": "gpt-4.5-preview",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 0.0000375,
      "input_cost_per_token": 0.000075,
      "input_cost_per_token_batches": 0.0000375,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.00015,
      "output_cost_per_token_batches": 0.000075,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-4.5-preview",
    "displayName": "gpt-4.5-preview"
  },
  {
    "id": "gpt-4.5-preview-2025-02-27",
    "name": "gpt-4.5-preview-2025-02-27",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 0.0000375,
      "deprecation_date": "2025-07-14",
      "input_cost_per_token": 0.000075,
      "input_cost_per_token_batches": 0.0000375,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.00015,
      "output_cost_per_token_batches": 0.000075,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-4.5-preview-2025-02-27",
    "displayName": "gpt-4.5-preview-2025-02-27"
  },
  {
    "id": "gpt-4o",
    "name": "gpt-4o",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 0.00000125,
      "cache_read_input_token_cost_priority": 0.000002125,
      "input_cost_per_token": 0.0000025,
      "input_cost_per_token_batches": 0.00000125,
      "input_cost_per_token_priority": 0.00000425,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_batches": 0.000005,
      "output_cost_per_token_priority": 0.000017,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_service_tier": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-4o",
    "displayName": "gpt-4o"
  },
  {
    "id": "gpt-4o-2024-05-13",
    "name": "gpt-4o-2024-05-13",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 0.000005,
      "input_cost_per_token_batches": 0.0000025,
      "input_cost_per_token_priority": 0.00000875,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "output_cost_per_token_batches": 0.0000075,
      "output_cost_per_token_priority": 0.00002625,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-4o-2024-05-13",
    "displayName": "gpt-4o-2024-05-13"
  },
  {
    "id": "gpt-4o-2024-08-06",
    "name": "gpt-4o-2024-08-06",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 0.00000125,
      "input_cost_per_token": 0.0000025,
      "input_cost_per_token_batches": 0.00000125,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_batches": 0.000005,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_service_tier": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-4o-2024-08-06",
    "displayName": "gpt-4o-2024-08-06"
  },
  {
    "id": "gpt-4o-2024-11-20",
    "name": "gpt-4o-2024-11-20",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 0.00000125,
      "input_cost_per_token": 0.0000025,
      "input_cost_per_token_batches": 0.00000125,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_batches": 0.000005,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_service_tier": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-4o-2024-11-20",
    "displayName": "gpt-4o-2024-11-20"
  },
  {
    "id": "gpt-4o-audio-preview",
    "name": "gpt-4o-audio-preview",
    "provider": "openai",
    "data": {
      "input_cost_per_audio_token": 0.00004,
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_audio_token": 0.00008,
      "output_cost_per_token": 0.00001,
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "gpt-4o-audio-preview",
    "displayName": "gpt-4o-audio-preview"
  },
  {
    "id": "gpt-4o-audio-preview-2024-10-01",
    "name": "gpt-4o-audio-preview-2024-10-01",
    "provider": "openai",
    "data": {
      "input_cost_per_audio_token": 0.00004,
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_audio_token": 0.00008,
      "output_cost_per_token": 0.00001,
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "gpt-4o-audio-preview-2024-10-01",
    "displayName": "gpt-4o-audio-preview-2024-10-01"
  },
  {
    "id": "gpt-4o-audio-preview-2024-12-17",
    "name": "gpt-4o-audio-preview-2024-12-17",
    "provider": "openai",
    "data": {
      "input_cost_per_audio_token": 0.00004,
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_audio_token": 0.00008,
      "output_cost_per_token": 0.00001,
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "gpt-4o-audio-preview-2024-12-17",
    "displayName": "gpt-4o-audio-preview-2024-12-17"
  },
  {
    "id": "gpt-4o-audio-preview-2025-06-03",
    "name": "gpt-4o-audio-preview-2025-06-03",
    "provider": "openai",
    "data": {
      "input_cost_per_audio_token": 0.00004,
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_audio_token": 0.00008,
      "output_cost_per_token": 0.00001,
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "gpt-4o-audio-preview-2025-06-03",
    "displayName": "gpt-4o-audio-preview-2025-06-03"
  },
  {
    "id": "gpt-audio",
    "name": "gpt-audio",
    "provider": "openai",
    "data": {
      "input_cost_per_audio_token": 0.000032,
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_audio_token": 0.000064,
      "output_cost_per_token": 0.00001,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/responses",
        "/v1/realtime",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "audio"
      ],
      "supported_output_modalities": [
        "text",
        "audio"
      ],
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": false,
      "supports_reasoning": false,
      "supports_response_schema": false,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "openai"
    },
    "slug": "gpt-audio",
    "displayName": "gpt-audio"
  },
  {
    "id": "gpt-audio-2025-08-28",
    "name": "gpt-audio-2025-08-28",
    "provider": "openai",
    "data": {
      "input_cost_per_audio_token": 0.000032,
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_audio_token": 0.000064,
      "output_cost_per_token": 0.00001,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/responses",
        "/v1/realtime",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "audio"
      ],
      "supported_output_modalities": [
        "text",
        "audio"
      ],
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": false,
      "supports_reasoning": false,
      "supports_response_schema": false,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "openai"
    },
    "slug": "gpt-audio-2025-08-28",
    "displayName": "gpt-audio-2025-08-28"
  },
  {
    "id": "gpt-audio-mini",
    "name": "gpt-audio-mini",
    "provider": "openai",
    "data": {
      "input_cost_per_audio_token": 0.00001,
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_audio_token": 0.00002,
      "output_cost_per_token": 0.0000024,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/responses",
        "/v1/realtime",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "audio"
      ],
      "supported_output_modalities": [
        "text",
        "audio"
      ],
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": false,
      "supports_reasoning": false,
      "supports_response_schema": false,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "openai"
    },
    "slug": "gpt-audio-mini",
    "displayName": "gpt-audio-mini"
  },
  {
    "id": "gpt-audio-mini-2025-10-06",
    "name": "gpt-audio-mini-2025-10-06",
    "provider": "openai",
    "data": {
      "input_cost_per_audio_token": 0.00001,
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_audio_token": 0.00002,
      "output_cost_per_token": 0.0000024,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/responses",
        "/v1/realtime",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "audio"
      ],
      "supported_output_modalities": [
        "text",
        "audio"
      ],
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": false,
      "supports_reasoning": false,
      "supports_response_schema": false,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "openai"
    },
    "slug": "gpt-audio-mini-2025-10-06",
    "displayName": "gpt-audio-mini-2025-10-06"
  },
  {
    "id": "gpt-audio-mini-2025-12-15",
    "name": "gpt-audio-mini-2025-12-15",
    "provider": "openai",
    "data": {
      "input_cost_per_audio_token": 0.00001,
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_audio_token": 0.00002,
      "output_cost_per_token": 0.0000024,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/responses",
        "/v1/realtime",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "audio"
      ],
      "supported_output_modalities": [
        "text",
        "audio"
      ],
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": false,
      "supports_reasoning": false,
      "supports_response_schema": false,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "openai"
    },
    "slug": "gpt-audio-mini-2025-12-15",
    "displayName": "gpt-audio-mini-2025-12-15"
  },
  {
    "id": "gpt-4o-mini",
    "name": "gpt-4o-mini",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 7.5e-8,
      "cache_read_input_token_cost_priority": 1.25e-7,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_token_batches": 7.5e-8,
      "input_cost_per_token_priority": 2.5e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "output_cost_per_token_batches": 3e-7,
      "output_cost_per_token_priority": 0.000001,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_service_tier": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-4o-mini",
    "displayName": "gpt-4o-mini"
  },
  {
    "id": "gpt-4o-mini-2024-07-18",
    "name": "gpt-4o-mini-2024-07-18",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 7.5e-8,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_token_batches": 7.5e-8,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "output_cost_per_token_batches": 3e-7,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.03,
        "search_context_size_low": 0.025,
        "search_context_size_medium": 0.0275
      },
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_service_tier": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-4o-mini-2024-07-18",
    "displayName": "gpt-4o-mini-2024-07-18"
  },
  {
    "id": "gpt-4o-mini-audio-preview",
    "name": "gpt-4o-mini-audio-preview",
    "provider": "openai",
    "data": {
      "input_cost_per_audio_token": 0.00001,
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_audio_token": 0.00002,
      "output_cost_per_token": 6e-7,
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "gpt-4o-mini-audio-preview",
    "displayName": "gpt-4o-mini-audio-preview"
  },
  {
    "id": "gpt-4o-mini-audio-preview-2024-12-17",
    "name": "gpt-4o-mini-audio-preview-2024-12-17",
    "provider": "openai",
    "data": {
      "input_cost_per_audio_token": 0.00001,
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_audio_token": 0.00002,
      "output_cost_per_token": 6e-7,
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "gpt-4o-mini-audio-preview-2024-12-17",
    "displayName": "gpt-4o-mini-audio-preview-2024-12-17"
  },
  {
    "id": "gpt-4o-mini-realtime-preview",
    "name": "gpt-4o-mini-realtime-preview",
    "provider": "openai",
    "data": {
      "cache_creation_input_audio_token_cost": 3e-7,
      "cache_read_input_token_cost": 3e-7,
      "input_cost_per_audio_token": 0.00001,
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_audio_token": 0.00002,
      "output_cost_per_token": 0.0000024,
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "gpt-4o-mini-realtime-preview",
    "displayName": "gpt-4o-mini-realtime-preview"
  },
  {
    "id": "gpt-4o-mini-realtime-preview-2024-12-17",
    "name": "gpt-4o-mini-realtime-preview-2024-12-17",
    "provider": "openai",
    "data": {
      "cache_creation_input_audio_token_cost": 3e-7,
      "cache_read_input_token_cost": 3e-7,
      "input_cost_per_audio_token": 0.00001,
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_audio_token": 0.00002,
      "output_cost_per_token": 0.0000024,
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "gpt-4o-mini-realtime-preview-2024-12-17",
    "displayName": "gpt-4o-mini-realtime-preview-2024-12-17"
  },
  {
    "id": "gpt-4o-mini-search-preview",
    "name": "gpt-4o-mini-search-preview",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 7.5e-8,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_token_batches": 7.5e-8,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "output_cost_per_token_batches": 3e-7,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.03,
        "search_context_size_low": 0.025,
        "search_context_size_medium": 0.0275
      },
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "openai"
    },
    "slug": "gpt-4o-mini-search-preview",
    "displayName": "gpt-4o-mini-search-preview"
  },
  {
    "id": "gpt-4o-mini-search-preview-2025-03-11",
    "name": "gpt-4o-mini-search-preview-2025-03-11",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 7.5e-8,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_token_batches": 7.5e-8,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "output_cost_per_token_batches": 3e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-4o-mini-search-preview-2025-03-11",
    "displayName": "gpt-4o-mini-search-preview-2025-03-11"
  },
  {
    "id": "gpt-4o-mini-transcribe",
    "name": "gpt-4o-mini-transcribe",
    "provider": "openai",
    "data": {
      "input_cost_per_audio_token": 0.000003,
      "input_cost_per_token": 0.00000125,
      "max_input_tokens": 16000,
      "max_output_tokens": 2000,
      "mode": "audio_transcription",
      "output_cost_per_token": 0.000005,
      "supported_endpoints": [
        "/v1/audio/transcriptions"
      ],
      "provider": "openai"
    },
    "slug": "gpt-4o-mini-transcribe",
    "displayName": "gpt-4o-mini-transcribe"
  },
  {
    "id": "gpt-4o-mini-tts",
    "name": "gpt-4o-mini-tts",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 0.0000025,
      "mode": "audio_speech",
      "output_cost_per_audio_token": 0.000012,
      "output_cost_per_second": 0.00025,
      "output_cost_per_token": 0.00001,
      "supported_endpoints": [
        "/v1/audio/speech"
      ],
      "supported_modalities": [
        "text",
        "audio"
      ],
      "supported_output_modalities": [
        "audio"
      ],
      "provider": "openai"
    },
    "slug": "gpt-4o-mini-tts",
    "displayName": "gpt-4o-mini-tts"
  },
  {
    "id": "gpt-4o-realtime-preview",
    "name": "gpt-4o-realtime-preview",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 0.0000025,
      "input_cost_per_audio_token": 0.00004,
      "input_cost_per_token": 0.000005,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_audio_token": 0.00008,
      "output_cost_per_token": 0.00002,
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "gpt-4o-realtime-preview",
    "displayName": "gpt-4o-realtime-preview"
  },
  {
    "id": "gpt-4o-realtime-preview-2024-10-01",
    "name": "gpt-4o-realtime-preview-2024-10-01",
    "provider": "openai",
    "data": {
      "cache_creation_input_audio_token_cost": 0.00002,
      "cache_read_input_token_cost": 0.0000025,
      "input_cost_per_audio_token": 0.0001,
      "input_cost_per_token": 0.000005,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_audio_token": 0.0002,
      "output_cost_per_token": 0.00002,
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "gpt-4o-realtime-preview-2024-10-01",
    "displayName": "gpt-4o-realtime-preview-2024-10-01"
  },
  {
    "id": "gpt-4o-realtime-preview-2024-12-17",
    "name": "gpt-4o-realtime-preview-2024-12-17",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 0.0000025,
      "input_cost_per_audio_token": 0.00004,
      "input_cost_per_token": 0.000005,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_audio_token": 0.00008,
      "output_cost_per_token": 0.00002,
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "gpt-4o-realtime-preview-2024-12-17",
    "displayName": "gpt-4o-realtime-preview-2024-12-17"
  },
  {
    "id": "gpt-4o-realtime-preview-2025-06-03",
    "name": "gpt-4o-realtime-preview-2025-06-03",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 0.0000025,
      "input_cost_per_audio_token": 0.00004,
      "input_cost_per_token": 0.000005,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_audio_token": 0.00008,
      "output_cost_per_token": 0.00002,
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "gpt-4o-realtime-preview-2025-06-03",
    "displayName": "gpt-4o-realtime-preview-2025-06-03"
  },
  {
    "id": "gpt-4o-search-preview",
    "name": "gpt-4o-search-preview",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 0.00000125,
      "input_cost_per_token": 0.0000025,
      "input_cost_per_token_batches": 0.00000125,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_batches": 0.000005,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.05,
        "search_context_size_low": 0.03,
        "search_context_size_medium": 0.035
      },
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "openai"
    },
    "slug": "gpt-4o-search-preview",
    "displayName": "gpt-4o-search-preview"
  },
  {
    "id": "gpt-4o-search-preview-2025-03-11",
    "name": "gpt-4o-search-preview-2025-03-11",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 0.00000125,
      "input_cost_per_token": 0.0000025,
      "input_cost_per_token_batches": 0.00000125,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_batches": 0.000005,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-4o-search-preview-2025-03-11",
    "displayName": "gpt-4o-search-preview-2025-03-11"
  },
  {
    "id": "gpt-4o-transcribe",
    "name": "gpt-4o-transcribe",
    "provider": "openai",
    "data": {
      "input_cost_per_audio_token": 0.000006,
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 16000,
      "max_output_tokens": 2000,
      "mode": "audio_transcription",
      "output_cost_per_token": 0.00001,
      "supported_endpoints": [
        "/v1/audio/transcriptions"
      ],
      "provider": "openai"
    },
    "slug": "gpt-4o-transcribe",
    "displayName": "gpt-4o-transcribe"
  },
  {
    "id": "gpt-image-1.5",
    "name": "gpt-image-1.5",
    "provider": "openai",
    "data": {
      "cache_read_input_image_token_cost": 0.000002,
      "cache_read_input_token_cost": 0.00000125,
      "input_cost_per_token": 0.000005,
      "mode": "image_generation",
      "output_cost_per_token": 0.00001,
      "input_cost_per_image_token": 0.000008,
      "output_cost_per_image_token": 0.000032,
      "supported_endpoints": [
        "/v1/images/generations"
      ],
      "supports_vision": true,
      "supports_pdf_input": true,
      "provider": "openai"
    },
    "slug": "gpt-image-1.5",
    "displayName": "gpt-image-1.5"
  },
  {
    "id": "gpt-image-1.5-2025-12-16",
    "name": "gpt-image-1.5-2025-12-16",
    "provider": "openai",
    "data": {
      "cache_read_input_image_token_cost": 0.000002,
      "cache_read_input_token_cost": 0.00000125,
      "input_cost_per_token": 0.000005,
      "mode": "image_generation",
      "output_cost_per_token": 0.00001,
      "input_cost_per_image_token": 0.000008,
      "output_cost_per_image_token": 0.000032,
      "supported_endpoints": [
        "/v1/images/generations"
      ],
      "supports_vision": true,
      "supports_pdf_input": true,
      "provider": "openai"
    },
    "slug": "gpt-image-1.5-2025-12-16",
    "displayName": "gpt-image-1.5-2025-12-16"
  },
  {
    "id": "gpt-5",
    "name": "gpt-5",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "cache_read_input_token_cost_flex": 6.25e-8,
      "cache_read_input_token_cost_priority": 2.5e-7,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_flex": 6.25e-7,
      "input_cost_per_token_priority": 0.0000025,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_flex": 0.000005,
      "output_cost_per_token_priority": 0.00002,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_service_tier": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-5",
    "displayName": "gpt-5"
  },
  {
    "id": "gpt-5.1",
    "name": "gpt-5.1",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "cache_read_input_token_cost_priority": 2.5e-7,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_priority": 0.0000025,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_priority": 0.00002,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_service_tier": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-5.1",
    "displayName": "gpt-5.1"
  },
  {
    "id": "gpt-5.1-2025-11-13",
    "name": "gpt-5.1-2025-11-13",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "cache_read_input_token_cost_priority": 2.5e-7,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_priority": 0.0000025,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_priority": 0.00002,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_service_tier": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-5.1-2025-11-13",
    "displayName": "gpt-5.1-2025-11-13"
  },
  {
    "id": "gpt-5.1-chat-latest",
    "name": "gpt-5.1-chat-latest",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "cache_read_input_token_cost_priority": 2.5e-7,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_priority": 0.0000025,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_priority": 0.00002,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_function_calling": false,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": false,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": false,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-5.1-chat-latest",
    "displayName": "gpt-5.1-chat-latest"
  },
  {
    "id": "gpt-5.2",
    "name": "gpt-5.2",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 1.75e-7,
      "cache_read_input_token_cost_priority": 3.5e-7,
      "input_cost_per_token": 0.00000175,
      "input_cost_per_token_priority": 0.0000035,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000014,
      "output_cost_per_token_priority": 0.000028,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_service_tier": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-5.2",
    "displayName": "gpt-5.2"
  },
  {
    "id": "gpt-5.2-2025-12-11",
    "name": "gpt-5.2-2025-12-11",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 1.75e-7,
      "cache_read_input_token_cost_priority": 3.5e-7,
      "input_cost_per_token": 0.00000175,
      "input_cost_per_token_priority": 0.0000035,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000014,
      "output_cost_per_token_priority": 0.000028,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_service_tier": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-5.2-2025-12-11",
    "displayName": "gpt-5.2-2025-12-11"
  },
  {
    "id": "gpt-5.2-chat-latest",
    "name": "gpt-5.2-chat-latest",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 1.75e-7,
      "cache_read_input_token_cost_priority": 3.5e-7,
      "input_cost_per_token": 0.00000175,
      "input_cost_per_token_priority": 0.0000035,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.000014,
      "output_cost_per_token_priority": 0.000028,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-5.2-chat-latest",
    "displayName": "gpt-5.2-chat-latest"
  },
  {
    "id": "gpt-5.2-pro",
    "name": "gpt-5.2-pro",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 0.000021,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "responses",
      "output_cost_per_token": 0.000168,
      "supported_endpoints": [
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "openai"
    },
    "slug": "gpt-5.2-pro",
    "displayName": "gpt-5.2-pro"
  },
  {
    "id": "gpt-5.2-pro-2025-12-11",
    "name": "gpt-5.2-pro-2025-12-11",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 0.000021,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "responses",
      "output_cost_per_token": 0.000168,
      "supported_endpoints": [
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "openai"
    },
    "slug": "gpt-5.2-pro-2025-12-11",
    "displayName": "gpt-5.2-pro-2025-12-11"
  },
  {
    "id": "gpt-5-pro",
    "name": "gpt-5-pro",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 0.000015,
      "input_cost_per_token_batches": 0.0000075,
      "max_input_tokens": 128000,
      "max_output_tokens": 272000,
      "max_tokens": 272000,
      "mode": "responses",
      "output_cost_per_token": 0.00012,
      "output_cost_per_token_batches": 0.00006,
      "supported_endpoints": [
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": false,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "openai"
    },
    "slug": "gpt-5-pro",
    "displayName": "gpt-5-pro"
  },
  {
    "id": "gpt-5-pro-2025-10-06",
    "name": "gpt-5-pro-2025-10-06",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 0.000015,
      "input_cost_per_token_batches": 0.0000075,
      "max_input_tokens": 128000,
      "max_output_tokens": 272000,
      "max_tokens": 272000,
      "mode": "responses",
      "output_cost_per_token": 0.00012,
      "output_cost_per_token_batches": 0.00006,
      "supported_endpoints": [
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": false,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "openai"
    },
    "slug": "gpt-5-pro-2025-10-06",
    "displayName": "gpt-5-pro-2025-10-06"
  },
  {
    "id": "gpt-5-2025-08-07",
    "name": "gpt-5-2025-08-07",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "cache_read_input_token_cost_flex": 6.25e-8,
      "cache_read_input_token_cost_priority": 2.5e-7,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_flex": 6.25e-7,
      "input_cost_per_token_priority": 0.0000025,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_flex": 0.000005,
      "output_cost_per_token_priority": 0.00002,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_service_tier": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-5-2025-08-07",
    "displayName": "gpt-5-2025-08-07"
  },
  {
    "id": "gpt-5-chat",
    "name": "gpt-5-chat",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "input_cost_per_token": 0.00000125,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": false,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": false,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": false,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-5-chat",
    "displayName": "gpt-5-chat"
  },
  {
    "id": "gpt-5-chat-latest",
    "name": "gpt-5-chat-latest",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "input_cost_per_token": 0.00000125,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": false,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": false,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": false,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-5-chat-latest",
    "displayName": "gpt-5-chat-latest"
  },
  {
    "id": "gpt-5-codex",
    "name": "gpt-5-codex",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "input_cost_per_token": 0.00000125,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "responses",
      "output_cost_per_token": 0.00001,
      "supported_endpoints": [
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": false,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-5-codex",
    "displayName": "gpt-5-codex"
  },
  {
    "id": "gpt-5.1-codex",
    "name": "gpt-5.1-codex",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "cache_read_input_token_cost_priority": 2.5e-7,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_token_priority": 0.0000025,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "responses",
      "output_cost_per_token": 0.00001,
      "output_cost_per_token_priority": 0.00002,
      "supported_endpoints": [
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": false,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-5.1-codex",
    "displayName": "gpt-5.1-codex"
  },
  {
    "id": "gpt-5.1-codex-max",
    "name": "gpt-5.1-codex-max",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "input_cost_per_token": 0.00000125,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "responses",
      "output_cost_per_token": 0.00001,
      "supported_endpoints": [
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": false,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-5.1-codex-max",
    "displayName": "gpt-5.1-codex-max"
  },
  {
    "id": "gpt-5.1-codex-mini",
    "name": "gpt-5.1-codex-mini",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 2.5e-8,
      "cache_read_input_token_cost_priority": 4.5e-8,
      "input_cost_per_token": 2.5e-7,
      "input_cost_per_token_priority": 4.5e-7,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "responses",
      "output_cost_per_token": 0.000002,
      "output_cost_per_token_priority": 0.0000036,
      "supported_endpoints": [
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": false,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-5.1-codex-mini",
    "displayName": "gpt-5.1-codex-mini"
  },
  {
    "id": "gpt-5.2-codex",
    "name": "gpt-5.2-codex",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 1.75e-7,
      "cache_read_input_token_cost_priority": 3.5e-7,
      "input_cost_per_token": 0.00000175,
      "input_cost_per_token_priority": 0.0000035,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "responses",
      "output_cost_per_token": 0.000014,
      "output_cost_per_token_priority": 0.000028,
      "supported_endpoints": [
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": false,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-5.2-codex",
    "displayName": "gpt-5.2-codex"
  },
  {
    "id": "gpt-5-mini",
    "name": "gpt-5-mini",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 2.5e-8,
      "cache_read_input_token_cost_flex": 1.25e-8,
      "cache_read_input_token_cost_priority": 4.5e-8,
      "input_cost_per_token": 2.5e-7,
      "input_cost_per_token_flex": 1.25e-7,
      "input_cost_per_token_priority": 4.5e-7,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "output_cost_per_token_flex": 0.000001,
      "output_cost_per_token_priority": 0.0000036,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_service_tier": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-5-mini",
    "displayName": "gpt-5-mini"
  },
  {
    "id": "gpt-5-mini-2025-08-07",
    "name": "gpt-5-mini-2025-08-07",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 2.5e-8,
      "cache_read_input_token_cost_flex": 1.25e-8,
      "cache_read_input_token_cost_priority": 4.5e-8,
      "input_cost_per_token": 2.5e-7,
      "input_cost_per_token_flex": 1.25e-7,
      "input_cost_per_token_priority": 4.5e-7,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "output_cost_per_token_flex": 0.000001,
      "output_cost_per_token_priority": 0.0000036,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_service_tier": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-5-mini-2025-08-07",
    "displayName": "gpt-5-mini-2025-08-07"
  },
  {
    "id": "gpt-5-nano",
    "name": "gpt-5-nano",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 5e-9,
      "cache_read_input_token_cost_flex": 2.5e-9,
      "input_cost_per_token": 5e-8,
      "input_cost_per_token_flex": 2.5e-8,
      "input_cost_per_token_priority": 0.0000025,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "output_cost_per_token_flex": 2e-7,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-5-nano",
    "displayName": "gpt-5-nano"
  },
  {
    "id": "gpt-5-nano-2025-08-07",
    "name": "gpt-5-nano-2025-08-07",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 5e-9,
      "cache_read_input_token_cost_flex": 2.5e-9,
      "input_cost_per_token": 5e-8,
      "input_cost_per_token_flex": 2.5e-8,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "output_cost_per_token_flex": 2e-7,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "gpt-5-nano-2025-08-07",
    "displayName": "gpt-5-nano-2025-08-07"
  },
  {
    "id": "gpt-image-1",
    "name": "gpt-image-1",
    "provider": "openai",
    "data": {
      "cache_read_input_image_token_cost": 0.0000025,
      "cache_read_input_token_cost": 0.00000125,
      "input_cost_per_image_token": 0.00001,
      "input_cost_per_token": 0.000005,
      "mode": "image_generation",
      "output_cost_per_image_token": 0.00004,
      "supported_endpoints": [
        "/v1/images/generations",
        "/v1/images/edits"
      ],
      "provider": "openai"
    },
    "slug": "gpt-image-1",
    "displayName": "gpt-image-1"
  },
  {
    "id": "gpt-image-1-mini",
    "name": "gpt-image-1-mini",
    "provider": "openai",
    "data": {
      "cache_read_input_image_token_cost": 2.5e-7,
      "cache_read_input_token_cost": 2e-7,
      "input_cost_per_image_token": 0.0000025,
      "input_cost_per_token": 0.000002,
      "mode": "image_generation",
      "output_cost_per_image_token": 0.000008,
      "supported_endpoints": [
        "/v1/images/generations",
        "/v1/images/edits"
      ],
      "provider": "openai"
    },
    "slug": "gpt-image-1-mini",
    "displayName": "gpt-image-1-mini"
  },
  {
    "id": "gpt-realtime",
    "name": "gpt-realtime",
    "provider": "openai",
    "data": {
      "cache_creation_input_audio_token_cost": 4e-7,
      "cache_read_input_token_cost": 4e-7,
      "input_cost_per_audio_token": 0.000032,
      "input_cost_per_image": 0.000005,
      "input_cost_per_token": 0.000004,
      "max_input_tokens": 32000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_audio_token": 0.000064,
      "output_cost_per_token": 0.000016,
      "supported_endpoints": [
        "/v1/realtime"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio"
      ],
      "supported_output_modalities": [
        "text",
        "audio"
      ],
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "gpt-realtime",
    "displayName": "gpt-realtime"
  },
  {
    "id": "gpt-realtime-mini",
    "name": "gpt-realtime-mini",
    "provider": "openai",
    "data": {
      "cache_creation_input_audio_token_cost": 3e-7,
      "cache_read_input_audio_token_cost": 3e-7,
      "input_cost_per_audio_token": 0.00001,
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_audio_token": 0.00002,
      "output_cost_per_token": 0.0000024,
      "supported_endpoints": [
        "/v1/realtime"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio"
      ],
      "supported_output_modalities": [
        "text",
        "audio"
      ],
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "gpt-realtime-mini",
    "displayName": "gpt-realtime-mini"
  },
  {
    "id": "gpt-realtime-2025-08-28",
    "name": "gpt-realtime-2025-08-28",
    "provider": "openai",
    "data": {
      "cache_creation_input_audio_token_cost": 4e-7,
      "cache_read_input_token_cost": 4e-7,
      "input_cost_per_audio_token": 0.000032,
      "input_cost_per_image": 0.000005,
      "input_cost_per_token": 0.000004,
      "max_input_tokens": 32000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_audio_token": 0.000064,
      "output_cost_per_token": 0.000016,
      "supported_endpoints": [
        "/v1/realtime"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio"
      ],
      "supported_output_modalities": [
        "text",
        "audio"
      ],
      "supports_audio_input": true,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "openai"
    },
    "slug": "gpt-realtime-2025-08-28",
    "displayName": "gpt-realtime-2025-08-28"
  },
  {
    "id": "gradient_ai/anthropic-claude-3-opus",
    "name": "anthropic-claude-3-opus",
    "provider": "gradient_ai",
    "data": {
      "input_cost_per_token": 0.000015,
      "max_tokens": 1024,
      "mode": "chat",
      "output_cost_per_token": 0.000075,
      "supported_endpoints": [
        "/v1/chat/completions"
      ],
      "supported_modalities": [
        "text"
      ],
      "supports_tool_choice": false,
      "provider": "gradient_ai"
    },
    "slug": "anthropic-claude-3-opus",
    "displayName": "anthropic-claude-3-opus"
  },
  {
    "id": "gradient_ai/anthropic-claude-3.5-haiku",
    "name": "anthropic-claude-3.5-haiku",
    "provider": "gradient_ai",
    "data": {
      "input_cost_per_token": 8e-7,
      "max_tokens": 1024,
      "mode": "chat",
      "output_cost_per_token": 0.000004,
      "supported_endpoints": [
        "/v1/chat/completions"
      ],
      "supported_modalities": [
        "text"
      ],
      "supports_tool_choice": false,
      "provider": "gradient_ai"
    },
    "slug": "anthropic-claude-3.5-haiku",
    "displayName": "anthropic-claude-3.5-haiku"
  },
  {
    "id": "gradient_ai/anthropic-claude-3.5-sonnet",
    "name": "anthropic-claude-3.5-sonnet",
    "provider": "gradient_ai",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_tokens": 1024,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supported_endpoints": [
        "/v1/chat/completions"
      ],
      "supported_modalities": [
        "text"
      ],
      "supports_tool_choice": false,
      "provider": "gradient_ai"
    },
    "slug": "anthropic-claude-3.5-sonnet",
    "displayName": "anthropic-claude-3.5-sonnet"
  },
  {
    "id": "gradient_ai/anthropic-claude-3.7-sonnet",
    "name": "anthropic-claude-3.7-sonnet",
    "provider": "gradient_ai",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_tokens": 1024,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supported_endpoints": [
        "/v1/chat/completions"
      ],
      "supported_modalities": [
        "text"
      ],
      "supports_tool_choice": false,
      "provider": "gradient_ai"
    },
    "slug": "anthropic-claude-3.7-sonnet",
    "displayName": "anthropic-claude-3.7-sonnet"
  },
  {
    "id": "gradient_ai/deepseek-r1-distill-llama-70b",
    "name": "deepseek-r1-distill-llama-70b",
    "provider": "gradient_ai",
    "data": {
      "input_cost_per_token": 9.9e-7,
      "max_tokens": 8000,
      "mode": "chat",
      "output_cost_per_token": 9.9e-7,
      "supported_endpoints": [
        "/v1/chat/completions"
      ],
      "supported_modalities": [
        "text"
      ],
      "supports_tool_choice": false,
      "provider": "gradient_ai"
    },
    "slug": "deepseek-r1-distill-llama-70b",
    "displayName": "deepseek-r1-distill-llama-70b"
  },
  {
    "id": "gradient_ai/llama3-8b-instruct",
    "name": "llama3-8b-instruct",
    "provider": "gradient_ai",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_tokens": 512,
      "mode": "chat",
      "output_cost_per_token": 2e-7,
      "supported_endpoints": [
        "/v1/chat/completions"
      ],
      "supported_modalities": [
        "text"
      ],
      "supports_tool_choice": false,
      "provider": "gradient_ai"
    },
    "slug": "llama3-8b-instruct",
    "displayName": "llama3-8b-instruct"
  },
  {
    "id": "gradient_ai/llama3.3-70b-instruct",
    "name": "llama3.3-70b-instruct",
    "provider": "gradient_ai",
    "data": {
      "input_cost_per_token": 6.5e-7,
      "max_tokens": 2048,
      "mode": "chat",
      "output_cost_per_token": 6.5e-7,
      "supported_endpoints": [
        "/v1/chat/completions"
      ],
      "supported_modalities": [
        "text"
      ],
      "supports_tool_choice": false,
      "provider": "gradient_ai"
    },
    "slug": "llama3.3-70b-instruct",
    "displayName": "llama3.3-70b-instruct"
  },
  {
    "id": "gradient_ai/mistral-nemo-instruct-2407",
    "name": "mistral-nemo-instruct-2407",
    "provider": "gradient_ai",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_tokens": 512,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "supported_endpoints": [
        "/v1/chat/completions"
      ],
      "supported_modalities": [
        "text"
      ],
      "supports_tool_choice": false,
      "provider": "gradient_ai"
    },
    "slug": "mistral-nemo-instruct-2407",
    "displayName": "mistral-nemo-instruct-2407"
  },
  {
    "id": "gradient_ai/openai-o3",
    "name": "openai-o3",
    "provider": "gradient_ai",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_tokens": 100000,
      "mode": "chat",
      "output_cost_per_token": 0.000008,
      "supported_endpoints": [
        "/v1/chat/completions"
      ],
      "supported_modalities": [
        "text"
      ],
      "supports_tool_choice": false,
      "provider": "gradient_ai"
    },
    "slug": "openai-o3",
    "displayName": "openai-o3"
  },
  {
    "id": "gradient_ai/openai-o3-mini",
    "name": "openai-o3-mini",
    "provider": "gradient_ai",
    "data": {
      "input_cost_per_token": 0.0000011,
      "max_tokens": 100000,
      "mode": "chat",
      "output_cost_per_token": 0.0000044,
      "supported_endpoints": [
        "/v1/chat/completions"
      ],
      "supported_modalities": [
        "text"
      ],
      "supports_tool_choice": false,
      "provider": "gradient_ai"
    },
    "slug": "openai-o3-mini",
    "displayName": "openai-o3-mini"
  },
  {
    "id": "amazon-nova/nova-micro-v1",
    "name": "nova-micro-v1",
    "provider": "amazon_nova",
    "data": {
      "input_cost_per_token": 3.5e-8,
      "max_input_tokens": 128000,
      "max_output_tokens": 10000,
      "max_tokens": 10000,
      "mode": "chat",
      "output_cost_per_token": 1.4e-7,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "provider": "amazon_nova"
    },
    "slug": "nova-micro-v1",
    "displayName": "nova-micro-v1"
  },
  {
    "id": "amazon-nova/nova-lite-v1",
    "name": "nova-lite-v1",
    "provider": "amazon_nova",
    "data": {
      "input_cost_per_token": 6e-8,
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "max_tokens": 10000,
      "mode": "chat",
      "output_cost_per_token": 2.4e-7,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "provider": "amazon_nova"
    },
    "slug": "nova-lite-v1",
    "displayName": "nova-lite-v1"
  },
  {
    "id": "amazon-nova/nova-premier-v1",
    "name": "nova-premier-v1",
    "provider": "amazon_nova",
    "data": {
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 1000000,
      "max_output_tokens": 10000,
      "max_tokens": 10000,
      "mode": "chat",
      "output_cost_per_token": 0.0000125,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": false,
      "supports_response_schema": true,
      "supports_vision": true,
      "provider": "amazon_nova"
    },
    "slug": "nova-premier-v1",
    "displayName": "nova-premier-v1"
  },
  {
    "id": "amazon-nova/nova-pro-v1",
    "name": "nova-pro-v1",
    "provider": "amazon_nova",
    "data": {
      "input_cost_per_token": 8e-7,
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "max_tokens": 10000,
      "mode": "chat",
      "output_cost_per_token": 0.0000032,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "provider": "amazon_nova"
    },
    "slug": "nova-pro-v1",
    "displayName": "nova-pro-v1"
  },
  {
    "id": "groq/llama-3.1-8b-instant",
    "name": "llama-3.1-8b-instant",
    "provider": "groq",
    "data": {
      "input_cost_per_token": 5e-8,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 8e-8,
      "supports_function_calling": true,
      "supports_response_schema": false,
      "supports_tool_choice": true,
      "provider": "groq"
    },
    "slug": "llama-3.1-8b-instant",
    "displayName": "llama-3.1-8b-instant"
  },
  {
    "id": "groq/llama-3.3-70b-versatile",
    "name": "llama-3.3-70b-versatile",
    "provider": "groq",
    "data": {
      "input_cost_per_token": 5.9e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 7.9e-7,
      "supports_function_calling": true,
      "supports_response_schema": false,
      "supports_tool_choice": true,
      "provider": "groq"
    },
    "slug": "llama-3.3-70b-versatile",
    "displayName": "llama-3.3-70b-versatile"
  },
  {
    "id": "groq/gemma-7b-it",
    "name": "gemma-7b-it",
    "provider": "groq",
    "data": {
      "input_cost_per_token": 5e-8,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 8e-8,
      "supports_function_calling": true,
      "supports_response_schema": false,
      "supports_tool_choice": true,
      "provider": "groq"
    },
    "slug": "gemma-7b-it",
    "displayName": "gemma-7b-it"
  },
  {
    "id": "groq/meta-llama/llama-guard-4-12b",
    "name": "llama-guard-4-12b",
    "provider": "groq",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 2e-7,
      "provider": "groq"
    },
    "slug": "llama-guard-4-12b",
    "displayName": "llama-guard-4-12b"
  },
  {
    "id": "groq/meta-llama/llama-4-maverick-17b-128e-instruct",
    "name": "llama-4-maverick-17b-128e-instruct",
    "provider": "groq",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "groq"
    },
    "slug": "llama-4-maverick-17b-128e-instruct",
    "displayName": "llama-4-maverick-17b-128e-instruct"
  },
  {
    "id": "groq/meta-llama/llama-4-scout-17b-16e-instruct",
    "name": "llama-4-scout-17b-16e-instruct",
    "provider": "groq",
    "data": {
      "input_cost_per_token": 1.1e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 3.4e-7,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "groq"
    },
    "slug": "llama-4-scout-17b-16e-instruct",
    "displayName": "llama-4-scout-17b-16e-instruct"
  },
  {
    "id": "groq/moonshotai/kimi-k2-instruct-0905",
    "name": "kimi-k2-instruct-0905",
    "provider": "groq",
    "data": {
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000003,
      "cache_read_input_token_cost": 5e-7,
      "max_input_tokens": 262144,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "groq"
    },
    "slug": "kimi-k2-instruct-0905",
    "displayName": "kimi-k2-instruct-0905"
  },
  {
    "id": "groq/openai/gpt-oss-120b",
    "name": "gpt-oss-120b",
    "provider": "groq",
    "data": {
      "cache_read_input_token_cost": 7.5e-8,
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 32766,
      "max_tokens": 32766,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "groq"
    },
    "slug": "gpt-oss-120b",
    "displayName": "gpt-oss-120b"
  },
  {
    "id": "groq/openai/gpt-oss-20b",
    "name": "gpt-oss-20b",
    "provider": "groq",
    "data": {
      "cache_read_input_token_cost": 3.75e-8,
      "input_cost_per_token": 7.5e-8,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "groq"
    },
    "slug": "gpt-oss-20b",
    "displayName": "gpt-oss-20b"
  },
  {
    "id": "groq/qwen/qwen3-32b",
    "name": "qwen3-32b",
    "provider": "groq",
    "data": {
      "input_cost_per_token": 2.9e-7,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "max_tokens": 131000,
      "mode": "chat",
      "output_cost_per_token": 5.9e-7,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": false,
      "supports_tool_choice": true,
      "provider": "groq"
    },
    "slug": "qwen3-32b",
    "displayName": "qwen3-32b"
  },
  {
    "id": "hyperbolic/NousResearch/Hermes-3-Llama-3.1-70B",
    "name": "Hermes-3-Llama-3.1-70B",
    "provider": "hyperbolic",
    "data": {
      "input_cost_per_token": 1.2e-7,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "hyperbolic"
    },
    "slug": "hermes-3-llama-3.1-70b",
    "displayName": "Hermes-3-Llama-3.1-70B"
  },
  {
    "id": "hyperbolic/Qwen/QwQ-32B",
    "name": "QwQ-32B",
    "provider": "hyperbolic",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 2e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "hyperbolic"
    },
    "slug": "qwq-32b",
    "displayName": "QwQ-32B"
  },
  {
    "id": "hyperbolic/Qwen/Qwen2.5-72B-Instruct",
    "name": "Qwen2.5-72B-Instruct",
    "provider": "hyperbolic",
    "data": {
      "input_cost_per_token": 1.2e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "hyperbolic"
    },
    "slug": "qwen2.5-72b-instruct",
    "displayName": "Qwen2.5-72B-Instruct"
  },
  {
    "id": "hyperbolic/Qwen/Qwen2.5-Coder-32B-Instruct",
    "name": "Qwen2.5-Coder-32B-Instruct",
    "provider": "hyperbolic",
    "data": {
      "input_cost_per_token": 1.2e-7,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "hyperbolic"
    },
    "slug": "qwen2.5-coder-32b-instruct",
    "displayName": "Qwen2.5-Coder-32B-Instruct"
  },
  {
    "id": "hyperbolic/Qwen/Qwen3-235B-A22B",
    "name": "Qwen3-235B-A22B",
    "provider": "hyperbolic",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "hyperbolic"
    },
    "slug": "qwen3-235b-a22b",
    "displayName": "Qwen3-235B-A22B"
  },
  {
    "id": "hyperbolic/deepseek-ai/DeepSeek-R1",
    "name": "DeepSeek-R1",
    "provider": "hyperbolic",
    "data": {
      "input_cost_per_token": 4e-7,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "hyperbolic"
    },
    "slug": "deepseek-r1",
    "displayName": "DeepSeek-R1"
  },
  {
    "id": "hyperbolic/deepseek-ai/DeepSeek-R1-0528",
    "name": "DeepSeek-R1-0528",
    "provider": "hyperbolic",
    "data": {
      "input_cost_per_token": 2.5e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 2.5e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "hyperbolic"
    },
    "slug": "deepseek-r1-0528",
    "displayName": "DeepSeek-R1-0528"
  },
  {
    "id": "hyperbolic/deepseek-ai/DeepSeek-V3",
    "name": "DeepSeek-V3",
    "provider": "hyperbolic",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 2e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "hyperbolic"
    },
    "slug": "deepseek-v3",
    "displayName": "DeepSeek-V3"
  },
  {
    "id": "hyperbolic/deepseek-ai/DeepSeek-V3-0324",
    "name": "DeepSeek-V3-0324",
    "provider": "hyperbolic",
    "data": {
      "input_cost_per_token": 4e-7,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "hyperbolic"
    },
    "slug": "deepseek-v3-0324",
    "displayName": "DeepSeek-V3-0324"
  },
  {
    "id": "hyperbolic/meta-llama/Llama-3.2-3B-Instruct",
    "name": "Llama-3.2-3B-Instruct",
    "provider": "hyperbolic",
    "data": {
      "input_cost_per_token": 1.2e-7,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "hyperbolic"
    },
    "slug": "llama-3.2-3b-instruct",
    "displayName": "Llama-3.2-3B-Instruct"
  },
  {
    "id": "hyperbolic/meta-llama/Llama-3.3-70B-Instruct",
    "name": "Llama-3.3-70B-Instruct",
    "provider": "hyperbolic",
    "data": {
      "input_cost_per_token": 1.2e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "hyperbolic"
    },
    "slug": "llama-3.3-70b-instruct",
    "displayName": "Llama-3.3-70B-Instruct"
  },
  {
    "id": "hyperbolic/meta-llama/Meta-Llama-3-70B-Instruct",
    "name": "Meta-Llama-3-70B-Instruct",
    "provider": "hyperbolic",
    "data": {
      "input_cost_per_token": 1.2e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "hyperbolic"
    },
    "slug": "meta-llama-3-70b-instruct",
    "displayName": "Meta-Llama-3-70B-Instruct"
  },
  {
    "id": "hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct",
    "name": "Meta-Llama-3.1-405B-Instruct",
    "provider": "hyperbolic",
    "data": {
      "input_cost_per_token": 1.2e-7,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "hyperbolic"
    },
    "slug": "meta-llama-3.1-405b-instruct",
    "displayName": "Meta-Llama-3.1-405B-Instruct"
  },
  {
    "id": "hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct",
    "name": "Meta-Llama-3.1-70B-Instruct",
    "provider": "hyperbolic",
    "data": {
      "input_cost_per_token": 1.2e-7,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "hyperbolic"
    },
    "slug": "meta-llama-3.1-70b-instruct",
    "displayName": "Meta-Llama-3.1-70B-Instruct"
  },
  {
    "id": "hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct",
    "name": "Meta-Llama-3.1-8B-Instruct",
    "provider": "hyperbolic",
    "data": {
      "input_cost_per_token": 1.2e-7,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "hyperbolic"
    },
    "slug": "meta-llama-3.1-8b-instruct",
    "displayName": "Meta-Llama-3.1-8B-Instruct"
  },
  {
    "id": "hyperbolic/moonshotai/Kimi-K2-Instruct",
    "name": "Kimi-K2-Instruct",
    "provider": "hyperbolic",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "hyperbolic"
    },
    "slug": "kimi-k2-instruct",
    "displayName": "Kimi-K2-Instruct"
  },
  {
    "id": "j2-light",
    "name": "j2-light",
    "provider": "ai21",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "completion",
      "output_cost_per_token": 0.000003,
      "provider": "ai21"
    },
    "slug": "j2-light",
    "displayName": "j2-light"
  },
  {
    "id": "j2-mid",
    "name": "j2-mid",
    "provider": "ai21",
    "data": {
      "input_cost_per_token": 0.00001,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "completion",
      "output_cost_per_token": 0.00001,
      "provider": "ai21"
    },
    "slug": "j2-mid",
    "displayName": "j2-mid"
  },
  {
    "id": "j2-ultra",
    "name": "j2-ultra",
    "provider": "ai21",
    "data": {
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "completion",
      "output_cost_per_token": 0.000015,
      "provider": "ai21"
    },
    "slug": "j2-ultra",
    "displayName": "j2-ultra"
  },
  {
    "id": "jamba-1.5",
    "name": "jamba-1.5",
    "provider": "ai21",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "supports_tool_choice": true,
      "provider": "ai21"
    },
    "slug": "jamba-1.5",
    "displayName": "jamba-1.5"
  },
  {
    "id": "jamba-1.5-large",
    "name": "jamba-1.5-large",
    "provider": "ai21",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 0.000008,
      "supports_tool_choice": true,
      "provider": "ai21"
    },
    "slug": "jamba-1.5-large",
    "displayName": "jamba-1.5-large"
  },
  {
    "id": "jamba-1.5-large@001",
    "name": "jamba-1.5-large@001",
    "provider": "ai21",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 0.000008,
      "supports_tool_choice": true,
      "provider": "ai21"
    },
    "slug": "jamba-1.5-large-001",
    "displayName": "jamba-1.5-large@001"
  },
  {
    "id": "jamba-1.5-mini",
    "name": "jamba-1.5-mini",
    "provider": "ai21",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "supports_tool_choice": true,
      "provider": "ai21"
    },
    "slug": "jamba-1.5-mini",
    "displayName": "jamba-1.5-mini"
  },
  {
    "id": "jamba-1.5-mini@001",
    "name": "jamba-1.5-mini@001",
    "provider": "ai21",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "supports_tool_choice": true,
      "provider": "ai21"
    },
    "slug": "jamba-1.5-mini-001",
    "displayName": "jamba-1.5-mini@001"
  },
  {
    "id": "jamba-large-1.6",
    "name": "jamba-large-1.6",
    "provider": "ai21",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 0.000008,
      "supports_tool_choice": true,
      "provider": "ai21"
    },
    "slug": "jamba-large-1.6",
    "displayName": "jamba-large-1.6"
  },
  {
    "id": "jamba-large-1.7",
    "name": "jamba-large-1.7",
    "provider": "ai21",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 0.000008,
      "supports_tool_choice": true,
      "provider": "ai21"
    },
    "slug": "jamba-large-1.7",
    "displayName": "jamba-large-1.7"
  },
  {
    "id": "jamba-mini-1.6",
    "name": "jamba-mini-1.6",
    "provider": "ai21",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "supports_tool_choice": true,
      "provider": "ai21"
    },
    "slug": "jamba-mini-1.6",
    "displayName": "jamba-mini-1.6"
  },
  {
    "id": "jamba-mini-1.7",
    "name": "jamba-mini-1.7",
    "provider": "ai21",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "supports_tool_choice": true,
      "provider": "ai21"
    },
    "slug": "jamba-mini-1.7",
    "displayName": "jamba-mini-1.7"
  },
  {
    "id": "jina-reranker-v2-base-multilingual",
    "name": "jina-reranker-v2-base-multilingual",
    "provider": "jina_ai",
    "data": {
      "input_cost_per_token": 1.8e-8,
      "max_document_chunks_per_query": 2048,
      "max_input_tokens": 1024,
      "max_output_tokens": 1024,
      "max_tokens": 1024,
      "mode": "rerank",
      "output_cost_per_token": 1.8e-8,
      "provider": "jina_ai"
    },
    "slug": "jina-reranker-v2-base-multilingual",
    "displayName": "jina-reranker-v2-base-multilingual"
  },
  {
    "id": "jp.anthropic.claude-sonnet-4-5-20250929-v1:0",
    "name": "jp.anthropic.claude-sonnet-4-5-20250929-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_creation_input_token_cost": 0.000004125,
      "cache_read_input_token_cost": 3.3e-7,
      "input_cost_per_token": 0.0000033,
      "input_cost_per_token_above_200k_tokens": 0.0000066,
      "output_cost_per_token_above_200k_tokens": 0.00002475,
      "cache_creation_input_token_cost_above_200k_tokens": 0.00000825,
      "cache_read_input_token_cost_above_200k_tokens": 6.6e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.0000165,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 346,
      "provider": "bedrock_converse"
    },
    "slug": "jp.anthropic.claude-sonnet-4-5-20250929-v1-0",
    "displayName": "jp.anthropic.claude-sonnet-4-5-20250929-v1:0"
  },
  {
    "id": "jp.anthropic.claude-haiku-4-5-20251001-v1:0",
    "name": "jp.anthropic.claude-haiku-4-5-20251001-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_creation_input_token_cost": 0.000001375,
      "cache_read_input_token_cost": 1.1e-7,
      "input_cost_per_token": 0.0000011,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.0000055,
      "source": "https://aws.amazon.com/about-aws/whats-new/2025/10/claude-4-5-haiku-anthropic-amazon-bedrock",
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 346,
      "provider": "bedrock_converse"
    },
    "slug": "jp.anthropic.claude-haiku-4-5-20251001-v1-0",
    "displayName": "jp.anthropic.claude-haiku-4-5-20251001-v1:0"
  },
  {
    "id": "lambda_ai/deepseek-llama3.3-70b",
    "name": "deepseek-llama3.3-70b",
    "provider": "lambda_ai",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_reasoning": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "lambda_ai"
    },
    "slug": "deepseek-llama3.3-70b",
    "displayName": "deepseek-llama3.3-70b"
  },
  {
    "id": "lambda_ai/deepseek-r1-0528",
    "name": "deepseek-r1-0528",
    "provider": "lambda_ai",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_reasoning": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "lambda_ai"
    },
    "slug": "deepseek-r1-0528",
    "displayName": "deepseek-r1-0528"
  },
  {
    "id": "lambda_ai/deepseek-r1-671b",
    "name": "deepseek-r1-671b",
    "provider": "lambda_ai",
    "data": {
      "input_cost_per_token": 8e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 8e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_reasoning": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "lambda_ai"
    },
    "slug": "deepseek-r1-671b",
    "displayName": "deepseek-r1-671b"
  },
  {
    "id": "lambda_ai/deepseek-v3-0324",
    "name": "deepseek-v3-0324",
    "provider": "lambda_ai",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "lambda_ai"
    },
    "slug": "deepseek-v3-0324",
    "displayName": "deepseek-v3-0324"
  },
  {
    "id": "lambda_ai/hermes3-405b",
    "name": "hermes3-405b",
    "provider": "lambda_ai",
    "data": {
      "input_cost_per_token": 8e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 8e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "lambda_ai"
    },
    "slug": "hermes3-405b",
    "displayName": "hermes3-405b"
  },
  {
    "id": "lambda_ai/hermes3-70b",
    "name": "hermes3-70b",
    "provider": "lambda_ai",
    "data": {
      "input_cost_per_token": 1.2e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "lambda_ai"
    },
    "slug": "hermes3-70b",
    "displayName": "hermes3-70b"
  },
  {
    "id": "lambda_ai/hermes3-8b",
    "name": "hermes3-8b",
    "provider": "lambda_ai",
    "data": {
      "input_cost_per_token": 2.5e-8,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 4e-8,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "lambda_ai"
    },
    "slug": "hermes3-8b",
    "displayName": "hermes3-8b"
  },
  {
    "id": "lambda_ai/lfm-40b",
    "name": "lfm-40b",
    "provider": "lambda_ai",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 2e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "lambda_ai"
    },
    "slug": "lfm-40b",
    "displayName": "lfm-40b"
  },
  {
    "id": "lambda_ai/lfm-7b",
    "name": "lfm-7b",
    "provider": "lambda_ai",
    "data": {
      "input_cost_per_token": 2.5e-8,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 4e-8,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "lambda_ai"
    },
    "slug": "lfm-7b",
    "displayName": "lfm-7b"
  },
  {
    "id": "lambda_ai/llama-4-maverick-17b-128e-instruct-fp8",
    "name": "llama-4-maverick-17b-128e-instruct-fp8",
    "provider": "lambda_ai",
    "data": {
      "input_cost_per_token": 5e-8,
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 1e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "lambda_ai"
    },
    "slug": "llama-4-maverick-17b-128e-instruct-fp8",
    "displayName": "llama-4-maverick-17b-128e-instruct-fp8"
  },
  {
    "id": "lambda_ai/llama-4-scout-17b-16e-instruct",
    "name": "llama-4-scout-17b-16e-instruct",
    "provider": "lambda_ai",
    "data": {
      "input_cost_per_token": 5e-8,
      "max_input_tokens": 16384,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 1e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "lambda_ai"
    },
    "slug": "llama-4-scout-17b-16e-instruct",
    "displayName": "llama-4-scout-17b-16e-instruct"
  },
  {
    "id": "lambda_ai/llama3.1-405b-instruct-fp8",
    "name": "llama3.1-405b-instruct-fp8",
    "provider": "lambda_ai",
    "data": {
      "input_cost_per_token": 8e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 8e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "lambda_ai"
    },
    "slug": "llama3.1-405b-instruct-fp8",
    "displayName": "llama3.1-405b-instruct-fp8"
  },
  {
    "id": "lambda_ai/llama3.1-70b-instruct-fp8",
    "name": "llama3.1-70b-instruct-fp8",
    "provider": "lambda_ai",
    "data": {
      "input_cost_per_token": 1.2e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "lambda_ai"
    },
    "slug": "llama3.1-70b-instruct-fp8",
    "displayName": "llama3.1-70b-instruct-fp8"
  },
  {
    "id": "lambda_ai/llama3.1-8b-instruct",
    "name": "llama3.1-8b-instruct",
    "provider": "lambda_ai",
    "data": {
      "input_cost_per_token": 2.5e-8,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 4e-8,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "lambda_ai"
    },
    "slug": "llama3.1-8b-instruct",
    "displayName": "llama3.1-8b-instruct"
  },
  {
    "id": "lambda_ai/llama3.1-nemotron-70b-instruct-fp8",
    "name": "llama3.1-nemotron-70b-instruct-fp8",
    "provider": "lambda_ai",
    "data": {
      "input_cost_per_token": 1.2e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "lambda_ai"
    },
    "slug": "llama3.1-nemotron-70b-instruct-fp8",
    "displayName": "llama3.1-nemotron-70b-instruct-fp8"
  },
  {
    "id": "lambda_ai/llama3.2-11b-vision-instruct",
    "name": "llama3.2-11b-vision-instruct",
    "provider": "lambda_ai",
    "data": {
      "input_cost_per_token": 1.5e-8,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 2.5e-8,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "lambda_ai"
    },
    "slug": "llama3.2-11b-vision-instruct",
    "displayName": "llama3.2-11b-vision-instruct"
  },
  {
    "id": "lambda_ai/llama3.2-3b-instruct",
    "name": "llama3.2-3b-instruct",
    "provider": "lambda_ai",
    "data": {
      "input_cost_per_token": 1.5e-8,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 2.5e-8,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "lambda_ai"
    },
    "slug": "llama3.2-3b-instruct",
    "displayName": "llama3.2-3b-instruct"
  },
  {
    "id": "lambda_ai/llama3.3-70b-instruct-fp8",
    "name": "llama3.3-70b-instruct-fp8",
    "provider": "lambda_ai",
    "data": {
      "input_cost_per_token": 1.2e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "lambda_ai"
    },
    "slug": "llama3.3-70b-instruct-fp8",
    "displayName": "llama3.3-70b-instruct-fp8"
  },
  {
    "id": "lambda_ai/qwen25-coder-32b-instruct",
    "name": "qwen25-coder-32b-instruct",
    "provider": "lambda_ai",
    "data": {
      "input_cost_per_token": 5e-8,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 1e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "lambda_ai"
    },
    "slug": "qwen25-coder-32b-instruct",
    "displayName": "qwen25-coder-32b-instruct"
  },
  {
    "id": "lambda_ai/qwen3-32b-fp8",
    "name": "qwen3-32b-fp8",
    "provider": "lambda_ai",
    "data": {
      "input_cost_per_token": 5e-8,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 1e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_reasoning": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "provider": "lambda_ai"
    },
    "slug": "qwen3-32b-fp8",
    "displayName": "qwen3-32b-fp8"
  },
  {
    "id": "luminous-base",
    "name": "luminous-base",
    "provider": "aleph_alpha",
    "data": {
      "input_cost_per_token": 0.00003,
      "max_tokens": 2048,
      "mode": "completion",
      "output_cost_per_token": 0.000033,
      "provider": "aleph_alpha"
    },
    "slug": "luminous-base",
    "displayName": "luminous-base"
  },
  {
    "id": "luminous-base-control",
    "name": "luminous-base-control",
    "provider": "aleph_alpha",
    "data": {
      "input_cost_per_token": 0.0000375,
      "max_tokens": 2048,
      "mode": "chat",
      "output_cost_per_token": 0.00004125,
      "provider": "aleph_alpha"
    },
    "slug": "luminous-base-control",
    "displayName": "luminous-base-control"
  },
  {
    "id": "luminous-extended",
    "name": "luminous-extended",
    "provider": "aleph_alpha",
    "data": {
      "input_cost_per_token": 0.000045,
      "max_tokens": 2048,
      "mode": "completion",
      "output_cost_per_token": 0.0000495,
      "provider": "aleph_alpha"
    },
    "slug": "luminous-extended",
    "displayName": "luminous-extended"
  },
  {
    "id": "luminous-extended-control",
    "name": "luminous-extended-control",
    "provider": "aleph_alpha",
    "data": {
      "input_cost_per_token": 0.00005625,
      "max_tokens": 2048,
      "mode": "chat",
      "output_cost_per_token": 0.000061875,
      "provider": "aleph_alpha"
    },
    "slug": "luminous-extended-control",
    "displayName": "luminous-extended-control"
  },
  {
    "id": "luminous-supreme",
    "name": "luminous-supreme",
    "provider": "aleph_alpha",
    "data": {
      "input_cost_per_token": 0.000175,
      "max_tokens": 2048,
      "mode": "completion",
      "output_cost_per_token": 0.0001925,
      "provider": "aleph_alpha"
    },
    "slug": "luminous-supreme",
    "displayName": "luminous-supreme"
  },
  {
    "id": "luminous-supreme-control",
    "name": "luminous-supreme-control",
    "provider": "aleph_alpha",
    "data": {
      "input_cost_per_token": 0.00021875,
      "max_tokens": 2048,
      "mode": "chat",
      "output_cost_per_token": 0.000240625,
      "provider": "aleph_alpha"
    },
    "slug": "luminous-supreme-control",
    "displayName": "luminous-supreme-control"
  },
  {
    "id": "meta.llama2-13b-chat-v1",
    "name": "meta.llama2-13b-chat-v1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 7.5e-7,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000001,
      "provider": "bedrock"
    },
    "slug": "meta.llama2-13b-chat-v1",
    "displayName": "meta.llama2-13b-chat-v1"
  },
  {
    "id": "meta.llama2-70b-chat-v1",
    "name": "meta.llama2-70b-chat-v1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.00000195,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00000256,
      "provider": "bedrock"
    },
    "slug": "meta.llama2-70b-chat-v1",
    "displayName": "meta.llama2-70b-chat-v1"
  },
  {
    "id": "meta.llama3-1-405b-instruct-v1:0",
    "name": "meta.llama3-1-405b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.00000532,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000016,
      "supports_function_calling": true,
      "supports_tool_choice": false,
      "provider": "bedrock"
    },
    "slug": "meta.llama3-1-405b-instruct-v1-0",
    "displayName": "meta.llama3-1-405b-instruct-v1:0"
  },
  {
    "id": "meta.llama3-1-70b-instruct-v1:0",
    "name": "meta.llama3-1-70b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 9.9e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "max_tokens": 2048,
      "mode": "chat",
      "output_cost_per_token": 9.9e-7,
      "supports_function_calling": true,
      "supports_tool_choice": false,
      "provider": "bedrock"
    },
    "slug": "meta.llama3-1-70b-instruct-v1-0",
    "displayName": "meta.llama3-1-70b-instruct-v1:0"
  },
  {
    "id": "meta.llama3-1-8b-instruct-v1:0",
    "name": "meta.llama3-1-8b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 2.2e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "max_tokens": 2048,
      "mode": "chat",
      "output_cost_per_token": 2.2e-7,
      "supports_function_calling": true,
      "supports_tool_choice": false,
      "provider": "bedrock"
    },
    "slug": "meta.llama3-1-8b-instruct-v1-0",
    "displayName": "meta.llama3-1-8b-instruct-v1:0"
  },
  {
    "id": "meta.llama3-2-11b-instruct-v1:0",
    "name": "meta.llama3-2-11b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 3.5e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 3.5e-7,
      "supports_function_calling": true,
      "supports_tool_choice": false,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "meta.llama3-2-11b-instruct-v1-0",
    "displayName": "meta.llama3-2-11b-instruct-v1:0"
  },
  {
    "id": "meta.llama3-2-1b-instruct-v1:0",
    "name": "meta.llama3-2-1b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 1e-7,
      "supports_function_calling": true,
      "supports_tool_choice": false,
      "provider": "bedrock"
    },
    "slug": "meta.llama3-2-1b-instruct-v1-0",
    "displayName": "meta.llama3-2-1b-instruct-v1:0"
  },
  {
    "id": "meta.llama3-2-3b-instruct-v1:0",
    "name": "meta.llama3-2-3b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 1.5e-7,
      "supports_function_calling": true,
      "supports_tool_choice": false,
      "provider": "bedrock"
    },
    "slug": "meta.llama3-2-3b-instruct-v1-0",
    "displayName": "meta.llama3-2-3b-instruct-v1:0"
  },
  {
    "id": "meta.llama3-2-90b-instruct-v1:0",
    "name": "meta.llama3-2-90b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "supports_function_calling": true,
      "supports_tool_choice": false,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "meta.llama3-2-90b-instruct-v1-0",
    "displayName": "meta.llama3-2-90b-instruct-v1:0"
  },
  {
    "id": "meta.llama3-3-70b-instruct-v1:0",
    "name": "meta.llama3-3-70b-instruct-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 7.2e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 7.2e-7,
      "supports_function_calling": true,
      "supports_tool_choice": false,
      "provider": "bedrock_converse"
    },
    "slug": "meta.llama3-3-70b-instruct-v1-0",
    "displayName": "meta.llama3-3-70b-instruct-v1:0"
  },
  {
    "id": "meta.llama3-70b-instruct-v1:0",
    "name": "meta.llama3-70b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.00000265,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.0000035,
      "provider": "bedrock"
    },
    "slug": "meta.llama3-70b-instruct-v1-0",
    "displayName": "meta.llama3-70b-instruct-v1:0"
  },
  {
    "id": "meta.llama3-8b-instruct-v1:0",
    "name": "meta.llama3-8b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "provider": "bedrock"
    },
    "slug": "meta.llama3-8b-instruct-v1-0",
    "displayName": "meta.llama3-8b-instruct-v1:0"
  },
  {
    "id": "meta.llama4-maverick-17b-instruct-v1:0",
    "name": "meta.llama4-maverick-17b-instruct-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 2.4e-7,
      "input_cost_per_token_batches": 1.2e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 9.7e-7,
      "output_cost_per_token_batches": 4.85e-7,
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text",
        "code"
      ],
      "supports_function_calling": true,
      "supports_tool_choice": false,
      "provider": "bedrock_converse"
    },
    "slug": "meta.llama4-maverick-17b-instruct-v1-0",
    "displayName": "meta.llama4-maverick-17b-instruct-v1:0"
  },
  {
    "id": "meta.llama4-scout-17b-instruct-v1:0",
    "name": "meta.llama4-scout-17b-instruct-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 1.7e-7,
      "input_cost_per_token_batches": 8.5e-8,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 6.6e-7,
      "output_cost_per_token_batches": 3.3e-7,
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text",
        "code"
      ],
      "supports_function_calling": true,
      "supports_tool_choice": false,
      "provider": "bedrock_converse"
    },
    "slug": "meta.llama4-scout-17b-instruct-v1-0",
    "displayName": "meta.llama4-scout-17b-instruct-v1:0"
  },
  {
    "id": "minimax.minimax-m2",
    "name": "minimax.minimax-m2",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.0000012,
      "supports_system_messages": true,
      "provider": "bedrock_converse"
    },
    "slug": "minimax.minimax-m2",
    "displayName": "minimax.minimax-m2"
  },
  {
    "id": "minimax/MiniMax-M2.1",
    "name": "MiniMax-M2.1",
    "provider": "minimax",
    "data": {
      "input_cost_per_token": 3e-7,
      "output_cost_per_token": 0.0000012,
      "cache_read_input_token_cost": 3e-8,
      "cache_creation_input_token_cost": 3.75e-7,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_system_messages": true,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "provider": "minimax"
    },
    "slug": "minimax-m2.1",
    "displayName": "MiniMax-M2.1"
  },
  {
    "id": "minimax/MiniMax-M2.1-lightning",
    "name": "MiniMax-M2.1-lightning",
    "provider": "minimax",
    "data": {
      "input_cost_per_token": 3e-7,
      "output_cost_per_token": 0.0000024,
      "cache_read_input_token_cost": 3e-8,
      "cache_creation_input_token_cost": 3.75e-7,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_system_messages": true,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "provider": "minimax"
    },
    "slug": "minimax-m2.1-lightning",
    "displayName": "MiniMax-M2.1-lightning"
  },
  {
    "id": "minimax/MiniMax-M2",
    "name": "MiniMax-M2",
    "provider": "minimax",
    "data": {
      "input_cost_per_token": 3e-7,
      "output_cost_per_token": 0.0000012,
      "cache_read_input_token_cost": 3e-8,
      "cache_creation_input_token_cost": 3.75e-7,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_system_messages": true,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "provider": "minimax"
    },
    "slug": "minimax-m2",
    "displayName": "MiniMax-M2"
  },
  {
    "id": "mistral.magistral-small-2509",
    "name": "mistral.magistral-small-2509",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 5e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_system_messages": true,
      "provider": "bedrock_converse"
    },
    "slug": "mistral.magistral-small-2509",
    "displayName": "mistral.magistral-small-2509"
  },
  {
    "id": "mistral.ministral-3-14b-instruct",
    "name": "mistral.ministral-3-14b-instruct",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 2e-7,
      "supports_function_calling": true,
      "supports_system_messages": true,
      "provider": "bedrock_converse"
    },
    "slug": "mistral.ministral-3-14b-instruct",
    "displayName": "mistral.ministral-3-14b-instruct"
  },
  {
    "id": "mistral.ministral-3-3b-instruct",
    "name": "mistral.ministral-3-3b-instruct",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 1e-7,
      "supports_function_calling": true,
      "supports_system_messages": true,
      "provider": "bedrock_converse"
    },
    "slug": "mistral.ministral-3-3b-instruct",
    "displayName": "mistral.ministral-3-3b-instruct"
  },
  {
    "id": "mistral.ministral-3-8b-instruct",
    "name": "mistral.ministral-3-8b-instruct",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 1.5e-7,
      "supports_function_calling": true,
      "supports_system_messages": true,
      "provider": "bedrock_converse"
    },
    "slug": "mistral.ministral-3-8b-instruct",
    "displayName": "mistral.ministral-3-8b-instruct"
  },
  {
    "id": "mistral.mistral-7b-instruct-v0:2",
    "name": "mistral.mistral-7b-instruct-v0:2",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 2e-7,
      "supports_tool_choice": true,
      "provider": "bedrock"
    },
    "slug": "mistral.mistral-7b-instruct-v0-2",
    "displayName": "mistral.mistral-7b-instruct-v0:2"
  },
  {
    "id": "mistral.mistral-large-2402-v1:0",
    "name": "mistral.mistral-large-2402-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000008,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000024,
      "supports_function_calling": true,
      "provider": "bedrock"
    },
    "slug": "mistral.mistral-large-2402-v1-0",
    "displayName": "mistral.mistral-large-2402-v1:0"
  },
  {
    "id": "mistral.mistral-large-2407-v1:0",
    "name": "mistral.mistral-large-2407-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 128000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000009,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "bedrock"
    },
    "slug": "mistral.mistral-large-2407-v1-0",
    "displayName": "mistral.mistral-large-2407-v1:0"
  },
  {
    "id": "mistral.mistral-large-3-675b-instruct",
    "name": "mistral.mistral-large-3-675b-instruct",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 5e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "supports_function_calling": true,
      "supports_system_messages": true,
      "provider": "bedrock_converse"
    },
    "slug": "mistral.mistral-large-3-675b-instruct",
    "displayName": "mistral.mistral-large-3-675b-instruct"
  },
  {
    "id": "mistral.mistral-small-2402-v1:0",
    "name": "mistral.mistral-small-2402-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000003,
      "supports_function_calling": true,
      "provider": "bedrock"
    },
    "slug": "mistral.mistral-small-2402-v1-0",
    "displayName": "mistral.mistral-small-2402-v1:0"
  },
  {
    "id": "mistral.mixtral-8x7b-instruct-v0:1",
    "name": "mistral.mixtral-8x7b-instruct-v0:1",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 4.5e-7,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 7e-7,
      "supports_tool_choice": true,
      "provider": "bedrock"
    },
    "slug": "mistral.mixtral-8x7b-instruct-v0-1",
    "displayName": "mistral.mixtral-8x7b-instruct-v0:1"
  },
  {
    "id": "mistral.voxtral-mini-3b-2507",
    "name": "mistral.voxtral-mini-3b-2507",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 4e-8,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 4e-8,
      "supports_audio_input": true,
      "supports_system_messages": true,
      "provider": "bedrock_converse"
    },
    "slug": "mistral.voxtral-mini-3b-2507",
    "displayName": "mistral.voxtral-mini-3b-2507"
  },
  {
    "id": "mistral.voxtral-small-24b-2507",
    "name": "mistral.voxtral-small-24b-2507",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "supports_audio_input": true,
      "supports_system_messages": true,
      "provider": "bedrock_converse"
    },
    "slug": "mistral.voxtral-small-24b-2507",
    "displayName": "mistral.voxtral-small-24b-2507"
  },
  {
    "id": "mistral/codestral-2405",
    "name": "codestral-2405",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000003,
      "supports_assistant_prefill": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "mistral"
    },
    "slug": "codestral-2405",
    "displayName": "codestral-2405"
  },
  {
    "id": "mistral/codestral-2508",
    "name": "codestral-2508",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 9e-7,
      "source": "https://mistral.ai/news/codestral-25-08",
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "mistral"
    },
    "slug": "codestral-2508",
    "displayName": "codestral-2508"
  },
  {
    "id": "mistral/codestral-latest",
    "name": "codestral-latest",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000003,
      "supports_assistant_prefill": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "mistral"
    },
    "slug": "codestral-latest",
    "displayName": "codestral-latest"
  },
  {
    "id": "mistral/codestral-mamba-latest",
    "name": "codestral-mamba-latest",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 2.5e-7,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 2.5e-7,
      "source": "https://mistral.ai/technology/",
      "supports_assistant_prefill": true,
      "supports_tool_choice": true,
      "provider": "mistral"
    },
    "slug": "codestral-mamba-latest",
    "displayName": "codestral-mamba-latest"
  },
  {
    "id": "mistral/devstral-medium-2507",
    "name": "devstral-medium-2507",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 4e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "source": "https://mistral.ai/news/devstral",
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "mistral"
    },
    "slug": "devstral-medium-2507",
    "displayName": "devstral-medium-2507"
  },
  {
    "id": "mistral/devstral-small-2505",
    "name": "devstral-small-2505",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "source": "https://mistral.ai/news/devstral",
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "mistral"
    },
    "slug": "devstral-small-2505",
    "displayName": "devstral-small-2505"
  },
  {
    "id": "mistral/devstral-small-2507",
    "name": "devstral-small-2507",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "source": "https://mistral.ai/news/devstral",
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "mistral"
    },
    "slug": "devstral-small-2507",
    "displayName": "devstral-small-2507"
  },
  {
    "id": "mistral/labs-devstral-small-2512",
    "name": "labs-devstral-small-2512",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "source": "https://docs.mistral.ai/models/devstral-small-2-25-12",
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "mistral"
    },
    "slug": "labs-devstral-small-2512",
    "displayName": "labs-devstral-small-2512"
  },
  {
    "id": "mistral/devstral-2512",
    "name": "devstral-2512",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 4e-7,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "source": "https://mistral.ai/news/devstral-2-vibe-cli",
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "mistral"
    },
    "slug": "devstral-2512",
    "displayName": "devstral-2512"
  },
  {
    "id": "mistral/magistral-medium-2506",
    "name": "magistral-medium-2506",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 40000,
      "max_output_tokens": 40000,
      "max_tokens": 40000,
      "mode": "chat",
      "output_cost_per_token": 0.000005,
      "source": "https://mistral.ai/news/magistral",
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "mistral"
    },
    "slug": "magistral-medium-2506",
    "displayName": "magistral-medium-2506"
  },
  {
    "id": "mistral/magistral-medium-2509",
    "name": "magistral-medium-2509",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 40000,
      "max_output_tokens": 40000,
      "max_tokens": 40000,
      "mode": "chat",
      "output_cost_per_token": 0.000005,
      "source": "https://mistral.ai/news/magistral",
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "mistral"
    },
    "slug": "magistral-medium-2509",
    "displayName": "magistral-medium-2509"
  },
  {
    "id": "mistral/magistral-medium-latest",
    "name": "magistral-medium-latest",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 40000,
      "max_output_tokens": 40000,
      "max_tokens": 40000,
      "mode": "chat",
      "output_cost_per_token": 0.000005,
      "source": "https://mistral.ai/news/magistral",
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "mistral"
    },
    "slug": "magistral-medium-latest",
    "displayName": "magistral-medium-latest"
  },
  {
    "id": "mistral/magistral-small-2506",
    "name": "magistral-small-2506",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 5e-7,
      "max_input_tokens": 40000,
      "max_output_tokens": 40000,
      "max_tokens": 40000,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "source": "https://mistral.ai/pricing#api-pricing",
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "mistral"
    },
    "slug": "magistral-small-2506",
    "displayName": "magistral-small-2506"
  },
  {
    "id": "mistral/magistral-small-latest",
    "name": "magistral-small-latest",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 5e-7,
      "max_input_tokens": 40000,
      "max_output_tokens": 40000,
      "max_tokens": 40000,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "source": "https://mistral.ai/pricing#api-pricing",
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "mistral"
    },
    "slug": "magistral-small-latest",
    "displayName": "magistral-small-latest"
  },
  {
    "id": "mistral/mistral-embed",
    "name": "mistral-embed",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 8192,
      "max_tokens": 8192,
      "mode": "embedding",
      "provider": "mistral"
    },
    "slug": "mistral-embed",
    "displayName": "mistral-embed"
  },
  {
    "id": "mistral/codestral-embed",
    "name": "codestral-embed",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 8192,
      "max_tokens": 8192,
      "mode": "embedding",
      "provider": "mistral"
    },
    "slug": "codestral-embed",
    "displayName": "codestral-embed"
  },
  {
    "id": "mistral/codestral-embed-2505",
    "name": "codestral-embed-2505",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 8192,
      "max_tokens": 8192,
      "mode": "embedding",
      "provider": "mistral"
    },
    "slug": "codestral-embed-2505",
    "displayName": "codestral-embed-2505"
  },
  {
    "id": "mistral/mistral-large-2402",
    "name": "mistral-large-2402",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 0.000004,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000012,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "mistral"
    },
    "slug": "mistral-large-2402",
    "displayName": "mistral-large-2402"
  },
  {
    "id": "mistral/mistral-large-2407",
    "name": "mistral-large-2407",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000009,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "mistral"
    },
    "slug": "mistral-large-2407",
    "displayName": "mistral-large-2407"
  },
  {
    "id": "mistral/mistral-large-2411",
    "name": "mistral-large-2411",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000006,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "mistral"
    },
    "slug": "mistral-large-2411",
    "displayName": "mistral-large-2411"
  },
  {
    "id": "mistral/mistral-large-latest",
    "name": "mistral-large-latest",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000006,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "mistral"
    },
    "slug": "mistral-large-latest",
    "displayName": "mistral-large-latest"
  },
  {
    "id": "mistral/mistral-large-3",
    "name": "mistral-large-3",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 5e-7,
      "max_input_tokens": 256000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "source": "https://docs.mistral.ai/models/mistral-large-3-25-12",
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "mistral"
    },
    "slug": "mistral-large-3",
    "displayName": "mistral-large-3"
  },
  {
    "id": "mistral/mistral-medium",
    "name": "mistral-medium",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 0.0000027,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.0000081,
      "supports_assistant_prefill": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "mistral"
    },
    "slug": "mistral-medium",
    "displayName": "mistral-medium"
  },
  {
    "id": "mistral/mistral-medium-2312",
    "name": "mistral-medium-2312",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 0.0000027,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.0000081,
      "supports_assistant_prefill": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "mistral"
    },
    "slug": "mistral-medium-2312",
    "displayName": "mistral-medium-2312"
  },
  {
    "id": "mistral/mistral-medium-2505",
    "name": "mistral-medium-2505",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 4e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "mistral"
    },
    "slug": "mistral-medium-2505",
    "displayName": "mistral-medium-2505"
  },
  {
    "id": "mistral/mistral-medium-latest",
    "name": "mistral-medium-latest",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 4e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "mistral"
    },
    "slug": "mistral-medium-latest",
    "displayName": "mistral-medium-latest"
  },
  {
    "id": "mistral/mistral-small",
    "name": "mistral-small",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "mistral"
    },
    "slug": "mistral-small",
    "displayName": "mistral-small"
  },
  {
    "id": "mistral/mistral-small-latest",
    "name": "mistral-small-latest",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "mistral"
    },
    "slug": "mistral-small-latest",
    "displayName": "mistral-small-latest"
  },
  {
    "id": "mistral/mistral-tiny",
    "name": "mistral-tiny",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 2.5e-7,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 2.5e-7,
      "supports_assistant_prefill": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "mistral"
    },
    "slug": "mistral-tiny",
    "displayName": "mistral-tiny"
  },
  {
    "id": "mistral/open-codestral-mamba",
    "name": "open-codestral-mamba",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 2.5e-7,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 2.5e-7,
      "source": "https://mistral.ai/technology/",
      "supports_assistant_prefill": true,
      "supports_tool_choice": true,
      "provider": "mistral"
    },
    "slug": "open-codestral-mamba",
    "displayName": "open-codestral-mamba"
  },
  {
    "id": "mistral/open-mistral-7b",
    "name": "open-mistral-7b",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 2.5e-7,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 2.5e-7,
      "supports_assistant_prefill": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "mistral"
    },
    "slug": "open-mistral-7b",
    "displayName": "open-mistral-7b"
  },
  {
    "id": "mistral/open-mistral-nemo",
    "name": "open-mistral-nemo",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "source": "https://mistral.ai/technology/",
      "supports_assistant_prefill": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "mistral"
    },
    "slug": "open-mistral-nemo",
    "displayName": "open-mistral-nemo"
  },
  {
    "id": "mistral/open-mistral-nemo-2407",
    "name": "open-mistral-nemo-2407",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "source": "https://mistral.ai/technology/",
      "supports_assistant_prefill": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "mistral"
    },
    "slug": "open-mistral-nemo-2407",
    "displayName": "open-mistral-nemo-2407"
  },
  {
    "id": "mistral/open-mixtral-8x22b",
    "name": "open-mixtral-8x22b",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 65336,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000006,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "mistral"
    },
    "slug": "open-mixtral-8x22b",
    "displayName": "open-mixtral-8x22b"
  },
  {
    "id": "mistral/open-mixtral-8x7b",
    "name": "open-mixtral-8x7b",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 7e-7,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 7e-7,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "mistral"
    },
    "slug": "open-mixtral-8x7b",
    "displayName": "open-mixtral-8x7b"
  },
  {
    "id": "mistral/pixtral-12b-2409",
    "name": "pixtral-12b-2409",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 1.5e-7,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "mistral"
    },
    "slug": "pixtral-12b-2409",
    "displayName": "pixtral-12b-2409"
  },
  {
    "id": "mistral/pixtral-large-2411",
    "name": "pixtral-large-2411",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000006,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "mistral"
    },
    "slug": "pixtral-large-2411",
    "displayName": "pixtral-large-2411"
  },
  {
    "id": "mistral/pixtral-large-latest",
    "name": "pixtral-large-latest",
    "provider": "mistral",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000006,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "mistral"
    },
    "slug": "pixtral-large-latest",
    "displayName": "pixtral-large-latest"
  },
  {
    "id": "moonshot.kimi-k2-thinking",
    "name": "moonshot.kimi-k2-thinking",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.0000025,
      "supports_reasoning": true,
      "supports_system_messages": true,
      "provider": "bedrock_converse"
    },
    "slug": "moonshot.kimi-k2-thinking",
    "displayName": "moonshot.kimi-k2-thinking"
  },
  {
    "id": "moonshot/kimi-k2-0711-preview",
    "name": "kimi-k2-0711-preview",
    "provider": "moonshot",
    "data": {
      "cache_read_input_token_cost": 1.5e-7,
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.0000025,
      "source": "https://platform.moonshot.ai/docs/pricing/chat#generation-model-kimi-k2",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "moonshot"
    },
    "slug": "kimi-k2-0711-preview",
    "displayName": "kimi-k2-0711-preview"
  },
  {
    "id": "moonshot/kimi-k2-0905-preview",
    "name": "kimi-k2-0905-preview",
    "provider": "moonshot",
    "data": {
      "cache_read_input_token_cost": 1.5e-7,
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "max_tokens": 262144,
      "mode": "chat",
      "output_cost_per_token": 0.0000025,
      "source": "https://platform.moonshot.ai/docs/pricing/chat#generation-model-kimi-k2",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "moonshot"
    },
    "slug": "kimi-k2-0905-preview",
    "displayName": "kimi-k2-0905-preview"
  },
  {
    "id": "moonshot/kimi-k2-turbo-preview",
    "name": "kimi-k2-turbo-preview",
    "provider": "moonshot",
    "data": {
      "cache_read_input_token_cost": 1.5e-7,
      "input_cost_per_token": 0.00000115,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "max_tokens": 262144,
      "mode": "chat",
      "output_cost_per_token": 0.000008,
      "source": "https://platform.moonshot.ai/docs/pricing/chat#generation-model-kimi-k2",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "moonshot"
    },
    "slug": "kimi-k2-turbo-preview",
    "displayName": "kimi-k2-turbo-preview"
  },
  {
    "id": "moonshot/kimi-k2.5",
    "name": "kimi-k2.5",
    "provider": "moonshot",
    "data": {
      "cache_read_input_token_cost": 1e-7,
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "max_tokens": 262144,
      "mode": "chat",
      "output_cost_per_token": 0.000003,
      "source": "https://platform.moonshot.ai/docs/pricing/chat",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "moonshot"
    },
    "slug": "kimi-k2.5",
    "displayName": "kimi-k2.5"
  },
  {
    "id": "moonshot/kimi-latest",
    "name": "kimi-latest",
    "provider": "moonshot",
    "data": {
      "cache_read_input_token_cost": 1.5e-7,
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.000005,
      "source": "https://platform.moonshot.ai/docs/pricing",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "moonshot"
    },
    "slug": "kimi-latest",
    "displayName": "kimi-latest"
  },
  {
    "id": "moonshot/kimi-latest-128k",
    "name": "kimi-latest-128k",
    "provider": "moonshot",
    "data": {
      "cache_read_input_token_cost": 1.5e-7,
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.000005,
      "source": "https://platform.moonshot.ai/docs/pricing",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "moonshot"
    },
    "slug": "kimi-latest-128k",
    "displayName": "kimi-latest-128k"
  },
  {
    "id": "moonshot/kimi-latest-32k",
    "name": "kimi-latest-32k",
    "provider": "moonshot",
    "data": {
      "cache_read_input_token_cost": 1.5e-7,
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.000003,
      "source": "https://platform.moonshot.ai/docs/pricing",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "moonshot"
    },
    "slug": "kimi-latest-32k",
    "displayName": "kimi-latest-32k"
  },
  {
    "id": "moonshot/kimi-latest-8k",
    "name": "kimi-latest-8k",
    "provider": "moonshot",
    "data": {
      "cache_read_input_token_cost": 1.5e-7,
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "source": "https://platform.moonshot.ai/docs/pricing",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "moonshot"
    },
    "slug": "kimi-latest-8k",
    "displayName": "kimi-latest-8k"
  },
  {
    "id": "moonshot/kimi-thinking-preview",
    "name": "kimi-thinking-preview",
    "provider": "moonshot",
    "data": {
      "cache_read_input_token_cost": 1.5e-7,
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.0000025,
      "source": "https://platform.moonshot.ai/docs/pricing/chat#generation-model-kimi-k2",
      "supports_vision": true,
      "provider": "moonshot"
    },
    "slug": "kimi-thinking-preview",
    "displayName": "kimi-thinking-preview"
  },
  {
    "id": "moonshot/kimi-k2-thinking",
    "name": "kimi-k2-thinking",
    "provider": "moonshot",
    "data": {
      "cache_read_input_token_cost": 1.5e-7,
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "max_tokens": 262144,
      "mode": "chat",
      "output_cost_per_token": 0.0000025,
      "source": "https://platform.moonshot.ai/docs/pricing/chat#generation-model-kimi-k2",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "moonshot"
    },
    "slug": "kimi-k2-thinking",
    "displayName": "kimi-k2-thinking"
  },
  {
    "id": "moonshot/kimi-k2-thinking-turbo",
    "name": "kimi-k2-thinking-turbo",
    "provider": "moonshot",
    "data": {
      "cache_read_input_token_cost": 1.5e-7,
      "input_cost_per_token": 0.00000115,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "max_tokens": 262144,
      "mode": "chat",
      "output_cost_per_token": 0.000008,
      "source": "https://platform.moonshot.ai/docs/pricing/chat#generation-model-kimi-k2",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "moonshot"
    },
    "slug": "kimi-k2-thinking-turbo",
    "displayName": "kimi-k2-thinking-turbo"
  },
  {
    "id": "moonshot/moonshot-v1-128k",
    "name": "moonshot-v1-128k",
    "provider": "moonshot",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.000005,
      "source": "https://platform.moonshot.ai/docs/pricing",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "moonshot"
    },
    "slug": "moonshot-v1-128k",
    "displayName": "moonshot-v1-128k"
  },
  {
    "id": "moonshot/moonshot-v1-128k-0430",
    "name": "moonshot-v1-128k-0430",
    "provider": "moonshot",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.000005,
      "source": "https://platform.moonshot.ai/docs/pricing",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "moonshot"
    },
    "slug": "moonshot-v1-128k-0430",
    "displayName": "moonshot-v1-128k-0430"
  },
  {
    "id": "moonshot/moonshot-v1-128k-vision-preview",
    "name": "moonshot-v1-128k-vision-preview",
    "provider": "moonshot",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.000005,
      "source": "https://platform.moonshot.ai/docs/pricing",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "moonshot"
    },
    "slug": "moonshot-v1-128k-vision-preview",
    "displayName": "moonshot-v1-128k-vision-preview"
  },
  {
    "id": "moonshot/moonshot-v1-32k",
    "name": "moonshot-v1-32k",
    "provider": "moonshot",
    "data": {
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.000003,
      "source": "https://platform.moonshot.ai/docs/pricing",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "moonshot"
    },
    "slug": "moonshot-v1-32k",
    "displayName": "moonshot-v1-32k"
  },
  {
    "id": "moonshot/moonshot-v1-32k-0430",
    "name": "moonshot-v1-32k-0430",
    "provider": "moonshot",
    "data": {
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.000003,
      "source": "https://platform.moonshot.ai/docs/pricing",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "moonshot"
    },
    "slug": "moonshot-v1-32k-0430",
    "displayName": "moonshot-v1-32k-0430"
  },
  {
    "id": "moonshot/moonshot-v1-32k-vision-preview",
    "name": "moonshot-v1-32k-vision-preview",
    "provider": "moonshot",
    "data": {
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.000003,
      "source": "https://platform.moonshot.ai/docs/pricing",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "moonshot"
    },
    "slug": "moonshot-v1-32k-vision-preview",
    "displayName": "moonshot-v1-32k-vision-preview"
  },
  {
    "id": "moonshot/moonshot-v1-8k",
    "name": "moonshot-v1-8k",
    "provider": "moonshot",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "source": "https://platform.moonshot.ai/docs/pricing",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "moonshot"
    },
    "slug": "moonshot-v1-8k",
    "displayName": "moonshot-v1-8k"
  },
  {
    "id": "moonshot/moonshot-v1-8k-0430",
    "name": "moonshot-v1-8k-0430",
    "provider": "moonshot",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "source": "https://platform.moonshot.ai/docs/pricing",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "moonshot"
    },
    "slug": "moonshot-v1-8k-0430",
    "displayName": "moonshot-v1-8k-0430"
  },
  {
    "id": "moonshot/moonshot-v1-8k-vision-preview",
    "name": "moonshot-v1-8k-vision-preview",
    "provider": "moonshot",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "source": "https://platform.moonshot.ai/docs/pricing",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "moonshot"
    },
    "slug": "moonshot-v1-8k-vision-preview",
    "displayName": "moonshot-v1-8k-vision-preview"
  },
  {
    "id": "moonshot/moonshot-v1-auto",
    "name": "moonshot-v1-auto",
    "provider": "moonshot",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.000005,
      "source": "https://platform.moonshot.ai/docs/pricing",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "moonshot"
    },
    "slug": "moonshot-v1-auto",
    "displayName": "moonshot-v1-auto"
  },
  {
    "id": "morph/morph-v3-fast",
    "name": "morph-v3-fast",
    "provider": "morph",
    "data": {
      "input_cost_per_token": 8e-7,
      "max_input_tokens": 16000,
      "max_output_tokens": 16000,
      "max_tokens": 16000,
      "mode": "chat",
      "output_cost_per_token": 0.0000012,
      "supports_function_calling": false,
      "supports_parallel_function_calling": false,
      "supports_system_messages": true,
      "supports_tool_choice": false,
      "supports_vision": false,
      "provider": "morph"
    },
    "slug": "morph-v3-fast",
    "displayName": "morph-v3-fast"
  },
  {
    "id": "morph/morph-v3-large",
    "name": "morph-v3-large",
    "provider": "morph",
    "data": {
      "input_cost_per_token": 9e-7,
      "max_input_tokens": 16000,
      "max_output_tokens": 16000,
      "max_tokens": 16000,
      "mode": "chat",
      "output_cost_per_token": 0.0000019,
      "supports_function_calling": false,
      "supports_parallel_function_calling": false,
      "supports_system_messages": true,
      "supports_tool_choice": false,
      "supports_vision": false,
      "provider": "morph"
    },
    "slug": "morph-v3-large",
    "displayName": "morph-v3-large"
  },
  {
    "id": "multimodalembedding",
    "name": "multimodalembedding",
    "provider": "vertex_ai-embedding-models",
    "data": {
      "input_cost_per_character": 2e-7,
      "input_cost_per_image": 0.0001,
      "input_cost_per_token": 8e-7,
      "input_cost_per_video_per_second": 0.0005,
      "input_cost_per_video_per_second_above_15s_interval": 0.002,
      "input_cost_per_video_per_second_above_8s_interval": 0.001,
      "max_input_tokens": 2048,
      "max_tokens": 2048,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_vector_size": 768,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models",
      "supported_endpoints": [
        "/v1/embeddings"
      ],
      "supported_modalities": [
        "text",
        "image",
        "video"
      ],
      "provider": "vertex_ai-embedding-models"
    },
    "slug": "multimodalembedding",
    "displayName": "multimodalembedding"
  },
  {
    "id": "multimodalembedding@001",
    "name": "multimodalembedding@001",
    "provider": "vertex_ai-embedding-models",
    "data": {
      "input_cost_per_character": 2e-7,
      "input_cost_per_image": 0.0001,
      "input_cost_per_token": 8e-7,
      "input_cost_per_video_per_second": 0.0005,
      "input_cost_per_video_per_second_above_15s_interval": 0.002,
      "input_cost_per_video_per_second_above_8s_interval": 0.001,
      "max_input_tokens": 2048,
      "max_tokens": 2048,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_vector_size": 768,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models",
      "supported_endpoints": [
        "/v1/embeddings"
      ],
      "supported_modalities": [
        "text",
        "image",
        "video"
      ],
      "provider": "vertex_ai-embedding-models"
    },
    "slug": "multimodalembedding-001",
    "displayName": "multimodalembedding@001"
  },
  {
    "id": "nscale/Qwen/QwQ-32B",
    "name": "QwQ-32B",
    "provider": "nscale",
    "data": {
      "input_cost_per_token": 1.8e-7,
      "mode": "chat",
      "output_cost_per_token": 2e-7,
      "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models",
      "provider": "nscale"
    },
    "slug": "qwq-32b",
    "displayName": "QwQ-32B"
  },
  {
    "id": "nscale/Qwen/Qwen2.5-Coder-32B-Instruct",
    "name": "Qwen2.5-Coder-32B-Instruct",
    "provider": "nscale",
    "data": {
      "input_cost_per_token": 6e-8,
      "mode": "chat",
      "output_cost_per_token": 2e-7,
      "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models",
      "provider": "nscale"
    },
    "slug": "qwen2.5-coder-32b-instruct",
    "displayName": "Qwen2.5-Coder-32B-Instruct"
  },
  {
    "id": "nscale/Qwen/Qwen2.5-Coder-3B-Instruct",
    "name": "Qwen2.5-Coder-3B-Instruct",
    "provider": "nscale",
    "data": {
      "input_cost_per_token": 1e-8,
      "mode": "chat",
      "output_cost_per_token": 3e-8,
      "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models",
      "provider": "nscale"
    },
    "slug": "qwen2.5-coder-3b-instruct",
    "displayName": "Qwen2.5-Coder-3B-Instruct"
  },
  {
    "id": "nscale/Qwen/Qwen2.5-Coder-7B-Instruct",
    "name": "Qwen2.5-Coder-7B-Instruct",
    "provider": "nscale",
    "data": {
      "input_cost_per_token": 1e-8,
      "mode": "chat",
      "output_cost_per_token": 3e-8,
      "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models",
      "provider": "nscale"
    },
    "slug": "qwen2.5-coder-7b-instruct",
    "displayName": "Qwen2.5-Coder-7B-Instruct"
  },
  {
    "id": "nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "name": "DeepSeek-R1-Distill-Llama-70B",
    "provider": "nscale",
    "data": {
      "input_cost_per_token": 3.75e-7,
      "metadata": {
        "notes": "Pricing listed as $0.75/1M tokens total. Assumed 50/50 split for input/output."
      },
      "mode": "chat",
      "output_cost_per_token": 3.75e-7,
      "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models",
      "provider": "nscale"
    },
    "slug": "deepseek-r1-distill-llama-70b",
    "displayName": "DeepSeek-R1-Distill-Llama-70B"
  },
  {
    "id": "nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
    "name": "DeepSeek-R1-Distill-Llama-8B",
    "provider": "nscale",
    "data": {
      "input_cost_per_token": 2.5e-8,
      "metadata": {
        "notes": "Pricing listed as $0.05/1M tokens total. Assumed 50/50 split for input/output."
      },
      "mode": "chat",
      "output_cost_per_token": 2.5e-8,
      "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models",
      "provider": "nscale"
    },
    "slug": "deepseek-r1-distill-llama-8b",
    "displayName": "DeepSeek-R1-Distill-Llama-8B"
  },
  {
    "id": "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
    "name": "DeepSeek-R1-Distill-Qwen-1.5B",
    "provider": "nscale",
    "data": {
      "input_cost_per_token": 9e-8,
      "metadata": {
        "notes": "Pricing listed as $0.18/1M tokens total. Assumed 50/50 split for input/output."
      },
      "mode": "chat",
      "output_cost_per_token": 9e-8,
      "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models",
      "provider": "nscale"
    },
    "slug": "deepseek-r1-distill-qwen-1.5b",
    "displayName": "DeepSeek-R1-Distill-Qwen-1.5B"
  },
  {
    "id": "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
    "name": "DeepSeek-R1-Distill-Qwen-14B",
    "provider": "nscale",
    "data": {
      "input_cost_per_token": 7e-8,
      "metadata": {
        "notes": "Pricing listed as $0.14/1M tokens total. Assumed 50/50 split for input/output."
      },
      "mode": "chat",
      "output_cost_per_token": 7e-8,
      "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models",
      "provider": "nscale"
    },
    "slug": "deepseek-r1-distill-qwen-14b",
    "displayName": "DeepSeek-R1-Distill-Qwen-14B"
  },
  {
    "id": "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
    "name": "DeepSeek-R1-Distill-Qwen-32B",
    "provider": "nscale",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "metadata": {
        "notes": "Pricing listed as $0.30/1M tokens total. Assumed 50/50 split for input/output."
      },
      "mode": "chat",
      "output_cost_per_token": 1.5e-7,
      "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models",
      "provider": "nscale"
    },
    "slug": "deepseek-r1-distill-qwen-32b",
    "displayName": "DeepSeek-R1-Distill-Qwen-32B"
  },
  {
    "id": "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
    "name": "DeepSeek-R1-Distill-Qwen-7B",
    "provider": "nscale",
    "data": {
      "input_cost_per_token": 2e-7,
      "metadata": {
        "notes": "Pricing listed as $0.40/1M tokens total. Assumed 50/50 split for input/output."
      },
      "mode": "chat",
      "output_cost_per_token": 2e-7,
      "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models",
      "provider": "nscale"
    },
    "slug": "deepseek-r1-distill-qwen-7b",
    "displayName": "DeepSeek-R1-Distill-Qwen-7B"
  },
  {
    "id": "nscale/meta-llama/Llama-3.1-8B-Instruct",
    "name": "Llama-3.1-8B-Instruct",
    "provider": "nscale",
    "data": {
      "input_cost_per_token": 3e-8,
      "metadata": {
        "notes": "Pricing listed as $0.06/1M tokens total. Assumed 50/50 split for input/output."
      },
      "mode": "chat",
      "output_cost_per_token": 3e-8,
      "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models",
      "provider": "nscale"
    },
    "slug": "llama-3.1-8b-instruct",
    "displayName": "Llama-3.1-8B-Instruct"
  },
  {
    "id": "nscale/meta-llama/Llama-3.3-70B-Instruct",
    "name": "Llama-3.3-70B-Instruct",
    "provider": "nscale",
    "data": {
      "input_cost_per_token": 2e-7,
      "metadata": {
        "notes": "Pricing listed as $0.40/1M tokens total. Assumed 50/50 split for input/output."
      },
      "mode": "chat",
      "output_cost_per_token": 2e-7,
      "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models",
      "provider": "nscale"
    },
    "slug": "llama-3.3-70b-instruct",
    "displayName": "Llama-3.3-70B-Instruct"
  },
  {
    "id": "nscale/meta-llama/Llama-4-Scout-17B-16E-Instruct",
    "name": "Llama-4-Scout-17B-16E-Instruct",
    "provider": "nscale",
    "data": {
      "input_cost_per_token": 9e-8,
      "mode": "chat",
      "output_cost_per_token": 2.9e-7,
      "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models",
      "provider": "nscale"
    },
    "slug": "llama-4-scout-17b-16e-instruct",
    "displayName": "Llama-4-Scout-17B-16E-Instruct"
  },
  {
    "id": "nscale/mistralai/mixtral-8x22b-instruct-v0.1",
    "name": "mixtral-8x22b-instruct-v0.1",
    "provider": "nscale",
    "data": {
      "input_cost_per_token": 6e-7,
      "metadata": {
        "notes": "Pricing listed as $1.20/1M tokens total. Assumed 50/50 split for input/output."
      },
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models",
      "provider": "nscale"
    },
    "slug": "mixtral-8x22b-instruct-v0.1",
    "displayName": "mixtral-8x22b-instruct-v0.1"
  },
  {
    "id": "nvidia.nemotron-nano-12b-v2",
    "name": "nvidia.nemotron-nano-12b-v2",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "supports_system_messages": true,
      "supports_vision": true,
      "provider": "bedrock_converse"
    },
    "slug": "nvidia.nemotron-nano-12b-v2",
    "displayName": "nvidia.nemotron-nano-12b-v2"
  },
  {
    "id": "nvidia.nemotron-nano-9b-v2",
    "name": "nvidia.nemotron-nano-9b-v2",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 6e-8,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 2.3e-7,
      "supports_system_messages": true,
      "provider": "bedrock_converse"
    },
    "slug": "nvidia.nemotron-nano-9b-v2",
    "displayName": "nvidia.nemotron-nano-9b-v2"
  },
  {
    "id": "o1",
    "name": "o1",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 0.0000075,
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "chat",
      "output_cost_per_token": 0.00006,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "o1",
    "displayName": "o1"
  },
  {
    "id": "o1-2024-12-17",
    "name": "o1-2024-12-17",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 0.0000075,
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "chat",
      "output_cost_per_token": 0.00006,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "o1-2024-12-17",
    "displayName": "o1-2024-12-17"
  },
  {
    "id": "o1-mini",
    "name": "o1-mini",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 5.5e-7,
      "input_cost_per_token": 0.0000011,
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "max_tokens": 65536,
      "mode": "chat",
      "output_cost_per_token": 0.0000044,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "o1-mini",
    "displayName": "o1-mini"
  },
  {
    "id": "o1-mini-2024-09-12",
    "name": "o1-mini-2024-09-12",
    "provider": "openai",
    "data": {
      "deprecation_date": "2025-10-27",
      "cache_read_input_token_cost": 0.0000015,
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "max_tokens": 65536,
      "mode": "chat",
      "output_cost_per_token": 0.000012,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "o1-mini-2024-09-12",
    "displayName": "o1-mini-2024-09-12"
  },
  {
    "id": "o1-preview",
    "name": "o1-preview",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 0.0000075,
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.00006,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "o1-preview",
    "displayName": "o1-preview"
  },
  {
    "id": "o1-preview-2024-09-12",
    "name": "o1-preview-2024-09-12",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 0.0000075,
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.00006,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "o1-preview-2024-09-12",
    "displayName": "o1-preview-2024-09-12"
  },
  {
    "id": "o1-pro",
    "name": "o1-pro",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 0.00015,
      "input_cost_per_token_batches": 0.000075,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "responses",
      "output_cost_per_token": 0.0006,
      "output_cost_per_token_batches": 0.0003,
      "supported_endpoints": [
        "/v1/responses",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": false,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "o1-pro",
    "displayName": "o1-pro"
  },
  {
    "id": "o1-pro-2025-03-19",
    "name": "o1-pro-2025-03-19",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 0.00015,
      "input_cost_per_token_batches": 0.000075,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "responses",
      "output_cost_per_token": 0.0006,
      "output_cost_per_token_batches": 0.0003,
      "supported_endpoints": [
        "/v1/responses",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": false,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "o1-pro-2025-03-19",
    "displayName": "o1-pro-2025-03-19"
  },
  {
    "id": "o3",
    "name": "o3",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 5e-7,
      "cache_read_input_token_cost_flex": 2.5e-7,
      "cache_read_input_token_cost_priority": 8.75e-7,
      "input_cost_per_token": 0.000002,
      "input_cost_per_token_flex": 0.000001,
      "input_cost_per_token_priority": 0.0000035,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "chat",
      "output_cost_per_token": 0.000008,
      "output_cost_per_token_flex": 0.000004,
      "output_cost_per_token_priority": 0.000014,
      "supported_endpoints": [
        "/v1/responses",
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_parallel_function_calling": false,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_service_tier": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "o3",
    "displayName": "o3"
  },
  {
    "id": "o3-2025-04-16",
    "name": "o3-2025-04-16",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 5e-7,
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "chat",
      "output_cost_per_token": 0.000008,
      "supported_endpoints": [
        "/v1/responses",
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_parallel_function_calling": false,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_service_tier": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "o3-2025-04-16",
    "displayName": "o3-2025-04-16"
  },
  {
    "id": "o3-deep-research",
    "name": "o3-deep-research",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 0.0000025,
      "input_cost_per_token": 0.00001,
      "input_cost_per_token_batches": 0.000005,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "responses",
      "output_cost_per_token": 0.00004,
      "output_cost_per_token_batches": 0.00002,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "o3-deep-research",
    "displayName": "o3-deep-research"
  },
  {
    "id": "o3-deep-research-2025-06-26",
    "name": "o3-deep-research-2025-06-26",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 0.0000025,
      "input_cost_per_token": 0.00001,
      "input_cost_per_token_batches": 0.000005,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "responses",
      "output_cost_per_token": 0.00004,
      "output_cost_per_token_batches": 0.00002,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "o3-deep-research-2025-06-26",
    "displayName": "o3-deep-research-2025-06-26"
  },
  {
    "id": "o3-mini",
    "name": "o3-mini",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 5.5e-7,
      "input_cost_per_token": 0.0000011,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "chat",
      "output_cost_per_token": 0.0000044,
      "supports_function_calling": true,
      "supports_parallel_function_calling": false,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "openai"
    },
    "slug": "o3-mini",
    "displayName": "o3-mini"
  },
  {
    "id": "o3-mini-2025-01-31",
    "name": "o3-mini-2025-01-31",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 5.5e-7,
      "input_cost_per_token": 0.0000011,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "chat",
      "output_cost_per_token": 0.0000044,
      "supports_function_calling": true,
      "supports_parallel_function_calling": false,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "openai"
    },
    "slug": "o3-mini-2025-01-31",
    "displayName": "o3-mini-2025-01-31"
  },
  {
    "id": "o3-pro",
    "name": "o3-pro",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 0.00002,
      "input_cost_per_token_batches": 0.00001,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "responses",
      "output_cost_per_token": 0.00008,
      "output_cost_per_token_batches": 0.00004,
      "supported_endpoints": [
        "/v1/responses",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_parallel_function_calling": false,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "o3-pro",
    "displayName": "o3-pro"
  },
  {
    "id": "o3-pro-2025-06-10",
    "name": "o3-pro-2025-06-10",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 0.00002,
      "input_cost_per_token_batches": 0.00001,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "responses",
      "output_cost_per_token": 0.00008,
      "output_cost_per_token_batches": 0.00004,
      "supported_endpoints": [
        "/v1/responses",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_parallel_function_calling": false,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "o3-pro-2025-06-10",
    "displayName": "o3-pro-2025-06-10"
  },
  {
    "id": "o4-mini",
    "name": "o4-mini",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 2.75e-7,
      "cache_read_input_token_cost_flex": 1.375e-7,
      "cache_read_input_token_cost_priority": 5e-7,
      "input_cost_per_token": 0.0000011,
      "input_cost_per_token_flex": 5.5e-7,
      "input_cost_per_token_priority": 0.000002,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "chat",
      "output_cost_per_token": 0.0000044,
      "output_cost_per_token_flex": 0.0000022,
      "output_cost_per_token_priority": 0.000008,
      "supports_function_calling": true,
      "supports_parallel_function_calling": false,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_service_tier": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "o4-mini",
    "displayName": "o4-mini"
  },
  {
    "id": "o4-mini-2025-04-16",
    "name": "o4-mini-2025-04-16",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 2.75e-7,
      "input_cost_per_token": 0.0000011,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "chat",
      "output_cost_per_token": 0.0000044,
      "supports_function_calling": true,
      "supports_parallel_function_calling": false,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_service_tier": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "o4-mini-2025-04-16",
    "displayName": "o4-mini-2025-04-16"
  },
  {
    "id": "o4-mini-deep-research",
    "name": "o4-mini-deep-research",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 5e-7,
      "input_cost_per_token": 0.000002,
      "input_cost_per_token_batches": 0.000001,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "responses",
      "output_cost_per_token": 0.000008,
      "output_cost_per_token_batches": 0.000004,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "o4-mini-deep-research",
    "displayName": "o4-mini-deep-research"
  },
  {
    "id": "o4-mini-deep-research-2025-06-26",
    "name": "o4-mini-deep-research-2025-06-26",
    "provider": "openai",
    "data": {
      "cache_read_input_token_cost": 5e-7,
      "input_cost_per_token": 0.000002,
      "input_cost_per_token_batches": 0.000001,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "responses",
      "output_cost_per_token": 0.000008,
      "output_cost_per_token_batches": 0.000004,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_function_calling": true,
      "supports_native_streaming": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openai"
    },
    "slug": "o4-mini-deep-research-2025-06-26",
    "displayName": "o4-mini-deep-research-2025-06-26"
  },
  {
    "id": "oci/meta.llama-3.1-405b-instruct",
    "name": "meta.llama-3.1-405b-instruct",
    "provider": "oci",
    "data": {
      "input_cost_per_token": 0.00001068,
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "max_tokens": 4000,
      "mode": "chat",
      "output_cost_per_token": 0.00001068,
      "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
      "supports_function_calling": true,
      "supports_response_schema": false,
      "provider": "oci"
    },
    "slug": "meta.llama-3.1-405b-instruct",
    "displayName": "meta.llama-3.1-405b-instruct"
  },
  {
    "id": "oci/meta.llama-3.2-90b-vision-instruct",
    "name": "meta.llama-3.2-90b-vision-instruct",
    "provider": "oci",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "max_tokens": 4000,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
      "supports_function_calling": true,
      "supports_response_schema": false,
      "provider": "oci"
    },
    "slug": "meta.llama-3.2-90b-vision-instruct",
    "displayName": "meta.llama-3.2-90b-vision-instruct"
  },
  {
    "id": "oci/meta.llama-3.3-70b-instruct",
    "name": "meta.llama-3.3-70b-instruct",
    "provider": "oci",
    "data": {
      "input_cost_per_token": 7.2e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "max_tokens": 4000,
      "mode": "chat",
      "output_cost_per_token": 7.2e-7,
      "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
      "supports_function_calling": true,
      "supports_response_schema": false,
      "provider": "oci"
    },
    "slug": "meta.llama-3.3-70b-instruct",
    "displayName": "meta.llama-3.3-70b-instruct"
  },
  {
    "id": "oci/meta.llama-4-maverick-17b-128e-instruct-fp8",
    "name": "meta.llama-4-maverick-17b-128e-instruct-fp8",
    "provider": "oci",
    "data": {
      "input_cost_per_token": 7.2e-7,
      "max_input_tokens": 512000,
      "max_output_tokens": 4000,
      "max_tokens": 4000,
      "mode": "chat",
      "output_cost_per_token": 7.2e-7,
      "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
      "supports_function_calling": true,
      "supports_response_schema": false,
      "provider": "oci"
    },
    "slug": "meta.llama-4-maverick-17b-128e-instruct-fp8",
    "displayName": "meta.llama-4-maverick-17b-128e-instruct-fp8"
  },
  {
    "id": "oci/meta.llama-4-scout-17b-16e-instruct",
    "name": "meta.llama-4-scout-17b-16e-instruct",
    "provider": "oci",
    "data": {
      "input_cost_per_token": 7.2e-7,
      "max_input_tokens": 192000,
      "max_output_tokens": 4000,
      "max_tokens": 4000,
      "mode": "chat",
      "output_cost_per_token": 7.2e-7,
      "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
      "supports_function_calling": true,
      "supports_response_schema": false,
      "provider": "oci"
    },
    "slug": "meta.llama-4-scout-17b-16e-instruct",
    "displayName": "meta.llama-4-scout-17b-16e-instruct"
  },
  {
    "id": "oci/xai.grok-3",
    "name": "xai.grok-3",
    "provider": "oci",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 1.5e-7,
      "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
      "supports_function_calling": true,
      "supports_response_schema": false,
      "provider": "oci"
    },
    "slug": "xai.grok-3",
    "displayName": "xai.grok-3"
  },
  {
    "id": "oci/xai.grok-3-fast",
    "name": "xai.grok-3-fast",
    "provider": "oci",
    "data": {
      "input_cost_per_token": 0.000005,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.000025,
      "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
      "supports_function_calling": true,
      "supports_response_schema": false,
      "provider": "oci"
    },
    "slug": "xai.grok-3-fast",
    "displayName": "xai.grok-3-fast"
  },
  {
    "id": "oci/xai.grok-3-mini",
    "name": "xai.grok-3-mini",
    "provider": "oci",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 5e-7,
      "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
      "supports_function_calling": true,
      "supports_response_schema": false,
      "provider": "oci"
    },
    "slug": "xai.grok-3-mini",
    "displayName": "xai.grok-3-mini"
  },
  {
    "id": "oci/xai.grok-3-mini-fast",
    "name": "xai.grok-3-mini-fast",
    "provider": "oci",
    "data": {
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.000004,
      "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
      "supports_function_calling": true,
      "supports_response_schema": false,
      "provider": "oci"
    },
    "slug": "xai.grok-3-mini-fast",
    "displayName": "xai.grok-3-mini-fast"
  },
  {
    "id": "oci/xai.grok-4",
    "name": "xai.grok-4",
    "provider": "oci",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 1.5e-7,
      "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
      "supports_function_calling": true,
      "supports_response_schema": false,
      "provider": "oci"
    },
    "slug": "xai.grok-4",
    "displayName": "xai.grok-4"
  },
  {
    "id": "oci/cohere.command-latest",
    "name": "cohere.command-latest",
    "provider": "oci",
    "data": {
      "input_cost_per_token": 0.00000156,
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "max_tokens": 4000,
      "mode": "chat",
      "output_cost_per_token": 0.00000156,
      "source": "https://www.oracle.com/cloud/ai/generative-ai/pricing/",
      "supports_function_calling": true,
      "supports_response_schema": false,
      "provider": "oci"
    },
    "slug": "cohere.command-latest",
    "displayName": "cohere.command-latest"
  },
  {
    "id": "oci/cohere.command-a-03-2025",
    "name": "cohere.command-a-03-2025",
    "provider": "oci",
    "data": {
      "input_cost_per_token": 0.00000156,
      "max_input_tokens": 256000,
      "max_output_tokens": 4000,
      "max_tokens": 4000,
      "mode": "chat",
      "output_cost_per_token": 0.00000156,
      "source": "https://www.oracle.com/cloud/ai/generative-ai/pricing/",
      "supports_function_calling": true,
      "supports_response_schema": false,
      "provider": "oci"
    },
    "slug": "cohere.command-a-03-2025",
    "displayName": "cohere.command-a-03-2025"
  },
  {
    "id": "oci/cohere.command-plus-latest",
    "name": "cohere.command-plus-latest",
    "provider": "oci",
    "data": {
      "input_cost_per_token": 0.00000156,
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "max_tokens": 4000,
      "mode": "chat",
      "output_cost_per_token": 0.00000156,
      "source": "https://www.oracle.com/cloud/ai/generative-ai/pricing/",
      "supports_function_calling": true,
      "supports_response_schema": false,
      "provider": "oci"
    },
    "slug": "cohere.command-plus-latest",
    "displayName": "cohere.command-plus-latest"
  },
  {
    "id": "openai.gpt-oss-120b-1:0",
    "name": "openai.gpt-oss-120b-1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "bedrock_converse"
    },
    "slug": "openai.gpt-oss-120b-1-0",
    "displayName": "openai.gpt-oss-120b-1:0"
  },
  {
    "id": "openai.gpt-oss-20b-1:0",
    "name": "openai.gpt-oss-20b-1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 7e-8,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "bedrock_converse"
    },
    "slug": "openai.gpt-oss-20b-1-0",
    "displayName": "openai.gpt-oss-20b-1:0"
  },
  {
    "id": "openai.gpt-oss-safeguard-120b",
    "name": "openai.gpt-oss-safeguard-120b",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "supports_system_messages": true,
      "provider": "bedrock_converse"
    },
    "slug": "openai.gpt-oss-safeguard-120b",
    "displayName": "openai.gpt-oss-safeguard-120b"
  },
  {
    "id": "openai.gpt-oss-safeguard-20b",
    "name": "openai.gpt-oss-safeguard-20b",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 7e-8,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 2e-7,
      "supports_system_messages": true,
      "provider": "bedrock_converse"
    },
    "slug": "openai.gpt-oss-safeguard-20b",
    "displayName": "openai.gpt-oss-safeguard-20b"
  },
  {
    "id": "openrouter/anthropic/claude-2",
    "name": "claude-2",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 0.00001102,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.00003268,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "claude-2",
    "displayName": "claude-2"
  },
  {
    "id": "openrouter/anthropic/claude-3-5-haiku",
    "name": "claude-3-5-haiku",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 0.000001,
      "max_tokens": 200000,
      "mode": "chat",
      "output_cost_per_token": 0.000005,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "claude-3-5-haiku",
    "displayName": "claude-3-5-haiku"
  },
  {
    "id": "openrouter/anthropic/claude-3-5-haiku-20241022",
    "name": "claude-3-5-haiku-20241022",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000005,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "tool_use_system_prompt_tokens": 264,
      "provider": "openrouter"
    },
    "slug": "claude-3-5-haiku-20241022",
    "displayName": "claude-3-5-haiku-20241022"
  },
  {
    "id": "openrouter/anthropic/claude-3-haiku",
    "name": "claude-3-haiku",
    "provider": "openrouter",
    "data": {
      "input_cost_per_image": 0.0004,
      "input_cost_per_token": 2.5e-7,
      "max_tokens": 200000,
      "mode": "chat",
      "output_cost_per_token": 0.00000125,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openrouter"
    },
    "slug": "claude-3-haiku",
    "displayName": "claude-3-haiku"
  },
  {
    "id": "openrouter/anthropic/claude-3-haiku-20240307",
    "name": "claude-3-haiku-20240307",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 2.5e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00000125,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 264,
      "provider": "openrouter"
    },
    "slug": "claude-3-haiku-20240307",
    "displayName": "claude-3-haiku-20240307"
  },
  {
    "id": "openrouter/anthropic/claude-3-opus",
    "name": "claude-3-opus",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000075,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 395,
      "provider": "openrouter"
    },
    "slug": "claude-3-opus",
    "displayName": "claude-3-opus"
  },
  {
    "id": "openrouter/anthropic/claude-3-sonnet",
    "name": "claude-3-sonnet",
    "provider": "openrouter",
    "data": {
      "input_cost_per_image": 0.0048,
      "input_cost_per_token": 0.000003,
      "max_tokens": 200000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openrouter"
    },
    "slug": "claude-3-sonnet",
    "displayName": "claude-3-sonnet"
  },
  {
    "id": "openrouter/anthropic/claude-3.5-sonnet",
    "name": "claude-3.5-sonnet",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "openrouter"
    },
    "slug": "claude-3.5-sonnet",
    "displayName": "claude-3.5-sonnet"
  },
  {
    "id": "openrouter/anthropic/claude-3.5-sonnet:beta",
    "name": "claude-3.5-sonnet:beta",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "openrouter"
    },
    "slug": "claude-3.5-sonnet-beta",
    "displayName": "claude-3.5-sonnet:beta"
  },
  {
    "id": "openrouter/anthropic/claude-3.7-sonnet",
    "name": "claude-3.7-sonnet",
    "provider": "openrouter",
    "data": {
      "input_cost_per_image": 0.0048,
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "openrouter"
    },
    "slug": "claude-3.7-sonnet",
    "displayName": "claude-3.7-sonnet"
  },
  {
    "id": "openrouter/anthropic/claude-3.7-sonnet:beta",
    "name": "claude-3.7-sonnet:beta",
    "provider": "openrouter",
    "data": {
      "input_cost_per_image": 0.0048,
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "openrouter"
    },
    "slug": "claude-3.7-sonnet-beta",
    "displayName": "claude-3.7-sonnet:beta"
  },
  {
    "id": "openrouter/anthropic/claude-instant-v1",
    "name": "claude-instant-v1",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 0.00000163,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.00000551,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "claude-instant-v1",
    "displayName": "claude-instant-v1"
  },
  {
    "id": "openrouter/anthropic/claude-opus-4",
    "name": "claude-opus-4",
    "provider": "openrouter",
    "data": {
      "input_cost_per_image": 0.0048,
      "cache_creation_input_token_cost": 0.00001875,
      "cache_read_input_token_cost": 0.0000015,
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.000075,
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "openrouter"
    },
    "slug": "claude-opus-4",
    "displayName": "claude-opus-4"
  },
  {
    "id": "openrouter/anthropic/claude-opus-4.1",
    "name": "claude-opus-4.1",
    "provider": "openrouter",
    "data": {
      "input_cost_per_image": 0.0048,
      "cache_creation_input_token_cost": 0.00001875,
      "cache_creation_input_token_cost_above_1hr": 0.00003,
      "cache_read_input_token_cost": 0.0000015,
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.000075,
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "openrouter"
    },
    "slug": "claude-opus-4.1",
    "displayName": "claude-opus-4.1"
  },
  {
    "id": "openrouter/anthropic/claude-sonnet-4",
    "name": "claude-sonnet-4",
    "provider": "openrouter",
    "data": {
      "input_cost_per_image": 0.0048,
      "cache_creation_input_token_cost": 0.00000375,
      "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
      "cache_read_input_token_cost": 3e-7,
      "cache_read_input_token_cost_above_200k_tokens": 6e-7,
      "input_cost_per_token": 0.000003,
      "input_cost_per_token_above_200k_tokens": 0.000006,
      "output_cost_per_token_above_200k_tokens": 0.0000225,
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "openrouter"
    },
    "slug": "claude-sonnet-4",
    "displayName": "claude-sonnet-4"
  },
  {
    "id": "openrouter/anthropic/claude-opus-4.5",
    "name": "claude-opus-4.5",
    "provider": "openrouter",
    "data": {
      "cache_creation_input_token_cost": 0.00000625,
      "cache_read_input_token_cost": 5e-7,
      "input_cost_per_token": 0.000005,
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.000025,
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "openrouter"
    },
    "slug": "claude-opus-4.5",
    "displayName": "claude-opus-4.5"
  },
  {
    "id": "openrouter/anthropic/claude-sonnet-4.5",
    "name": "claude-sonnet-4.5",
    "provider": "openrouter",
    "data": {
      "input_cost_per_image": 0.0048,
      "cache_creation_input_token_cost": 0.00000375,
      "cache_read_input_token_cost": 3e-7,
      "input_cost_per_token": 0.000003,
      "input_cost_per_token_above_200k_tokens": 0.000006,
      "output_cost_per_token_above_200k_tokens": 0.0000225,
      "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
      "cache_read_input_token_cost_above_200k_tokens": 6e-7,
      "max_input_tokens": 1000000,
      "max_output_tokens": 1000000,
      "max_tokens": 1000000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "openrouter"
    },
    "slug": "claude-sonnet-4.5",
    "displayName": "claude-sonnet-4.5"
  },
  {
    "id": "openrouter/anthropic/claude-haiku-4.5",
    "name": "claude-haiku-4.5",
    "provider": "openrouter",
    "data": {
      "cache_creation_input_token_cost": 0.00000125,
      "cache_read_input_token_cost": 1e-7,
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 200000,
      "max_output_tokens": 200000,
      "max_tokens": 200000,
      "mode": "chat",
      "output_cost_per_token": 0.000005,
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 346,
      "provider": "openrouter"
    },
    "slug": "claude-haiku-4.5",
    "displayName": "claude-haiku-4.5"
  },
  {
    "id": "openrouter/bytedance/ui-tars-1.5-7b",
    "name": "ui-tars-1.5-7b",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 2048,
      "max_tokens": 2048,
      "mode": "chat",
      "output_cost_per_token": 2e-7,
      "source": "https://openrouter.ai/api/v1/models/bytedance/ui-tars-1.5-7b",
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "ui-tars-1.5-7b",
    "displayName": "ui-tars-1.5-7b"
  },
  {
    "id": "openrouter/cognitivecomputations/dolphin-mixtral-8x7b",
    "name": "dolphin-mixtral-8x7b",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 5e-7,
      "max_tokens": 32769,
      "mode": "chat",
      "output_cost_per_token": 5e-7,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "dolphin-mixtral-8x7b",
    "displayName": "dolphin-mixtral-8x7b"
  },
  {
    "id": "openrouter/cohere/command-r-plus",
    "name": "command-r-plus",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "command-r-plus",
    "displayName": "command-r-plus"
  },
  {
    "id": "openrouter/databricks/dbrx-instruct",
    "name": "dbrx-instruct",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 6e-7,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "dbrx-instruct",
    "displayName": "dbrx-instruct"
  },
  {
    "id": "openrouter/deepseek/deepseek-chat",
    "name": "deepseek-chat",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 1.4e-7,
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 2.8e-7,
      "supports_prompt_caching": true,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "deepseek-chat",
    "displayName": "deepseek-chat"
  },
  {
    "id": "openrouter/deepseek/deepseek-chat-v3-0324",
    "name": "deepseek-chat-v3-0324",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 1.4e-7,
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 2.8e-7,
      "supports_prompt_caching": true,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "deepseek-chat-v3-0324",
    "displayName": "deepseek-chat-v3-0324"
  },
  {
    "id": "openrouter/deepseek/deepseek-chat-v3.1",
    "name": "deepseek-chat-v3.1",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 2e-7,
      "input_cost_per_token_cache_hit": 2e-8,
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "max_tokens": 163840,
      "mode": "chat",
      "output_cost_per_token": 8e-7,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "deepseek-chat-v3.1",
    "displayName": "deepseek-chat-v3.1"
  },
  {
    "id": "openrouter/deepseek/deepseek-v3.2",
    "name": "deepseek-v3.2",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 2.8e-7,
      "input_cost_per_token_cache_hit": 2.8e-8,
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "max_tokens": 163840,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "deepseek-v3.2",
    "displayName": "deepseek-v3.2"
  },
  {
    "id": "openrouter/deepseek/deepseek-v3.2-exp",
    "name": "deepseek-v3.2-exp",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 2e-7,
      "input_cost_per_token_cache_hit": 2e-8,
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "max_tokens": 163840,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": false,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "deepseek-v3.2-exp",
    "displayName": "deepseek-v3.2-exp"
  },
  {
    "id": "openrouter/deepseek/deepseek-coder",
    "name": "deepseek-coder",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 1.4e-7,
      "max_input_tokens": 66000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 2.8e-7,
      "supports_prompt_caching": true,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "deepseek-coder",
    "displayName": "deepseek-coder"
  },
  {
    "id": "openrouter/deepseek/deepseek-r1",
    "name": "deepseek-r1",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 5.5e-7,
      "input_cost_per_token_cache_hit": 1.4e-7,
      "max_input_tokens": 65336,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.00000219,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "deepseek-r1",
    "displayName": "deepseek-r1"
  },
  {
    "id": "openrouter/deepseek/deepseek-r1-0528",
    "name": "deepseek-r1-0528",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 5e-7,
      "input_cost_per_token_cache_hit": 1.4e-7,
      "max_input_tokens": 65336,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.00000215,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "deepseek-r1-0528",
    "displayName": "deepseek-r1-0528"
  },
  {
    "id": "openrouter/fireworks/firellava-13b",
    "name": "firellava-13b",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 2e-7,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "firellava-13b",
    "displayName": "firellava-13b"
  },
  {
    "id": "openrouter/google/gemini-2.0-flash-001",
    "name": "gemini-2.0-flash-001",
    "provider": "openrouter",
    "data": {
      "deprecation_date": "2026-03-31",
      "input_cost_per_audio_token": 7e-7,
      "input_cost_per_token": 1e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_pdf_size_mb": 30,
      "max_tokens": 8192,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openrouter"
    },
    "slug": "gemini-2.0-flash-001",
    "displayName": "gemini-2.0-flash-001"
  },
  {
    "id": "openrouter/google/gemini-2.5-flash",
    "name": "gemini-2.5-flash",
    "provider": "openrouter",
    "data": {
      "input_cost_per_audio_token": 7e-7,
      "input_cost_per_token": 3e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_pdf_size_mb": 30,
      "max_tokens": 8192,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 0.0000025,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openrouter"
    },
    "slug": "gemini-2.5-flash",
    "displayName": "gemini-2.5-flash"
  },
  {
    "id": "openrouter/google/gemini-2.5-pro",
    "name": "gemini-2.5-pro",
    "provider": "openrouter",
    "data": {
      "input_cost_per_audio_token": 7e-7,
      "input_cost_per_token": 0.00000125,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_pdf_size_mb": 30,
      "max_tokens": 8192,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supports_audio_output": true,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openrouter"
    },
    "slug": "gemini-2.5-pro",
    "displayName": "gemini-2.5-pro"
  },
  {
    "id": "openrouter/google/gemini-3-pro-preview",
    "name": "gemini-3-pro-preview",
    "provider": "openrouter",
    "data": {
      "cache_read_input_token_cost": 2e-7,
      "cache_read_input_token_cost_above_200k_tokens": 4e-7,
      "cache_creation_input_token_cost_above_200k_tokens": 2.5e-7,
      "input_cost_per_token": 0.000002,
      "input_cost_per_token_above_200k_tokens": 0.000004,
      "input_cost_per_token_batches": 0.000001,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_token": 0.000012,
      "output_cost_per_token_above_200k_tokens": 0.000018,
      "output_cost_per_token_batches": 0.000006,
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_input": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_video_input": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "openrouter"
    },
    "slug": "gemini-3-pro-preview",
    "displayName": "gemini-3-pro-preview"
  },
  {
    "id": "openrouter/google/gemini-3-flash-preview",
    "name": "gemini-3-flash-preview",
    "provider": "openrouter",
    "data": {
      "cache_read_input_token_cost": 5e-8,
      "input_cost_per_audio_token": 0.000001,
      "input_cost_per_token": 5e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "max_pdf_size_mb": 30,
      "max_tokens": 65535,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "chat",
      "output_cost_per_reasoning_token": 0.000003,
      "output_cost_per_token": 0.000003,
      "rpm": 2000,
      "source": "https://ai.google.dev/pricing/gemini-3",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "supports_web_search": true,
      "tpm": 800000,
      "provider": "openrouter"
    },
    "slug": "gemini-3-flash-preview",
    "displayName": "gemini-3-flash-preview"
  },
  {
    "id": "openrouter/google/gemini-pro-1.5",
    "name": "gemini-pro-1.5",
    "provider": "openrouter",
    "data": {
      "input_cost_per_image": 0.00265,
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.0000075,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openrouter"
    },
    "slug": "gemini-pro-1.5",
    "displayName": "gemini-pro-1.5"
  },
  {
    "id": "openrouter/google/gemini-pro-vision",
    "name": "gemini-pro-vision",
    "provider": "openrouter",
    "data": {
      "input_cost_per_image": 0.0025,
      "input_cost_per_token": 1.25e-7,
      "max_tokens": 45875,
      "mode": "chat",
      "output_cost_per_token": 3.75e-7,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openrouter"
    },
    "slug": "gemini-pro-vision",
    "displayName": "gemini-pro-vision"
  },
  {
    "id": "openrouter/google/palm-2-chat-bison",
    "name": "palm-2-chat-bison",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 5e-7,
      "max_tokens": 25804,
      "mode": "chat",
      "output_cost_per_token": 5e-7,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "palm-2-chat-bison",
    "displayName": "palm-2-chat-bison"
  },
  {
    "id": "openrouter/google/palm-2-codechat-bison",
    "name": "palm-2-codechat-bison",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 5e-7,
      "max_tokens": 20070,
      "mode": "chat",
      "output_cost_per_token": 5e-7,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "palm-2-codechat-bison",
    "displayName": "palm-2-codechat-bison"
  },
  {
    "id": "openrouter/gryphe/mythomax-l2-13b",
    "name": "mythomax-l2-13b",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 0.000001875,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000001875,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "mythomax-l2-13b",
    "displayName": "mythomax-l2-13b"
  },
  {
    "id": "openrouter/jondurbin/airoboros-l2-70b-2.1",
    "name": "airoboros-l2-70b-2.1",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 0.000013875,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000013875,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "airoboros-l2-70b-2.1",
    "displayName": "airoboros-l2-70b-2.1"
  },
  {
    "id": "openrouter/mancer/weaver",
    "name": "weaver",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 0.000005625,
      "max_tokens": 8000,
      "mode": "chat",
      "output_cost_per_token": 0.000005625,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "weaver",
    "displayName": "weaver"
  },
  {
    "id": "openrouter/meta-llama/codellama-34b-instruct",
    "name": "codellama-34b-instruct",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 5e-7,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 5e-7,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "codellama-34b-instruct",
    "displayName": "codellama-34b-instruct"
  },
  {
    "id": "openrouter/meta-llama/llama-2-13b-chat",
    "name": "llama-2-13b-chat",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 2e-7,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "llama-2-13b-chat",
    "displayName": "llama-2-13b-chat"
  },
  {
    "id": "openrouter/meta-llama/llama-2-70b-chat",
    "name": "llama-2-70b-chat",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 0.0000015,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "llama-2-70b-chat",
    "displayName": "llama-2-70b-chat"
  },
  {
    "id": "openrouter/meta-llama/llama-3-70b-instruct",
    "name": "llama-3-70b-instruct",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 5.9e-7,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 7.9e-7,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "llama-3-70b-instruct",
    "displayName": "llama-3-70b-instruct"
  },
  {
    "id": "openrouter/meta-llama/llama-3-70b-instruct:nitro",
    "name": "llama-3-70b-instruct:nitro",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 9e-7,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 9e-7,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "llama-3-70b-instruct-nitro",
    "displayName": "llama-3-70b-instruct:nitro"
  },
  {
    "id": "openrouter/meta-llama/llama-3-8b-instruct:extended",
    "name": "llama-3-8b-instruct:extended",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 2.25e-7,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.00000225,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "llama-3-8b-instruct-extended",
    "displayName": "llama-3-8b-instruct:extended"
  },
  {
    "id": "openrouter/microsoft/wizardlm-2-8x22b:nitro",
    "name": "wizardlm-2-8x22b:nitro",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 0.000001,
      "max_tokens": 65536,
      "mode": "chat",
      "output_cost_per_token": 0.000001,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "wizardlm-2-8x22b-nitro",
    "displayName": "wizardlm-2-8x22b:nitro"
  },
  {
    "id": "openrouter/minimax/minimax-m2",
    "name": "minimax-m2",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 2.55e-7,
      "max_input_tokens": 204800,
      "max_output_tokens": 204800,
      "max_tokens": 204800,
      "mode": "chat",
      "output_cost_per_token": 0.00000102,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "minimax-m2",
    "displayName": "minimax-m2"
  },
  {
    "id": "openrouter/mistralai/devstral-2512",
    "name": "devstral-2512",
    "provider": "openrouter",
    "data": {
      "input_cost_per_image": 0,
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "max_tokens": 65536,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "supports_function_calling": true,
      "supports_prompt_caching": false,
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "openrouter"
    },
    "slug": "devstral-2512",
    "displayName": "devstral-2512"
  },
  {
    "id": "openrouter/mistralai/ministral-3b-2512",
    "name": "ministral-3b-2512",
    "provider": "openrouter",
    "data": {
      "input_cost_per_image": 0,
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 1e-7,
      "supports_function_calling": true,
      "supports_prompt_caching": false,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openrouter"
    },
    "slug": "ministral-3b-2512",
    "displayName": "ministral-3b-2512"
  },
  {
    "id": "openrouter/mistralai/ministral-8b-2512",
    "name": "ministral-8b-2512",
    "provider": "openrouter",
    "data": {
      "input_cost_per_image": 0,
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "max_tokens": 262144,
      "mode": "chat",
      "output_cost_per_token": 1.5e-7,
      "supports_function_calling": true,
      "supports_prompt_caching": false,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openrouter"
    },
    "slug": "ministral-8b-2512",
    "displayName": "ministral-8b-2512"
  },
  {
    "id": "openrouter/mistralai/ministral-14b-2512",
    "name": "ministral-14b-2512",
    "provider": "openrouter",
    "data": {
      "input_cost_per_image": 0,
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "max_tokens": 262144,
      "mode": "chat",
      "output_cost_per_token": 2e-7,
      "supports_function_calling": true,
      "supports_prompt_caching": false,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openrouter"
    },
    "slug": "ministral-14b-2512",
    "displayName": "ministral-14b-2512"
  },
  {
    "id": "openrouter/mistralai/mistral-large-2512",
    "name": "mistral-large-2512",
    "provider": "openrouter",
    "data": {
      "input_cost_per_image": 0,
      "input_cost_per_token": 5e-7,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "max_tokens": 262144,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "supports_function_calling": true,
      "supports_prompt_caching": false,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openrouter"
    },
    "slug": "mistral-large-2512",
    "displayName": "mistral-large-2512"
  },
  {
    "id": "openrouter/mistralai/mistral-7b-instruct",
    "name": "mistral-7b-instruct",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 1.3e-7,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 1.3e-7,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "mistral-7b-instruct",
    "displayName": "mistral-7b-instruct"
  },
  {
    "id": "openrouter/mistralai/mistral-large",
    "name": "mistral-large",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 0.000008,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.000024,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "mistral-large",
    "displayName": "mistral-large"
  },
  {
    "id": "openrouter/mistralai/mistral-small-3.1-24b-instruct",
    "name": "mistral-small-3.1-24b-instruct",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "mistral-small-3.1-24b-instruct",
    "displayName": "mistral-small-3.1-24b-instruct"
  },
  {
    "id": "openrouter/mistralai/mistral-small-3.2-24b-instruct",
    "name": "mistral-small-3.2-24b-instruct",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "mistral-small-3.2-24b-instruct",
    "displayName": "mistral-small-3.2-24b-instruct"
  },
  {
    "id": "openrouter/mistralai/mixtral-8x22b-instruct",
    "name": "mixtral-8x22b-instruct",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 6.5e-7,
      "max_tokens": 65536,
      "mode": "chat",
      "output_cost_per_token": 6.5e-7,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "mixtral-8x22b-instruct",
    "displayName": "mixtral-8x22b-instruct"
  },
  {
    "id": "openrouter/moonshotai/kimi-k2.5",
    "name": "kimi-k2.5",
    "provider": "openrouter",
    "data": {
      "cache_read_input_token_cost": 1e-7,
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "max_tokens": 262144,
      "mode": "chat",
      "output_cost_per_token": 0.000003,
      "source": "https://openrouter.ai/moonshotai/kimi-k2.5",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openrouter"
    },
    "slug": "kimi-k2.5",
    "displayName": "kimi-k2.5"
  },
  {
    "id": "openrouter/nousresearch/nous-hermes-llama2-13b",
    "name": "nous-hermes-llama2-13b",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 2e-7,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "nous-hermes-llama2-13b",
    "displayName": "nous-hermes-llama2-13b"
  },
  {
    "id": "openrouter/openai/gpt-3.5-turbo",
    "name": "gpt-3.5-turbo",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 0.0000015,
      "max_tokens": 4095,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "gpt-3.5-turbo",
    "displayName": "gpt-3.5-turbo"
  },
  {
    "id": "openrouter/openai/gpt-3.5-turbo-16k",
    "name": "gpt-3.5-turbo-16k",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_tokens": 16383,
      "mode": "chat",
      "output_cost_per_token": 0.000004,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "gpt-3.5-turbo-16k",
    "displayName": "gpt-3.5-turbo-16k"
  },
  {
    "id": "openrouter/openai/gpt-4",
    "name": "gpt-4",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 0.00003,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.00006,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "gpt-4",
    "displayName": "gpt-4"
  },
  {
    "id": "openrouter/openai/gpt-4-vision-preview",
    "name": "gpt-4-vision-preview",
    "provider": "openrouter",
    "data": {
      "input_cost_per_image": 0.01445,
      "input_cost_per_token": 0.00001,
      "max_tokens": 130000,
      "mode": "chat",
      "output_cost_per_token": 0.00003,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openrouter"
    },
    "slug": "gpt-4-vision-preview",
    "displayName": "gpt-4-vision-preview"
  },
  {
    "id": "openrouter/openai/gpt-4.1",
    "name": "gpt-4.1",
    "provider": "openrouter",
    "data": {
      "cache_read_input_token_cost": 5e-7,
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.000008,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openrouter"
    },
    "slug": "gpt-4.1",
    "displayName": "gpt-4.1"
  },
  {
    "id": "openrouter/openai/gpt-4.1-2025-04-14",
    "name": "gpt-4.1-2025-04-14",
    "provider": "openrouter",
    "data": {
      "cache_read_input_token_cost": 5e-7,
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.000008,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openrouter"
    },
    "slug": "gpt-4.1-2025-04-14",
    "displayName": "gpt-4.1-2025-04-14"
  },
  {
    "id": "openrouter/openai/gpt-4.1-mini",
    "name": "gpt-4.1-mini",
    "provider": "openrouter",
    "data": {
      "cache_read_input_token_cost": 1e-7,
      "input_cost_per_token": 4e-7,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.0000016,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openrouter"
    },
    "slug": "gpt-4.1-mini",
    "displayName": "gpt-4.1-mini"
  },
  {
    "id": "openrouter/openai/gpt-4.1-mini-2025-04-14",
    "name": "gpt-4.1-mini-2025-04-14",
    "provider": "openrouter",
    "data": {
      "cache_read_input_token_cost": 1e-7,
      "input_cost_per_token": 4e-7,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.0000016,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openrouter"
    },
    "slug": "gpt-4.1-mini-2025-04-14",
    "displayName": "gpt-4.1-mini-2025-04-14"
  },
  {
    "id": "openrouter/openai/gpt-4.1-nano",
    "name": "gpt-4.1-nano",
    "provider": "openrouter",
    "data": {
      "cache_read_input_token_cost": 2.5e-8,
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openrouter"
    },
    "slug": "gpt-4.1-nano",
    "displayName": "gpt-4.1-nano"
  },
  {
    "id": "openrouter/openai/gpt-4.1-nano-2025-04-14",
    "name": "gpt-4.1-nano-2025-04-14",
    "provider": "openrouter",
    "data": {
      "cache_read_input_token_cost": 2.5e-8,
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openrouter"
    },
    "slug": "gpt-4.1-nano-2025-04-14",
    "displayName": "gpt-4.1-nano-2025-04-14"
  },
  {
    "id": "openrouter/openai/gpt-4o",
    "name": "gpt-4o",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openrouter"
    },
    "slug": "gpt-4o",
    "displayName": "gpt-4o"
  },
  {
    "id": "openrouter/openai/gpt-4o-2024-05-13",
    "name": "gpt-4o-2024-05-13",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 0.000005,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openrouter"
    },
    "slug": "gpt-4o-2024-05-13",
    "displayName": "gpt-4o-2024-05-13"
  },
  {
    "id": "openrouter/openai/gpt-5-chat",
    "name": "gpt-5-chat",
    "provider": "openrouter",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "input_cost_per_token": 0.00000125,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "gpt-5-chat",
    "displayName": "gpt-5-chat"
  },
  {
    "id": "openrouter/openai/gpt-5-codex",
    "name": "gpt-5-codex",
    "provider": "openrouter",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "input_cost_per_token": 0.00000125,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "gpt-5-codex",
    "displayName": "gpt-5-codex"
  },
  {
    "id": "openrouter/openai/gpt-5.2-codex",
    "name": "gpt-5.2-codex",
    "provider": "openrouter",
    "data": {
      "cache_read_input_token_cost": 1.75e-7,
      "input_cost_per_token": 0.00000175,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "responses",
      "output_cost_per_token": 0.000014,
      "supported_endpoints": [
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "gpt-5.2-codex",
    "displayName": "gpt-5.2-codex"
  },
  {
    "id": "openrouter/openai/gpt-5",
    "name": "gpt-5",
    "provider": "openrouter",
    "data": {
      "cache_read_input_token_cost": 1.25e-7,
      "input_cost_per_token": 0.00000125,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "gpt-5",
    "displayName": "gpt-5"
  },
  {
    "id": "openrouter/openai/gpt-5-mini",
    "name": "gpt-5-mini",
    "provider": "openrouter",
    "data": {
      "cache_read_input_token_cost": 2.5e-8,
      "input_cost_per_token": 2.5e-7,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "gpt-5-mini",
    "displayName": "gpt-5-mini"
  },
  {
    "id": "openrouter/openai/gpt-5-nano",
    "name": "gpt-5-nano",
    "provider": "openrouter",
    "data": {
      "cache_read_input_token_cost": 5e-9,
      "input_cost_per_token": 5e-8,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "gpt-5-nano",
    "displayName": "gpt-5-nano"
  },
  {
    "id": "openrouter/openai/gpt-5.2",
    "name": "gpt-5.2",
    "provider": "openrouter",
    "data": {
      "input_cost_per_image": 0,
      "cache_read_input_token_cost": 1.75e-7,
      "input_cost_per_token": 0.00000175,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000014,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openrouter"
    },
    "slug": "gpt-5.2",
    "displayName": "gpt-5.2"
  },
  {
    "id": "openrouter/openai/gpt-5.2-chat",
    "name": "gpt-5.2-chat",
    "provider": "openrouter",
    "data": {
      "input_cost_per_image": 0,
      "cache_read_input_token_cost": 1.75e-7,
      "input_cost_per_token": 0.00000175,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.000014,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openrouter"
    },
    "slug": "gpt-5.2-chat",
    "displayName": "gpt-5.2-chat"
  },
  {
    "id": "openrouter/openai/gpt-5.2-pro",
    "name": "gpt-5.2-pro",
    "provider": "openrouter",
    "data": {
      "input_cost_per_image": 0,
      "input_cost_per_token": 0.000021,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000168,
      "supports_function_calling": true,
      "supports_prompt_caching": false,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openrouter"
    },
    "slug": "gpt-5.2-pro",
    "displayName": "gpt-5.2-pro"
  },
  {
    "id": "openrouter/openai/gpt-oss-120b",
    "name": "gpt-oss-120b",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 1.8e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 8e-7,
      "source": "https://openrouter.ai/openai/gpt-oss-120b",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "gpt-oss-120b",
    "displayName": "gpt-oss-120b"
  },
  {
    "id": "openrouter/openai/gpt-oss-20b",
    "name": "gpt-oss-20b",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 2e-8,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 1e-7,
      "source": "https://openrouter.ai/openai/gpt-oss-20b",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "gpt-oss-20b",
    "displayName": "gpt-oss-20b"
  },
  {
    "id": "openrouter/openai/o1",
    "name": "o1",
    "provider": "openrouter",
    "data": {
      "cache_read_input_token_cost": 0.0000075,
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "chat",
      "output_cost_per_token": 0.00006,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openrouter"
    },
    "slug": "o1",
    "displayName": "o1"
  },
  {
    "id": "openrouter/openai/o1-mini",
    "name": "o1-mini",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "max_tokens": 65536,
      "mode": "chat",
      "output_cost_per_token": 0.000012,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "openrouter"
    },
    "slug": "o1-mini",
    "displayName": "o1-mini"
  },
  {
    "id": "openrouter/openai/o1-mini-2024-09-12",
    "name": "o1-mini-2024-09-12",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "max_tokens": 65536,
      "mode": "chat",
      "output_cost_per_token": 0.000012,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "openrouter"
    },
    "slug": "o1-mini-2024-09-12",
    "displayName": "o1-mini-2024-09-12"
  },
  {
    "id": "openrouter/openai/o1-preview",
    "name": "o1-preview",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.00006,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "openrouter"
    },
    "slug": "o1-preview",
    "displayName": "o1-preview"
  },
  {
    "id": "openrouter/openai/o1-preview-2024-09-12",
    "name": "o1-preview-2024-09-12",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.00006,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "openrouter"
    },
    "slug": "o1-preview-2024-09-12",
    "displayName": "o1-preview-2024-09-12"
  },
  {
    "id": "openrouter/openai/o3-mini",
    "name": "o3-mini",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 0.0000011,
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "max_tokens": 65536,
      "mode": "chat",
      "output_cost_per_token": 0.0000044,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "openrouter"
    },
    "slug": "o3-mini",
    "displayName": "o3-mini"
  },
  {
    "id": "openrouter/openai/o3-mini-high",
    "name": "o3-mini-high",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 0.0000011,
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "max_tokens": 65536,
      "mode": "chat",
      "output_cost_per_token": 0.0000044,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "openrouter"
    },
    "slug": "o3-mini-high",
    "displayName": "o3-mini-high"
  },
  {
    "id": "openrouter/pygmalionai/mythalion-13b",
    "name": "mythalion-13b",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 0.000001875,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000001875,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "mythalion-13b",
    "displayName": "mythalion-13b"
  },
  {
    "id": "openrouter/qwen/qwen-2.5-coder-32b-instruct",
    "name": "qwen-2.5-coder-32b-instruct",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 1.8e-7,
      "max_input_tokens": 33792,
      "max_output_tokens": 33792,
      "max_tokens": 33792,
      "mode": "chat",
      "output_cost_per_token": 1.8e-7,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "qwen-2.5-coder-32b-instruct",
    "displayName": "qwen-2.5-coder-32b-instruct"
  },
  {
    "id": "openrouter/qwen/qwen-vl-plus",
    "name": "qwen-vl-plus",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 2.1e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "max_tokens": 2048,
      "mode": "chat",
      "output_cost_per_token": 6.3e-7,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "openrouter"
    },
    "slug": "qwen-vl-plus",
    "displayName": "qwen-vl-plus"
  },
  {
    "id": "openrouter/qwen/qwen3-coder",
    "name": "qwen3-coder",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 2.2e-7,
      "max_input_tokens": 262100,
      "max_output_tokens": 262100,
      "max_tokens": 262100,
      "mode": "chat",
      "output_cost_per_token": 9.5e-7,
      "source": "https://openrouter.ai/qwen/qwen3-coder",
      "supports_tool_choice": true,
      "supports_function_calling": true,
      "provider": "openrouter"
    },
    "slug": "qwen3-coder",
    "displayName": "qwen3-coder"
  },
  {
    "id": "openrouter/qwen/qwen3-235b-a22b-2507",
    "name": "qwen3-235b-a22b-2507",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 7.1e-8,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "max_tokens": 262144,
      "mode": "chat",
      "output_cost_per_token": 1e-7,
      "source": "https://openrouter.ai/qwen/qwen3-235b-a22b-2507",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "qwen3-235b-a22b-2507",
    "displayName": "qwen3-235b-a22b-2507"
  },
  {
    "id": "openrouter/qwen/qwen3-235b-a22b-thinking-2507",
    "name": "qwen3-235b-a22b-thinking-2507",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 1.1e-7,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "max_tokens": 262144,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "source": "https://openrouter.ai/qwen/qwen3-235b-a22b-thinking-2507",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "qwen3-235b-a22b-thinking-2507",
    "displayName": "qwen3-235b-a22b-thinking-2507"
  },
  {
    "id": "openrouter/switchpoint/router",
    "name": "router",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 8.5e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.0000034,
      "source": "https://openrouter.ai/switchpoint/router",
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "router",
    "displayName": "router"
  },
  {
    "id": "openrouter/undi95/remm-slerp-l2-13b",
    "name": "remm-slerp-l2-13b",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 0.000001875,
      "max_tokens": 6144,
      "mode": "chat",
      "output_cost_per_token": 0.000001875,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "remm-slerp-l2-13b",
    "displayName": "remm-slerp-l2-13b"
  },
  {
    "id": "openrouter/x-ai/grok-4",
    "name": "grok-4",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "source": "https://openrouter.ai/x-ai/grok-4",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "openrouter"
    },
    "slug": "grok-4",
    "displayName": "grok-4"
  },
  {
    "id": "openrouter/z-ai/glm-4.6",
    "name": "glm-4.6",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 4e-7,
      "max_input_tokens": 202800,
      "max_output_tokens": 131000,
      "max_tokens": 131000,
      "mode": "chat",
      "output_cost_per_token": 0.00000175,
      "source": "https://openrouter.ai/z-ai/glm-4.6",
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "glm-4.6",
    "displayName": "glm-4.6"
  },
  {
    "id": "openrouter/z-ai/glm-4.6:exacto",
    "name": "glm-4.6:exacto",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 4.5e-7,
      "max_input_tokens": 202800,
      "max_output_tokens": 131000,
      "max_tokens": 131000,
      "mode": "chat",
      "output_cost_per_token": 0.0000019,
      "source": "https://openrouter.ai/z-ai/glm-4.6:exacto",
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "openrouter"
    },
    "slug": "glm-4.6-exacto",
    "displayName": "glm-4.6:exacto"
  },
  {
    "id": "openrouter/xiaomi/mimo-v2-flash",
    "name": "mimo-v2-flash",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 9e-8,
      "output_cost_per_token": 2.9e-7,
      "cache_creation_input_token_cost": 0,
      "cache_read_input_token_cost": 0,
      "max_input_tokens": 262144,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_reasoning": true,
      "supports_vision": false,
      "supports_prompt_caching": false,
      "provider": "openrouter"
    },
    "slug": "mimo-v2-flash",
    "displayName": "mimo-v2-flash"
  },
  {
    "id": "openrouter/z-ai/glm-4.7",
    "name": "glm-4.7",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 4e-7,
      "output_cost_per_token": 0.0000015,
      "cache_creation_input_token_cost": 0,
      "cache_read_input_token_cost": 0,
      "max_input_tokens": 202752,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_reasoning": true,
      "supports_vision": true,
      "supports_prompt_caching": false,
      "supports_assistant_prefill": true,
      "provider": "openrouter"
    },
    "slug": "glm-4.7",
    "displayName": "glm-4.7"
  },
  {
    "id": "openrouter/z-ai/glm-4.7-flash",
    "name": "glm-4.7-flash",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 7e-8,
      "output_cost_per_token": 4e-7,
      "cache_creation_input_token_cost": 0,
      "cache_read_input_token_cost": 0,
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_reasoning": true,
      "supports_vision": true,
      "supports_prompt_caching": false,
      "provider": "openrouter"
    },
    "slug": "glm-4.7-flash",
    "displayName": "glm-4.7-flash"
  },
  {
    "id": "openrouter/minimax/minimax-m2.1",
    "name": "minimax-m2.1",
    "provider": "openrouter",
    "data": {
      "input_cost_per_token": 2.7e-7,
      "output_cost_per_token": 0.0000012,
      "cache_creation_input_token_cost": 0,
      "cache_read_input_token_cost": 0,
      "max_input_tokens": 204000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_reasoning": true,
      "supports_vision": true,
      "supports_prompt_caching": false,
      "supports_computer_use": false,
      "provider": "openrouter"
    },
    "slug": "minimax-m2.1",
    "displayName": "minimax-m2.1"
  },
  {
    "id": "ovhcloud/DeepSeek-R1-Distill-Llama-70B",
    "name": "DeepSeek-R1-Distill-Llama-70B",
    "provider": "ovhcloud",
    "data": {
      "input_cost_per_token": 6.7e-7,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "max_tokens": 131000,
      "mode": "chat",
      "output_cost_per_token": 6.7e-7,
      "source": "https://endpoints.ai.cloud.ovh.net/models/deepseek-r1-distill-llama-70b",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "ovhcloud"
    },
    "slug": "deepseek-r1-distill-llama-70b",
    "displayName": "DeepSeek-R1-Distill-Llama-70B"
  },
  {
    "id": "ovhcloud/Llama-3.1-8B-Instruct",
    "name": "Llama-3.1-8B-Instruct",
    "provider": "ovhcloud",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "max_tokens": 131000,
      "mode": "chat",
      "output_cost_per_token": 1e-7,
      "source": "https://endpoints.ai.cloud.ovh.net/models/llama-3-1-8b-instruct",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "ovhcloud"
    },
    "slug": "llama-3.1-8b-instruct",
    "displayName": "Llama-3.1-8B-Instruct"
  },
  {
    "id": "ovhcloud/Meta-Llama-3_1-70B-Instruct",
    "name": "Meta-Llama-3_1-70B-Instruct",
    "provider": "ovhcloud",
    "data": {
      "input_cost_per_token": 6.7e-7,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "max_tokens": 131000,
      "mode": "chat",
      "output_cost_per_token": 6.7e-7,
      "source": "https://endpoints.ai.cloud.ovh.net/models/meta-llama-3-1-70b-instruct",
      "supports_function_calling": false,
      "supports_response_schema": false,
      "supports_tool_choice": false,
      "provider": "ovhcloud"
    },
    "slug": "meta-llama-3_1-70b-instruct",
    "displayName": "Meta-Llama-3_1-70B-Instruct"
  },
  {
    "id": "ovhcloud/Meta-Llama-3_3-70B-Instruct",
    "name": "Meta-Llama-3_3-70B-Instruct",
    "provider": "ovhcloud",
    "data": {
      "input_cost_per_token": 6.7e-7,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "max_tokens": 131000,
      "mode": "chat",
      "output_cost_per_token": 6.7e-7,
      "source": "https://endpoints.ai.cloud.ovh.net/models/meta-llama-3-3-70b-instruct",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "ovhcloud"
    },
    "slug": "meta-llama-3_3-70b-instruct",
    "displayName": "Meta-Llama-3_3-70B-Instruct"
  },
  {
    "id": "ovhcloud/Mistral-7B-Instruct-v0.3",
    "name": "Mistral-7B-Instruct-v0.3",
    "provider": "ovhcloud",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 127000,
      "max_output_tokens": 127000,
      "max_tokens": 127000,
      "mode": "chat",
      "output_cost_per_token": 1e-7,
      "source": "https://endpoints.ai.cloud.ovh.net/models/mistral-7b-instruct-v0-3",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "ovhcloud"
    },
    "slug": "mistral-7b-instruct-v0.3",
    "displayName": "Mistral-7B-Instruct-v0.3"
  },
  {
    "id": "ovhcloud/Mistral-Nemo-Instruct-2407",
    "name": "Mistral-Nemo-Instruct-2407",
    "provider": "ovhcloud",
    "data": {
      "input_cost_per_token": 1.3e-7,
      "max_input_tokens": 118000,
      "max_output_tokens": 118000,
      "max_tokens": 118000,
      "mode": "chat",
      "output_cost_per_token": 1.3e-7,
      "source": "https://endpoints.ai.cloud.ovh.net/models/mistral-nemo-instruct-2407",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "ovhcloud"
    },
    "slug": "mistral-nemo-instruct-2407",
    "displayName": "Mistral-Nemo-Instruct-2407"
  },
  {
    "id": "ovhcloud/Mistral-Small-3.2-24B-Instruct-2506",
    "name": "Mistral-Small-3.2-24B-Instruct-2506",
    "provider": "ovhcloud",
    "data": {
      "input_cost_per_token": 9e-8,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 2.8e-7,
      "source": "https://endpoints.ai.cloud.ovh.net/models/mistral-small-3-2-24b-instruct-2506",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "ovhcloud"
    },
    "slug": "mistral-small-3.2-24b-instruct-2506",
    "displayName": "Mistral-Small-3.2-24B-Instruct-2506"
  },
  {
    "id": "ovhcloud/Mixtral-8x7B-Instruct-v0.1",
    "name": "Mixtral-8x7B-Instruct-v0.1",
    "provider": "ovhcloud",
    "data": {
      "input_cost_per_token": 6.3e-7,
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 6.3e-7,
      "source": "https://endpoints.ai.cloud.ovh.net/models/mixtral-8x7b-instruct-v0-1",
      "supports_function_calling": false,
      "supports_response_schema": true,
      "supports_tool_choice": false,
      "provider": "ovhcloud"
    },
    "slug": "mixtral-8x7b-instruct-v0.1",
    "displayName": "Mixtral-8x7B-Instruct-v0.1"
  },
  {
    "id": "ovhcloud/Qwen2.5-Coder-32B-Instruct",
    "name": "Qwen2.5-Coder-32B-Instruct",
    "provider": "ovhcloud",
    "data": {
      "input_cost_per_token": 8.7e-7,
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 8.7e-7,
      "source": "https://endpoints.ai.cloud.ovh.net/models/qwen2-5-coder-32b-instruct",
      "supports_function_calling": false,
      "supports_response_schema": true,
      "supports_tool_choice": false,
      "provider": "ovhcloud"
    },
    "slug": "qwen2.5-coder-32b-instruct",
    "displayName": "Qwen2.5-Coder-32B-Instruct"
  },
  {
    "id": "ovhcloud/Qwen2.5-VL-72B-Instruct",
    "name": "Qwen2.5-VL-72B-Instruct",
    "provider": "ovhcloud",
    "data": {
      "input_cost_per_token": 9.1e-7,
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 9.1e-7,
      "source": "https://endpoints.ai.cloud.ovh.net/models/qwen2-5-vl-72b-instruct",
      "supports_function_calling": false,
      "supports_response_schema": true,
      "supports_tool_choice": false,
      "supports_vision": true,
      "provider": "ovhcloud"
    },
    "slug": "qwen2.5-vl-72b-instruct",
    "displayName": "Qwen2.5-VL-72B-Instruct"
  },
  {
    "id": "ovhcloud/Qwen3-32B",
    "name": "Qwen3-32B",
    "provider": "ovhcloud",
    "data": {
      "input_cost_per_token": 8e-8,
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 2.3e-7,
      "source": "https://endpoints.ai.cloud.ovh.net/models/qwen3-32b",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "ovhcloud"
    },
    "slug": "qwen3-32b",
    "displayName": "Qwen3-32B"
  },
  {
    "id": "ovhcloud/gpt-oss-120b",
    "name": "gpt-oss-120b",
    "provider": "ovhcloud",
    "data": {
      "input_cost_per_token": 8e-8,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "max_tokens": 131000,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "source": "https://endpoints.ai.cloud.ovh.net/models/gpt-oss-120b",
      "supports_function_calling": false,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": false,
      "provider": "ovhcloud"
    },
    "slug": "gpt-oss-120b",
    "displayName": "gpt-oss-120b"
  },
  {
    "id": "ovhcloud/gpt-oss-20b",
    "name": "gpt-oss-20b",
    "provider": "ovhcloud",
    "data": {
      "input_cost_per_token": 4e-8,
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "max_tokens": 131000,
      "mode": "chat",
      "output_cost_per_token": 1.5e-7,
      "source": "https://endpoints.ai.cloud.ovh.net/models/gpt-oss-20b",
      "supports_function_calling": false,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": false,
      "provider": "ovhcloud"
    },
    "slug": "gpt-oss-20b",
    "displayName": "gpt-oss-20b"
  },
  {
    "id": "ovhcloud/llava-v1.6-mistral-7b-hf",
    "name": "llava-v1.6-mistral-7b-hf",
    "provider": "ovhcloud",
    "data": {
      "input_cost_per_token": 2.9e-7,
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 2.9e-7,
      "source": "https://endpoints.ai.cloud.ovh.net/models/llava-next-mistral-7b",
      "supports_function_calling": false,
      "supports_response_schema": true,
      "supports_tool_choice": false,
      "supports_vision": true,
      "provider": "ovhcloud"
    },
    "slug": "llava-v1.6-mistral-7b-hf",
    "displayName": "llava-v1.6-mistral-7b-hf"
  },
  {
    "id": "ovhcloud/mamba-codestral-7B-v0.1",
    "name": "mamba-codestral-7B-v0.1",
    "provider": "ovhcloud",
    "data": {
      "input_cost_per_token": 1.9e-7,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 1.9e-7,
      "source": "https://endpoints.ai.cloud.ovh.net/models/mamba-codestral-7b-v0-1",
      "supports_function_calling": false,
      "supports_response_schema": true,
      "supports_tool_choice": false,
      "provider": "ovhcloud"
    },
    "slug": "mamba-codestral-7b-v0.1",
    "displayName": "mamba-codestral-7B-v0.1"
  },
  {
    "id": "palm/chat-bison",
    "name": "chat-bison",
    "provider": "palm",
    "data": {
      "input_cost_per_token": 1.25e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 1.25e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "palm"
    },
    "slug": "chat-bison",
    "displayName": "chat-bison"
  },
  {
    "id": "palm/chat-bison-001",
    "name": "chat-bison-001",
    "provider": "palm",
    "data": {
      "input_cost_per_token": 1.25e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 1.25e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "palm"
    },
    "slug": "chat-bison-001",
    "displayName": "chat-bison-001"
  },
  {
    "id": "palm/text-bison",
    "name": "text-bison",
    "provider": "palm",
    "data": {
      "input_cost_per_token": 1.25e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "max_tokens": 1024,
      "mode": "completion",
      "output_cost_per_token": 1.25e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "palm"
    },
    "slug": "text-bison",
    "displayName": "text-bison"
  },
  {
    "id": "palm/text-bison-001",
    "name": "text-bison-001",
    "provider": "palm",
    "data": {
      "input_cost_per_token": 1.25e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "max_tokens": 1024,
      "mode": "completion",
      "output_cost_per_token": 1.25e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "palm"
    },
    "slug": "text-bison-001",
    "displayName": "text-bison-001"
  },
  {
    "id": "palm/text-bison-safety-off",
    "name": "text-bison-safety-off",
    "provider": "palm",
    "data": {
      "input_cost_per_token": 1.25e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "max_tokens": 1024,
      "mode": "completion",
      "output_cost_per_token": 1.25e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "palm"
    },
    "slug": "text-bison-safety-off",
    "displayName": "text-bison-safety-off"
  },
  {
    "id": "palm/text-bison-safety-recitation-off",
    "name": "text-bison-safety-recitation-off",
    "provider": "palm",
    "data": {
      "input_cost_per_token": 1.25e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "max_tokens": 1024,
      "mode": "completion",
      "output_cost_per_token": 1.25e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "palm"
    },
    "slug": "text-bison-safety-recitation-off",
    "displayName": "text-bison-safety-recitation-off"
  },
  {
    "id": "perplexity/codellama-34b-instruct",
    "name": "codellama-34b-instruct",
    "provider": "perplexity",
    "data": {
      "input_cost_per_token": 3.5e-7,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.0000014,
      "provider": "perplexity"
    },
    "slug": "codellama-34b-instruct",
    "displayName": "codellama-34b-instruct"
  },
  {
    "id": "perplexity/codellama-70b-instruct",
    "name": "codellama-70b-instruct",
    "provider": "perplexity",
    "data": {
      "input_cost_per_token": 7e-7,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.0000028,
      "provider": "perplexity"
    },
    "slug": "codellama-70b-instruct",
    "displayName": "codellama-70b-instruct"
  },
  {
    "id": "perplexity/llama-2-70b-chat",
    "name": "llama-2-70b-chat",
    "provider": "perplexity",
    "data": {
      "input_cost_per_token": 7e-7,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.0000028,
      "provider": "perplexity"
    },
    "slug": "llama-2-70b-chat",
    "displayName": "llama-2-70b-chat"
  },
  {
    "id": "perplexity/llama-3.1-70b-instruct",
    "name": "llama-3.1-70b-instruct",
    "provider": "perplexity",
    "data": {
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.000001,
      "provider": "perplexity"
    },
    "slug": "llama-3.1-70b-instruct",
    "displayName": "llama-3.1-70b-instruct"
  },
  {
    "id": "perplexity/llama-3.1-8b-instruct",
    "name": "llama-3.1-8b-instruct",
    "provider": "perplexity",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 2e-7,
      "provider": "perplexity"
    },
    "slug": "llama-3.1-8b-instruct",
    "displayName": "llama-3.1-8b-instruct"
  },
  {
    "id": "perplexity/llama-3.1-sonar-huge-128k-online",
    "name": "llama-3.1-sonar-huge-128k-online",
    "provider": "perplexity",
    "data": {
      "deprecation_date": "2025-02-22",
      "input_cost_per_token": 0.000005,
      "max_input_tokens": 127072,
      "max_output_tokens": 127072,
      "max_tokens": 127072,
      "mode": "chat",
      "output_cost_per_token": 0.000005,
      "provider": "perplexity"
    },
    "slug": "llama-3.1-sonar-huge-128k-online",
    "displayName": "llama-3.1-sonar-huge-128k-online"
  },
  {
    "id": "perplexity/llama-3.1-sonar-large-128k-chat",
    "name": "llama-3.1-sonar-large-128k-chat",
    "provider": "perplexity",
    "data": {
      "deprecation_date": "2025-02-22",
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.000001,
      "provider": "perplexity"
    },
    "slug": "llama-3.1-sonar-large-128k-chat",
    "displayName": "llama-3.1-sonar-large-128k-chat"
  },
  {
    "id": "perplexity/llama-3.1-sonar-large-128k-online",
    "name": "llama-3.1-sonar-large-128k-online",
    "provider": "perplexity",
    "data": {
      "deprecation_date": "2025-02-22",
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 127072,
      "max_output_tokens": 127072,
      "max_tokens": 127072,
      "mode": "chat",
      "output_cost_per_token": 0.000001,
      "provider": "perplexity"
    },
    "slug": "llama-3.1-sonar-large-128k-online",
    "displayName": "llama-3.1-sonar-large-128k-online"
  },
  {
    "id": "perplexity/llama-3.1-sonar-small-128k-chat",
    "name": "llama-3.1-sonar-small-128k-chat",
    "provider": "perplexity",
    "data": {
      "deprecation_date": "2025-02-22",
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 2e-7,
      "provider": "perplexity"
    },
    "slug": "llama-3.1-sonar-small-128k-chat",
    "displayName": "llama-3.1-sonar-small-128k-chat"
  },
  {
    "id": "perplexity/llama-3.1-sonar-small-128k-online",
    "name": "llama-3.1-sonar-small-128k-online",
    "provider": "perplexity",
    "data": {
      "deprecation_date": "2025-02-22",
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 127072,
      "max_output_tokens": 127072,
      "max_tokens": 127072,
      "mode": "chat",
      "output_cost_per_token": 2e-7,
      "provider": "perplexity"
    },
    "slug": "llama-3.1-sonar-small-128k-online",
    "displayName": "llama-3.1-sonar-small-128k-online"
  },
  {
    "id": "perplexity/mistral-7b-instruct",
    "name": "mistral-7b-instruct",
    "provider": "perplexity",
    "data": {
      "input_cost_per_token": 7e-8,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 2.8e-7,
      "provider": "perplexity"
    },
    "slug": "mistral-7b-instruct",
    "displayName": "mistral-7b-instruct"
  },
  {
    "id": "perplexity/mixtral-8x7b-instruct",
    "name": "mixtral-8x7b-instruct",
    "provider": "perplexity",
    "data": {
      "input_cost_per_token": 7e-8,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 2.8e-7,
      "provider": "perplexity"
    },
    "slug": "mixtral-8x7b-instruct",
    "displayName": "mixtral-8x7b-instruct"
  },
  {
    "id": "perplexity/pplx-70b-chat",
    "name": "pplx-70b-chat",
    "provider": "perplexity",
    "data": {
      "input_cost_per_token": 7e-7,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.0000028,
      "provider": "perplexity"
    },
    "slug": "pplx-70b-chat",
    "displayName": "pplx-70b-chat"
  },
  {
    "id": "perplexity/pplx-70b-online",
    "name": "pplx-70b-online",
    "provider": "perplexity",
    "data": {
      "input_cost_per_request": 0.005,
      "input_cost_per_token": 0,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.0000028,
      "provider": "perplexity"
    },
    "slug": "pplx-70b-online",
    "displayName": "pplx-70b-online"
  },
  {
    "id": "perplexity/pplx-7b-chat",
    "name": "pplx-7b-chat",
    "provider": "perplexity",
    "data": {
      "input_cost_per_token": 7e-8,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 2.8e-7,
      "provider": "perplexity"
    },
    "slug": "pplx-7b-chat",
    "displayName": "pplx-7b-chat"
  },
  {
    "id": "perplexity/pplx-7b-online",
    "name": "pplx-7b-online",
    "provider": "perplexity",
    "data": {
      "input_cost_per_request": 0.005,
      "input_cost_per_token": 0,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 2.8e-7,
      "provider": "perplexity"
    },
    "slug": "pplx-7b-online",
    "displayName": "pplx-7b-online"
  },
  {
    "id": "perplexity/sonar",
    "name": "sonar",
    "provider": "perplexity",
    "data": {
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000001,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.012,
        "search_context_size_low": 0.005,
        "search_context_size_medium": 0.008
      },
      "supports_web_search": true,
      "provider": "perplexity"
    },
    "slug": "sonar",
    "displayName": "sonar"
  },
  {
    "id": "perplexity/sonar-deep-research",
    "name": "sonar-deep-research",
    "provider": "perplexity",
    "data": {
      "citation_cost_per_token": 0.000002,
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_reasoning_token": 0.000003,
      "output_cost_per_token": 0.000008,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.005,
        "search_context_size_low": 0.005,
        "search_context_size_medium": 0.005
      },
      "supports_reasoning": true,
      "supports_web_search": true,
      "provider": "perplexity"
    },
    "slug": "sonar-deep-research",
    "displayName": "sonar-deep-research"
  },
  {
    "id": "perplexity/sonar-medium-chat",
    "name": "sonar-medium-chat",
    "provider": "perplexity",
    "data": {
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.0000018,
      "provider": "perplexity"
    },
    "slug": "sonar-medium-chat",
    "displayName": "sonar-medium-chat"
  },
  {
    "id": "perplexity/sonar-medium-online",
    "name": "sonar-medium-online",
    "provider": "perplexity",
    "data": {
      "input_cost_per_request": 0.005,
      "input_cost_per_token": 0,
      "max_input_tokens": 12000,
      "max_output_tokens": 12000,
      "max_tokens": 12000,
      "mode": "chat",
      "output_cost_per_token": 0.0000018,
      "provider": "perplexity"
    },
    "slug": "sonar-medium-online",
    "displayName": "sonar-medium-online"
  },
  {
    "id": "perplexity/sonar-pro",
    "name": "sonar-pro",
    "provider": "perplexity",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 8000,
      "max_tokens": 8000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.014,
        "search_context_size_low": 0.006,
        "search_context_size_medium": 0.01
      },
      "supports_web_search": true,
      "provider": "perplexity"
    },
    "slug": "sonar-pro",
    "displayName": "sonar-pro"
  },
  {
    "id": "perplexity/sonar-reasoning",
    "name": "sonar-reasoning",
    "provider": "perplexity",
    "data": {
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000005,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.014,
        "search_context_size_low": 0.005,
        "search_context_size_medium": 0.008
      },
      "supports_reasoning": true,
      "supports_web_search": true,
      "provider": "perplexity"
    },
    "slug": "sonar-reasoning",
    "displayName": "sonar-reasoning"
  },
  {
    "id": "perplexity/sonar-reasoning-pro",
    "name": "sonar-reasoning-pro",
    "provider": "perplexity",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000008,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.014,
        "search_context_size_low": 0.006,
        "search_context_size_medium": 0.01
      },
      "supports_reasoning": true,
      "supports_web_search": true,
      "provider": "perplexity"
    },
    "slug": "sonar-reasoning-pro",
    "displayName": "sonar-reasoning-pro"
  },
  {
    "id": "perplexity/sonar-small-chat",
    "name": "sonar-small-chat",
    "provider": "perplexity",
    "data": {
      "input_cost_per_token": 7e-8,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 2.8e-7,
      "provider": "perplexity"
    },
    "slug": "sonar-small-chat",
    "displayName": "sonar-small-chat"
  },
  {
    "id": "perplexity/sonar-small-online",
    "name": "sonar-small-online",
    "provider": "perplexity",
    "data": {
      "input_cost_per_request": 0.005,
      "input_cost_per_token": 0,
      "max_input_tokens": 12000,
      "max_output_tokens": 12000,
      "max_tokens": 12000,
      "mode": "chat",
      "output_cost_per_token": 2.8e-7,
      "provider": "perplexity"
    },
    "slug": "sonar-small-online",
    "displayName": "sonar-small-online"
  },
  {
    "id": "qwen.qwen3-coder-480b-a35b-v1:0",
    "name": "qwen.qwen3-coder-480b-a35b-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 2.2e-7,
      "max_input_tokens": 262000,
      "max_output_tokens": 65536,
      "max_tokens": 65536,
      "mode": "chat",
      "output_cost_per_token": 0.0000018,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "bedrock_converse"
    },
    "slug": "qwen.qwen3-coder-480b-a35b-v1-0",
    "displayName": "qwen.qwen3-coder-480b-a35b-v1:0"
  },
  {
    "id": "qwen.qwen3-235b-a22b-2507-v1:0",
    "name": "qwen.qwen3-235b-a22b-2507-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 2.2e-7,
      "max_input_tokens": 262144,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 8.8e-7,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "bedrock_converse"
    },
    "slug": "qwen.qwen3-235b-a22b-2507-v1-0",
    "displayName": "qwen.qwen3-235b-a22b-2507-v1:0"
  },
  {
    "id": "qwen.qwen3-coder-30b-a3b-v1:0",
    "name": "qwen.qwen3-coder-30b-a3b-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 262144,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "bedrock_converse"
    },
    "slug": "qwen.qwen3-coder-30b-a3b-v1-0",
    "displayName": "qwen.qwen3-coder-30b-a3b-v1:0"
  },
  {
    "id": "qwen.qwen3-32b-v1:0",
    "name": "qwen.qwen3-32b-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "bedrock_converse"
    },
    "slug": "qwen.qwen3-32b-v1-0",
    "displayName": "qwen.qwen3-32b-v1:0"
  },
  {
    "id": "qwen.qwen3-next-80b-a3b",
    "name": "qwen.qwen3-next-80b-a3b",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.0000012,
      "supports_function_calling": true,
      "supports_system_messages": true,
      "provider": "bedrock_converse"
    },
    "slug": "qwen.qwen3-next-80b-a3b",
    "displayName": "qwen.qwen3-next-80b-a3b"
  },
  {
    "id": "qwen.qwen3-vl-235b-a22b",
    "name": "qwen.qwen3-vl-235b-a22b",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 5.3e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.00000266,
      "supports_function_calling": true,
      "supports_system_messages": true,
      "supports_vision": true,
      "provider": "bedrock_converse"
    },
    "slug": "qwen.qwen3-vl-235b-a22b",
    "displayName": "qwen.qwen3-vl-235b-a22b"
  },
  {
    "id": "replicate/meta/llama-2-13b",
    "name": "llama-2-13b",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 5e-7,
      "supports_tool_choice": true,
      "provider": "replicate"
    },
    "slug": "llama-2-13b",
    "displayName": "llama-2-13b"
  },
  {
    "id": "replicate/meta/llama-2-13b-chat",
    "name": "llama-2-13b-chat",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 5e-7,
      "supports_tool_choice": true,
      "provider": "replicate"
    },
    "slug": "llama-2-13b-chat",
    "displayName": "llama-2-13b-chat"
  },
  {
    "id": "replicate/meta/llama-2-70b",
    "name": "llama-2-70b",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 6.5e-7,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00000275,
      "supports_tool_choice": true,
      "provider": "replicate"
    },
    "slug": "llama-2-70b",
    "displayName": "llama-2-70b"
  },
  {
    "id": "replicate/meta/llama-2-70b-chat",
    "name": "llama-2-70b-chat",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 6.5e-7,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00000275,
      "supports_tool_choice": true,
      "provider": "replicate"
    },
    "slug": "llama-2-70b-chat",
    "displayName": "llama-2-70b-chat"
  },
  {
    "id": "replicate/meta/llama-2-7b",
    "name": "llama-2-7b",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 5e-8,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 2.5e-7,
      "supports_tool_choice": true,
      "provider": "replicate"
    },
    "slug": "llama-2-7b",
    "displayName": "llama-2-7b"
  },
  {
    "id": "replicate/meta/llama-2-7b-chat",
    "name": "llama-2-7b-chat",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 5e-8,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 2.5e-7,
      "supports_tool_choice": true,
      "provider": "replicate"
    },
    "slug": "llama-2-7b-chat",
    "displayName": "llama-2-7b-chat"
  },
  {
    "id": "replicate/meta/llama-3-70b",
    "name": "llama-3-70b",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 6.5e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.00000275,
      "supports_tool_choice": true,
      "provider": "replicate"
    },
    "slug": "llama-3-70b",
    "displayName": "llama-3-70b"
  },
  {
    "id": "replicate/meta/llama-3-70b-instruct",
    "name": "llama-3-70b-instruct",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 6.5e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.00000275,
      "supports_tool_choice": true,
      "provider": "replicate"
    },
    "slug": "llama-3-70b-instruct",
    "displayName": "llama-3-70b-instruct"
  },
  {
    "id": "replicate/meta/llama-3-8b",
    "name": "llama-3-8b",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 5e-8,
      "max_input_tokens": 8086,
      "max_output_tokens": 8086,
      "max_tokens": 8086,
      "mode": "chat",
      "output_cost_per_token": 2.5e-7,
      "supports_tool_choice": true,
      "provider": "replicate"
    },
    "slug": "llama-3-8b",
    "displayName": "llama-3-8b"
  },
  {
    "id": "replicate/meta/llama-3-8b-instruct",
    "name": "llama-3-8b-instruct",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 5e-8,
      "max_input_tokens": 8086,
      "max_output_tokens": 8086,
      "max_tokens": 8086,
      "mode": "chat",
      "output_cost_per_token": 2.5e-7,
      "supports_tool_choice": true,
      "provider": "replicate"
    },
    "slug": "llama-3-8b-instruct",
    "displayName": "llama-3-8b-instruct"
  },
  {
    "id": "replicate/mistralai/mistral-7b-instruct-v0.2",
    "name": "mistral-7b-instruct-v0.2",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 5e-8,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 2.5e-7,
      "supports_tool_choice": true,
      "provider": "replicate"
    },
    "slug": "mistral-7b-instruct-v0.2",
    "displayName": "mistral-7b-instruct-v0.2"
  },
  {
    "id": "replicate/mistralai/mistral-7b-v0.1",
    "name": "mistral-7b-v0.1",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 5e-8,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 2.5e-7,
      "supports_tool_choice": true,
      "provider": "replicate"
    },
    "slug": "mistral-7b-v0.1",
    "displayName": "mistral-7b-v0.1"
  },
  {
    "id": "replicate/mistralai/mixtral-8x7b-instruct-v0.1",
    "name": "mixtral-8x7b-instruct-v0.1",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000001,
      "supports_tool_choice": true,
      "provider": "replicate"
    },
    "slug": "mixtral-8x7b-instruct-v0.1",
    "displayName": "mixtral-8x7b-instruct-v0.1"
  },
  {
    "id": "replicate/openai/gpt-5",
    "name": "gpt-5",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 0.00000125,
      "output_cost_per_token": 0.00001,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "replicate"
    },
    "slug": "gpt-5",
    "displayName": "gpt-5"
  },
  {
    "id": "replicateopenai/gpt-oss-20b",
    "name": "gpt-oss-20b",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 9e-8,
      "output_cost_per_token": 3.6e-7,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_system_messages": true,
      "provider": "replicate"
    },
    "slug": "gpt-oss-20b",
    "displayName": "gpt-oss-20b"
  },
  {
    "id": "replicate/anthropic/claude-4.5-haiku",
    "name": "claude-4.5-haiku",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000005,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "supports_prompt_caching": true,
      "provider": "replicate"
    },
    "slug": "claude-4.5-haiku",
    "displayName": "claude-4.5-haiku"
  },
  {
    "id": "replicate/ibm-granite/granite-3.3-8b-instruct",
    "name": "granite-3.3-8b-instruct",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 3e-8,
      "output_cost_per_token": 2.5e-7,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_system_messages": true,
      "provider": "replicate"
    },
    "slug": "granite-3.3-8b-instruct",
    "displayName": "granite-3.3-8b-instruct"
  },
  {
    "id": "replicate/openai/gpt-4o",
    "name": "gpt-4o",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 0.0000025,
      "output_cost_per_token": 0.00001,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "supports_audio_input": true,
      "supports_audio_output": true,
      "provider": "replicate"
    },
    "slug": "gpt-4o",
    "displayName": "gpt-4o"
  },
  {
    "id": "replicate/openai/o4-mini",
    "name": "o4-mini",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000004,
      "output_cost_per_reasoning_token": 0.000004,
      "mode": "chat",
      "supports_reasoning": true,
      "supports_system_messages": true,
      "provider": "replicate"
    },
    "slug": "o4-mini",
    "displayName": "o4-mini"
  },
  {
    "id": "replicate/openai/o1-mini",
    "name": "o1-mini",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 0.0000011,
      "output_cost_per_token": 0.0000044,
      "output_cost_per_reasoning_token": 0.0000044,
      "mode": "chat",
      "supports_reasoning": true,
      "supports_system_messages": true,
      "provider": "replicate"
    },
    "slug": "o1-mini",
    "displayName": "o1-mini"
  },
  {
    "id": "replicate/openai/o1",
    "name": "o1",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.00006,
      "output_cost_per_reasoning_token": 0.00006,
      "mode": "chat",
      "supports_reasoning": true,
      "supports_system_messages": true,
      "provider": "replicate"
    },
    "slug": "o1",
    "displayName": "o1"
  },
  {
    "id": "replicate/openai/gpt-4o-mini",
    "name": "gpt-4o-mini",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "output_cost_per_token": 6e-7,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "replicate"
    },
    "slug": "gpt-4o-mini",
    "displayName": "gpt-4o-mini"
  },
  {
    "id": "replicate/qwen/qwen3-235b-a22b-instruct-2507",
    "name": "qwen3-235b-a22b-instruct-2507",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 2.64e-7,
      "output_cost_per_token": 0.00000106,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_system_messages": true,
      "provider": "replicate"
    },
    "slug": "qwen3-235b-a22b-instruct-2507",
    "displayName": "qwen3-235b-a22b-instruct-2507"
  },
  {
    "id": "replicate/anthropic/claude-4-sonnet",
    "name": "claude-4-sonnet",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "supports_prompt_caching": true,
      "provider": "replicate"
    },
    "slug": "claude-4-sonnet",
    "displayName": "claude-4-sonnet"
  },
  {
    "id": "replicate/deepseek-ai/deepseek-v3",
    "name": "deepseek-v3",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 0.00000145,
      "output_cost_per_token": 0.00000145,
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "supports_function_calling": true,
      "supports_system_messages": true,
      "provider": "replicate"
    },
    "slug": "deepseek-v3",
    "displayName": "deepseek-v3"
  },
  {
    "id": "replicate/anthropic/claude-3.7-sonnet",
    "name": "claude-3.7-sonnet",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "supports_prompt_caching": true,
      "provider": "replicate"
    },
    "slug": "claude-3.7-sonnet",
    "displayName": "claude-3.7-sonnet"
  },
  {
    "id": "replicate/anthropic/claude-3.5-haiku",
    "name": "claude-3.5-haiku",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000005,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "supports_prompt_caching": true,
      "provider": "replicate"
    },
    "slug": "claude-3.5-haiku",
    "displayName": "claude-3.5-haiku"
  },
  {
    "id": "replicate/anthropic/claude-3.5-sonnet",
    "name": "claude-3.5-sonnet",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 0.00000375,
      "output_cost_per_token": 0.00001875,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "supports_prompt_caching": true,
      "provider": "replicate"
    },
    "slug": "claude-3.5-sonnet",
    "displayName": "claude-3.5-sonnet"
  },
  {
    "id": "replicate/google/gemini-3-pro",
    "name": "gemini-3-pro",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 0.000002,
      "output_cost_per_token": 0.000012,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "replicate"
    },
    "slug": "gemini-3-pro",
    "displayName": "gemini-3-pro"
  },
  {
    "id": "replicate/anthropic/claude-4.5-sonnet",
    "name": "claude-4.5-sonnet",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "supports_prompt_caching": true,
      "provider": "replicate"
    },
    "slug": "claude-4.5-sonnet",
    "displayName": "claude-4.5-sonnet"
  },
  {
    "id": "replicate/openai/gpt-4.1",
    "name": "gpt-4.1",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 0.000002,
      "output_cost_per_token": 0.000008,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "replicate"
    },
    "slug": "gpt-4.1",
    "displayName": "gpt-4.1"
  },
  {
    "id": "replicate/openai/gpt-4.1-nano",
    "name": "gpt-4.1-nano",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 4e-7,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_system_messages": true,
      "provider": "replicate"
    },
    "slug": "gpt-4.1-nano",
    "displayName": "gpt-4.1-nano"
  },
  {
    "id": "replicate/openai/gpt-4.1-mini",
    "name": "gpt-4.1-mini",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 4e-7,
      "output_cost_per_token": 0.0000016,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "replicate"
    },
    "slug": "gpt-4.1-mini",
    "displayName": "gpt-4.1-mini"
  },
  {
    "id": "replicate/openai/gpt-5-nano",
    "name": "gpt-5-nano",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 5e-8,
      "output_cost_per_token": 4e-7,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_system_messages": true,
      "provider": "replicate"
    },
    "slug": "gpt-5-nano",
    "displayName": "gpt-5-nano"
  },
  {
    "id": "replicate/openai/gpt-5-mini",
    "name": "gpt-5-mini",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 2.5e-7,
      "output_cost_per_token": 0.000002,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "replicate"
    },
    "slug": "gpt-5-mini",
    "displayName": "gpt-5-mini"
  },
  {
    "id": "replicate/google/gemini-2.5-flash",
    "name": "gemini-2.5-flash",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 0.0000025,
      "output_cost_per_token": 0.0000025,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "replicate"
    },
    "slug": "gemini-2.5-flash",
    "displayName": "gemini-2.5-flash"
  },
  {
    "id": "replicate/openai/gpt-oss-120b",
    "name": "gpt-oss-120b",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 1.8e-7,
      "output_cost_per_token": 7.2e-7,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_system_messages": true,
      "provider": "replicate"
    },
    "slug": "gpt-oss-120b",
    "displayName": "gpt-oss-120b"
  },
  {
    "id": "replicate/deepseek-ai/deepseek-v3.1",
    "name": "deepseek-v3.1",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 6.72e-7,
      "output_cost_per_token": 0.000002016,
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "max_tokens": 163840,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_system_messages": true,
      "provider": "replicate"
    },
    "slug": "deepseek-v3.1",
    "displayName": "deepseek-v3.1"
  },
  {
    "id": "replicate/xai/grok-4",
    "name": "grok-4",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 0.0000072,
      "output_cost_per_token": 0.000036,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_system_messages": true,
      "provider": "replicate"
    },
    "slug": "grok-4",
    "displayName": "grok-4"
  },
  {
    "id": "replicate/deepseek-ai/deepseek-r1",
    "name": "deepseek-r1",
    "provider": "replicate",
    "data": {
      "input_cost_per_token": 0.00000375,
      "output_cost_per_token": 0.00001,
      "output_cost_per_reasoning_token": 0.00001,
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "supports_reasoning": true,
      "supports_system_messages": true,
      "provider": "replicate"
    },
    "slug": "deepseek-r1",
    "displayName": "deepseek-r1"
  },
  {
    "id": "sambanova/DeepSeek-R1",
    "name": "DeepSeek-R1",
    "provider": "sambanova",
    "data": {
      "input_cost_per_token": 0.000005,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.000007,
      "source": "https://cloud.sambanova.ai/plans/pricing",
      "provider": "sambanova"
    },
    "slug": "deepseek-r1",
    "displayName": "DeepSeek-R1"
  },
  {
    "id": "sambanova/DeepSeek-R1-Distill-Llama-70B",
    "name": "DeepSeek-R1-Distill-Llama-70B",
    "provider": "sambanova",
    "data": {
      "input_cost_per_token": 7e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.0000014,
      "source": "https://cloud.sambanova.ai/plans/pricing",
      "provider": "sambanova"
    },
    "slug": "deepseek-r1-distill-llama-70b",
    "displayName": "DeepSeek-R1-Distill-Llama-70B"
  },
  {
    "id": "sambanova/DeepSeek-V3-0324",
    "name": "DeepSeek-V3-0324",
    "provider": "sambanova",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.0000045,
      "source": "https://cloud.sambanova.ai/plans/pricing",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "sambanova"
    },
    "slug": "deepseek-v3-0324",
    "displayName": "DeepSeek-V3-0324"
  },
  {
    "id": "sambanova/Llama-4-Maverick-17B-128E-Instruct",
    "name": "Llama-4-Maverick-17B-128E-Instruct",
    "provider": "sambanova",
    "data": {
      "input_cost_per_token": 6.3e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "metadata": {
        "notes": "For vision models, images are converted to 6432 input tokens and are billed at that amount"
      },
      "mode": "chat",
      "output_cost_per_token": 0.0000018,
      "source": "https://cloud.sambanova.ai/plans/pricing",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "sambanova"
    },
    "slug": "llama-4-maverick-17b-128e-instruct",
    "displayName": "Llama-4-Maverick-17B-128E-Instruct"
  },
  {
    "id": "sambanova/Llama-4-Scout-17B-16E-Instruct",
    "name": "Llama-4-Scout-17B-16E-Instruct",
    "provider": "sambanova",
    "data": {
      "input_cost_per_token": 4e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "metadata": {
        "notes": "For vision models, images are converted to 6432 input tokens and are billed at that amount"
      },
      "mode": "chat",
      "output_cost_per_token": 7e-7,
      "source": "https://cloud.sambanova.ai/plans/pricing",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "sambanova"
    },
    "slug": "llama-4-scout-17b-16e-instruct",
    "displayName": "Llama-4-Scout-17B-16E-Instruct"
  },
  {
    "id": "sambanova/Meta-Llama-3.1-405B-Instruct",
    "name": "Meta-Llama-3.1-405B-Instruct",
    "provider": "sambanova",
    "data": {
      "input_cost_per_token": 0.000005,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "source": "https://cloud.sambanova.ai/plans/pricing",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "sambanova"
    },
    "slug": "meta-llama-3.1-405b-instruct",
    "displayName": "Meta-Llama-3.1-405B-Instruct"
  },
  {
    "id": "sambanova/Meta-Llama-3.1-8B-Instruct",
    "name": "Meta-Llama-3.1-8B-Instruct",
    "provider": "sambanova",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 2e-7,
      "source": "https://cloud.sambanova.ai/plans/pricing",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "sambanova"
    },
    "slug": "meta-llama-3.1-8b-instruct",
    "displayName": "Meta-Llama-3.1-8B-Instruct"
  },
  {
    "id": "sambanova/Meta-Llama-3.2-1B-Instruct",
    "name": "Meta-Llama-3.2-1B-Instruct",
    "provider": "sambanova",
    "data": {
      "input_cost_per_token": 4e-8,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 8e-8,
      "source": "https://cloud.sambanova.ai/plans/pricing",
      "provider": "sambanova"
    },
    "slug": "meta-llama-3.2-1b-instruct",
    "displayName": "Meta-Llama-3.2-1B-Instruct"
  },
  {
    "id": "sambanova/Meta-Llama-3.2-3B-Instruct",
    "name": "Meta-Llama-3.2-3B-Instruct",
    "provider": "sambanova",
    "data": {
      "input_cost_per_token": 8e-8,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 1.6e-7,
      "source": "https://cloud.sambanova.ai/plans/pricing",
      "provider": "sambanova"
    },
    "slug": "meta-llama-3.2-3b-instruct",
    "displayName": "Meta-Llama-3.2-3B-Instruct"
  },
  {
    "id": "sambanova/Meta-Llama-3.3-70B-Instruct",
    "name": "Meta-Llama-3.3-70B-Instruct",
    "provider": "sambanova",
    "data": {
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.0000012,
      "source": "https://cloud.sambanova.ai/plans/pricing",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "sambanova"
    },
    "slug": "meta-llama-3.3-70b-instruct",
    "displayName": "Meta-Llama-3.3-70B-Instruct"
  },
  {
    "id": "sambanova/Meta-Llama-Guard-3-8B",
    "name": "Meta-Llama-Guard-3-8B",
    "provider": "sambanova",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "source": "https://cloud.sambanova.ai/plans/pricing",
      "provider": "sambanova"
    },
    "slug": "meta-llama-guard-3-8b",
    "displayName": "Meta-Llama-Guard-3-8B"
  },
  {
    "id": "sambanova/QwQ-32B",
    "name": "QwQ-32B",
    "provider": "sambanova",
    "data": {
      "input_cost_per_token": 5e-7,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.000001,
      "source": "https://cloud.sambanova.ai/plans/pricing",
      "provider": "sambanova"
    },
    "slug": "qwq-32b",
    "displayName": "QwQ-32B"
  },
  {
    "id": "sambanova/Qwen2-Audio-7B-Instruct",
    "name": "Qwen2-Audio-7B-Instruct",
    "provider": "sambanova",
    "data": {
      "input_cost_per_token": 5e-7,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.0001,
      "source": "https://cloud.sambanova.ai/plans/pricing",
      "supports_audio_input": true,
      "provider": "sambanova"
    },
    "slug": "qwen2-audio-7b-instruct",
    "displayName": "Qwen2-Audio-7B-Instruct"
  },
  {
    "id": "sambanova/Qwen3-32B",
    "name": "Qwen3-32B",
    "provider": "sambanova",
    "data": {
      "input_cost_per_token": 4e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 8e-7,
      "source": "https://cloud.sambanova.ai/plans/pricing",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "sambanova"
    },
    "slug": "qwen3-32b",
    "displayName": "Qwen3-32B"
  },
  {
    "id": "sambanova/DeepSeek-V3.1",
    "name": "DeepSeek-V3.1",
    "provider": "sambanova",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.0000045,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_reasoning": true,
      "source": "https://cloud.sambanova.ai/plans/pricing",
      "provider": "sambanova"
    },
    "slug": "deepseek-v3.1",
    "displayName": "DeepSeek-V3.1"
  },
  {
    "id": "sambanova/gpt-oss-120b",
    "name": "gpt-oss-120b",
    "provider": "sambanova",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.0000045,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_reasoning": true,
      "source": "https://cloud.sambanova.ai/plans/pricing",
      "provider": "sambanova"
    },
    "slug": "gpt-oss-120b",
    "displayName": "gpt-oss-120b"
  },
  {
    "id": "text-bison32k",
    "name": "text-bison32k",
    "provider": "vertex_ai-text-models",
    "data": {
      "input_cost_per_character": 2.5e-7,
      "input_cost_per_token": 1.25e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "max_tokens": 1024,
      "mode": "completion",
      "output_cost_per_character": 5e-7,
      "output_cost_per_token": 1.25e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-text-models"
    },
    "slug": "text-bison32k",
    "displayName": "text-bison32k"
  },
  {
    "id": "text-bison32k@002",
    "name": "text-bison32k@002",
    "provider": "vertex_ai-text-models",
    "data": {
      "input_cost_per_character": 2.5e-7,
      "input_cost_per_token": 1.25e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "max_tokens": 1024,
      "mode": "completion",
      "output_cost_per_character": 5e-7,
      "output_cost_per_token": 1.25e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-text-models"
    },
    "slug": "text-bison32k-002",
    "displayName": "text-bison32k@002"
  },
  {
    "id": "text-embedding-004",
    "name": "text-embedding-004",
    "provider": "vertex_ai-embedding-models",
    "data": {
      "deprecation_date": "2026-01-14",
      "input_cost_per_character": 2.5e-8,
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 2048,
      "max_tokens": 2048,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_vector_size": 768,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models",
      "provider": "vertex_ai-embedding-models"
    },
    "slug": "text-embedding-004",
    "displayName": "text-embedding-004"
  },
  {
    "id": "text-embedding-005",
    "name": "text-embedding-005",
    "provider": "vertex_ai-embedding-models",
    "data": {
      "input_cost_per_character": 2.5e-8,
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 2048,
      "max_tokens": 2048,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_vector_size": 768,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models",
      "provider": "vertex_ai-embedding-models"
    },
    "slug": "text-embedding-005",
    "displayName": "text-embedding-005"
  },
  {
    "id": "text-embedding-3-large",
    "name": "text-embedding-3-large",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 1.3e-7,
      "input_cost_per_token_batches": 6.5e-8,
      "max_input_tokens": 8191,
      "max_tokens": 8191,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_cost_per_token_batches": 0,
      "output_vector_size": 3072,
      "provider": "openai"
    },
    "slug": "text-embedding-3-large",
    "displayName": "text-embedding-3-large"
  },
  {
    "id": "text-embedding-3-small",
    "name": "text-embedding-3-small",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 2e-8,
      "input_cost_per_token_batches": 1e-8,
      "max_input_tokens": 8191,
      "max_tokens": 8191,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_cost_per_token_batches": 0,
      "output_vector_size": 1536,
      "provider": "openai"
    },
    "slug": "text-embedding-3-small",
    "displayName": "text-embedding-3-small"
  },
  {
    "id": "text-embedding-ada-002",
    "name": "text-embedding-ada-002",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 8191,
      "max_tokens": 8191,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_vector_size": 1536,
      "provider": "openai"
    },
    "slug": "text-embedding-ada-002",
    "displayName": "text-embedding-ada-002"
  },
  {
    "id": "text-embedding-ada-002-v2",
    "name": "text-embedding-ada-002-v2",
    "provider": "openai",
    "data": {
      "input_cost_per_token": 1e-7,
      "input_cost_per_token_batches": 5e-8,
      "max_input_tokens": 8191,
      "max_tokens": 8191,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_cost_per_token_batches": 0,
      "provider": "openai"
    },
    "slug": "text-embedding-ada-002-v2",
    "displayName": "text-embedding-ada-002-v2"
  },
  {
    "id": "text-embedding-large-exp-03-07",
    "name": "text-embedding-large-exp-03-07",
    "provider": "vertex_ai-embedding-models",
    "data": {
      "input_cost_per_character": 2.5e-8,
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 8192,
      "max_tokens": 8192,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_vector_size": 3072,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models",
      "provider": "vertex_ai-embedding-models"
    },
    "slug": "text-embedding-large-exp-03-07",
    "displayName": "text-embedding-large-exp-03-07"
  },
  {
    "id": "text-multilingual-embedding-002",
    "name": "text-multilingual-embedding-002",
    "provider": "vertex_ai-embedding-models",
    "data": {
      "input_cost_per_character": 2.5e-8,
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 2048,
      "max_tokens": 2048,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_vector_size": 768,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models",
      "provider": "vertex_ai-embedding-models"
    },
    "slug": "text-multilingual-embedding-002",
    "displayName": "text-multilingual-embedding-002"
  },
  {
    "id": "text-unicorn",
    "name": "text-unicorn",
    "provider": "vertex_ai-text-models",
    "data": {
      "input_cost_per_token": 0.00001,
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "max_tokens": 1024,
      "mode": "completion",
      "output_cost_per_token": 0.000028,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-text-models"
    },
    "slug": "text-unicorn",
    "displayName": "text-unicorn"
  },
  {
    "id": "text-unicorn@001",
    "name": "text-unicorn@001",
    "provider": "vertex_ai-text-models",
    "data": {
      "input_cost_per_token": 0.00001,
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "max_tokens": 1024,
      "mode": "completion",
      "output_cost_per_token": 0.000028,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-text-models"
    },
    "slug": "text-unicorn-001",
    "displayName": "text-unicorn@001"
  },
  {
    "id": "textembedding-gecko",
    "name": "textembedding-gecko",
    "provider": "vertex_ai-embedding-models",
    "data": {
      "input_cost_per_character": 2.5e-8,
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 3072,
      "max_tokens": 3072,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_vector_size": 768,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-embedding-models"
    },
    "slug": "textembedding-gecko",
    "displayName": "textembedding-gecko"
  },
  {
    "id": "textembedding-gecko-multilingual",
    "name": "textembedding-gecko-multilingual",
    "provider": "vertex_ai-embedding-models",
    "data": {
      "input_cost_per_character": 2.5e-8,
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 3072,
      "max_tokens": 3072,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_vector_size": 768,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-embedding-models"
    },
    "slug": "textembedding-gecko-multilingual",
    "displayName": "textembedding-gecko-multilingual"
  },
  {
    "id": "textembedding-gecko-multilingual@001",
    "name": "textembedding-gecko-multilingual@001",
    "provider": "vertex_ai-embedding-models",
    "data": {
      "input_cost_per_character": 2.5e-8,
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 3072,
      "max_tokens": 3072,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_vector_size": 768,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-embedding-models"
    },
    "slug": "textembedding-gecko-multilingual-001",
    "displayName": "textembedding-gecko-multilingual@001"
  },
  {
    "id": "textembedding-gecko@001",
    "name": "textembedding-gecko@001",
    "provider": "vertex_ai-embedding-models",
    "data": {
      "input_cost_per_character": 2.5e-8,
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 3072,
      "max_tokens": 3072,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_vector_size": 768,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-embedding-models"
    },
    "slug": "textembedding-gecko-001",
    "displayName": "textembedding-gecko@001"
  },
  {
    "id": "textembedding-gecko@003",
    "name": "textembedding-gecko@003",
    "provider": "vertex_ai-embedding-models",
    "data": {
      "input_cost_per_character": 2.5e-8,
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 3072,
      "max_tokens": 3072,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "output_vector_size": 768,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-embedding-models"
    },
    "slug": "textembedding-gecko-003",
    "displayName": "textembedding-gecko@003"
  },
  {
    "id": "together-ai-21.1b-41b",
    "name": "together-ai-21.1b-41b",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 8e-7,
      "mode": "chat",
      "output_cost_per_token": 8e-7,
      "provider": "together_ai"
    },
    "slug": "together-ai-21.1b-41b",
    "displayName": "together-ai-21.1b-41b"
  },
  {
    "id": "together-ai-4.1b-8b",
    "name": "together-ai-4.1b-8b",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 2e-7,
      "mode": "chat",
      "output_cost_per_token": 2e-7,
      "provider": "together_ai"
    },
    "slug": "together-ai-4.1b-8b",
    "displayName": "together-ai-4.1b-8b"
  },
  {
    "id": "together-ai-41.1b-80b",
    "name": "together-ai-41.1b-80b",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 9e-7,
      "mode": "chat",
      "output_cost_per_token": 9e-7,
      "provider": "together_ai"
    },
    "slug": "together-ai-41.1b-80b",
    "displayName": "together-ai-41.1b-80b"
  },
  {
    "id": "together-ai-8.1b-21b",
    "name": "together-ai-8.1b-21b",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_tokens": 1000,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "provider": "together_ai"
    },
    "slug": "together-ai-8.1b-21b",
    "displayName": "together-ai-8.1b-21b"
  },
  {
    "id": "together-ai-81.1b-110b",
    "name": "together-ai-81.1b-110b",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 0.0000018,
      "mode": "chat",
      "output_cost_per_token": 0.0000018,
      "provider": "together_ai"
    },
    "slug": "together-ai-81.1b-110b",
    "displayName": "together-ai-81.1b-110b"
  },
  {
    "id": "together-ai-embedding-151m-to-350m",
    "name": "together-ai-embedding-151m-to-350m",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 1.6e-8,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "provider": "together_ai"
    },
    "slug": "together-ai-embedding-151m-to-350m",
    "displayName": "together-ai-embedding-151m-to-350m"
  },
  {
    "id": "together-ai-up-to-4b",
    "name": "together-ai-up-to-4b",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 1e-7,
      "mode": "chat",
      "output_cost_per_token": 1e-7,
      "provider": "together_ai"
    },
    "slug": "together-ai-up-to-4b",
    "displayName": "together-ai-up-to-4b"
  },
  {
    "id": "together_ai/Qwen/Qwen3-235B-A22B-Instruct-2507-tput",
    "name": "Qwen3-235B-A22B-Instruct-2507-tput",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 262000,
      "mode": "chat",
      "output_cost_per_token": 0.000006,
      "source": "https://www.together.ai/models/qwen3-235b-a22b-instruct-2507-fp8",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "together_ai"
    },
    "slug": "qwen3-235b-a22b-instruct-2507-tput",
    "displayName": "Qwen3-235B-A22B-Instruct-2507-tput"
  },
  {
    "id": "together_ai/Qwen/Qwen3-235B-A22B-Thinking-2507",
    "name": "Qwen3-235B-A22B-Thinking-2507",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 6.5e-7,
      "max_input_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 0.000003,
      "source": "https://www.together.ai/models/qwen3-235b-a22b-thinking-2507",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "together_ai"
    },
    "slug": "qwen3-235b-a22b-thinking-2507",
    "displayName": "Qwen3-235B-A22B-Thinking-2507"
  },
  {
    "id": "together_ai/Qwen/Qwen3-235B-A22B-fp8-tput",
    "name": "Qwen3-235B-A22B-fp8-tput",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 40000,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "source": "https://www.together.ai/models/qwen3-235b-a22b-fp8-tput",
      "supports_function_calling": false,
      "supports_parallel_function_calling": false,
      "supports_tool_choice": false,
      "provider": "together_ai"
    },
    "slug": "qwen3-235b-a22b-fp8-tput",
    "displayName": "Qwen3-235B-A22B-fp8-tput"
  },
  {
    "id": "together_ai/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
    "name": "Qwen3-Coder-480B-A35B-Instruct-FP8",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "source": "https://www.together.ai/models/qwen3-coder-480b-a35b-instruct",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "together_ai"
    },
    "slug": "qwen3-coder-480b-a35b-instruct-fp8",
    "displayName": "Qwen3-Coder-480B-A35B-Instruct-FP8"
  },
  {
    "id": "together_ai/deepseek-ai/DeepSeek-R1",
    "name": "DeepSeek-R1",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 128000,
      "max_output_tokens": 20480,
      "max_tokens": 20480,
      "mode": "chat",
      "output_cost_per_token": 0.000007,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "together_ai"
    },
    "slug": "deepseek-r1",
    "displayName": "DeepSeek-R1"
  },
  {
    "id": "together_ai/deepseek-ai/DeepSeek-R1-0528-tput",
    "name": "DeepSeek-R1-0528-tput",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 5.5e-7,
      "max_input_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.00000219,
      "source": "https://www.together.ai/models/deepseek-r1-0528-throughput",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "together_ai"
    },
    "slug": "deepseek-r1-0528-tput",
    "displayName": "DeepSeek-R1-0528-tput"
  },
  {
    "id": "together_ai/deepseek-ai/DeepSeek-V3",
    "name": "DeepSeek-V3",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 0.00000125,
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.00000125,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "together_ai"
    },
    "slug": "deepseek-v3",
    "displayName": "DeepSeek-V3"
  },
  {
    "id": "together_ai/deepseek-ai/DeepSeek-V3.1",
    "name": "DeepSeek-V3.1",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 6e-7,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.0000017,
      "source": "https://www.together.ai/models/deepseek-v3-1",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "together_ai"
    },
    "slug": "deepseek-v3.1",
    "displayName": "DeepSeek-V3.1"
  },
  {
    "id": "together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo",
    "name": "Llama-3.3-70B-Instruct-Turbo",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 8.8e-7,
      "mode": "chat",
      "output_cost_per_token": 8.8e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "together_ai"
    },
    "slug": "llama-3.3-70b-instruct-turbo",
    "displayName": "Llama-3.3-70B-Instruct-Turbo"
  },
  {
    "id": "together_ai/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
    "name": "Llama-4-Maverick-17B-128E-Instruct-FP8",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 2.7e-7,
      "mode": "chat",
      "output_cost_per_token": 8.5e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "together_ai"
    },
    "slug": "llama-4-maverick-17b-128e-instruct-fp8",
    "displayName": "Llama-4-Maverick-17B-128E-Instruct-FP8"
  },
  {
    "id": "together_ai/meta-llama/Llama-4-Scout-17B-16E-Instruct",
    "name": "Llama-4-Scout-17B-16E-Instruct",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 1.8e-7,
      "mode": "chat",
      "output_cost_per_token": 5.9e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "together_ai"
    },
    "slug": "llama-4-scout-17b-16e-instruct",
    "displayName": "Llama-4-Scout-17B-16E-Instruct"
  },
  {
    "id": "together_ai/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
    "name": "Meta-Llama-3.1-405B-Instruct-Turbo",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 0.0000035,
      "mode": "chat",
      "output_cost_per_token": 0.0000035,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "together_ai"
    },
    "slug": "meta-llama-3.1-405b-instruct-turbo",
    "displayName": "Meta-Llama-3.1-405B-Instruct-Turbo"
  },
  {
    "id": "together_ai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
    "name": "Meta-Llama-3.1-70B-Instruct-Turbo",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 8.8e-7,
      "mode": "chat",
      "output_cost_per_token": 8.8e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "together_ai"
    },
    "slug": "meta-llama-3.1-70b-instruct-turbo",
    "displayName": "Meta-Llama-3.1-70B-Instruct-Turbo"
  },
  {
    "id": "together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
    "name": "Meta-Llama-3.1-8B-Instruct-Turbo",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 1.8e-7,
      "mode": "chat",
      "output_cost_per_token": 1.8e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "together_ai"
    },
    "slug": "meta-llama-3.1-8b-instruct-turbo",
    "displayName": "Meta-Llama-3.1-8B-Instruct-Turbo"
  },
  {
    "id": "together_ai/mistralai/Mixtral-8x7B-Instruct-v0.1",
    "name": "Mixtral-8x7B-Instruct-v0.1",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 6e-7,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "together_ai"
    },
    "slug": "mixtral-8x7b-instruct-v0.1",
    "displayName": "Mixtral-8x7B-Instruct-v0.1"
  },
  {
    "id": "together_ai/moonshotai/Kimi-K2-Instruct",
    "name": "Kimi-K2-Instruct",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 0.000001,
      "mode": "chat",
      "output_cost_per_token": 0.000003,
      "source": "https://www.together.ai/models/kimi-k2-instruct",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "together_ai"
    },
    "slug": "kimi-k2-instruct",
    "displayName": "Kimi-K2-Instruct"
  },
  {
    "id": "together_ai/openai/gpt-oss-120b",
    "name": "gpt-oss-120b",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "source": "https://www.together.ai/models/gpt-oss-120b",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "together_ai"
    },
    "slug": "gpt-oss-120b",
    "displayName": "gpt-oss-120b"
  },
  {
    "id": "together_ai/openai/gpt-oss-20b",
    "name": "gpt-oss-20b",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 5e-8,
      "max_input_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 2e-7,
      "source": "https://www.together.ai/models/gpt-oss-20b",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "together_ai"
    },
    "slug": "gpt-oss-20b",
    "displayName": "gpt-oss-20b"
  },
  {
    "id": "together_ai/zai-org/GLM-4.5-Air-FP8",
    "name": "GLM-4.5-Air-FP8",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.0000011,
      "source": "https://www.together.ai/models/glm-4-5-air",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "together_ai"
    },
    "slug": "glm-4.5-air-fp8",
    "displayName": "GLM-4.5-Air-FP8"
  },
  {
    "id": "together_ai/zai-org/GLM-4.6",
    "name": "GLM-4.6",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 200000,
      "max_tokens": 200000,
      "mode": "chat",
      "output_cost_per_token": 0.0000022,
      "source": "https://www.together.ai/models/glm-4-6",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "together_ai"
    },
    "slug": "glm-4.6",
    "displayName": "GLM-4.6"
  },
  {
    "id": "together_ai/zai-org/GLM-4.7",
    "name": "GLM-4.7",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 4.5e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 200000,
      "max_tokens": 200000,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "source": "https://www.together.ai/models/glm-4-7",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "together_ai"
    },
    "slug": "glm-4.7",
    "displayName": "GLM-4.7"
  },
  {
    "id": "together_ai/moonshotai/Kimi-K2.5",
    "name": "Kimi-K2.5",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 5e-7,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 0.0000028,
      "source": "https://www.together.ai/models/kimi-k2-5",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_reasoning": true,
      "provider": "together_ai"
    },
    "slug": "kimi-k2.5",
    "displayName": "Kimi-K2.5"
  },
  {
    "id": "together_ai/moonshotai/Kimi-K2-Instruct-0905",
    "name": "Kimi-K2-Instruct-0905",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 262144,
      "mode": "chat",
      "output_cost_per_token": 0.000003,
      "source": "https://www.together.ai/models/kimi-k2-0905",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "provider": "together_ai"
    },
    "slug": "kimi-k2-instruct-0905",
    "displayName": "Kimi-K2-Instruct-0905"
  },
  {
    "id": "together_ai/Qwen/Qwen3-Next-80B-A3B-Instruct",
    "name": "Qwen3-Next-80B-A3B-Instruct",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 262144,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "source": "https://www.together.ai/models/qwen3-next-80b-a3b-instruct",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "together_ai"
    },
    "slug": "qwen3-next-80b-a3b-instruct",
    "displayName": "Qwen3-Next-80B-A3B-Instruct"
  },
  {
    "id": "together_ai/Qwen/Qwen3-Next-80B-A3B-Thinking",
    "name": "Qwen3-Next-80B-A3B-Thinking",
    "provider": "together_ai",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 262144,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "source": "https://www.together.ai/models/qwen3-next-80b-a3b-thinking",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "together_ai"
    },
    "slug": "qwen3-next-80b-a3b-thinking",
    "displayName": "Qwen3-Next-80B-A3B-Thinking"
  },
  {
    "id": "us.amazon.nova-lite-v1:0",
    "name": "us.amazon.nova-lite-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 6e-8,
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "max_tokens": 10000,
      "mode": "chat",
      "output_cost_per_token": 2.4e-7,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "provider": "bedrock_converse"
    },
    "slug": "us.amazon.nova-lite-v1-0",
    "displayName": "us.amazon.nova-lite-v1:0"
  },
  {
    "id": "us.amazon.nova-micro-v1:0",
    "name": "us.amazon.nova-micro-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 3.5e-8,
      "max_input_tokens": 128000,
      "max_output_tokens": 10000,
      "max_tokens": 10000,
      "mode": "chat",
      "output_cost_per_token": 1.4e-7,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "provider": "bedrock_converse"
    },
    "slug": "us.amazon.nova-micro-v1-0",
    "displayName": "us.amazon.nova-micro-v1:0"
  },
  {
    "id": "us.amazon.nova-premier-v1:0",
    "name": "us.amazon.nova-premier-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 1000000,
      "max_output_tokens": 10000,
      "max_tokens": 10000,
      "mode": "chat",
      "output_cost_per_token": 0.0000125,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": false,
      "supports_response_schema": true,
      "supports_vision": true,
      "provider": "bedrock_converse"
    },
    "slug": "us.amazon.nova-premier-v1-0",
    "displayName": "us.amazon.nova-premier-v1:0"
  },
  {
    "id": "us.amazon.nova-pro-v1:0",
    "name": "us.amazon.nova-pro-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 8e-7,
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "max_tokens": 10000,
      "mode": "chat",
      "output_cost_per_token": 0.0000032,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "provider": "bedrock_converse"
    },
    "slug": "us.amazon.nova-pro-v1-0",
    "displayName": "us.amazon.nova-pro-v1:0"
  },
  {
    "id": "us.anthropic.claude-3-5-haiku-20241022-v1:0",
    "name": "us.anthropic.claude-3-5-haiku-20241022-v1:0",
    "provider": "bedrock",
    "data": {
      "cache_creation_input_token_cost": 0.000001,
      "cache_read_input_token_cost": 8e-8,
      "input_cost_per_token": 8e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000004,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "provider": "bedrock"
    },
    "slug": "us.anthropic.claude-3-5-haiku-20241022-v1-0",
    "displayName": "us.anthropic.claude-3-5-haiku-20241022-v1:0"
  },
  {
    "id": "us.anthropic.claude-haiku-4-5-20251001-v1:0",
    "name": "us.anthropic.claude-haiku-4-5-20251001-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_creation_input_token_cost": 0.000001375,
      "cache_read_input_token_cost": 1.1e-7,
      "input_cost_per_token": 0.0000011,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.0000055,
      "source": "https://aws.amazon.com/about-aws/whats-new/2025/10/claude-4-5-haiku-anthropic-amazon-bedrock",
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 346,
      "provider": "bedrock_converse"
    },
    "slug": "us.anthropic.claude-haiku-4-5-20251001-v1-0",
    "displayName": "us.anthropic.claude-haiku-4-5-20251001-v1:0"
  },
  {
    "id": "us.anthropic.claude-3-5-sonnet-20240620-v1:0",
    "name": "us.anthropic.claude-3-5-sonnet-20240620-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "us.anthropic.claude-3-5-sonnet-20240620-v1-0",
    "displayName": "us.anthropic.claude-3-5-sonnet-20240620-v1:0"
  },
  {
    "id": "us.anthropic.claude-3-5-sonnet-20241022-v2:0",
    "name": "us.anthropic.claude-3-5-sonnet-20241022-v2:0",
    "provider": "bedrock",
    "data": {
      "cache_creation_input_token_cost": 0.00000375,
      "cache_read_input_token_cost": 3e-7,
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "us.anthropic.claude-3-5-sonnet-20241022-v2-0",
    "displayName": "us.anthropic.claude-3-5-sonnet-20241022-v2:0"
  },
  {
    "id": "us.anthropic.claude-3-7-sonnet-20250219-v1:0",
    "name": "us.anthropic.claude-3-7-sonnet-20250219-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_creation_input_token_cost": 0.00000375,
      "cache_read_input_token_cost": 3e-7,
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "bedrock_converse"
    },
    "slug": "us.anthropic.claude-3-7-sonnet-20250219-v1-0",
    "displayName": "us.anthropic.claude-3-7-sonnet-20250219-v1:0"
  },
  {
    "id": "us.anthropic.claude-3-haiku-20240307-v1:0",
    "name": "us.anthropic.claude-3-haiku-20240307-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 2.5e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00000125,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "us.anthropic.claude-3-haiku-20240307-v1-0",
    "displayName": "us.anthropic.claude-3-haiku-20240307-v1:0"
  },
  {
    "id": "us.anthropic.claude-3-opus-20240229-v1:0",
    "name": "us.anthropic.claude-3-opus-20240229-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000075,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "us.anthropic.claude-3-opus-20240229-v1-0",
    "displayName": "us.anthropic.claude-3-opus-20240229-v1:0"
  },
  {
    "id": "us.anthropic.claude-3-sonnet-20240229-v1:0",
    "name": "us.anthropic.claude-3-sonnet-20240229-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "us.anthropic.claude-3-sonnet-20240229-v1-0",
    "displayName": "us.anthropic.claude-3-sonnet-20240229-v1:0"
  },
  {
    "id": "us.anthropic.claude-opus-4-1-20250805-v1:0",
    "name": "us.anthropic.claude-opus-4-1-20250805-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_creation_input_token_cost": 0.00001875,
      "cache_read_input_token_cost": 0.0000015,
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.000075,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "bedrock_converse"
    },
    "slug": "us.anthropic.claude-opus-4-1-20250805-v1-0",
    "displayName": "us.anthropic.claude-opus-4-1-20250805-v1:0"
  },
  {
    "id": "us.anthropic.claude-sonnet-4-5-20250929-v1:0",
    "name": "us.anthropic.claude-sonnet-4-5-20250929-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_creation_input_token_cost": 0.000004125,
      "cache_read_input_token_cost": 3.3e-7,
      "input_cost_per_token": 0.0000033,
      "input_cost_per_token_above_200k_tokens": 0.0000066,
      "output_cost_per_token_above_200k_tokens": 0.00002475,
      "cache_creation_input_token_cost_above_200k_tokens": 0.00000825,
      "cache_read_input_token_cost_above_200k_tokens": 6.6e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.0000165,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 346,
      "provider": "bedrock_converse"
    },
    "slug": "us.anthropic.claude-sonnet-4-5-20250929-v1-0",
    "displayName": "us.anthropic.claude-sonnet-4-5-20250929-v1:0"
  },
  {
    "id": "au.anthropic.claude-haiku-4-5-20251001-v1:0",
    "name": "au.anthropic.claude-haiku-4-5-20251001-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_creation_input_token_cost": 0.000001375,
      "cache_read_input_token_cost": 1.1e-7,
      "input_cost_per_token": 0.0000011,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.0000055,
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 346,
      "provider": "bedrock_converse"
    },
    "slug": "au.anthropic.claude-haiku-4-5-20251001-v1-0",
    "displayName": "au.anthropic.claude-haiku-4-5-20251001-v1:0"
  },
  {
    "id": "us.anthropic.claude-opus-4-20250514-v1:0",
    "name": "us.anthropic.claude-opus-4-20250514-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_creation_input_token_cost": 0.00001875,
      "cache_read_input_token_cost": 0.0000015,
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.000075,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "bedrock_converse"
    },
    "slug": "us.anthropic.claude-opus-4-20250514-v1-0",
    "displayName": "us.anthropic.claude-opus-4-20250514-v1:0"
  },
  {
    "id": "us.anthropic.claude-opus-4-5-20251101-v1:0",
    "name": "us.anthropic.claude-opus-4-5-20251101-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_creation_input_token_cost": 0.000006875,
      "cache_read_input_token_cost": 5.5e-7,
      "input_cost_per_token": 0.0000055,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.0000275,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "bedrock_converse"
    },
    "slug": "us.anthropic.claude-opus-4-5-20251101-v1-0",
    "displayName": "us.anthropic.claude-opus-4-5-20251101-v1:0"
  },
  {
    "id": "global.anthropic.claude-opus-4-5-20251101-v1:0",
    "name": "global.anthropic.claude-opus-4-5-20251101-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_creation_input_token_cost": 0.00000625,
      "cache_read_input_token_cost": 5e-7,
      "input_cost_per_token": 0.000005,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000025,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "bedrock_converse"
    },
    "slug": "global.anthropic.claude-opus-4-5-20251101-v1-0",
    "displayName": "global.anthropic.claude-opus-4-5-20251101-v1:0"
  },
  {
    "id": "eu.anthropic.claude-opus-4-5-20251101-v1:0",
    "name": "eu.anthropic.claude-opus-4-5-20251101-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_creation_input_token_cost": 0.00000625,
      "cache_read_input_token_cost": 5e-7,
      "input_cost_per_token": 0.000005,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000025,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "bedrock_converse"
    },
    "slug": "eu.anthropic.claude-opus-4-5-20251101-v1-0",
    "displayName": "eu.anthropic.claude-opus-4-5-20251101-v1:0"
  },
  {
    "id": "us.anthropic.claude-sonnet-4-20250514-v1:0",
    "name": "us.anthropic.claude-sonnet-4-20250514-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "cache_creation_input_token_cost": 0.00000375,
      "cache_read_input_token_cost": 3e-7,
      "input_cost_per_token": 0.000003,
      "input_cost_per_token_above_200k_tokens": 0.000006,
      "output_cost_per_token_above_200k_tokens": 0.0000225,
      "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
      "cache_read_input_token_cost_above_200k_tokens": 6e-7,
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "bedrock_converse"
    },
    "slug": "us.anthropic.claude-sonnet-4-20250514-v1-0",
    "displayName": "us.anthropic.claude-sonnet-4-20250514-v1:0"
  },
  {
    "id": "us.deepseek.r1-v1:0",
    "name": "us.deepseek.r1-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 0.00000135,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.0000054,
      "supports_function_calling": false,
      "supports_reasoning": true,
      "supports_tool_choice": false,
      "provider": "bedrock_converse"
    },
    "slug": "us.deepseek.r1-v1-0",
    "displayName": "us.deepseek.r1-v1:0"
  },
  {
    "id": "us.meta.llama3-1-405b-instruct-v1:0",
    "name": "us.meta.llama3-1-405b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.00000532,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000016,
      "supports_function_calling": true,
      "supports_tool_choice": false,
      "provider": "bedrock"
    },
    "slug": "us.meta.llama3-1-405b-instruct-v1-0",
    "displayName": "us.meta.llama3-1-405b-instruct-v1:0"
  },
  {
    "id": "us.meta.llama3-1-70b-instruct-v1:0",
    "name": "us.meta.llama3-1-70b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 9.9e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "max_tokens": 2048,
      "mode": "chat",
      "output_cost_per_token": 9.9e-7,
      "supports_function_calling": true,
      "supports_tool_choice": false,
      "provider": "bedrock"
    },
    "slug": "us.meta.llama3-1-70b-instruct-v1-0",
    "displayName": "us.meta.llama3-1-70b-instruct-v1:0"
  },
  {
    "id": "us.meta.llama3-1-8b-instruct-v1:0",
    "name": "us.meta.llama3-1-8b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 2.2e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "max_tokens": 2048,
      "mode": "chat",
      "output_cost_per_token": 2.2e-7,
      "supports_function_calling": true,
      "supports_tool_choice": false,
      "provider": "bedrock"
    },
    "slug": "us.meta.llama3-1-8b-instruct-v1-0",
    "displayName": "us.meta.llama3-1-8b-instruct-v1:0"
  },
  {
    "id": "us.meta.llama3-2-11b-instruct-v1:0",
    "name": "us.meta.llama3-2-11b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 3.5e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 3.5e-7,
      "supports_function_calling": true,
      "supports_tool_choice": false,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "us.meta.llama3-2-11b-instruct-v1-0",
    "displayName": "us.meta.llama3-2-11b-instruct-v1:0"
  },
  {
    "id": "us.meta.llama3-2-1b-instruct-v1:0",
    "name": "us.meta.llama3-2-1b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 1e-7,
      "supports_function_calling": true,
      "supports_tool_choice": false,
      "provider": "bedrock"
    },
    "slug": "us.meta.llama3-2-1b-instruct-v1-0",
    "displayName": "us.meta.llama3-2-1b-instruct-v1:0"
  },
  {
    "id": "us.meta.llama3-2-3b-instruct-v1:0",
    "name": "us.meta.llama3-2-3b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 1.5e-7,
      "supports_function_calling": true,
      "supports_tool_choice": false,
      "provider": "bedrock"
    },
    "slug": "us.meta.llama3-2-3b-instruct-v1-0",
    "displayName": "us.meta.llama3-2-3b-instruct-v1:0"
  },
  {
    "id": "us.meta.llama3-2-90b-instruct-v1:0",
    "name": "us.meta.llama3-2-90b-instruct-v1:0",
    "provider": "bedrock",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "supports_function_calling": true,
      "supports_tool_choice": false,
      "supports_vision": true,
      "provider": "bedrock"
    },
    "slug": "us.meta.llama3-2-90b-instruct-v1-0",
    "displayName": "us.meta.llama3-2-90b-instruct-v1:0"
  },
  {
    "id": "us.meta.llama3-3-70b-instruct-v1:0",
    "name": "us.meta.llama3-3-70b-instruct-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 7.2e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 7.2e-7,
      "supports_function_calling": true,
      "supports_tool_choice": false,
      "provider": "bedrock_converse"
    },
    "slug": "us.meta.llama3-3-70b-instruct-v1-0",
    "displayName": "us.meta.llama3-3-70b-instruct-v1:0"
  },
  {
    "id": "us.meta.llama4-maverick-17b-instruct-v1:0",
    "name": "us.meta.llama4-maverick-17b-instruct-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 2.4e-7,
      "input_cost_per_token_batches": 1.2e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 9.7e-7,
      "output_cost_per_token_batches": 4.85e-7,
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text",
        "code"
      ],
      "supports_function_calling": true,
      "supports_tool_choice": false,
      "provider": "bedrock_converse"
    },
    "slug": "us.meta.llama4-maverick-17b-instruct-v1-0",
    "displayName": "us.meta.llama4-maverick-17b-instruct-v1:0"
  },
  {
    "id": "us.meta.llama4-scout-17b-instruct-v1:0",
    "name": "us.meta.llama4-scout-17b-instruct-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 1.7e-7,
      "input_cost_per_token_batches": 8.5e-8,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 6.6e-7,
      "output_cost_per_token_batches": 3.3e-7,
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text",
        "code"
      ],
      "supports_function_calling": true,
      "supports_tool_choice": false,
      "provider": "bedrock_converse"
    },
    "slug": "us.meta.llama4-scout-17b-instruct-v1-0",
    "displayName": "us.meta.llama4-scout-17b-instruct-v1:0"
  },
  {
    "id": "us.mistral.pixtral-large-2502-v1:0",
    "name": "us.mistral.pixtral-large-2502-v1:0",
    "provider": "bedrock_converse",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000006,
      "supports_function_calling": true,
      "supports_tool_choice": false,
      "provider": "bedrock_converse"
    },
    "slug": "us.mistral.pixtral-large-2502-v1-0",
    "displayName": "us.mistral.pixtral-large-2502-v1:0"
  },
  {
    "id": "v0/v0-1.0-md",
    "name": "v0-1.0-md",
    "provider": "v0",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "v0"
    },
    "slug": "v0-1.0-md",
    "displayName": "v0-1.0-md"
  },
  {
    "id": "v0/v0-1.5-lg",
    "name": "v0-1.5-lg",
    "provider": "v0",
    "data": {
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 512000,
      "max_output_tokens": 512000,
      "max_tokens": 512000,
      "mode": "chat",
      "output_cost_per_token": 0.000075,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "v0"
    },
    "slug": "v0-1.5-lg",
    "displayName": "v0-1.5-lg"
  },
  {
    "id": "v0/v0-1.5-md",
    "name": "v0-1.5-md",
    "provider": "v0",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "v0"
    },
    "slug": "v0-1.5-md",
    "displayName": "v0-1.5-md"
  },
  {
    "id": "vercel_ai_gateway/alibaba/qwen-3-14b",
    "name": "qwen-3-14b",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 8e-8,
      "max_input_tokens": 40960,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 2.4e-7,
      "provider": "vercel_ai_gateway"
    },
    "slug": "qwen-3-14b",
    "displayName": "qwen-3-14b"
  },
  {
    "id": "vercel_ai_gateway/alibaba/qwen-3-235b",
    "name": "qwen-3-235b",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 40960,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "provider": "vercel_ai_gateway"
    },
    "slug": "qwen-3-235b",
    "displayName": "qwen-3-235b"
  },
  {
    "id": "vercel_ai_gateway/alibaba/qwen-3-30b",
    "name": "qwen-3-30b",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 40960,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "provider": "vercel_ai_gateway"
    },
    "slug": "qwen-3-30b",
    "displayName": "qwen-3-30b"
  },
  {
    "id": "vercel_ai_gateway/alibaba/qwen-3-32b",
    "name": "qwen-3-32b",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 40960,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "qwen-3-32b",
    "displayName": "qwen-3-32b"
  },
  {
    "id": "vercel_ai_gateway/alibaba/qwen3-coder",
    "name": "qwen3-coder",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 4e-7,
      "max_input_tokens": 262144,
      "max_output_tokens": 66536,
      "max_tokens": 66536,
      "mode": "chat",
      "output_cost_per_token": 0.0000016,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "qwen3-coder",
    "displayName": "qwen3-coder"
  },
  {
    "id": "vercel_ai_gateway/amazon/nova-lite",
    "name": "nova-lite",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 6e-8,
      "max_input_tokens": 300000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 2.4e-7,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "nova-lite",
    "displayName": "nova-lite"
  },
  {
    "id": "vercel_ai_gateway/amazon/nova-micro",
    "name": "nova-micro",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 3.5e-8,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 1.4e-7,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "nova-micro",
    "displayName": "nova-micro"
  },
  {
    "id": "vercel_ai_gateway/amazon/nova-pro",
    "name": "nova-pro",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 8e-7,
      "max_input_tokens": 300000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.0000032,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "nova-pro",
    "displayName": "nova-pro"
  },
  {
    "id": "vercel_ai_gateway/amazon/titan-embed-text-v2",
    "name": "titan-embed-text-v2",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 2e-8,
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "max_tokens": 0,
      "mode": "chat",
      "output_cost_per_token": 0,
      "provider": "vercel_ai_gateway"
    },
    "slug": "titan-embed-text-v2",
    "displayName": "titan-embed-text-v2"
  },
  {
    "id": "vercel_ai_gateway/anthropic/claude-3-haiku",
    "name": "claude-3-haiku",
    "provider": "vercel_ai_gateway",
    "data": {
      "cache_creation_input_token_cost": 3e-7,
      "cache_read_input_token_cost": 3e-8,
      "input_cost_per_token": 2.5e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00000125,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "claude-3-haiku",
    "displayName": "claude-3-haiku"
  },
  {
    "id": "vercel_ai_gateway/anthropic/claude-3-opus",
    "name": "claude-3-opus",
    "provider": "vercel_ai_gateway",
    "data": {
      "cache_creation_input_token_cost": 0.00001875,
      "cache_read_input_token_cost": 0.0000015,
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000075,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "claude-3-opus",
    "displayName": "claude-3-opus"
  },
  {
    "id": "vercel_ai_gateway/anthropic/claude-3.5-haiku",
    "name": "claude-3.5-haiku",
    "provider": "vercel_ai_gateway",
    "data": {
      "cache_creation_input_token_cost": 0.000001,
      "cache_read_input_token_cost": 8e-8,
      "input_cost_per_token": 8e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000004,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "claude-3.5-haiku",
    "displayName": "claude-3.5-haiku"
  },
  {
    "id": "vercel_ai_gateway/anthropic/claude-3.5-sonnet",
    "name": "claude-3.5-sonnet",
    "provider": "vercel_ai_gateway",
    "data": {
      "cache_creation_input_token_cost": 0.00000375,
      "cache_read_input_token_cost": 3e-7,
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "claude-3.5-sonnet",
    "displayName": "claude-3.5-sonnet"
  },
  {
    "id": "vercel_ai_gateway/anthropic/claude-3.7-sonnet",
    "name": "claude-3.7-sonnet",
    "provider": "vercel_ai_gateway",
    "data": {
      "cache_creation_input_token_cost": 0.00000375,
      "cache_read_input_token_cost": 3e-7,
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "claude-3.7-sonnet",
    "displayName": "claude-3.7-sonnet"
  },
  {
    "id": "vercel_ai_gateway/anthropic/claude-4-opus",
    "name": "claude-4-opus",
    "provider": "vercel_ai_gateway",
    "data": {
      "cache_creation_input_token_cost": 0.00001875,
      "cache_read_input_token_cost": 0.0000015,
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.000075,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "claude-4-opus",
    "displayName": "claude-4-opus"
  },
  {
    "id": "vercel_ai_gateway/anthropic/claude-4-sonnet",
    "name": "claude-4-sonnet",
    "provider": "vercel_ai_gateway",
    "data": {
      "cache_creation_input_token_cost": 0.00000375,
      "cache_read_input_token_cost": 3e-7,
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "claude-4-sonnet",
    "displayName": "claude-4-sonnet"
  },
  {
    "id": "vercel_ai_gateway/cohere/command-a",
    "name": "command-a",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 256000,
      "max_output_tokens": 8000,
      "max_tokens": 8000,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "command-a",
    "displayName": "command-a"
  },
  {
    "id": "vercel_ai_gateway/cohere/command-r",
    "name": "command-r",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "command-r",
    "displayName": "command-r"
  },
  {
    "id": "vercel_ai_gateway/cohere/command-r-plus",
    "name": "command-r-plus",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "command-r-plus",
    "displayName": "command-r-plus"
  },
  {
    "id": "vercel_ai_gateway/cohere/embed-v4.0",
    "name": "embed-v4.0",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 1.2e-7,
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "max_tokens": 0,
      "mode": "chat",
      "output_cost_per_token": 0,
      "provider": "vercel_ai_gateway"
    },
    "slug": "embed-v4.0",
    "displayName": "embed-v4.0"
  },
  {
    "id": "vercel_ai_gateway/deepseek/deepseek-r1",
    "name": "deepseek-r1",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 5.5e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.00000219,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "deepseek-r1",
    "displayName": "deepseek-r1"
  },
  {
    "id": "vercel_ai_gateway/deepseek/deepseek-r1-distill-llama-70b",
    "name": "deepseek-r1-distill-llama-70b",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 7.5e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 9.9e-7,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "deepseek-r1-distill-llama-70b",
    "displayName": "deepseek-r1-distill-llama-70b"
  },
  {
    "id": "vercel_ai_gateway/deepseek/deepseek-v3",
    "name": "deepseek-v3",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 9e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 9e-7,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "deepseek-v3",
    "displayName": "deepseek-v3"
  },
  {
    "id": "vercel_ai_gateway/google/gemini-2.0-flash",
    "name": "gemini-2.0-flash",
    "provider": "vercel_ai_gateway",
    "data": {
      "deprecation_date": "2026-03-31",
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "gemini-2.0-flash",
    "displayName": "gemini-2.0-flash"
  },
  {
    "id": "vercel_ai_gateway/google/gemini-2.0-flash-lite",
    "name": "gemini-2.0-flash-lite",
    "provider": "vercel_ai_gateway",
    "data": {
      "deprecation_date": "2026-03-31",
      "input_cost_per_token": 7.5e-8,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "gemini-2.0-flash-lite",
    "displayName": "gemini-2.0-flash-lite"
  },
  {
    "id": "vercel_ai_gateway/google/gemini-2.5-flash",
    "name": "gemini-2.5-flash",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 1000000,
      "max_output_tokens": 65536,
      "max_tokens": 65536,
      "mode": "chat",
      "output_cost_per_token": 0.0000025,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "gemini-2.5-flash",
    "displayName": "gemini-2.5-flash"
  },
  {
    "id": "vercel_ai_gateway/google/gemini-2.5-pro",
    "name": "gemini-2.5-pro",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "max_tokens": 65536,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "gemini-2.5-pro",
    "displayName": "gemini-2.5-pro"
  },
  {
    "id": "vercel_ai_gateway/google/gemini-embedding-001",
    "name": "gemini-embedding-001",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "max_tokens": 0,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "provider": "vercel_ai_gateway"
    },
    "slug": "gemini-embedding-001",
    "displayName": "gemini-embedding-001"
  },
  {
    "id": "vercel_ai_gateway/google/gemma-2-9b",
    "name": "gemma-2-9b",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 2e-7,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "gemma-2-9b",
    "displayName": "gemma-2-9b"
  },
  {
    "id": "vercel_ai_gateway/google/text-embedding-005",
    "name": "text-embedding-005",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 2.5e-8,
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "max_tokens": 0,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "provider": "vercel_ai_gateway"
    },
    "slug": "text-embedding-005",
    "displayName": "text-embedding-005"
  },
  {
    "id": "vercel_ai_gateway/google/text-multilingual-embedding-002",
    "name": "text-multilingual-embedding-002",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 2.5e-8,
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "max_tokens": 0,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "provider": "vercel_ai_gateway"
    },
    "slug": "text-multilingual-embedding-002",
    "displayName": "text-multilingual-embedding-002"
  },
  {
    "id": "vercel_ai_gateway/inception/mercury-coder-small",
    "name": "mercury-coder-small",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 2.5e-7,
      "max_input_tokens": 32000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.000001,
      "provider": "vercel_ai_gateway"
    },
    "slug": "mercury-coder-small",
    "displayName": "mercury-coder-small"
  },
  {
    "id": "vercel_ai_gateway/meta/llama-3-70b",
    "name": "llama-3-70b",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 5.9e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 7.9e-7,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "llama-3-70b",
    "displayName": "llama-3-70b"
  },
  {
    "id": "vercel_ai_gateway/meta/llama-3-8b",
    "name": "llama-3-8b",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 5e-8,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 8e-8,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "llama-3-8b",
    "displayName": "llama-3-8b"
  },
  {
    "id": "vercel_ai_gateway/meta/llama-3.1-70b",
    "name": "llama-3.1-70b",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 7.2e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 7.2e-7,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "llama-3.1-70b",
    "displayName": "llama-3.1-70b"
  },
  {
    "id": "vercel_ai_gateway/meta/llama-3.1-8b",
    "name": "llama-3.1-8b",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 5e-8,
      "max_input_tokens": 131000,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 8e-8,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "llama-3.1-8b",
    "displayName": "llama-3.1-8b"
  },
  {
    "id": "vercel_ai_gateway/meta/llama-3.2-11b",
    "name": "llama-3.2-11b",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 1.6e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 1.6e-7,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "llama-3.2-11b",
    "displayName": "llama-3.2-11b"
  },
  {
    "id": "vercel_ai_gateway/meta/llama-3.2-1b",
    "name": "llama-3.2-1b",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 1e-7,
      "provider": "vercel_ai_gateway"
    },
    "slug": "llama-3.2-1b",
    "displayName": "llama-3.2-1b"
  },
  {
    "id": "vercel_ai_gateway/meta/llama-3.2-3b",
    "name": "llama-3.2-3b",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 1.5e-7,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "llama-3.2-3b",
    "displayName": "llama-3.2-3b"
  },
  {
    "id": "vercel_ai_gateway/meta/llama-3.2-90b",
    "name": "llama-3.2-90b",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 7.2e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 7.2e-7,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "llama-3.2-90b",
    "displayName": "llama-3.2-90b"
  },
  {
    "id": "vercel_ai_gateway/meta/llama-3.3-70b",
    "name": "llama-3.3-70b",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 7.2e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 7.2e-7,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "llama-3.3-70b",
    "displayName": "llama-3.3-70b"
  },
  {
    "id": "vercel_ai_gateway/meta/llama-4-maverick",
    "name": "llama-4-maverick",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "llama-4-maverick",
    "displayName": "llama-4-maverick"
  },
  {
    "id": "vercel_ai_gateway/meta/llama-4-scout",
    "name": "llama-4-scout",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "llama-4-scout",
    "displayName": "llama-4-scout"
  },
  {
    "id": "vercel_ai_gateway/mistral/codestral",
    "name": "codestral",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 256000,
      "max_output_tokens": 4000,
      "max_tokens": 4000,
      "mode": "chat",
      "output_cost_per_token": 9e-7,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "codestral",
    "displayName": "codestral"
  },
  {
    "id": "vercel_ai_gateway/mistral/codestral-embed",
    "name": "codestral-embed",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "max_tokens": 0,
      "mode": "chat",
      "output_cost_per_token": 0,
      "provider": "vercel_ai_gateway"
    },
    "slug": "codestral-embed",
    "displayName": "codestral-embed"
  },
  {
    "id": "vercel_ai_gateway/mistral/devstral-small",
    "name": "devstral-small",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 7e-8,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 2.8e-7,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "devstral-small",
    "displayName": "devstral-small"
  },
  {
    "id": "vercel_ai_gateway/mistral/magistral-medium",
    "name": "magistral-medium",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000005,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "magistral-medium",
    "displayName": "magistral-medium"
  },
  {
    "id": "vercel_ai_gateway/mistral/magistral-small",
    "name": "magistral-small",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 5e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "supports_function_calling": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "magistral-small",
    "displayName": "magistral-small"
  },
  {
    "id": "vercel_ai_gateway/mistral/ministral-3b",
    "name": "ministral-3b",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 4e-8,
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "max_tokens": 4000,
      "mode": "chat",
      "output_cost_per_token": 4e-8,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "ministral-3b",
    "displayName": "ministral-3b"
  },
  {
    "id": "vercel_ai_gateway/mistral/ministral-8b",
    "name": "ministral-8b",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "max_tokens": 4000,
      "mode": "chat",
      "output_cost_per_token": 1e-7,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "ministral-8b",
    "displayName": "ministral-8b"
  },
  {
    "id": "vercel_ai_gateway/mistral/mistral-embed",
    "name": "mistral-embed",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "max_tokens": 0,
      "mode": "chat",
      "output_cost_per_token": 0,
      "provider": "vercel_ai_gateway"
    },
    "slug": "mistral-embed",
    "displayName": "mistral-embed"
  },
  {
    "id": "vercel_ai_gateway/mistral/mistral-large",
    "name": "mistral-large",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 32000,
      "max_output_tokens": 4000,
      "max_tokens": 4000,
      "mode": "chat",
      "output_cost_per_token": 0.000006,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "mistral-large",
    "displayName": "mistral-large"
  },
  {
    "id": "vercel_ai_gateway/mistral/mistral-saba-24b",
    "name": "mistral-saba-24b",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 7.9e-7,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 7.9e-7,
      "provider": "vercel_ai_gateway"
    },
    "slug": "mistral-saba-24b",
    "displayName": "mistral-saba-24b"
  },
  {
    "id": "vercel_ai_gateway/mistral/mistral-small",
    "name": "mistral-small",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 32000,
      "max_output_tokens": 4000,
      "max_tokens": 4000,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "mistral-small",
    "displayName": "mistral-small"
  },
  {
    "id": "vercel_ai_gateway/mistral/mixtral-8x22b-instruct",
    "name": "mixtral-8x22b-instruct",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 0.0000012,
      "max_input_tokens": 65536,
      "max_output_tokens": 2048,
      "max_tokens": 2048,
      "mode": "chat",
      "output_cost_per_token": 0.0000012,
      "supports_function_calling": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "mixtral-8x22b-instruct",
    "displayName": "mixtral-8x22b-instruct"
  },
  {
    "id": "vercel_ai_gateway/mistral/pixtral-12b",
    "name": "pixtral-12b",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "max_tokens": 4000,
      "mode": "chat",
      "output_cost_per_token": 1.5e-7,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "pixtral-12b",
    "displayName": "pixtral-12b"
  },
  {
    "id": "vercel_ai_gateway/mistral/pixtral-large",
    "name": "pixtral-large",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "max_tokens": 4000,
      "mode": "chat",
      "output_cost_per_token": 0.000006,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "pixtral-large",
    "displayName": "pixtral-large"
  },
  {
    "id": "vercel_ai_gateway/moonshotai/kimi-k2",
    "name": "kimi-k2",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 5.5e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.0000022,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "kimi-k2",
    "displayName": "kimi-k2"
  },
  {
    "id": "vercel_ai_gateway/morph/morph-v3-fast",
    "name": "morph-v3-fast",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 8e-7,
      "max_input_tokens": 32768,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.0000012,
      "provider": "vercel_ai_gateway"
    },
    "slug": "morph-v3-fast",
    "displayName": "morph-v3-fast"
  },
  {
    "id": "vercel_ai_gateway/morph/morph-v3-large",
    "name": "morph-v3-large",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 9e-7,
      "max_input_tokens": 32768,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.0000019,
      "provider": "vercel_ai_gateway"
    },
    "slug": "morph-v3-large",
    "displayName": "morph-v3-large"
  },
  {
    "id": "vercel_ai_gateway/openai/gpt-3.5-turbo",
    "name": "gpt-3.5-turbo",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 5e-7,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "gpt-3.5-turbo",
    "displayName": "gpt-3.5-turbo"
  },
  {
    "id": "vercel_ai_gateway/openai/gpt-3.5-turbo-instruct",
    "name": "gpt-3.5-turbo-instruct",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 0.0000015,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "provider": "vercel_ai_gateway"
    },
    "slug": "gpt-3.5-turbo-instruct",
    "displayName": "gpt-3.5-turbo-instruct"
  },
  {
    "id": "vercel_ai_gateway/openai/gpt-4-turbo",
    "name": "gpt-4-turbo",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 0.00001,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00003,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "gpt-4-turbo",
    "displayName": "gpt-4-turbo"
  },
  {
    "id": "vercel_ai_gateway/openai/gpt-4.1",
    "name": "gpt-4.1",
    "provider": "vercel_ai_gateway",
    "data": {
      "cache_creation_input_token_cost": 0,
      "cache_read_input_token_cost": 5e-7,
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.000008,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "gpt-4.1",
    "displayName": "gpt-4.1"
  },
  {
    "id": "vercel_ai_gateway/openai/gpt-4.1-mini",
    "name": "gpt-4.1-mini",
    "provider": "vercel_ai_gateway",
    "data": {
      "cache_creation_input_token_cost": 0,
      "cache_read_input_token_cost": 1e-7,
      "input_cost_per_token": 4e-7,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.0000016,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "gpt-4.1-mini",
    "displayName": "gpt-4.1-mini"
  },
  {
    "id": "vercel_ai_gateway/openai/gpt-4.1-nano",
    "name": "gpt-4.1-nano",
    "provider": "vercel_ai_gateway",
    "data": {
      "cache_creation_input_token_cost": 0,
      "cache_read_input_token_cost": 2.5e-8,
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "gpt-4.1-nano",
    "displayName": "gpt-4.1-nano"
  },
  {
    "id": "vercel_ai_gateway/openai/gpt-4o",
    "name": "gpt-4o",
    "provider": "vercel_ai_gateway",
    "data": {
      "cache_creation_input_token_cost": 0,
      "cache_read_input_token_cost": 0.00000125,
      "input_cost_per_token": 0.0000025,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "gpt-4o",
    "displayName": "gpt-4o"
  },
  {
    "id": "vercel_ai_gateway/openai/gpt-4o-mini",
    "name": "gpt-4o-mini",
    "provider": "vercel_ai_gateway",
    "data": {
      "cache_creation_input_token_cost": 0,
      "cache_read_input_token_cost": 7.5e-8,
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "gpt-4o-mini",
    "displayName": "gpt-4o-mini"
  },
  {
    "id": "vercel_ai_gateway/openai/o1",
    "name": "o1",
    "provider": "vercel_ai_gateway",
    "data": {
      "cache_creation_input_token_cost": 0,
      "cache_read_input_token_cost": 0.0000075,
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "chat",
      "output_cost_per_token": 0.00006,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "o1",
    "displayName": "o1"
  },
  {
    "id": "vercel_ai_gateway/openai/o3",
    "name": "o3",
    "provider": "vercel_ai_gateway",
    "data": {
      "cache_creation_input_token_cost": 0,
      "cache_read_input_token_cost": 5e-7,
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "chat",
      "output_cost_per_token": 0.000008,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "o3",
    "displayName": "o3"
  },
  {
    "id": "vercel_ai_gateway/openai/o3-mini",
    "name": "o3-mini",
    "provider": "vercel_ai_gateway",
    "data": {
      "cache_creation_input_token_cost": 0,
      "cache_read_input_token_cost": 5.5e-7,
      "input_cost_per_token": 0.0000011,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "chat",
      "output_cost_per_token": 0.0000044,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "o3-mini",
    "displayName": "o3-mini"
  },
  {
    "id": "vercel_ai_gateway/openai/o4-mini",
    "name": "o4-mini",
    "provider": "vercel_ai_gateway",
    "data": {
      "cache_creation_input_token_cost": 0,
      "cache_read_input_token_cost": 2.75e-7,
      "input_cost_per_token": 0.0000011,
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "max_tokens": 100000,
      "mode": "chat",
      "output_cost_per_token": 0.0000044,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "o4-mini",
    "displayName": "o4-mini"
  },
  {
    "id": "vercel_ai_gateway/openai/text-embedding-3-large",
    "name": "text-embedding-3-large",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 1.3e-7,
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "max_tokens": 0,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "provider": "vercel_ai_gateway"
    },
    "slug": "text-embedding-3-large",
    "displayName": "text-embedding-3-large"
  },
  {
    "id": "vercel_ai_gateway/openai/text-embedding-3-small",
    "name": "text-embedding-3-small",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 2e-8,
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "max_tokens": 0,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "provider": "vercel_ai_gateway"
    },
    "slug": "text-embedding-3-small",
    "displayName": "text-embedding-3-small"
  },
  {
    "id": "vercel_ai_gateway/openai/text-embedding-ada-002",
    "name": "text-embedding-ada-002",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "max_tokens": 0,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "provider": "vercel_ai_gateway"
    },
    "slug": "text-embedding-ada-002",
    "displayName": "text-embedding-ada-002"
  },
  {
    "id": "vercel_ai_gateway/perplexity/sonar",
    "name": "sonar",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 127000,
      "max_output_tokens": 8000,
      "max_tokens": 8000,
      "mode": "chat",
      "output_cost_per_token": 0.000001,
      "provider": "vercel_ai_gateway"
    },
    "slug": "sonar",
    "displayName": "sonar"
  },
  {
    "id": "vercel_ai_gateway/perplexity/sonar-pro",
    "name": "sonar-pro",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 8000,
      "max_tokens": 8000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "provider": "vercel_ai_gateway"
    },
    "slug": "sonar-pro",
    "displayName": "sonar-pro"
  },
  {
    "id": "vercel_ai_gateway/perplexity/sonar-reasoning",
    "name": "sonar-reasoning",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 127000,
      "max_output_tokens": 8000,
      "max_tokens": 8000,
      "mode": "chat",
      "output_cost_per_token": 0.000005,
      "provider": "vercel_ai_gateway"
    },
    "slug": "sonar-reasoning",
    "displayName": "sonar-reasoning"
  },
  {
    "id": "vercel_ai_gateway/perplexity/sonar-reasoning-pro",
    "name": "sonar-reasoning-pro",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 127000,
      "max_output_tokens": 8000,
      "max_tokens": 8000,
      "mode": "chat",
      "output_cost_per_token": 0.000008,
      "provider": "vercel_ai_gateway"
    },
    "slug": "sonar-reasoning-pro",
    "displayName": "sonar-reasoning-pro"
  },
  {
    "id": "vercel_ai_gateway/vercel/v0-1.0-md",
    "name": "v0-1.0-md",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "v0-1.0-md",
    "displayName": "v0-1.0-md"
  },
  {
    "id": "vercel_ai_gateway/vercel/v0-1.5-md",
    "name": "v0-1.5-md",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "v0-1.5-md",
    "displayName": "v0-1.5-md"
  },
  {
    "id": "vercel_ai_gateway/xai/grok-2",
    "name": "grok-2",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 131072,
      "max_output_tokens": 4000,
      "max_tokens": 4000,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "grok-2",
    "displayName": "grok-2"
  },
  {
    "id": "vercel_ai_gateway/xai/grok-2-vision",
    "name": "grok-2-vision",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "grok-2-vision",
    "displayName": "grok-2-vision"
  },
  {
    "id": "vercel_ai_gateway/xai/grok-3",
    "name": "grok-3",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "grok-3",
    "displayName": "grok-3"
  },
  {
    "id": "vercel_ai_gateway/xai/grok-3-fast",
    "name": "grok-3-fast",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 0.000005,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.000025,
      "supports_function_calling": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "grok-3-fast",
    "displayName": "grok-3-fast"
  },
  {
    "id": "vercel_ai_gateway/xai/grok-3-mini",
    "name": "grok-3-mini",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 5e-7,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "grok-3-mini",
    "displayName": "grok-3-mini"
  },
  {
    "id": "vercel_ai_gateway/xai/grok-3-mini-fast",
    "name": "grok-3-mini-fast",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.000004,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "grok-3-mini-fast",
    "displayName": "grok-3-mini-fast"
  },
  {
    "id": "vercel_ai_gateway/xai/grok-4",
    "name": "grok-4",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "grok-4",
    "displayName": "grok-4"
  },
  {
    "id": "vercel_ai_gateway/zai/glm-4.5",
    "name": "glm-4.5",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.0000022,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "glm-4.5",
    "displayName": "glm-4.5"
  },
  {
    "id": "vercel_ai_gateway/zai/glm-4.5-air",
    "name": "glm-4.5-air",
    "provider": "vercel_ai_gateway",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 96000,
      "max_tokens": 96000,
      "mode": "chat",
      "output_cost_per_token": 0.0000011,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "glm-4.5-air",
    "displayName": "glm-4.5-air"
  },
  {
    "id": "vercel_ai_gateway/zai/glm-4.6",
    "name": "glm-4.6",
    "provider": "vercel_ai_gateway",
    "data": {
      "cache_read_input_token_cost": 1.1e-7,
      "input_cost_per_token": 4.5e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 200000,
      "max_tokens": 200000,
      "mode": "chat",
      "output_cost_per_token": 0.0000018,
      "source": "https://vercel.com/ai-gateway/models/glm-4.6",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vercel_ai_gateway"
    },
    "slug": "glm-4.6",
    "displayName": "glm-4.6"
  },
  {
    "id": "vertex_ai/claude-3-5-haiku",
    "name": "claude-3-5-haiku",
    "provider": "vertex_ai-anthropic_models",
    "data": {
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000005,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-anthropic_models"
    },
    "slug": "claude-3-5-haiku",
    "displayName": "claude-3-5-haiku"
  },
  {
    "id": "vertex_ai/claude-3-5-haiku@20241022",
    "name": "claude-3-5-haiku@20241022",
    "provider": "vertex_ai-anthropic_models",
    "data": {
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000005,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-anthropic_models"
    },
    "slug": "claude-3-5-haiku-20241022",
    "displayName": "claude-3-5-haiku@20241022"
  },
  {
    "id": "vertex_ai/claude-haiku-4-5@20251001",
    "name": "claude-haiku-4-5@20251001",
    "provider": "vertex_ai-anthropic_models",
    "data": {
      "cache_creation_input_token_cost": 0.00000125,
      "cache_read_input_token_cost": 1e-7,
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000005,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/haiku-4-5",
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_native_streaming": true,
      "supports_vision": true,
      "provider": "vertex_ai-anthropic_models"
    },
    "slug": "claude-haiku-4-5-20251001",
    "displayName": "claude-haiku-4-5@20251001"
  },
  {
    "id": "vertex_ai/claude-3-5-sonnet",
    "name": "claude-3-5-sonnet",
    "provider": "vertex_ai-anthropic_models",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "vertex_ai-anthropic_models"
    },
    "slug": "claude-3-5-sonnet",
    "displayName": "claude-3-5-sonnet"
  },
  {
    "id": "vertex_ai/claude-3-5-sonnet-v2",
    "name": "claude-3-5-sonnet-v2",
    "provider": "vertex_ai-anthropic_models",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "vertex_ai-anthropic_models"
    },
    "slug": "claude-3-5-sonnet-v2",
    "displayName": "claude-3-5-sonnet-v2"
  },
  {
    "id": "vertex_ai/claude-3-5-sonnet-v2@20241022",
    "name": "claude-3-5-sonnet-v2@20241022",
    "provider": "vertex_ai-anthropic_models",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "vertex_ai-anthropic_models"
    },
    "slug": "claude-3-5-sonnet-v2-20241022",
    "displayName": "claude-3-5-sonnet-v2@20241022"
  },
  {
    "id": "vertex_ai/claude-3-5-sonnet@20240620",
    "name": "claude-3-5-sonnet@20240620",
    "provider": "vertex_ai-anthropic_models",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "vertex_ai-anthropic_models"
    },
    "slug": "claude-3-5-sonnet-20240620",
    "displayName": "claude-3-5-sonnet@20240620"
  },
  {
    "id": "vertex_ai/claude-3-7-sonnet@20250219",
    "name": "claude-3-7-sonnet@20250219",
    "provider": "vertex_ai-anthropic_models",
    "data": {
      "cache_creation_input_token_cost": 0.00000375,
      "cache_read_input_token_cost": 3e-7,
      "deprecation_date": "2025-06-01",
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "vertex_ai-anthropic_models"
    },
    "slug": "claude-3-7-sonnet-20250219",
    "displayName": "claude-3-7-sonnet@20250219"
  },
  {
    "id": "vertex_ai/claude-3-haiku",
    "name": "claude-3-haiku",
    "provider": "vertex_ai-anthropic_models",
    "data": {
      "input_cost_per_token": 2.5e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00000125,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "vertex_ai-anthropic_models"
    },
    "slug": "claude-3-haiku",
    "displayName": "claude-3-haiku"
  },
  {
    "id": "vertex_ai/claude-3-haiku@20240307",
    "name": "claude-3-haiku@20240307",
    "provider": "vertex_ai-anthropic_models",
    "data": {
      "input_cost_per_token": 2.5e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.00000125,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "vertex_ai-anthropic_models"
    },
    "slug": "claude-3-haiku-20240307",
    "displayName": "claude-3-haiku@20240307"
  },
  {
    "id": "vertex_ai/claude-3-opus",
    "name": "claude-3-opus",
    "provider": "vertex_ai-anthropic_models",
    "data": {
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000075,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "vertex_ai-anthropic_models"
    },
    "slug": "claude-3-opus",
    "displayName": "claude-3-opus"
  },
  {
    "id": "vertex_ai/claude-3-opus@20240229",
    "name": "claude-3-opus@20240229",
    "provider": "vertex_ai-anthropic_models",
    "data": {
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000075,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "vertex_ai-anthropic_models"
    },
    "slug": "claude-3-opus-20240229",
    "displayName": "claude-3-opus@20240229"
  },
  {
    "id": "vertex_ai/claude-3-sonnet",
    "name": "claude-3-sonnet",
    "provider": "vertex_ai-anthropic_models",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "vertex_ai-anthropic_models"
    },
    "slug": "claude-3-sonnet",
    "displayName": "claude-3-sonnet"
  },
  {
    "id": "vertex_ai/claude-3-sonnet@20240229",
    "name": "claude-3-sonnet@20240229",
    "provider": "vertex_ai-anthropic_models",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "vertex_ai-anthropic_models"
    },
    "slug": "claude-3-sonnet-20240229",
    "displayName": "claude-3-sonnet@20240229"
  },
  {
    "id": "vertex_ai/claude-opus-4",
    "name": "claude-opus-4",
    "provider": "vertex_ai-anthropic_models",
    "data": {
      "cache_creation_input_token_cost": 0.00001875,
      "cache_read_input_token_cost": 0.0000015,
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.000075,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "vertex_ai-anthropic_models"
    },
    "slug": "claude-opus-4",
    "displayName": "claude-opus-4"
  },
  {
    "id": "vertex_ai/claude-opus-4-1",
    "name": "claude-opus-4-1",
    "provider": "vertex_ai-anthropic_models",
    "data": {
      "cache_creation_input_token_cost": 0.00001875,
      "cache_read_input_token_cost": 0.0000015,
      "input_cost_per_token": 0.000015,
      "input_cost_per_token_batches": 0.0000075,
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.000075,
      "output_cost_per_token_batches": 0.0000375,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "vertex_ai-anthropic_models"
    },
    "slug": "claude-opus-4-1",
    "displayName": "claude-opus-4-1"
  },
  {
    "id": "vertex_ai/claude-opus-4-1@20250805",
    "name": "claude-opus-4-1@20250805",
    "provider": "vertex_ai-anthropic_models",
    "data": {
      "cache_creation_input_token_cost": 0.00001875,
      "cache_read_input_token_cost": 0.0000015,
      "input_cost_per_token": 0.000015,
      "input_cost_per_token_batches": 0.0000075,
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.000075,
      "output_cost_per_token_batches": 0.0000375,
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "vertex_ai-anthropic_models"
    },
    "slug": "claude-opus-4-1-20250805",
    "displayName": "claude-opus-4-1@20250805"
  },
  {
    "id": "vertex_ai/claude-opus-4-5",
    "name": "claude-opus-4-5",
    "provider": "vertex_ai-anthropic_models",
    "data": {
      "cache_creation_input_token_cost": 0.00000625,
      "cache_read_input_token_cost": 5e-7,
      "input_cost_per_token": 0.000005,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000025,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "vertex_ai-anthropic_models"
    },
    "slug": "claude-opus-4-5",
    "displayName": "claude-opus-4-5"
  },
  {
    "id": "vertex_ai/claude-opus-4-5@20251101",
    "name": "claude-opus-4-5@20251101",
    "provider": "vertex_ai-anthropic_models",
    "data": {
      "cache_creation_input_token_cost": 0.00000625,
      "cache_read_input_token_cost": 5e-7,
      "input_cost_per_token": 0.000005,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000025,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "supports_native_streaming": true,
      "provider": "vertex_ai-anthropic_models"
    },
    "slug": "claude-opus-4-5-20251101",
    "displayName": "claude-opus-4-5@20251101"
  },
  {
    "id": "vertex_ai/claude-sonnet-4-5",
    "name": "claude-sonnet-4-5",
    "provider": "vertex_ai-anthropic_models",
    "data": {
      "cache_creation_input_token_cost": 0.00000375,
      "cache_read_input_token_cost": 3e-7,
      "input_cost_per_token": 0.000003,
      "input_cost_per_token_above_200k_tokens": 0.000006,
      "output_cost_per_token_above_200k_tokens": 0.0000225,
      "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
      "cache_read_input_token_cost_above_200k_tokens": 6e-7,
      "input_cost_per_token_batches": 0.0000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "output_cost_per_token_batches": 0.0000075,
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "vertex_ai-anthropic_models"
    },
    "slug": "claude-sonnet-4-5",
    "displayName": "claude-sonnet-4-5"
  },
  {
    "id": "vertex_ai/claude-sonnet-4-5@20250929",
    "name": "claude-sonnet-4-5@20250929",
    "provider": "vertex_ai-anthropic_models",
    "data": {
      "cache_creation_input_token_cost": 0.00000375,
      "cache_read_input_token_cost": 3e-7,
      "input_cost_per_token": 0.000003,
      "input_cost_per_token_above_200k_tokens": 0.000006,
      "output_cost_per_token_above_200k_tokens": 0.0000225,
      "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
      "cache_read_input_token_cost_above_200k_tokens": 6e-7,
      "input_cost_per_token_batches": 0.0000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "output_cost_per_token_batches": 0.0000075,
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_native_streaming": true,
      "provider": "vertex_ai-anthropic_models"
    },
    "slug": "claude-sonnet-4-5-20250929",
    "displayName": "claude-sonnet-4-5@20250929"
  },
  {
    "id": "vertex_ai/claude-opus-4@20250514",
    "name": "claude-opus-4@20250514",
    "provider": "vertex_ai-anthropic_models",
    "data": {
      "cache_creation_input_token_cost": 0.00001875,
      "cache_read_input_token_cost": 0.0000015,
      "input_cost_per_token": 0.000015,
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "mode": "chat",
      "output_cost_per_token": 0.000075,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "vertex_ai-anthropic_models"
    },
    "slug": "claude-opus-4-20250514",
    "displayName": "claude-opus-4@20250514"
  },
  {
    "id": "vertex_ai/claude-sonnet-4",
    "name": "claude-sonnet-4",
    "provider": "vertex_ai-anthropic_models",
    "data": {
      "cache_creation_input_token_cost": 0.00000375,
      "cache_read_input_token_cost": 3e-7,
      "input_cost_per_token": 0.000003,
      "input_cost_per_token_above_200k_tokens": 0.000006,
      "output_cost_per_token_above_200k_tokens": 0.0000225,
      "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
      "cache_read_input_token_cost_above_200k_tokens": 6e-7,
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "vertex_ai-anthropic_models"
    },
    "slug": "claude-sonnet-4",
    "displayName": "claude-sonnet-4"
  },
  {
    "id": "vertex_ai/claude-sonnet-4@20250514",
    "name": "claude-sonnet-4@20250514",
    "provider": "vertex_ai-anthropic_models",
    "data": {
      "cache_creation_input_token_cost": 0.00000375,
      "cache_read_input_token_cost": 3e-7,
      "input_cost_per_token": 0.000003,
      "input_cost_per_token_above_200k_tokens": 0.000006,
      "output_cost_per_token_above_200k_tokens": 0.0000225,
      "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
      "cache_read_input_token_cost_above_200k_tokens": 6e-7,
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "max_tokens": 64000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "search_context_cost_per_query": {
        "search_context_size_high": 0.01,
        "search_context_size_low": 0.01,
        "search_context_size_medium": 0.01
      },
      "supports_assistant_prefill": true,
      "supports_computer_use": true,
      "supports_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "provider": "vertex_ai-anthropic_models"
    },
    "slug": "claude-sonnet-4-20250514",
    "displayName": "claude-sonnet-4@20250514"
  },
  {
    "id": "vertex_ai/mistralai/codestral-2@001",
    "name": "codestral-2@001",
    "provider": "vertex_ai-mistral_models",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 9e-7,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-mistral_models"
    },
    "slug": "codestral-2-001",
    "displayName": "codestral-2@001"
  },
  {
    "id": "vertex_ai/codestral-2",
    "name": "codestral-2",
    "provider": "vertex_ai-mistral_models",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 9e-7,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-mistral_models"
    },
    "slug": "codestral-2",
    "displayName": "codestral-2"
  },
  {
    "id": "vertex_ai/codestral-2@001",
    "name": "codestral-2@001",
    "provider": "vertex_ai-mistral_models",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 9e-7,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-mistral_models"
    },
    "slug": "codestral-2-001",
    "displayName": "codestral-2@001"
  },
  {
    "id": "vertex_ai/mistralai/codestral-2",
    "name": "codestral-2",
    "provider": "vertex_ai-mistral_models",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 9e-7,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-mistral_models"
    },
    "slug": "codestral-2",
    "displayName": "codestral-2"
  },
  {
    "id": "vertex_ai/codestral-2501",
    "name": "codestral-2501",
    "provider": "vertex_ai-mistral_models",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-mistral_models"
    },
    "slug": "codestral-2501",
    "displayName": "codestral-2501"
  },
  {
    "id": "vertex_ai/codestral@2405",
    "name": "codestral@2405",
    "provider": "vertex_ai-mistral_models",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-mistral_models"
    },
    "slug": "codestral-2405",
    "displayName": "codestral@2405"
  },
  {
    "id": "vertex_ai/codestral@latest",
    "name": "codestral@latest",
    "provider": "vertex_ai-mistral_models",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-mistral_models"
    },
    "slug": "codestral-latest",
    "displayName": "codestral@latest"
  },
  {
    "id": "vertex_ai/deepseek-ai/deepseek-v3.1-maas",
    "name": "deepseek-v3.1-maas",
    "provider": "vertex_ai-deepseek_models",
    "data": {
      "input_cost_per_token": 0.00000135,
      "max_input_tokens": 163840,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.0000054,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
      "supported_regions": [
        "us-west2"
      ],
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-deepseek_models"
    },
    "slug": "deepseek-v3.1-maas",
    "displayName": "deepseek-v3.1-maas"
  },
  {
    "id": "vertex_ai/deepseek-ai/deepseek-v3.2-maas",
    "name": "deepseek-v3.2-maas",
    "provider": "vertex_ai-deepseek_models",
    "data": {
      "input_cost_per_token": 5.6e-7,
      "input_cost_per_token_batches": 2.8e-7,
      "max_input_tokens": 163840,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.00000168,
      "output_cost_per_token_batches": 8.4e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
      "supported_regions": [
        "us-west2"
      ],
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-deepseek_models"
    },
    "slug": "deepseek-v3.2-maas",
    "displayName": "deepseek-v3.2-maas"
  },
  {
    "id": "vertex_ai/deepseek-ai/deepseek-r1-0528-maas",
    "name": "deepseek-r1-0528-maas",
    "provider": "vertex_ai-deepseek_models",
    "data": {
      "input_cost_per_token": 0.00000135,
      "max_input_tokens": 65336,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.0000054,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
      "supports_assistant_prefill": true,
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-deepseek_models"
    },
    "slug": "deepseek-r1-0528-maas",
    "displayName": "deepseek-r1-0528-maas"
  },
  {
    "id": "vertex_ai/gemini-2.5-flash-image",
    "name": "gemini-2.5-flash-image",
    "provider": "vertex_ai-language-models",
    "data": {
      "cache_read_input_token_cost": 3e-8,
      "input_cost_per_audio_token": 0.000001,
      "input_cost_per_token": 3e-7,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_images_per_prompt": 3000,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "max_pdf_size_mb": 30,
      "max_video_length": 1,
      "max_videos_per_prompt": 10,
      "mode": "image_generation",
      "output_cost_per_image": 0.039,
      "output_cost_per_image_token": 0.00003,
      "output_cost_per_reasoning_token": 0.0000025,
      "output_cost_per_token": 0.0000025,
      "rpm": 100000,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/image-generation#edit-an-image",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/completions",
        "/v1/batch"
      ],
      "supported_modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "supported_output_modalities": [
        "text",
        "image"
      ],
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_pdf_input": true,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_url_context": true,
      "supports_vision": true,
      "supports_web_search": false,
      "tpm": 8000000,
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-2.5-flash-image",
    "displayName": "gemini-2.5-flash-image"
  },
  {
    "id": "vertex_ai/gemini-3-pro-image-preview",
    "name": "gemini-3-pro-image-preview",
    "provider": "vertex_ai-language-models",
    "data": {
      "input_cost_per_image": 0.0011,
      "input_cost_per_token": 0.000002,
      "input_cost_per_token_batches": 0.000001,
      "max_input_tokens": 65536,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "image_generation",
      "output_cost_per_image": 0.134,
      "output_cost_per_image_token": 0.00012,
      "output_cost_per_token": 0.000012,
      "output_cost_per_token_batches": 0.000006,
      "source": "https://docs.cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/3-pro-image",
      "provider": "vertex_ai-language-models"
    },
    "slug": "gemini-3-pro-image-preview",
    "displayName": "gemini-3-pro-image-preview"
  },
  {
    "id": "vertex_ai/deep-research-pro-preview-12-2025",
    "name": "deep-research-pro-preview-12-2025",
    "provider": "vertex_ai-language-models",
    "data": {
      "input_cost_per_image": 0.0011,
      "input_cost_per_token": 0.000002,
      "input_cost_per_token_batches": 0.000001,
      "max_input_tokens": 65536,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "image_generation",
      "output_cost_per_image": 0.134,
      "output_cost_per_image_token": 0.00012,
      "output_cost_per_token": 0.000012,
      "output_cost_per_token_batches": 0.000006,
      "source": "https://docs.cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/3-pro-image",
      "provider": "vertex_ai-language-models"
    },
    "slug": "deep-research-pro-preview-12-2025",
    "displayName": "deep-research-pro-preview-12-2025"
  },
  {
    "id": "vertex_ai/jamba-1.5",
    "name": "jamba-1.5",
    "provider": "vertex_ai-ai21_models",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "supports_tool_choice": true,
      "provider": "vertex_ai-ai21_models"
    },
    "slug": "jamba-1.5",
    "displayName": "jamba-1.5"
  },
  {
    "id": "vertex_ai/jamba-1.5-large",
    "name": "jamba-1.5-large",
    "provider": "vertex_ai-ai21_models",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 0.000008,
      "supports_tool_choice": true,
      "provider": "vertex_ai-ai21_models"
    },
    "slug": "jamba-1.5-large",
    "displayName": "jamba-1.5-large"
  },
  {
    "id": "vertex_ai/jamba-1.5-large@001",
    "name": "jamba-1.5-large@001",
    "provider": "vertex_ai-ai21_models",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 0.000008,
      "supports_tool_choice": true,
      "provider": "vertex_ai-ai21_models"
    },
    "slug": "jamba-1.5-large-001",
    "displayName": "jamba-1.5-large@001"
  },
  {
    "id": "vertex_ai/jamba-1.5-mini",
    "name": "jamba-1.5-mini",
    "provider": "vertex_ai-ai21_models",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "supports_tool_choice": true,
      "provider": "vertex_ai-ai21_models"
    },
    "slug": "jamba-1.5-mini",
    "displayName": "jamba-1.5-mini"
  },
  {
    "id": "vertex_ai/jamba-1.5-mini@001",
    "name": "jamba-1.5-mini@001",
    "provider": "vertex_ai-ai21_models",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 4e-7,
      "supports_tool_choice": true,
      "provider": "vertex_ai-ai21_models"
    },
    "slug": "jamba-1.5-mini-001",
    "displayName": "jamba-1.5-mini@001"
  },
  {
    "id": "vertex_ai/meta/llama-3.1-405b-instruct-maas",
    "name": "llama-3.1-405b-instruct-maas",
    "provider": "vertex_ai-llama_models",
    "data": {
      "input_cost_per_token": 0.000005,
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "max_tokens": 2048,
      "mode": "chat",
      "output_cost_per_token": 0.000016,
      "source": "https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3.2-90b-vision-instruct-maas",
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "vertex_ai-llama_models"
    },
    "slug": "llama-3.1-405b-instruct-maas",
    "displayName": "llama-3.1-405b-instruct-maas"
  },
  {
    "id": "vertex_ai/meta/llama-4-maverick-17b-128e-instruct-maas",
    "name": "llama-4-maverick-17b-128e-instruct-maas",
    "provider": "vertex_ai-llama_models",
    "data": {
      "input_cost_per_token": 3.5e-7,
      "max_input_tokens": 1000000,
      "max_output_tokens": 1000000,
      "max_tokens": 1000000,
      "mode": "chat",
      "output_cost_per_token": 0.00000115,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text",
        "code"
      ],
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-llama_models"
    },
    "slug": "llama-4-maverick-17b-128e-instruct-maas",
    "displayName": "llama-4-maverick-17b-128e-instruct-maas"
  },
  {
    "id": "vertex_ai/meta/llama-4-maverick-17b-16e-instruct-maas",
    "name": "llama-4-maverick-17b-16e-instruct-maas",
    "provider": "vertex_ai-llama_models",
    "data": {
      "input_cost_per_token": 3.5e-7,
      "max_input_tokens": 1000000,
      "max_output_tokens": 1000000,
      "max_tokens": 1000000,
      "mode": "chat",
      "output_cost_per_token": 0.00000115,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text",
        "code"
      ],
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-llama_models"
    },
    "slug": "llama-4-maverick-17b-16e-instruct-maas",
    "displayName": "llama-4-maverick-17b-16e-instruct-maas"
  },
  {
    "id": "vertex_ai/meta/llama-4-scout-17b-128e-instruct-maas",
    "name": "llama-4-scout-17b-128e-instruct-maas",
    "provider": "vertex_ai-llama_models",
    "data": {
      "input_cost_per_token": 2.5e-7,
      "max_input_tokens": 10000000,
      "max_output_tokens": 10000000,
      "max_tokens": 10000000,
      "mode": "chat",
      "output_cost_per_token": 7e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text",
        "code"
      ],
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-llama_models"
    },
    "slug": "llama-4-scout-17b-128e-instruct-maas",
    "displayName": "llama-4-scout-17b-128e-instruct-maas"
  },
  {
    "id": "vertex_ai/meta/llama-4-scout-17b-16e-instruct-maas",
    "name": "llama-4-scout-17b-16e-instruct-maas",
    "provider": "vertex_ai-llama_models",
    "data": {
      "input_cost_per_token": 2.5e-7,
      "max_input_tokens": 10000000,
      "max_output_tokens": 10000000,
      "max_tokens": 10000000,
      "mode": "chat",
      "output_cost_per_token": 7e-7,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text",
        "code"
      ],
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-llama_models"
    },
    "slug": "llama-4-scout-17b-16e-instruct-maas",
    "displayName": "llama-4-scout-17b-16e-instruct-maas"
  },
  {
    "id": "vertex_ai/minimaxai/minimax-m2-maas",
    "name": "minimax-m2-maas",
    "provider": "vertex_ai-minimax_models",
    "data": {
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 196608,
      "max_output_tokens": 196608,
      "max_tokens": 196608,
      "mode": "chat",
      "output_cost_per_token": 0.0000012,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-minimax_models"
    },
    "slug": "minimax-m2-maas",
    "displayName": "minimax-m2-maas"
  },
  {
    "id": "vertex_ai/moonshotai/kimi-k2-thinking-maas",
    "name": "kimi-k2-thinking-maas",
    "provider": "vertex_ai-moonshot_models",
    "data": {
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 0.0000025,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "vertex_ai-moonshot_models"
    },
    "slug": "kimi-k2-thinking-maas",
    "displayName": "kimi-k2-thinking-maas"
  },
  {
    "id": "vertex_ai/zai-org/glm-4.7-maas",
    "name": "glm-4.7-maas",
    "provider": "vertex_ai-zai_models",
    "data": {
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 200000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.0000022,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-zai_models"
    },
    "slug": "glm-4.7-maas",
    "displayName": "glm-4.7-maas"
  },
  {
    "id": "vertex_ai/mistral-medium-3",
    "name": "mistral-medium-3",
    "provider": "vertex_ai-mistral_models",
    "data": {
      "input_cost_per_token": 4e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-mistral_models"
    },
    "slug": "mistral-medium-3",
    "displayName": "mistral-medium-3"
  },
  {
    "id": "vertex_ai/mistral-medium-3@001",
    "name": "mistral-medium-3@001",
    "provider": "vertex_ai-mistral_models",
    "data": {
      "input_cost_per_token": 4e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-mistral_models"
    },
    "slug": "mistral-medium-3-001",
    "displayName": "mistral-medium-3@001"
  },
  {
    "id": "vertex_ai/mistralai/mistral-medium-3",
    "name": "mistral-medium-3",
    "provider": "vertex_ai-mistral_models",
    "data": {
      "input_cost_per_token": 4e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-mistral_models"
    },
    "slug": "mistral-medium-3",
    "displayName": "mistral-medium-3"
  },
  {
    "id": "vertex_ai/mistralai/mistral-medium-3@001",
    "name": "mistral-medium-3@001",
    "provider": "vertex_ai-mistral_models",
    "data": {
      "input_cost_per_token": 4e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000002,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-mistral_models"
    },
    "slug": "mistral-medium-3-001",
    "displayName": "mistral-medium-3@001"
  },
  {
    "id": "vertex_ai/mistral-large-2411",
    "name": "mistral-large-2411",
    "provider": "vertex_ai-mistral_models",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 128000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000006,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-mistral_models"
    },
    "slug": "mistral-large-2411",
    "displayName": "mistral-large-2411"
  },
  {
    "id": "vertex_ai/mistral-large@2407",
    "name": "mistral-large@2407",
    "provider": "vertex_ai-mistral_models",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 128000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000006,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-mistral_models"
    },
    "slug": "mistral-large-2407",
    "displayName": "mistral-large@2407"
  },
  {
    "id": "vertex_ai/mistral-large@2411-001",
    "name": "mistral-large@2411-001",
    "provider": "vertex_ai-mistral_models",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 128000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000006,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-mistral_models"
    },
    "slug": "mistral-large-2411-001",
    "displayName": "mistral-large@2411-001"
  },
  {
    "id": "vertex_ai/mistral-large@latest",
    "name": "mistral-large@latest",
    "provider": "vertex_ai-mistral_models",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 128000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000006,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-mistral_models"
    },
    "slug": "mistral-large-latest",
    "displayName": "mistral-large@latest"
  },
  {
    "id": "vertex_ai/mistral-nemo@2407",
    "name": "mistral-nemo@2407",
    "provider": "vertex_ai-mistral_models",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000003,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-mistral_models"
    },
    "slug": "mistral-nemo-2407",
    "displayName": "mistral-nemo@2407"
  },
  {
    "id": "vertex_ai/mistral-nemo@latest",
    "name": "mistral-nemo@latest",
    "provider": "vertex_ai-mistral_models",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 1.5e-7,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-mistral_models"
    },
    "slug": "mistral-nemo-latest",
    "displayName": "mistral-nemo@latest"
  },
  {
    "id": "vertex_ai/mistral-small-2503",
    "name": "mistral-small-2503",
    "provider": "vertex_ai-mistral_models",
    "data": {
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "mode": "chat",
      "output_cost_per_token": 0.000003,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "provider": "vertex_ai-mistral_models"
    },
    "slug": "mistral-small-2503",
    "displayName": "mistral-small-2503"
  },
  {
    "id": "vertex_ai/mistral-small-2503@001",
    "name": "mistral-small-2503@001",
    "provider": "vertex_ai-mistral_models",
    "data": {
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "max_tokens": 8191,
      "mode": "chat",
      "output_cost_per_token": 0.000003,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-mistral_models"
    },
    "slug": "mistral-small-2503-001",
    "displayName": "mistral-small-2503@001"
  },
  {
    "id": "vertex_ai/deepseek-ai/deepseek-ocr-maas",
    "name": "deepseek-ocr-maas",
    "provider": "vertex_ai",
    "data": {
      "mode": "ocr",
      "input_cost_per_token": 3e-7,
      "output_cost_per_token": 0.0000012,
      "ocr_cost_per_page": 0.0003,
      "source": "https://cloud.google.com/vertex-ai/pricing",
      "provider": "vertex_ai"
    },
    "slug": "deepseek-ocr-maas",
    "displayName": "deepseek-ocr-maas"
  },
  {
    "id": "vertex_ai/openai/gpt-oss-120b-maas",
    "name": "gpt-oss-120b-maas",
    "provider": "vertex_ai-openai_models",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 6e-7,
      "source": "https://console.cloud.google.com/vertex-ai/publishers/openai/model-garden/gpt-oss-120b-maas",
      "supports_reasoning": true,
      "provider": "vertex_ai-openai_models"
    },
    "slug": "gpt-oss-120b-maas",
    "displayName": "gpt-oss-120b-maas"
  },
  {
    "id": "vertex_ai/openai/gpt-oss-20b-maas",
    "name": "gpt-oss-20b-maas",
    "provider": "vertex_ai-openai_models",
    "data": {
      "input_cost_per_token": 7.5e-8,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 3e-7,
      "source": "https://console.cloud.google.com/vertex-ai/publishers/openai/model-garden/gpt-oss-120b-maas",
      "supports_reasoning": true,
      "provider": "vertex_ai-openai_models"
    },
    "slug": "gpt-oss-20b-maas",
    "displayName": "gpt-oss-20b-maas"
  },
  {
    "id": "vertex_ai/qwen/qwen3-235b-a22b-instruct-2507-maas",
    "name": "qwen3-235b-a22b-instruct-2507-maas",
    "provider": "vertex_ai-qwen_models",
    "data": {
      "input_cost_per_token": 2.5e-7,
      "max_input_tokens": 262144,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.000001,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
      "supported_regions": [
        "global"
      ],
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-qwen_models"
    },
    "slug": "qwen3-235b-a22b-instruct-2507-maas",
    "displayName": "qwen3-235b-a22b-instruct-2507-maas"
  },
  {
    "id": "vertex_ai/qwen/qwen3-coder-480b-a35b-instruct-maas",
    "name": "qwen3-coder-480b-a35b-instruct-maas",
    "provider": "vertex_ai-qwen_models",
    "data": {
      "input_cost_per_token": 0.000001,
      "max_input_tokens": 262144,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.000004,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
      "supported_regions": [
        "global"
      ],
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-qwen_models"
    },
    "slug": "qwen3-coder-480b-a35b-instruct-maas",
    "displayName": "qwen3-coder-480b-a35b-instruct-maas"
  },
  {
    "id": "vertex_ai/qwen/qwen3-next-80b-a3b-instruct-maas",
    "name": "qwen3-next-80b-a3b-instruct-maas",
    "provider": "vertex_ai-qwen_models",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "max_tokens": 262144,
      "mode": "chat",
      "output_cost_per_token": 0.0000012,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
      "supported_regions": [
        "global"
      ],
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-qwen_models"
    },
    "slug": "qwen3-next-80b-a3b-instruct-maas",
    "displayName": "qwen3-next-80b-a3b-instruct-maas"
  },
  {
    "id": "vertex_ai/qwen/qwen3-next-80b-a3b-thinking-maas",
    "name": "qwen3-next-80b-a3b-thinking-maas",
    "provider": "vertex_ai-qwen_models",
    "data": {
      "input_cost_per_token": 1.5e-7,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "max_tokens": 262144,
      "mode": "chat",
      "output_cost_per_token": 0.0000012,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
      "supported_regions": [
        "global"
      ],
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "provider": "vertex_ai-qwen_models"
    },
    "slug": "qwen3-next-80b-a3b-thinking-maas",
    "displayName": "qwen3-next-80b-a3b-thinking-maas"
  },
  {
    "id": "voyage/rerank-2",
    "name": "rerank-2",
    "provider": "voyage",
    "data": {
      "input_cost_per_token": 5e-8,
      "max_input_tokens": 16000,
      "max_output_tokens": 16000,
      "max_query_tokens": 16000,
      "max_tokens": 16000,
      "mode": "rerank",
      "output_cost_per_token": 0,
      "provider": "voyage"
    },
    "slug": "rerank-2",
    "displayName": "rerank-2"
  },
  {
    "id": "voyage/rerank-2-lite",
    "name": "rerank-2-lite",
    "provider": "voyage",
    "data": {
      "input_cost_per_token": 2e-8,
      "max_input_tokens": 8000,
      "max_output_tokens": 8000,
      "max_query_tokens": 8000,
      "max_tokens": 8000,
      "mode": "rerank",
      "output_cost_per_token": 0,
      "provider": "voyage"
    },
    "slug": "rerank-2-lite",
    "displayName": "rerank-2-lite"
  },
  {
    "id": "voyage/rerank-2.5",
    "name": "rerank-2.5",
    "provider": "voyage",
    "data": {
      "input_cost_per_token": 5e-8,
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "max_query_tokens": 32000,
      "max_tokens": 32000,
      "mode": "rerank",
      "output_cost_per_token": 0,
      "provider": "voyage"
    },
    "slug": "rerank-2.5",
    "displayName": "rerank-2.5"
  },
  {
    "id": "voyage/rerank-2.5-lite",
    "name": "rerank-2.5-lite",
    "provider": "voyage",
    "data": {
      "input_cost_per_token": 2e-8,
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "max_query_tokens": 32000,
      "max_tokens": 32000,
      "mode": "rerank",
      "output_cost_per_token": 0,
      "provider": "voyage"
    },
    "slug": "rerank-2.5-lite",
    "displayName": "rerank-2.5-lite"
  },
  {
    "id": "voyage/voyage-2",
    "name": "voyage-2",
    "provider": "voyage",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 4000,
      "max_tokens": 4000,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "provider": "voyage"
    },
    "slug": "voyage-2",
    "displayName": "voyage-2"
  },
  {
    "id": "voyage/voyage-3",
    "name": "voyage-3",
    "provider": "voyage",
    "data": {
      "input_cost_per_token": 6e-8,
      "max_input_tokens": 32000,
      "max_tokens": 32000,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "provider": "voyage"
    },
    "slug": "voyage-3",
    "displayName": "voyage-3"
  },
  {
    "id": "voyage/voyage-3-large",
    "name": "voyage-3-large",
    "provider": "voyage",
    "data": {
      "input_cost_per_token": 1.8e-7,
      "max_input_tokens": 32000,
      "max_tokens": 32000,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "provider": "voyage"
    },
    "slug": "voyage-3-large",
    "displayName": "voyage-3-large"
  },
  {
    "id": "voyage/voyage-3-lite",
    "name": "voyage-3-lite",
    "provider": "voyage",
    "data": {
      "input_cost_per_token": 2e-8,
      "max_input_tokens": 32000,
      "max_tokens": 32000,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "provider": "voyage"
    },
    "slug": "voyage-3-lite",
    "displayName": "voyage-3-lite"
  },
  {
    "id": "voyage/voyage-3.5",
    "name": "voyage-3.5",
    "provider": "voyage",
    "data": {
      "input_cost_per_token": 6e-8,
      "max_input_tokens": 32000,
      "max_tokens": 32000,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "provider": "voyage"
    },
    "slug": "voyage-3.5",
    "displayName": "voyage-3.5"
  },
  {
    "id": "voyage/voyage-3.5-lite",
    "name": "voyage-3.5-lite",
    "provider": "voyage",
    "data": {
      "input_cost_per_token": 2e-8,
      "max_input_tokens": 32000,
      "max_tokens": 32000,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "provider": "voyage"
    },
    "slug": "voyage-3.5-lite",
    "displayName": "voyage-3.5-lite"
  },
  {
    "id": "voyage/voyage-code-2",
    "name": "voyage-code-2",
    "provider": "voyage",
    "data": {
      "input_cost_per_token": 1.2e-7,
      "max_input_tokens": 16000,
      "max_tokens": 16000,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "provider": "voyage"
    },
    "slug": "voyage-code-2",
    "displayName": "voyage-code-2"
  },
  {
    "id": "voyage/voyage-code-3",
    "name": "voyage-code-3",
    "provider": "voyage",
    "data": {
      "input_cost_per_token": 1.8e-7,
      "max_input_tokens": 32000,
      "max_tokens": 32000,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "provider": "voyage"
    },
    "slug": "voyage-code-3",
    "displayName": "voyage-code-3"
  },
  {
    "id": "voyage/voyage-context-3",
    "name": "voyage-context-3",
    "provider": "voyage",
    "data": {
      "input_cost_per_token": 1.8e-7,
      "max_input_tokens": 120000,
      "max_tokens": 120000,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "provider": "voyage"
    },
    "slug": "voyage-context-3",
    "displayName": "voyage-context-3"
  },
  {
    "id": "voyage/voyage-finance-2",
    "name": "voyage-finance-2",
    "provider": "voyage",
    "data": {
      "input_cost_per_token": 1.2e-7,
      "max_input_tokens": 32000,
      "max_tokens": 32000,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "provider": "voyage"
    },
    "slug": "voyage-finance-2",
    "displayName": "voyage-finance-2"
  },
  {
    "id": "voyage/voyage-large-2",
    "name": "voyage-large-2",
    "provider": "voyage",
    "data": {
      "input_cost_per_token": 1.2e-7,
      "max_input_tokens": 16000,
      "max_tokens": 16000,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "provider": "voyage"
    },
    "slug": "voyage-large-2",
    "displayName": "voyage-large-2"
  },
  {
    "id": "voyage/voyage-law-2",
    "name": "voyage-law-2",
    "provider": "voyage",
    "data": {
      "input_cost_per_token": 1.2e-7,
      "max_input_tokens": 16000,
      "max_tokens": 16000,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "provider": "voyage"
    },
    "slug": "voyage-law-2",
    "displayName": "voyage-law-2"
  },
  {
    "id": "voyage/voyage-lite-01",
    "name": "voyage-lite-01",
    "provider": "voyage",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 4096,
      "max_tokens": 4096,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "provider": "voyage"
    },
    "slug": "voyage-lite-01",
    "displayName": "voyage-lite-01"
  },
  {
    "id": "voyage/voyage-lite-02-instruct",
    "name": "voyage-lite-02-instruct",
    "provider": "voyage",
    "data": {
      "input_cost_per_token": 1e-7,
      "max_input_tokens": 4000,
      "max_tokens": 4000,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "provider": "voyage"
    },
    "slug": "voyage-lite-02-instruct",
    "displayName": "voyage-lite-02-instruct"
  },
  {
    "id": "voyage/voyage-multimodal-3",
    "name": "voyage-multimodal-3",
    "provider": "voyage",
    "data": {
      "input_cost_per_token": 1.2e-7,
      "max_input_tokens": 32000,
      "max_tokens": 32000,
      "mode": "embedding",
      "output_cost_per_token": 0,
      "provider": "voyage"
    },
    "slug": "voyage-multimodal-3",
    "displayName": "voyage-multimodal-3"
  },
  {
    "id": "wandb/openai/gpt-oss-120b",
    "name": "gpt-oss-120b",
    "provider": "wandb",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 1.5e-8,
      "output_cost_per_token": 6e-8,
      "mode": "chat",
      "provider": "wandb"
    },
    "slug": "gpt-oss-120b",
    "displayName": "gpt-oss-120b"
  },
  {
    "id": "wandb/openai/gpt-oss-20b",
    "name": "gpt-oss-20b",
    "provider": "wandb",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 5e-9,
      "output_cost_per_token": 2e-8,
      "mode": "chat",
      "provider": "wandb"
    },
    "slug": "gpt-oss-20b",
    "displayName": "gpt-oss-20b"
  },
  {
    "id": "wandb/zai-org/GLM-4.5",
    "name": "GLM-4.5",
    "provider": "wandb",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 5.5e-8,
      "output_cost_per_token": 2.0000000000000002e-7,
      "mode": "chat",
      "provider": "wandb"
    },
    "slug": "glm-4.5",
    "displayName": "GLM-4.5"
  },
  {
    "id": "wandb/Qwen/Qwen3-235B-A22B-Instruct-2507",
    "name": "Qwen3-235B-A22B-Instruct-2507",
    "provider": "wandb",
    "data": {
      "max_tokens": 262144,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_token": 1e-8,
      "output_cost_per_token": 1e-8,
      "mode": "chat",
      "provider": "wandb"
    },
    "slug": "qwen3-235b-a22b-instruct-2507",
    "displayName": "Qwen3-235B-A22B-Instruct-2507"
  },
  {
    "id": "wandb/Qwen/Qwen3-Coder-480B-A35B-Instruct",
    "name": "Qwen3-Coder-480B-A35B-Instruct",
    "provider": "wandb",
    "data": {
      "max_tokens": 262144,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_token": 1.0000000000000001e-7,
      "output_cost_per_token": 1.5e-7,
      "mode": "chat",
      "provider": "wandb"
    },
    "slug": "qwen3-coder-480b-a35b-instruct",
    "displayName": "Qwen3-Coder-480B-A35B-Instruct"
  },
  {
    "id": "wandb/Qwen/Qwen3-235B-A22B-Thinking-2507",
    "name": "Qwen3-235B-A22B-Thinking-2507",
    "provider": "wandb",
    "data": {
      "max_tokens": 262144,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_token": 1e-8,
      "output_cost_per_token": 1e-8,
      "mode": "chat",
      "provider": "wandb"
    },
    "slug": "qwen3-235b-a22b-thinking-2507",
    "displayName": "Qwen3-235B-A22B-Thinking-2507"
  },
  {
    "id": "wandb/moonshotai/Kimi-K2-Instruct",
    "name": "Kimi-K2-Instruct",
    "provider": "wandb",
    "data": {
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 6e-7,
      "output_cost_per_token": 0.0000025,
      "mode": "chat",
      "provider": "wandb"
    },
    "slug": "kimi-k2-instruct",
    "displayName": "Kimi-K2-Instruct"
  },
  {
    "id": "wandb/meta-llama/Llama-3.1-8B-Instruct",
    "name": "Llama-3.1-8B-Instruct",
    "provider": "wandb",
    "data": {
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 2.2e-8,
      "output_cost_per_token": 2.2e-8,
      "mode": "chat",
      "provider": "wandb"
    },
    "slug": "llama-3.1-8b-instruct",
    "displayName": "Llama-3.1-8B-Instruct"
  },
  {
    "id": "wandb/deepseek-ai/DeepSeek-V3.1",
    "name": "DeepSeek-V3.1",
    "provider": "wandb",
    "data": {
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 5.5e-8,
      "output_cost_per_token": 1.65e-7,
      "mode": "chat",
      "provider": "wandb"
    },
    "slug": "deepseek-v3.1",
    "displayName": "DeepSeek-V3.1"
  },
  {
    "id": "wandb/deepseek-ai/DeepSeek-R1-0528",
    "name": "DeepSeek-R1-0528",
    "provider": "wandb",
    "data": {
      "max_tokens": 161000,
      "max_input_tokens": 161000,
      "max_output_tokens": 161000,
      "input_cost_per_token": 1.35e-7,
      "output_cost_per_token": 5.4e-7,
      "mode": "chat",
      "provider": "wandb"
    },
    "slug": "deepseek-r1-0528",
    "displayName": "DeepSeek-R1-0528"
  },
  {
    "id": "wandb/deepseek-ai/DeepSeek-V3-0324",
    "name": "DeepSeek-V3-0324",
    "provider": "wandb",
    "data": {
      "max_tokens": 161000,
      "max_input_tokens": 161000,
      "max_output_tokens": 161000,
      "input_cost_per_token": 1.14e-7,
      "output_cost_per_token": 2.75e-7,
      "mode": "chat",
      "provider": "wandb"
    },
    "slug": "deepseek-v3-0324",
    "displayName": "DeepSeek-V3-0324"
  },
  {
    "id": "wandb/meta-llama/Llama-3.3-70B-Instruct",
    "name": "Llama-3.3-70B-Instruct",
    "provider": "wandb",
    "data": {
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 7.099999999999999e-8,
      "output_cost_per_token": 7.099999999999999e-8,
      "mode": "chat",
      "provider": "wandb"
    },
    "slug": "llama-3.3-70b-instruct",
    "displayName": "Llama-3.3-70B-Instruct"
  },
  {
    "id": "wandb/meta-llama/Llama-4-Scout-17B-16E-Instruct",
    "name": "Llama-4-Scout-17B-16E-Instruct",
    "provider": "wandb",
    "data": {
      "max_tokens": 64000,
      "max_input_tokens": 64000,
      "max_output_tokens": 64000,
      "input_cost_per_token": 1.7e-8,
      "output_cost_per_token": 6.600000000000001e-8,
      "mode": "chat",
      "provider": "wandb"
    },
    "slug": "llama-4-scout-17b-16e-instruct",
    "displayName": "Llama-4-Scout-17B-16E-Instruct"
  },
  {
    "id": "wandb/microsoft/Phi-4-mini-instruct",
    "name": "Phi-4-mini-instruct",
    "provider": "wandb",
    "data": {
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 8e-9,
      "output_cost_per_token": 3.5e-8,
      "mode": "chat",
      "provider": "wandb"
    },
    "slug": "phi-4-mini-instruct",
    "displayName": "Phi-4-mini-instruct"
  },
  {
    "id": "watsonx/ibm/granite-3-8b-instruct",
    "name": "granite-3-8b-instruct",
    "provider": "watsonx",
    "data": {
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "max_tokens": 1024,
      "mode": "chat",
      "output_cost_per_token": 2e-7,
      "supports_audio_input": false,
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_parallel_function_calling": false,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "watsonx"
    },
    "slug": "granite-3-8b-instruct",
    "displayName": "granite-3-8b-instruct"
  },
  {
    "id": "watsonx/mistralai/mistral-large",
    "name": "mistral-large",
    "provider": "watsonx",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supports_audio_input": false,
      "supports_audio_output": false,
      "supports_function_calling": true,
      "supports_parallel_function_calling": false,
      "supports_prompt_caching": true,
      "supports_response_schema": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_vision": false,
      "provider": "watsonx"
    },
    "slug": "mistral-large",
    "displayName": "mistral-large"
  },
  {
    "id": "watsonx/bigscience/mt0-xxl-13b",
    "name": "mt0-xxl-13b",
    "provider": "watsonx",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.0005,
      "output_cost_per_token": 2e-9,
      "mode": "chat",
      "supports_function_calling": false,
      "supports_parallel_function_calling": false,
      "supports_vision": false,
      "provider": "watsonx"
    },
    "slug": "mt0-xxl-13b",
    "displayName": "mt0-xxl-13b"
  },
  {
    "id": "watsonx/core42/jais-13b-chat",
    "name": "jais-13b-chat",
    "provider": "watsonx",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.0005,
      "output_cost_per_token": 2e-9,
      "mode": "chat",
      "supports_function_calling": false,
      "supports_parallel_function_calling": false,
      "supports_vision": false,
      "provider": "watsonx"
    },
    "slug": "jais-13b-chat",
    "displayName": "jais-13b-chat"
  },
  {
    "id": "watsonx/google/flan-t5-xl-3b",
    "name": "flan-t5-xl-3b",
    "provider": "watsonx",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 6e-7,
      "output_cost_per_token": 6e-7,
      "mode": "chat",
      "supports_function_calling": false,
      "supports_parallel_function_calling": false,
      "supports_vision": false,
      "provider": "watsonx"
    },
    "slug": "flan-t5-xl-3b",
    "displayName": "flan-t5-xl-3b"
  },
  {
    "id": "watsonx/ibm/granite-13b-chat-v2",
    "name": "granite-13b-chat-v2",
    "provider": "watsonx",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 6e-7,
      "output_cost_per_token": 6e-7,
      "mode": "chat",
      "supports_function_calling": false,
      "supports_parallel_function_calling": false,
      "supports_vision": false,
      "provider": "watsonx"
    },
    "slug": "granite-13b-chat-v2",
    "displayName": "granite-13b-chat-v2"
  },
  {
    "id": "watsonx/ibm/granite-13b-instruct-v2",
    "name": "granite-13b-instruct-v2",
    "provider": "watsonx",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 6e-7,
      "output_cost_per_token": 6e-7,
      "mode": "chat",
      "supports_function_calling": false,
      "supports_parallel_function_calling": false,
      "supports_vision": false,
      "provider": "watsonx"
    },
    "slug": "granite-13b-instruct-v2",
    "displayName": "granite-13b-instruct-v2"
  },
  {
    "id": "watsonx/ibm/granite-3-3-8b-instruct",
    "name": "granite-3-3-8b-instruct",
    "provider": "watsonx",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": false,
      "provider": "watsonx"
    },
    "slug": "granite-3-3-8b-instruct",
    "displayName": "granite-3-3-8b-instruct"
  },
  {
    "id": "watsonx/ibm/granite-4-h-small",
    "name": "granite-4-h-small",
    "provider": "watsonx",
    "data": {
      "max_tokens": 20480,
      "max_input_tokens": 20480,
      "max_output_tokens": 20480,
      "input_cost_per_token": 6e-8,
      "output_cost_per_token": 2.5e-7,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": false,
      "provider": "watsonx"
    },
    "slug": "granite-4-h-small",
    "displayName": "granite-4-h-small"
  },
  {
    "id": "watsonx/ibm/granite-guardian-3-2-2b",
    "name": "granite-guardian-3-2-2b",
    "provider": "watsonx",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "supports_function_calling": false,
      "supports_parallel_function_calling": false,
      "supports_vision": false,
      "provider": "watsonx"
    },
    "slug": "granite-guardian-3-2-2b",
    "displayName": "granite-guardian-3-2-2b"
  },
  {
    "id": "watsonx/ibm/granite-guardian-3-3-8b",
    "name": "granite-guardian-3-3-8b",
    "provider": "watsonx",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "supports_function_calling": false,
      "supports_parallel_function_calling": false,
      "supports_vision": false,
      "provider": "watsonx"
    },
    "slug": "granite-guardian-3-3-8b",
    "displayName": "granite-guardian-3-3-8b"
  },
  {
    "id": "watsonx/ibm/granite-ttm-1024-96-r2",
    "name": "granite-ttm-1024-96-r2",
    "provider": "watsonx",
    "data": {
      "max_tokens": 512,
      "max_input_tokens": 512,
      "max_output_tokens": 512,
      "input_cost_per_token": 3.8e-7,
      "output_cost_per_token": 3.8e-7,
      "mode": "chat",
      "supports_function_calling": false,
      "supports_parallel_function_calling": false,
      "supports_vision": false,
      "provider": "watsonx"
    },
    "slug": "granite-ttm-1024-96-r2",
    "displayName": "granite-ttm-1024-96-r2"
  },
  {
    "id": "watsonx/ibm/granite-ttm-1536-96-r2",
    "name": "granite-ttm-1536-96-r2",
    "provider": "watsonx",
    "data": {
      "max_tokens": 512,
      "max_input_tokens": 512,
      "max_output_tokens": 512,
      "input_cost_per_token": 3.8e-7,
      "output_cost_per_token": 3.8e-7,
      "mode": "chat",
      "supports_function_calling": false,
      "supports_parallel_function_calling": false,
      "supports_vision": false,
      "provider": "watsonx"
    },
    "slug": "granite-ttm-1536-96-r2",
    "displayName": "granite-ttm-1536-96-r2"
  },
  {
    "id": "watsonx/ibm/granite-ttm-512-96-r2",
    "name": "granite-ttm-512-96-r2",
    "provider": "watsonx",
    "data": {
      "max_tokens": 512,
      "max_input_tokens": 512,
      "max_output_tokens": 512,
      "input_cost_per_token": 3.8e-7,
      "output_cost_per_token": 3.8e-7,
      "mode": "chat",
      "supports_function_calling": false,
      "supports_parallel_function_calling": false,
      "supports_vision": false,
      "provider": "watsonx"
    },
    "slug": "granite-ttm-512-96-r2",
    "displayName": "granite-ttm-512-96-r2"
  },
  {
    "id": "watsonx/ibm/granite-vision-3-2-2b",
    "name": "granite-vision-3-2-2b",
    "provider": "watsonx",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "supports_function_calling": false,
      "supports_parallel_function_calling": false,
      "supports_vision": true,
      "provider": "watsonx"
    },
    "slug": "granite-vision-3-2-2b",
    "displayName": "granite-vision-3-2-2b"
  },
  {
    "id": "watsonx/meta-llama/llama-3-2-11b-vision-instruct",
    "name": "llama-3-2-11b-vision-instruct",
    "provider": "watsonx",
    "data": {
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 3.5e-7,
      "output_cost_per_token": 3.5e-7,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "provider": "watsonx"
    },
    "slug": "llama-3-2-11b-vision-instruct",
    "displayName": "llama-3-2-11b-vision-instruct"
  },
  {
    "id": "watsonx/meta-llama/llama-3-2-1b-instruct",
    "name": "llama-3-2-1b-instruct",
    "provider": "watsonx",
    "data": {
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": false,
      "provider": "watsonx"
    },
    "slug": "llama-3-2-1b-instruct",
    "displayName": "llama-3-2-1b-instruct"
  },
  {
    "id": "watsonx/meta-llama/llama-3-2-3b-instruct",
    "name": "llama-3-2-3b-instruct",
    "provider": "watsonx",
    "data": {
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 1.5e-7,
      "output_cost_per_token": 1.5e-7,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": false,
      "provider": "watsonx"
    },
    "slug": "llama-3-2-3b-instruct",
    "displayName": "llama-3-2-3b-instruct"
  },
  {
    "id": "watsonx/meta-llama/llama-3-2-90b-vision-instruct",
    "name": "llama-3-2-90b-vision-instruct",
    "provider": "watsonx",
    "data": {
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.000002,
      "output_cost_per_token": 0.000002,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true,
      "provider": "watsonx"
    },
    "slug": "llama-3-2-90b-vision-instruct",
    "displayName": "llama-3-2-90b-vision-instruct"
  },
  {
    "id": "watsonx/meta-llama/llama-3-3-70b-instruct",
    "name": "llama-3-3-70b-instruct",
    "provider": "watsonx",
    "data": {
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 7.1e-7,
      "output_cost_per_token": 7.1e-7,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": false,
      "provider": "watsonx"
    },
    "slug": "llama-3-3-70b-instruct",
    "displayName": "llama-3-3-70b-instruct"
  },
  {
    "id": "watsonx/meta-llama/llama-4-maverick-17b",
    "name": "llama-4-maverick-17b",
    "provider": "watsonx",
    "data": {
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 3.5e-7,
      "output_cost_per_token": 0.0000014,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": false,
      "provider": "watsonx"
    },
    "slug": "llama-4-maverick-17b",
    "displayName": "llama-4-maverick-17b"
  },
  {
    "id": "watsonx/meta-llama/llama-guard-3-11b-vision",
    "name": "llama-guard-3-11b-vision",
    "provider": "watsonx",
    "data": {
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 3.5e-7,
      "output_cost_per_token": 3.5e-7,
      "mode": "chat",
      "supports_function_calling": false,
      "supports_parallel_function_calling": false,
      "supports_vision": true,
      "provider": "watsonx"
    },
    "slug": "llama-guard-3-11b-vision",
    "displayName": "llama-guard-3-11b-vision"
  },
  {
    "id": "watsonx/mistralai/mistral-medium-2505",
    "name": "mistral-medium-2505",
    "provider": "watsonx",
    "data": {
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.00001,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": false,
      "provider": "watsonx"
    },
    "slug": "mistral-medium-2505",
    "displayName": "mistral-medium-2505"
  },
  {
    "id": "watsonx/mistralai/mistral-small-2503",
    "name": "mistral-small-2503",
    "provider": "watsonx",
    "data": {
      "max_tokens": 32000,
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 3e-7,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": false,
      "provider": "watsonx"
    },
    "slug": "mistral-small-2503",
    "displayName": "mistral-small-2503"
  },
  {
    "id": "watsonx/mistralai/mistral-small-3-1-24b-instruct-2503",
    "name": "mistral-small-3-1-24b-instruct-2503",
    "provider": "watsonx",
    "data": {
      "max_tokens": 32000,
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 3e-7,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": false,
      "provider": "watsonx"
    },
    "slug": "mistral-small-3-1-24b-instruct-2503",
    "displayName": "mistral-small-3-1-24b-instruct-2503"
  },
  {
    "id": "watsonx/mistralai/pixtral-12b-2409",
    "name": "pixtral-12b-2409",
    "provider": "watsonx",
    "data": {
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 3.5e-7,
      "output_cost_per_token": 3.5e-7,
      "mode": "chat",
      "supports_function_calling": false,
      "supports_parallel_function_calling": false,
      "supports_vision": true,
      "provider": "watsonx"
    },
    "slug": "pixtral-12b-2409",
    "displayName": "pixtral-12b-2409"
  },
  {
    "id": "watsonx/openai/gpt-oss-120b",
    "name": "gpt-oss-120b",
    "provider": "watsonx",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1.5e-7,
      "output_cost_per_token": 6e-7,
      "mode": "chat",
      "supports_function_calling": false,
      "supports_parallel_function_calling": false,
      "supports_vision": false,
      "provider": "watsonx"
    },
    "slug": "gpt-oss-120b",
    "displayName": "gpt-oss-120b"
  },
  {
    "id": "watsonx/sdaia/allam-1-13b-instruct",
    "name": "allam-1-13b-instruct",
    "provider": "watsonx",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.0000018,
      "output_cost_per_token": 0.0000018,
      "mode": "chat",
      "supports_function_calling": false,
      "supports_parallel_function_calling": false,
      "supports_vision": false,
      "provider": "watsonx"
    },
    "slug": "allam-1-13b-instruct",
    "displayName": "allam-1-13b-instruct"
  },
  {
    "id": "xai/grok-2",
    "name": "grok-2",
    "provider": "xai",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "xai"
    },
    "slug": "grok-2",
    "displayName": "grok-2"
  },
  {
    "id": "xai/grok-2-1212",
    "name": "grok-2-1212",
    "provider": "xai",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "xai"
    },
    "slug": "grok-2-1212",
    "displayName": "grok-2-1212"
  },
  {
    "id": "xai/grok-2-latest",
    "name": "grok-2-latest",
    "provider": "xai",
    "data": {
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "xai"
    },
    "slug": "grok-2-latest",
    "displayName": "grok-2-latest"
  },
  {
    "id": "xai/grok-2-vision",
    "name": "grok-2-vision",
    "provider": "xai",
    "data": {
      "input_cost_per_image": 0.000002,
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "xai"
    },
    "slug": "grok-2-vision",
    "displayName": "grok-2-vision"
  },
  {
    "id": "xai/grok-2-vision-1212",
    "name": "grok-2-vision-1212",
    "provider": "xai",
    "data": {
      "input_cost_per_image": 0.000002,
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "xai"
    },
    "slug": "grok-2-vision-1212",
    "displayName": "grok-2-vision-1212"
  },
  {
    "id": "xai/grok-2-vision-latest",
    "name": "grok-2-vision-latest",
    "provider": "xai",
    "data": {
      "input_cost_per_image": 0.000002,
      "input_cost_per_token": 0.000002,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "mode": "chat",
      "output_cost_per_token": 0.00001,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "xai"
    },
    "slug": "grok-2-vision-latest",
    "displayName": "grok-2-vision-latest"
  },
  {
    "id": "xai/grok-3",
    "name": "grok-3",
    "provider": "xai",
    "data": {
      "cache_read_input_token_cost": 7.5e-7,
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "source": "https://x.ai/api#pricing",
      "supports_function_calling": true,
      "supports_response_schema": false,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "xai"
    },
    "slug": "grok-3",
    "displayName": "grok-3"
  },
  {
    "id": "xai/grok-3-beta",
    "name": "grok-3-beta",
    "provider": "xai",
    "data": {
      "cache_read_input_token_cost": 7.5e-7,
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "source": "https://x.ai/api#pricing",
      "supports_function_calling": true,
      "supports_response_schema": false,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "xai"
    },
    "slug": "grok-3-beta",
    "displayName": "grok-3-beta"
  },
  {
    "id": "xai/grok-3-fast-beta",
    "name": "grok-3-fast-beta",
    "provider": "xai",
    "data": {
      "cache_read_input_token_cost": 0.00000125,
      "input_cost_per_token": 0.000005,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.000025,
      "source": "https://x.ai/api#pricing",
      "supports_function_calling": true,
      "supports_response_schema": false,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "xai"
    },
    "slug": "grok-3-fast-beta",
    "displayName": "grok-3-fast-beta"
  },
  {
    "id": "xai/grok-3-fast-latest",
    "name": "grok-3-fast-latest",
    "provider": "xai",
    "data": {
      "cache_read_input_token_cost": 0.00000125,
      "input_cost_per_token": 0.000005,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.000025,
      "source": "https://x.ai/api#pricing",
      "supports_function_calling": true,
      "supports_response_schema": false,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "xai"
    },
    "slug": "grok-3-fast-latest",
    "displayName": "grok-3-fast-latest"
  },
  {
    "id": "xai/grok-3-latest",
    "name": "grok-3-latest",
    "provider": "xai",
    "data": {
      "cache_read_input_token_cost": 7.5e-7,
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "source": "https://x.ai/api#pricing",
      "supports_function_calling": true,
      "supports_response_schema": false,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "xai"
    },
    "slug": "grok-3-latest",
    "displayName": "grok-3-latest"
  },
  {
    "id": "xai/grok-3-mini",
    "name": "grok-3-mini",
    "provider": "xai",
    "data": {
      "cache_read_input_token_cost": 7.5e-8,
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 5e-7,
      "source": "https://x.ai/api#pricing",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": false,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "xai"
    },
    "slug": "grok-3-mini",
    "displayName": "grok-3-mini"
  },
  {
    "id": "xai/grok-3-mini-beta",
    "name": "grok-3-mini-beta",
    "provider": "xai",
    "data": {
      "cache_read_input_token_cost": 7.5e-8,
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 5e-7,
      "source": "https://x.ai/api#pricing",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": false,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "xai"
    },
    "slug": "grok-3-mini-beta",
    "displayName": "grok-3-mini-beta"
  },
  {
    "id": "xai/grok-3-mini-fast",
    "name": "grok-3-mini-fast",
    "provider": "xai",
    "data": {
      "cache_read_input_token_cost": 1.5e-7,
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.000004,
      "source": "https://x.ai/api#pricing",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": false,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "xai"
    },
    "slug": "grok-3-mini-fast",
    "displayName": "grok-3-mini-fast"
  },
  {
    "id": "xai/grok-3-mini-fast-beta",
    "name": "grok-3-mini-fast-beta",
    "provider": "xai",
    "data": {
      "cache_read_input_token_cost": 1.5e-7,
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.000004,
      "source": "https://x.ai/api#pricing",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": false,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "xai"
    },
    "slug": "grok-3-mini-fast-beta",
    "displayName": "grok-3-mini-fast-beta"
  },
  {
    "id": "xai/grok-3-mini-fast-latest",
    "name": "grok-3-mini-fast-latest",
    "provider": "xai",
    "data": {
      "cache_read_input_token_cost": 1.5e-7,
      "input_cost_per_token": 6e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.000004,
      "source": "https://x.ai/api#pricing",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": false,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "xai"
    },
    "slug": "grok-3-mini-fast-latest",
    "displayName": "grok-3-mini-fast-latest"
  },
  {
    "id": "xai/grok-3-mini-latest",
    "name": "grok-3-mini-latest",
    "provider": "xai",
    "data": {
      "cache_read_input_token_cost": 7.5e-8,
      "input_cost_per_token": 3e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 5e-7,
      "source": "https://x.ai/api#pricing",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": false,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "xai"
    },
    "slug": "grok-3-mini-latest",
    "displayName": "grok-3-mini-latest"
  },
  {
    "id": "xai/grok-4",
    "name": "grok-4",
    "provider": "xai",
    "data": {
      "input_cost_per_token": 0.000003,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "source": "https://docs.x.ai/docs/models",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "xai"
    },
    "slug": "grok-4",
    "displayName": "grok-4"
  },
  {
    "id": "xai/grok-4-fast-reasoning",
    "name": "grok-4-fast-reasoning",
    "provider": "xai",
    "data": {
      "max_input_tokens": 2000000,
      "max_output_tokens": 2000000,
      "max_tokens": 2000000,
      "mode": "chat",
      "input_cost_per_token": 2e-7,
      "input_cost_per_token_above_128k_tokens": 4e-7,
      "output_cost_per_token": 5e-7,
      "output_cost_per_token_above_128k_tokens": 0.000001,
      "cache_read_input_token_cost": 5e-8,
      "source": "https://docs.x.ai/docs/models",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "xai"
    },
    "slug": "grok-4-fast-reasoning",
    "displayName": "grok-4-fast-reasoning"
  },
  {
    "id": "xai/grok-4-fast-non-reasoning",
    "name": "grok-4-fast-non-reasoning",
    "provider": "xai",
    "data": {
      "max_input_tokens": 2000000,
      "max_output_tokens": 2000000,
      "cache_read_input_token_cost": 5e-8,
      "max_tokens": 2000000,
      "mode": "chat",
      "input_cost_per_token": 2e-7,
      "input_cost_per_token_above_128k_tokens": 4e-7,
      "output_cost_per_token": 5e-7,
      "output_cost_per_token_above_128k_tokens": 0.000001,
      "source": "https://docs.x.ai/docs/models",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "xai"
    },
    "slug": "grok-4-fast-non-reasoning",
    "displayName": "grok-4-fast-non-reasoning"
  },
  {
    "id": "xai/grok-4-0709",
    "name": "grok-4-0709",
    "provider": "xai",
    "data": {
      "input_cost_per_token": 0.000003,
      "input_cost_per_token_above_128k_tokens": 0.000006,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "output_cost_per_token_above_128k_tokens": 0.00003,
      "source": "https://docs.x.ai/docs/models",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "xai"
    },
    "slug": "grok-4-0709",
    "displayName": "grok-4-0709"
  },
  {
    "id": "xai/grok-4-latest",
    "name": "grok-4-latest",
    "provider": "xai",
    "data": {
      "input_cost_per_token": 0.000003,
      "input_cost_per_token_above_128k_tokens": 0.000006,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "output_cost_per_token_above_128k_tokens": 0.00003,
      "source": "https://docs.x.ai/docs/models",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_web_search": true,
      "provider": "xai"
    },
    "slug": "grok-4-latest",
    "displayName": "grok-4-latest"
  },
  {
    "id": "xai/grok-4-1-fast",
    "name": "grok-4-1-fast",
    "provider": "xai",
    "data": {
      "cache_read_input_token_cost": 5e-8,
      "input_cost_per_token": 2e-7,
      "input_cost_per_token_above_128k_tokens": 4e-7,
      "max_input_tokens": 2000000,
      "max_output_tokens": 2000000,
      "max_tokens": 2000000,
      "mode": "chat",
      "output_cost_per_token": 5e-7,
      "output_cost_per_token_above_128k_tokens": 0.000001,
      "source": "https://docs.x.ai/docs/models/grok-4-1-fast-reasoning",
      "supports_audio_input": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "xai"
    },
    "slug": "grok-4-1-fast",
    "displayName": "grok-4-1-fast"
  },
  {
    "id": "xai/grok-4-1-fast-reasoning",
    "name": "grok-4-1-fast-reasoning",
    "provider": "xai",
    "data": {
      "cache_read_input_token_cost": 5e-8,
      "input_cost_per_token": 2e-7,
      "input_cost_per_token_above_128k_tokens": 4e-7,
      "max_input_tokens": 2000000,
      "max_output_tokens": 2000000,
      "max_tokens": 2000000,
      "mode": "chat",
      "output_cost_per_token": 5e-7,
      "output_cost_per_token_above_128k_tokens": 0.000001,
      "source": "https://docs.x.ai/docs/models/grok-4-1-fast-reasoning",
      "supports_audio_input": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "xai"
    },
    "slug": "grok-4-1-fast-reasoning",
    "displayName": "grok-4-1-fast-reasoning"
  },
  {
    "id": "xai/grok-4-1-fast-reasoning-latest",
    "name": "grok-4-1-fast-reasoning-latest",
    "provider": "xai",
    "data": {
      "cache_read_input_token_cost": 5e-8,
      "input_cost_per_token": 2e-7,
      "input_cost_per_token_above_128k_tokens": 4e-7,
      "max_input_tokens": 2000000,
      "max_output_tokens": 2000000,
      "max_tokens": 2000000,
      "mode": "chat",
      "output_cost_per_token": 5e-7,
      "output_cost_per_token_above_128k_tokens": 0.000001,
      "source": "https://docs.x.ai/docs/models/grok-4-1-fast-reasoning",
      "supports_audio_input": true,
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "xai"
    },
    "slug": "grok-4-1-fast-reasoning-latest",
    "displayName": "grok-4-1-fast-reasoning-latest"
  },
  {
    "id": "xai/grok-4-1-fast-non-reasoning",
    "name": "grok-4-1-fast-non-reasoning",
    "provider": "xai",
    "data": {
      "cache_read_input_token_cost": 5e-8,
      "input_cost_per_token": 2e-7,
      "input_cost_per_token_above_128k_tokens": 4e-7,
      "max_input_tokens": 2000000,
      "max_output_tokens": 2000000,
      "max_tokens": 2000000,
      "mode": "chat",
      "output_cost_per_token": 5e-7,
      "output_cost_per_token_above_128k_tokens": 0.000001,
      "source": "https://docs.x.ai/docs/models/grok-4-1-fast-non-reasoning",
      "supports_audio_input": true,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "xai"
    },
    "slug": "grok-4-1-fast-non-reasoning",
    "displayName": "grok-4-1-fast-non-reasoning"
  },
  {
    "id": "xai/grok-4-1-fast-non-reasoning-latest",
    "name": "grok-4-1-fast-non-reasoning-latest",
    "provider": "xai",
    "data": {
      "cache_read_input_token_cost": 5e-8,
      "input_cost_per_token": 2e-7,
      "input_cost_per_token_above_128k_tokens": 4e-7,
      "max_input_tokens": 2000000,
      "max_output_tokens": 2000000,
      "max_tokens": 2000000,
      "mode": "chat",
      "output_cost_per_token": 5e-7,
      "output_cost_per_token_above_128k_tokens": 0.000001,
      "source": "https://docs.x.ai/docs/models/grok-4-1-fast-non-reasoning",
      "supports_audio_input": true,
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "xai"
    },
    "slug": "grok-4-1-fast-non-reasoning-latest",
    "displayName": "grok-4-1-fast-non-reasoning-latest"
  },
  {
    "id": "xai/grok-beta",
    "name": "grok-beta",
    "provider": "xai",
    "data": {
      "input_cost_per_token": 0.000005,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "xai"
    },
    "slug": "grok-beta",
    "displayName": "grok-beta"
  },
  {
    "id": "xai/grok-code-fast",
    "name": "grok-code-fast",
    "provider": "xai",
    "data": {
      "cache_read_input_token_cost": 2e-8,
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "source": "https://docs.x.ai/docs/models",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "xai"
    },
    "slug": "grok-code-fast",
    "displayName": "grok-code-fast"
  },
  {
    "id": "xai/grok-code-fast-1",
    "name": "grok-code-fast-1",
    "provider": "xai",
    "data": {
      "cache_read_input_token_cost": 2e-8,
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "source": "https://docs.x.ai/docs/models",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "xai"
    },
    "slug": "grok-code-fast-1",
    "displayName": "grok-code-fast-1"
  },
  {
    "id": "xai/grok-code-fast-1-0825",
    "name": "grok-code-fast-1-0825",
    "provider": "xai",
    "data": {
      "cache_read_input_token_cost": 2e-8,
      "input_cost_per_token": 2e-7,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "max_tokens": 256000,
      "mode": "chat",
      "output_cost_per_token": 0.0000015,
      "source": "https://docs.x.ai/docs/models",
      "supports_function_calling": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "provider": "xai"
    },
    "slug": "grok-code-fast-1-0825",
    "displayName": "grok-code-fast-1-0825"
  },
  {
    "id": "xai/grok-vision-beta",
    "name": "grok-vision-beta",
    "provider": "xai",
    "data": {
      "input_cost_per_image": 0.000005,
      "input_cost_per_token": 0.000005,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "mode": "chat",
      "output_cost_per_token": 0.000015,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_web_search": true,
      "provider": "xai"
    },
    "slug": "grok-vision-beta",
    "displayName": "grok-vision-beta"
  },
  {
    "id": "zai/glm-4.7",
    "name": "glm-4.7",
    "provider": "zai",
    "data": {
      "cache_creation_input_token_cost": 0,
      "cache_read_input_token_cost": 1.1e-7,
      "input_cost_per_token": 6e-7,
      "output_cost_per_token": 0.0000022,
      "max_input_tokens": 200000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "source": "https://docs.z.ai/guides/overview/pricing",
      "provider": "zai"
    },
    "slug": "glm-4.7",
    "displayName": "glm-4.7"
  },
  {
    "id": "zai/glm-4.6",
    "name": "glm-4.6",
    "provider": "zai",
    "data": {
      "cache_creation_input_token_cost": 0,
      "cache_read_input_token_cost": 1.1e-7,
      "input_cost_per_token": 6e-7,
      "output_cost_per_token": 0.0000022,
      "max_input_tokens": 200000,
      "max_output_tokens": 128000,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_prompt_caching": true,
      "supports_reasoning": true,
      "supports_tool_choice": true,
      "source": "https://docs.z.ai/guides/overview/pricing",
      "provider": "zai"
    },
    "slug": "glm-4.6",
    "displayName": "glm-4.6"
  },
  {
    "id": "zai/glm-4.5",
    "name": "glm-4.5",
    "provider": "zai",
    "data": {
      "input_cost_per_token": 6e-7,
      "output_cost_per_token": 0.0000022,
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "source": "https://docs.z.ai/guides/overview/pricing",
      "provider": "zai"
    },
    "slug": "glm-4.5",
    "displayName": "glm-4.5"
  },
  {
    "id": "zai/glm-4.5v",
    "name": "glm-4.5v",
    "provider": "zai",
    "data": {
      "input_cost_per_token": 6e-7,
      "output_cost_per_token": 0.0000018,
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "source": "https://docs.z.ai/guides/overview/pricing",
      "provider": "zai"
    },
    "slug": "glm-4.5v",
    "displayName": "glm-4.5v"
  },
  {
    "id": "zai/glm-4.5-x",
    "name": "glm-4.5-x",
    "provider": "zai",
    "data": {
      "input_cost_per_token": 0.0000022,
      "output_cost_per_token": 0.0000089,
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "source": "https://docs.z.ai/guides/overview/pricing",
      "provider": "zai"
    },
    "slug": "glm-4.5-x",
    "displayName": "glm-4.5-x"
  },
  {
    "id": "zai/glm-4.5-air",
    "name": "glm-4.5-air",
    "provider": "zai",
    "data": {
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 0.0000011,
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "source": "https://docs.z.ai/guides/overview/pricing",
      "provider": "zai"
    },
    "slug": "glm-4.5-air",
    "displayName": "glm-4.5-air"
  },
  {
    "id": "zai/glm-4.5-airx",
    "name": "glm-4.5-airx",
    "provider": "zai",
    "data": {
      "input_cost_per_token": 0.0000011,
      "output_cost_per_token": 0.0000045,
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "source": "https://docs.z.ai/guides/overview/pricing",
      "provider": "zai"
    },
    "slug": "glm-4.5-airx",
    "displayName": "glm-4.5-airx"
  },
  {
    "id": "zai/glm-4-32b-0414-128k",
    "name": "glm-4-32b-0414-128k",
    "provider": "zai",
    "data": {
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "source": "https://docs.z.ai/guides/overview/pricing",
      "provider": "zai"
    },
    "slug": "glm-4-32b-0414-128k",
    "displayName": "glm-4-32b-0414-128k"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen3-coder-480b-a35b-instruct",
    "name": "qwen3-coder-480b-a35b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 262144,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_token": 4.5e-7,
      "output_cost_per_token": 0.0000018,
      "mode": "chat",
      "supports_reasoning": true,
      "provider": "fireworks_ai"
    },
    "slug": "qwen3-coder-480b-a35b-instruct",
    "displayName": "qwen3-coder-480b-a35b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/flux-kontext-pro",
    "name": "flux-kontext-pro",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 4e-8,
      "output_cost_per_token": 4e-8,
      "mode": "image_generation",
      "provider": "fireworks_ai"
    },
    "slug": "flux-kontext-pro",
    "displayName": "flux-kontext-pro"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/chronos-hermes-13b-v2",
    "name": "chronos-hermes-13b-v2",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "chronos-hermes-13b-v2",
    "displayName": "chronos-hermes-13b-v2"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/code-llama-13b",
    "name": "code-llama-13b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "code-llama-13b",
    "displayName": "code-llama-13b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/code-llama-13b-instruct",
    "name": "code-llama-13b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "code-llama-13b-instruct",
    "displayName": "code-llama-13b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/code-llama-13b-python",
    "name": "code-llama-13b-python",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "code-llama-13b-python",
    "displayName": "code-llama-13b-python"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/code-llama-34b",
    "name": "code-llama-34b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "code-llama-34b",
    "displayName": "code-llama-34b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/code-llama-34b-instruct",
    "name": "code-llama-34b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "code-llama-34b-instruct",
    "displayName": "code-llama-34b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/code-llama-34b-python",
    "name": "code-llama-34b-python",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "code-llama-34b-python",
    "displayName": "code-llama-34b-python"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/code-llama-70b",
    "name": "code-llama-70b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "code-llama-70b",
    "displayName": "code-llama-70b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/code-llama-70b-instruct",
    "name": "code-llama-70b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "code-llama-70b-instruct",
    "displayName": "code-llama-70b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/code-llama-70b-python",
    "name": "code-llama-70b-python",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "code-llama-70b-python",
    "displayName": "code-llama-70b-python"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/code-llama-7b",
    "name": "code-llama-7b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "code-llama-7b",
    "displayName": "code-llama-7b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/code-llama-7b-instruct",
    "name": "code-llama-7b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "code-llama-7b-instruct",
    "displayName": "code-llama-7b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/code-llama-7b-python",
    "name": "code-llama-7b-python",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "code-llama-7b-python",
    "displayName": "code-llama-7b-python"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/code-qwen-1p5-7b",
    "name": "code-qwen-1p5-7b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 65536,
      "max_input_tokens": 65536,
      "max_output_tokens": 65536,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "code-qwen-1p5-7b",
    "displayName": "code-qwen-1p5-7b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/codegemma-2b",
    "name": "codegemma-2b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "codegemma-2b",
    "displayName": "codegemma-2b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/codegemma-7b",
    "name": "codegemma-7b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "codegemma-7b",
    "displayName": "codegemma-7b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/cogito-671b-v2-p1",
    "name": "cogito-671b-v2-p1",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 163840,
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_token": 0.0000012,
      "output_cost_per_token": 0.0000012,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "cogito-671b-v2-p1",
    "displayName": "cogito-671b-v2-p1"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-llama-3b",
    "name": "cogito-v1-preview-llama-3b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "cogito-v1-preview-llama-3b",
    "displayName": "cogito-v1-preview-llama-3b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-llama-70b",
    "name": "cogito-v1-preview-llama-70b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "cogito-v1-preview-llama-70b",
    "displayName": "cogito-v1-preview-llama-70b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-llama-8b",
    "name": "cogito-v1-preview-llama-8b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "cogito-v1-preview-llama-8b",
    "displayName": "cogito-v1-preview-llama-8b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-qwen-14b",
    "name": "cogito-v1-preview-qwen-14b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "cogito-v1-preview-qwen-14b",
    "displayName": "cogito-v1-preview-qwen-14b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-qwen-32b",
    "name": "cogito-v1-preview-qwen-32b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "cogito-v1-preview-qwen-32b",
    "displayName": "cogito-v1-preview-qwen-32b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/flux-kontext-max",
    "name": "flux-kontext-max",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 8e-8,
      "output_cost_per_token": 8e-8,
      "mode": "image_generation",
      "provider": "fireworks_ai"
    },
    "slug": "flux-kontext-max",
    "displayName": "flux-kontext-max"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/dbrx-instruct",
    "name": "dbrx-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.0000012,
      "output_cost_per_token": 0.0000012,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "dbrx-instruct",
    "displayName": "dbrx-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/deepseek-coder-1b-base",
    "name": "deepseek-coder-1b-base",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "deepseek-coder-1b-base",
    "displayName": "deepseek-coder-1b-base"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/deepseek-coder-33b-instruct",
    "name": "deepseek-coder-33b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "deepseek-coder-33b-instruct",
    "displayName": "deepseek-coder-33b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/deepseek-coder-7b-base",
    "name": "deepseek-coder-7b-base",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "deepseek-coder-7b-base",
    "displayName": "deepseek-coder-7b-base"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/deepseek-coder-7b-base-v1p5",
    "name": "deepseek-coder-7b-base-v1p5",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "deepseek-coder-7b-base-v1p5",
    "displayName": "deepseek-coder-7b-base-v1p5"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/deepseek-coder-7b-instruct-v1p5",
    "name": "deepseek-coder-7b-instruct-v1p5",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "deepseek-coder-7b-instruct-v1p5",
    "displayName": "deepseek-coder-7b-instruct-v1p5"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-lite-base",
    "name": "deepseek-coder-v2-lite-base",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 163840,
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 5e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "deepseek-coder-v2-lite-base",
    "displayName": "deepseek-coder-v2-lite-base"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-lite-instruct",
    "name": "deepseek-coder-v2-lite-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 163840,
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 5e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "deepseek-coder-v2-lite-instruct",
    "displayName": "deepseek-coder-v2-lite-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/deepseek-prover-v2",
    "name": "deepseek-prover-v2",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 163840,
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_token": 0.0000012,
      "output_cost_per_token": 0.0000012,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "deepseek-prover-v2",
    "displayName": "deepseek-prover-v2"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/deepseek-r1-0528-distill-qwen3-8b",
    "name": "deepseek-r1-0528-distill-qwen3-8b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "deepseek-r1-0528-distill-qwen3-8b",
    "displayName": "deepseek-r1-0528-distill-qwen3-8b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-llama-70b",
    "name": "deepseek-r1-distill-llama-70b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "deepseek-r1-distill-llama-70b",
    "displayName": "deepseek-r1-distill-llama-70b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-llama-8b",
    "name": "deepseek-r1-distill-llama-8b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "deepseek-r1-distill-llama-8b",
    "displayName": "deepseek-r1-distill-llama-8b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-qwen-14b",
    "name": "deepseek-r1-distill-qwen-14b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "deepseek-r1-distill-qwen-14b",
    "displayName": "deepseek-r1-distill-qwen-14b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-qwen-1p5b",
    "name": "deepseek-r1-distill-qwen-1p5b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "deepseek-r1-distill-qwen-1p5b",
    "displayName": "deepseek-r1-distill-qwen-1p5b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-qwen-32b",
    "name": "deepseek-r1-distill-qwen-32b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "deepseek-r1-distill-qwen-32b",
    "displayName": "deepseek-r1-distill-qwen-32b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-qwen-7b",
    "name": "deepseek-r1-distill-qwen-7b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "deepseek-r1-distill-qwen-7b",
    "displayName": "deepseek-r1-distill-qwen-7b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/deepseek-v2-lite-chat",
    "name": "deepseek-v2-lite-chat",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 163840,
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 5e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "deepseek-v2-lite-chat",
    "displayName": "deepseek-v2-lite-chat"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/deepseek-v2p5",
    "name": "deepseek-v2p5",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.0000012,
      "output_cost_per_token": 0.0000012,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "deepseek-v2p5",
    "displayName": "deepseek-v2p5"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/devstral-small-2505",
    "name": "devstral-small-2505",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "devstral-small-2505",
    "displayName": "devstral-small-2505"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/dobby-mini-unhinged-plus-llama-3-1-8b",
    "name": "dobby-mini-unhinged-plus-llama-3-1-8b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "dobby-mini-unhinged-plus-llama-3-1-8b",
    "displayName": "dobby-mini-unhinged-plus-llama-3-1-8b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/dobby-unhinged-llama-3-3-70b-new",
    "name": "dobby-unhinged-llama-3-3-70b-new",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "dobby-unhinged-llama-3-3-70b-new",
    "displayName": "dobby-unhinged-llama-3-3-70b-new"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/dolphin-2-9-2-qwen2-72b",
    "name": "dolphin-2-9-2-qwen2-72b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "dolphin-2-9-2-qwen2-72b",
    "displayName": "dolphin-2-9-2-qwen2-72b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/dolphin-2p6-mixtral-8x7b",
    "name": "dolphin-2p6-mixtral-8x7b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 5e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "dolphin-2p6-mixtral-8x7b",
    "displayName": "dolphin-2p6-mixtral-8x7b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/ernie-4p5-21b-a3b-pt",
    "name": "ernie-4p5-21b-a3b-pt",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "ernie-4p5-21b-a3b-pt",
    "displayName": "ernie-4p5-21b-a3b-pt"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/ernie-4p5-300b-a47b-pt",
    "name": "ernie-4p5-300b-a47b-pt",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "ernie-4p5-300b-a47b-pt",
    "displayName": "ernie-4p5-300b-a47b-pt"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/fare-20b",
    "name": "fare-20b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "fare-20b",
    "displayName": "fare-20b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/firefunction-v1",
    "name": "firefunction-v1",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 5e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "firefunction-v1",
    "displayName": "firefunction-v1"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/firellava-13b",
    "name": "firellava-13b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "firellava-13b",
    "displayName": "firellava-13b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/firesearch-ocr-v6",
    "name": "firesearch-ocr-v6",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "firesearch-ocr-v6",
    "displayName": "firesearch-ocr-v6"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/flux-1-dev",
    "name": "flux-1-dev",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "flux-1-dev",
    "displayName": "flux-1-dev"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/flux-1-schnell",
    "name": "flux-1-schnell",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "flux-1-schnell",
    "displayName": "flux-1-schnell"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/gemma-2b-it",
    "name": "gemma-2b-it",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "gemma-2b-it",
    "displayName": "gemma-2b-it"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/gemma-3-27b-it",
    "name": "gemma-3-27b-it",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "gemma-3-27b-it",
    "displayName": "gemma-3-27b-it"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/gemma-7b",
    "name": "gemma-7b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "gemma-7b",
    "displayName": "gemma-7b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/gemma-7b-it",
    "name": "gemma-7b-it",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "gemma-7b-it",
    "displayName": "gemma-7b-it"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/gemma2-9b-it",
    "name": "gemma2-9b-it",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "gemma2-9b-it",
    "displayName": "gemma2-9b-it"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/glm-4p5v",
    "name": "glm-4p5v",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 0.0000012,
      "output_cost_per_token": 0.0000012,
      "mode": "chat",
      "supports_reasoning": true,
      "provider": "fireworks_ai"
    },
    "slug": "glm-4p5v",
    "displayName": "glm-4p5v"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/gpt-oss-safeguard-120b",
    "name": "gpt-oss-safeguard-120b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 0.0000012,
      "output_cost_per_token": 0.0000012,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "gpt-oss-safeguard-120b",
    "displayName": "gpt-oss-safeguard-120b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/gpt-oss-safeguard-20b",
    "name": "gpt-oss-safeguard-20b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 5e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "gpt-oss-safeguard-20b",
    "displayName": "gpt-oss-safeguard-20b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/hermes-2-pro-mistral-7b",
    "name": "hermes-2-pro-mistral-7b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "hermes-2-pro-mistral-7b",
    "displayName": "hermes-2-pro-mistral-7b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/internvl3-38b",
    "name": "internvl3-38b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "internvl3-38b",
    "displayName": "internvl3-38b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/internvl3-78b",
    "name": "internvl3-78b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "internvl3-78b",
    "displayName": "internvl3-78b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/internvl3-8b",
    "name": "internvl3-8b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "internvl3-8b",
    "displayName": "internvl3-8b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/kat-coder",
    "name": "kat-coder",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 262144,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "kat-coder",
    "displayName": "kat-coder"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/kat-dev-32b",
    "name": "kat-dev-32b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "kat-dev-32b",
    "displayName": "kat-dev-32b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/kat-dev-72b-exp",
    "name": "kat-dev-72b-exp",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "kat-dev-72b-exp",
    "displayName": "kat-dev-72b-exp"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/llama-guard-2-8b",
    "name": "llama-guard-2-8b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "llama-guard-2-8b",
    "displayName": "llama-guard-2-8b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/llama-guard-3-1b",
    "name": "llama-guard-3-1b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "llama-guard-3-1b",
    "displayName": "llama-guard-3-1b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/llama-guard-3-8b",
    "name": "llama-guard-3-8b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "llama-guard-3-8b",
    "displayName": "llama-guard-3-8b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/llama-v2-13b",
    "name": "llama-v2-13b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "llama-v2-13b",
    "displayName": "llama-v2-13b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/llama-v2-13b-chat",
    "name": "llama-v2-13b-chat",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "llama-v2-13b-chat",
    "displayName": "llama-v2-13b-chat"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/llama-v2-70b",
    "name": "llama-v2-70b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "llama-v2-70b",
    "displayName": "llama-v2-70b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/llama-v2-70b-chat",
    "name": "llama-v2-70b-chat",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 2048,
      "max_input_tokens": 2048,
      "max_output_tokens": 2048,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "llama-v2-70b-chat",
    "displayName": "llama-v2-70b-chat"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/llama-v2-7b",
    "name": "llama-v2-7b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "llama-v2-7b",
    "displayName": "llama-v2-7b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/llama-v2-7b-chat",
    "name": "llama-v2-7b-chat",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "llama-v2-7b-chat",
    "displayName": "llama-v2-7b-chat"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/llama-v3-70b-instruct",
    "name": "llama-v3-70b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "llama-v3-70b-instruct",
    "displayName": "llama-v3-70b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/llama-v3-70b-instruct-hf",
    "name": "llama-v3-70b-instruct-hf",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "llama-v3-70b-instruct-hf",
    "displayName": "llama-v3-70b-instruct-hf"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/llama-v3-8b",
    "name": "llama-v3-8b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "llama-v3-8b",
    "displayName": "llama-v3-8b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/llama-v3-8b-instruct-hf",
    "name": "llama-v3-8b-instruct-hf",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "llama-v3-8b-instruct-hf",
    "displayName": "llama-v3-8b-instruct-hf"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/llama-v3p1-405b-instruct-long",
    "name": "llama-v3p1-405b-instruct-long",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "llama-v3p1-405b-instruct-long",
    "displayName": "llama-v3p1-405b-instruct-long"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/llama-v3p1-70b-instruct",
    "name": "llama-v3p1-70b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "llama-v3p1-70b-instruct",
    "displayName": "llama-v3p1-70b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/llama-v3p1-70b-instruct-1b",
    "name": "llama-v3p1-70b-instruct-1b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "llama-v3p1-70b-instruct-1b",
    "displayName": "llama-v3p1-70b-instruct-1b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/llama-v3p1-nemotron-70b-instruct",
    "name": "llama-v3p1-nemotron-70b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "llama-v3p1-nemotron-70b-instruct",
    "displayName": "llama-v3p1-nemotron-70b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/llama-v3p2-1b",
    "name": "llama-v3p2-1b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "llama-v3p2-1b",
    "displayName": "llama-v3p2-1b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/llama-v3p2-3b",
    "name": "llama-v3p2-3b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "llama-v3p2-3b",
    "displayName": "llama-v3p2-3b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/llama-v3p3-70b-instruct",
    "name": "llama-v3p3-70b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "llama-v3p3-70b-instruct",
    "displayName": "llama-v3p3-70b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/llamaguard-7b",
    "name": "llamaguard-7b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "llamaguard-7b",
    "displayName": "llamaguard-7b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/llava-yi-34b",
    "name": "llava-yi-34b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "llava-yi-34b",
    "displayName": "llava-yi-34b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/minimax-m1-80k",
    "name": "minimax-m1-80k",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "minimax-m1-80k",
    "displayName": "minimax-m1-80k"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/minimax-m2",
    "name": "minimax-m2",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 3e-7,
      "output_cost_per_token": 0.0000012,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "minimax-m2",
    "displayName": "minimax-m2"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/ministral-3-14b-instruct-2512",
    "name": "ministral-3-14b-instruct-2512",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 256000,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "ministral-3-14b-instruct-2512",
    "displayName": "ministral-3-14b-instruct-2512"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/ministral-3-3b-instruct-2512",
    "name": "ministral-3-3b-instruct-2512",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 256000,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "ministral-3-3b-instruct-2512",
    "displayName": "ministral-3-3b-instruct-2512"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/ministral-3-8b-instruct-2512",
    "name": "ministral-3-8b-instruct-2512",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 256000,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "ministral-3-8b-instruct-2512",
    "displayName": "ministral-3-8b-instruct-2512"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/mistral-7b",
    "name": "mistral-7b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "mistral-7b",
    "displayName": "mistral-7b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/mistral-7b-instruct-4k",
    "name": "mistral-7b-instruct-4k",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "mistral-7b-instruct-4k",
    "displayName": "mistral-7b-instruct-4k"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/mistral-7b-instruct-v0p2",
    "name": "mistral-7b-instruct-v0p2",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "mistral-7b-instruct-v0p2",
    "displayName": "mistral-7b-instruct-v0p2"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/mistral-7b-instruct-v3",
    "name": "mistral-7b-instruct-v3",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "mistral-7b-instruct-v3",
    "displayName": "mistral-7b-instruct-v3"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/mistral-7b-v0p2",
    "name": "mistral-7b-v0p2",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "mistral-7b-v0p2",
    "displayName": "mistral-7b-v0p2"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/mistral-large-3-fp8",
    "name": "mistral-large-3-fp8",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 256000,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 0.0000012,
      "output_cost_per_token": 0.0000012,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "mistral-large-3-fp8",
    "displayName": "mistral-large-3-fp8"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/mistral-nemo-base-2407",
    "name": "mistral-nemo-base-2407",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "mistral-nemo-base-2407",
    "displayName": "mistral-nemo-base-2407"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/mistral-nemo-instruct-2407",
    "name": "mistral-nemo-instruct-2407",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "mistral-nemo-instruct-2407",
    "displayName": "mistral-nemo-instruct-2407"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/mistral-small-24b-instruct-2501",
    "name": "mistral-small-24b-instruct-2501",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "mistral-small-24b-instruct-2501",
    "displayName": "mistral-small-24b-instruct-2501"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/mixtral-8x22b",
    "name": "mixtral-8x22b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 65536,
      "max_input_tokens": 65536,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0.0000012,
      "output_cost_per_token": 0.0000012,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "mixtral-8x22b",
    "displayName": "mixtral-8x22b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct",
    "name": "mixtral-8x22b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 65536,
      "max_input_tokens": 65536,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0.0000012,
      "output_cost_per_token": 0.0000012,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "mixtral-8x22b-instruct",
    "displayName": "mixtral-8x22b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/mixtral-8x7b",
    "name": "mixtral-8x7b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 5e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "mixtral-8x7b",
    "displayName": "mixtral-8x7b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/mixtral-8x7b-instruct",
    "name": "mixtral-8x7b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 5e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "mixtral-8x7b-instruct",
    "displayName": "mixtral-8x7b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/mixtral-8x7b-instruct-hf",
    "name": "mixtral-8x7b-instruct-hf",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 5e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "mixtral-8x7b-instruct-hf",
    "displayName": "mixtral-8x7b-instruct-hf"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/mythomax-l2-13b",
    "name": "mythomax-l2-13b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "mythomax-l2-13b",
    "displayName": "mythomax-l2-13b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/nemotron-nano-v2-12b-vl",
    "name": "nemotron-nano-v2-12b-vl",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "nemotron-nano-v2-12b-vl",
    "displayName": "nemotron-nano-v2-12b-vl"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/nous-capybara-7b-v1p9",
    "name": "nous-capybara-7b-v1p9",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "nous-capybara-7b-v1p9",
    "displayName": "nous-capybara-7b-v1p9"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/nous-hermes-2-mixtral-8x7b-dpo",
    "name": "nous-hermes-2-mixtral-8x7b-dpo",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 5e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "nous-hermes-2-mixtral-8x7b-dpo",
    "displayName": "nous-hermes-2-mixtral-8x7b-dpo"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/nous-hermes-2-yi-34b",
    "name": "nous-hermes-2-yi-34b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "nous-hermes-2-yi-34b",
    "displayName": "nous-hermes-2-yi-34b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/nous-hermes-llama2-13b",
    "name": "nous-hermes-llama2-13b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "nous-hermes-llama2-13b",
    "displayName": "nous-hermes-llama2-13b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/nous-hermes-llama2-70b",
    "name": "nous-hermes-llama2-70b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "nous-hermes-llama2-70b",
    "displayName": "nous-hermes-llama2-70b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/nous-hermes-llama2-7b",
    "name": "nous-hermes-llama2-7b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "nous-hermes-llama2-7b",
    "displayName": "nous-hermes-llama2-7b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/nvidia-nemotron-nano-12b-v2",
    "name": "nvidia-nemotron-nano-12b-v2",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "nvidia-nemotron-nano-12b-v2",
    "displayName": "nvidia-nemotron-nano-12b-v2"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/nvidia-nemotron-nano-9b-v2",
    "name": "nvidia-nemotron-nano-9b-v2",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "nvidia-nemotron-nano-9b-v2",
    "displayName": "nvidia-nemotron-nano-9b-v2"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/openchat-3p5-0106-7b",
    "name": "openchat-3p5-0106-7b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "openchat-3p5-0106-7b",
    "displayName": "openchat-3p5-0106-7b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/openhermes-2-mistral-7b",
    "name": "openhermes-2-mistral-7b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "openhermes-2-mistral-7b",
    "displayName": "openhermes-2-mistral-7b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/openhermes-2p5-mistral-7b",
    "name": "openhermes-2p5-mistral-7b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "openhermes-2p5-mistral-7b",
    "displayName": "openhermes-2p5-mistral-7b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/openorca-7b",
    "name": "openorca-7b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "openorca-7b",
    "displayName": "openorca-7b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/phi-2-3b",
    "name": "phi-2-3b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 2048,
      "max_input_tokens": 2048,
      "max_output_tokens": 2048,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "phi-2-3b",
    "displayName": "phi-2-3b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/phi-3-mini-128k-instruct",
    "name": "phi-3-mini-128k-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "phi-3-mini-128k-instruct",
    "displayName": "phi-3-mini-128k-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/phi-3-vision-128k-instruct",
    "name": "phi-3-vision-128k-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32064,
      "max_input_tokens": 32064,
      "max_output_tokens": 32064,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "phi-3-vision-128k-instruct",
    "displayName": "phi-3-vision-128k-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/phind-code-llama-34b-python-v1",
    "name": "phind-code-llama-34b-python-v1",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "phind-code-llama-34b-python-v1",
    "displayName": "phind-code-llama-34b-python-v1"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/phind-code-llama-34b-v1",
    "name": "phind-code-llama-34b-v1",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "phind-code-llama-34b-v1",
    "displayName": "phind-code-llama-34b-v1"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/phind-code-llama-34b-v2",
    "name": "phind-code-llama-34b-v2",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "phind-code-llama-34b-v2",
    "displayName": "phind-code-llama-34b-v2"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/pythia-12b",
    "name": "pythia-12b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 2048,
      "max_input_tokens": 2048,
      "max_output_tokens": 2048,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "pythia-12b",
    "displayName": "pythia-12b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen-qwq-32b-preview",
    "name": "qwen-qwq-32b-preview",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen-qwq-32b-preview",
    "displayName": "qwen-qwq-32b-preview"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen-v2p5-14b-instruct",
    "name": "qwen-v2p5-14b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen-v2p5-14b-instruct",
    "displayName": "qwen-v2p5-14b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen-v2p5-7b",
    "name": "qwen-v2p5-7b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen-v2p5-7b",
    "displayName": "qwen-v2p5-7b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen1p5-72b-chat",
    "name": "qwen1p5-72b-chat",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen1p5-72b-chat",
    "displayName": "qwen1p5-72b-chat"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2-7b-instruct",
    "name": "qwen2-7b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen2-7b-instruct",
    "displayName": "qwen2-7b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2-vl-2b-instruct",
    "name": "qwen2-vl-2b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen2-vl-2b-instruct",
    "displayName": "qwen2-vl-2b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2-vl-72b-instruct",
    "name": "qwen2-vl-72b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen2-vl-72b-instruct",
    "displayName": "qwen2-vl-72b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2-vl-7b-instruct",
    "name": "qwen2-vl-7b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen2-vl-7b-instruct",
    "displayName": "qwen2-vl-7b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2p5-0p5b-instruct",
    "name": "qwen2p5-0p5b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen2p5-0p5b-instruct",
    "displayName": "qwen2p5-0p5b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2p5-14b",
    "name": "qwen2p5-14b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen2p5-14b",
    "displayName": "qwen2p5-14b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2p5-1p5b-instruct",
    "name": "qwen2p5-1p5b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen2p5-1p5b-instruct",
    "displayName": "qwen2p5-1p5b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2p5-32b",
    "name": "qwen2p5-32b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen2p5-32b",
    "displayName": "qwen2p5-32b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2p5-32b-instruct",
    "name": "qwen2p5-32b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen2p5-32b-instruct",
    "displayName": "qwen2p5-32b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2p5-72b",
    "name": "qwen2p5-72b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen2p5-72b",
    "displayName": "qwen2p5-72b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2p5-72b-instruct",
    "name": "qwen2p5-72b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen2p5-72b-instruct",
    "displayName": "qwen2p5-72b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2p5-7b-instruct",
    "name": "qwen2p5-7b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen2p5-7b-instruct",
    "displayName": "qwen2p5-7b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-0p5b",
    "name": "qwen2p5-coder-0p5b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen2p5-coder-0p5b",
    "displayName": "qwen2p5-coder-0p5b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-0p5b-instruct",
    "name": "qwen2p5-coder-0p5b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen2p5-coder-0p5b-instruct",
    "displayName": "qwen2p5-coder-0p5b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-14b",
    "name": "qwen2p5-coder-14b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen2p5-coder-14b",
    "displayName": "qwen2p5-coder-14b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-14b-instruct",
    "name": "qwen2p5-coder-14b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen2p5-coder-14b-instruct",
    "displayName": "qwen2p5-coder-14b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-1p5b",
    "name": "qwen2p5-coder-1p5b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen2p5-coder-1p5b",
    "displayName": "qwen2p5-coder-1p5b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-1p5b-instruct",
    "name": "qwen2p5-coder-1p5b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen2p5-coder-1p5b-instruct",
    "displayName": "qwen2p5-coder-1p5b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b",
    "name": "qwen2p5-coder-32b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen2p5-coder-32b",
    "displayName": "qwen2p5-coder-32b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct-128k",
    "name": "qwen2p5-coder-32b-instruct-128k",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen2p5-coder-32b-instruct-128k",
    "displayName": "qwen2p5-coder-32b-instruct-128k"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct-32k-rope",
    "name": "qwen2p5-coder-32b-instruct-32k-rope",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen2p5-coder-32b-instruct-32k-rope",
    "displayName": "qwen2p5-coder-32b-instruct-32k-rope"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct-64k",
    "name": "qwen2p5-coder-32b-instruct-64k",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 65536,
      "max_input_tokens": 65536,
      "max_output_tokens": 65536,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen2p5-coder-32b-instruct-64k",
    "displayName": "qwen2p5-coder-32b-instruct-64k"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-3b",
    "name": "qwen2p5-coder-3b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen2p5-coder-3b",
    "displayName": "qwen2p5-coder-3b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-3b-instruct",
    "name": "qwen2p5-coder-3b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen2p5-coder-3b-instruct",
    "displayName": "qwen2p5-coder-3b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-7b",
    "name": "qwen2p5-coder-7b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen2p5-coder-7b",
    "displayName": "qwen2p5-coder-7b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-7b-instruct",
    "name": "qwen2p5-coder-7b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen2p5-coder-7b-instruct",
    "displayName": "qwen2p5-coder-7b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2p5-math-72b-instruct",
    "name": "qwen2p5-math-72b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen2p5-math-72b-instruct",
    "displayName": "qwen2p5-math-72b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2p5-vl-32b-instruct",
    "name": "qwen2p5-vl-32b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen2p5-vl-32b-instruct",
    "displayName": "qwen2p5-vl-32b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2p5-vl-3b-instruct",
    "name": "qwen2p5-vl-3b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen2p5-vl-3b-instruct",
    "displayName": "qwen2p5-vl-3b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2p5-vl-72b-instruct",
    "name": "qwen2p5-vl-72b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen2p5-vl-72b-instruct",
    "displayName": "qwen2p5-vl-72b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen2p5-vl-7b-instruct",
    "name": "qwen2p5-vl-7b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen2p5-vl-7b-instruct",
    "displayName": "qwen2p5-vl-7b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen3-0p6b",
    "name": "qwen3-0p6b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 40960,
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen3-0p6b",
    "displayName": "qwen3-0p6b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen3-14b",
    "name": "qwen3-14b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 40960,
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen3-14b",
    "displayName": "qwen3-14b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen3-1p7b",
    "name": "qwen3-1p7b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen3-1p7b",
    "displayName": "qwen3-1p7b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen3-1p7b-fp8-draft",
    "name": "qwen3-1p7b-fp8-draft",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 262144,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen3-1p7b-fp8-draft",
    "displayName": "qwen3-1p7b-fp8-draft"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen3-1p7b-fp8-draft-131072",
    "name": "qwen3-1p7b-fp8-draft-131072",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen3-1p7b-fp8-draft-131072",
    "displayName": "qwen3-1p7b-fp8-draft-131072"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen3-1p7b-fp8-draft-40960",
    "name": "qwen3-1p7b-fp8-draft-40960",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 40960,
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen3-1p7b-fp8-draft-40960",
    "displayName": "qwen3-1p7b-fp8-draft-40960"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen3-235b-a22b",
    "name": "qwen3-235b-a22b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 2.2e-7,
      "output_cost_per_token": 8.8e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen3-235b-a22b",
    "displayName": "qwen3-235b-a22b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen3-235b-a22b-instruct-2507",
    "name": "qwen3-235b-a22b-instruct-2507",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 262144,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_token": 2.2e-7,
      "output_cost_per_token": 8.8e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen3-235b-a22b-instruct-2507",
    "displayName": "qwen3-235b-a22b-instruct-2507"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen3-235b-a22b-thinking-2507",
    "name": "qwen3-235b-a22b-thinking-2507",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 262144,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_token": 2.2e-7,
      "output_cost_per_token": 8.8e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen3-235b-a22b-thinking-2507",
    "displayName": "qwen3-235b-a22b-thinking-2507"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen3-30b-a3b",
    "name": "qwen3-30b-a3b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 1.5e-7,
      "output_cost_per_token": 6e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen3-30b-a3b",
    "displayName": "qwen3-30b-a3b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen3-30b-a3b-instruct-2507",
    "name": "qwen3-30b-a3b-instruct-2507",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 262144,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 5e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen3-30b-a3b-instruct-2507",
    "displayName": "qwen3-30b-a3b-instruct-2507"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen3-30b-a3b-thinking-2507",
    "name": "qwen3-30b-a3b-thinking-2507",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 262144,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen3-30b-a3b-thinking-2507",
    "displayName": "qwen3-30b-a3b-thinking-2507"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen3-32b",
    "name": "qwen3-32b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "supports_reasoning": true,
      "provider": "fireworks_ai"
    },
    "slug": "qwen3-32b",
    "displayName": "qwen3-32b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen3-4b",
    "name": "qwen3-4b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 40960,
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen3-4b",
    "displayName": "qwen3-4b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen3-4b-instruct-2507",
    "name": "qwen3-4b-instruct-2507",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 262144,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen3-4b-instruct-2507",
    "displayName": "qwen3-4b-instruct-2507"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen3-8b",
    "name": "qwen3-8b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 40960,
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "supports_reasoning": true,
      "provider": "fireworks_ai"
    },
    "slug": "qwen3-8b",
    "displayName": "qwen3-8b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen3-coder-30b-a3b-instruct",
    "name": "qwen3-coder-30b-a3b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 262144,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_token": 1.5e-7,
      "output_cost_per_token": 6e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen3-coder-30b-a3b-instruct",
    "displayName": "qwen3-coder-30b-a3b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen3-coder-480b-instruct-bf16",
    "name": "qwen3-coder-480b-instruct-bf16",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen3-coder-480b-instruct-bf16",
    "displayName": "qwen3-coder-480b-instruct-bf16"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen3-next-80b-a3b-instruct",
    "name": "qwen3-next-80b-a3b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen3-next-80b-a3b-instruct",
    "displayName": "qwen3-next-80b-a3b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen3-next-80b-a3b-thinking",
    "name": "qwen3-next-80b-a3b-thinking",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen3-next-80b-a3b-thinking",
    "displayName": "qwen3-next-80b-a3b-thinking"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen3-vl-235b-a22b-instruct",
    "name": "qwen3-vl-235b-a22b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 262144,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_token": 2.2e-7,
      "output_cost_per_token": 8.8e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen3-vl-235b-a22b-instruct",
    "displayName": "qwen3-vl-235b-a22b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen3-vl-235b-a22b-thinking",
    "name": "qwen3-vl-235b-a22b-thinking",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 262144,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_token": 2.2e-7,
      "output_cost_per_token": 8.8e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen3-vl-235b-a22b-thinking",
    "displayName": "qwen3-vl-235b-a22b-thinking"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen3-vl-30b-a3b-instruct",
    "name": "qwen3-vl-30b-a3b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 262144,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_token": 1.5e-7,
      "output_cost_per_token": 6e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen3-vl-30b-a3b-instruct",
    "displayName": "qwen3-vl-30b-a3b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen3-vl-30b-a3b-thinking",
    "name": "qwen3-vl-30b-a3b-thinking",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 262144,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_token": 1.5e-7,
      "output_cost_per_token": 6e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen3-vl-30b-a3b-thinking",
    "displayName": "qwen3-vl-30b-a3b-thinking"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen3-vl-32b-instruct",
    "name": "qwen3-vl-32b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen3-vl-32b-instruct",
    "displayName": "qwen3-vl-32b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwen3-vl-8b-instruct",
    "name": "qwen3-vl-8b-instruct",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwen3-vl-8b-instruct",
    "displayName": "qwen3-vl-8b-instruct"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/qwq-32b",
    "name": "qwq-32b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "qwq-32b",
    "displayName": "qwq-32b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/rolm-ocr",
    "name": "rolm-ocr",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "rolm-ocr",
    "displayName": "rolm-ocr"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/snorkel-mistral-7b-pairrm-dpo",
    "name": "snorkel-mistral-7b-pairrm-dpo",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "snorkel-mistral-7b-pairrm-dpo",
    "displayName": "snorkel-mistral-7b-pairrm-dpo"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/stablecode-3b",
    "name": "stablecode-3b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "stablecode-3b",
    "displayName": "stablecode-3b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/starcoder-16b",
    "name": "starcoder-16b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "starcoder-16b",
    "displayName": "starcoder-16b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/starcoder-7b",
    "name": "starcoder-7b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "starcoder-7b",
    "displayName": "starcoder-7b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/starcoder2-15b",
    "name": "starcoder2-15b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "starcoder2-15b",
    "displayName": "starcoder2-15b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/starcoder2-3b",
    "name": "starcoder2-3b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "starcoder2-3b",
    "displayName": "starcoder2-3b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/starcoder2-7b",
    "name": "starcoder2-7b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "starcoder2-7b",
    "displayName": "starcoder2-7b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/toppy-m-7b",
    "name": "toppy-m-7b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "toppy-m-7b",
    "displayName": "toppy-m-7b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/yi-34b",
    "name": "yi-34b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "yi-34b",
    "displayName": "yi-34b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/yi-34b-200k-capybara",
    "name": "yi-34b-200k-capybara",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 200000,
      "max_input_tokens": 200000,
      "max_output_tokens": 200000,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "yi-34b-200k-capybara",
    "displayName": "yi-34b-200k-capybara"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/yi-34b-chat",
    "name": "yi-34b-chat",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "yi-34b-chat",
    "displayName": "yi-34b-chat"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/yi-6b",
    "name": "yi-6b",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "yi-6b",
    "displayName": "yi-6b"
  },
  {
    "id": "fireworks_ai/accounts/fireworks/models/zephyr-7b-beta",
    "name": "zephyr-7b-beta",
    "provider": "fireworks_ai",
    "data": {
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "provider": "fireworks_ai"
    },
    "slug": "zephyr-7b-beta",
    "displayName": "zephyr-7b-beta"
  },
  {
    "id": "novita/deepseek/deepseek-v3.2",
    "name": "deepseek-v3.2",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 2.69e-7,
      "output_cost_per_token": 4e-7,
      "max_input_tokens": 163840,
      "max_output_tokens": 65536,
      "max_tokens": 65536,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "cache_read_input_token_cost": 1.345e-7,
      "input_cost_per_token_cache_hit": 1.345e-7,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "deepseek-v3.2",
    "displayName": "deepseek-v3.2"
  },
  {
    "id": "novita/minimax/minimax-m2.1",
    "name": "minimax-m2.1",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 3e-7,
      "output_cost_per_token": 0.0000012,
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "cache_read_input_token_cost": 3e-8,
      "input_cost_per_token_cache_hit": 3e-8,
      "provider": "novita"
    },
    "slug": "minimax-m2.1",
    "displayName": "minimax-m2.1"
  },
  {
    "id": "novita/zai-org/glm-4.7",
    "name": "glm-4.7",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 6e-7,
      "output_cost_per_token": 0.0000022,
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "cache_read_input_token_cost": 1.1e-7,
      "input_cost_per_token_cache_hit": 1.1e-7,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "glm-4.7",
    "displayName": "glm-4.7"
  },
  {
    "id": "novita/xiaomimimo/mimo-v2-flash",
    "name": "mimo-v2-flash",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 3e-7,
      "max_input_tokens": 262144,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "cache_read_input_token_cost": 2e-8,
      "input_cost_per_token_cache_hit": 2e-8,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "mimo-v2-flash",
    "displayName": "mimo-v2-flash"
  },
  {
    "id": "novita/zai-org/autoglm-phone-9b-multilingual",
    "name": "autoglm-phone-9b-multilingual",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 3.5e-8,
      "output_cost_per_token": 1.38e-7,
      "max_input_tokens": 65536,
      "max_output_tokens": 65536,
      "max_tokens": 65536,
      "supports_vision": true,
      "supports_system_messages": true,
      "provider": "novita"
    },
    "slug": "autoglm-phone-9b-multilingual",
    "displayName": "autoglm-phone-9b-multilingual"
  },
  {
    "id": "novita/moonshotai/kimi-k2-thinking",
    "name": "kimi-k2-thinking",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 6e-7,
      "output_cost_per_token": 0.0000025,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "max_tokens": 262144,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "kimi-k2-thinking",
    "displayName": "kimi-k2-thinking"
  },
  {
    "id": "novita/minimax/minimax-m2",
    "name": "minimax-m2",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 3e-7,
      "output_cost_per_token": 0.0000012,
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "cache_read_input_token_cost": 3e-8,
      "input_cost_per_token_cache_hit": 3e-8,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "minimax-m2",
    "displayName": "minimax-m2"
  },
  {
    "id": "novita/paddlepaddle/paddleocr-vl",
    "name": "paddleocr-vl",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 2e-8,
      "output_cost_per_token": 2e-8,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "supports_vision": true,
      "supports_system_messages": true,
      "provider": "novita"
    },
    "slug": "paddleocr-vl",
    "displayName": "paddleocr-vl"
  },
  {
    "id": "novita/deepseek/deepseek-v3.2-exp",
    "name": "deepseek-v3.2-exp",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 2.7e-7,
      "output_cost_per_token": 4.1e-7,
      "max_input_tokens": 163840,
      "max_output_tokens": 65536,
      "max_tokens": 65536,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "deepseek-v3.2-exp",
    "displayName": "deepseek-v3.2-exp"
  },
  {
    "id": "novita/qwen/qwen3-vl-235b-a22b-thinking",
    "name": "qwen3-vl-235b-a22b-thinking",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 9.8e-7,
      "output_cost_per_token": 0.00000395,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "qwen3-vl-235b-a22b-thinking",
    "displayName": "qwen3-vl-235b-a22b-thinking"
  },
  {
    "id": "novita/zai-org/glm-4.6v",
    "name": "glm-4.6v",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 3e-7,
      "output_cost_per_token": 9e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "cache_read_input_token_cost": 5.5e-8,
      "input_cost_per_token_cache_hit": 5.5e-8,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "glm-4.6v",
    "displayName": "glm-4.6v"
  },
  {
    "id": "novita/zai-org/glm-4.6",
    "name": "glm-4.6",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 5.5e-7,
      "output_cost_per_token": 0.0000022,
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "cache_read_input_token_cost": 1.1e-7,
      "input_cost_per_token_cache_hit": 1.1e-7,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "glm-4.6",
    "displayName": "glm-4.6"
  },
  {
    "id": "novita/kwaipilot/kat-coder-pro",
    "name": "kat-coder-pro",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 3e-7,
      "output_cost_per_token": 0.0000012,
      "max_input_tokens": 256000,
      "max_output_tokens": 128000,
      "max_tokens": 128000,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "cache_read_input_token_cost": 6e-8,
      "input_cost_per_token_cache_hit": 6e-8,
      "provider": "novita"
    },
    "slug": "kat-coder-pro",
    "displayName": "kat-coder-pro"
  },
  {
    "id": "novita/qwen/qwen3-next-80b-a3b-instruct",
    "name": "qwen3-next-80b-a3b-instruct",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 1.5e-7,
      "output_cost_per_token": 0.0000015,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "provider": "novita"
    },
    "slug": "qwen3-next-80b-a3b-instruct",
    "displayName": "qwen3-next-80b-a3b-instruct"
  },
  {
    "id": "novita/qwen/qwen3-next-80b-a3b-thinking",
    "name": "qwen3-next-80b-a3b-thinking",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 1.5e-7,
      "output_cost_per_token": 0.0000015,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "qwen3-next-80b-a3b-thinking",
    "displayName": "qwen3-next-80b-a3b-thinking"
  },
  {
    "id": "novita/deepseek/deepseek-ocr",
    "name": "deepseek-ocr",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 3e-8,
      "output_cost_per_token": 3e-8,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "provider": "novita"
    },
    "slug": "deepseek-ocr",
    "displayName": "deepseek-ocr"
  },
  {
    "id": "novita/deepseek/deepseek-v3.1-terminus",
    "name": "deepseek-v3.1-terminus",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 2.7e-7,
      "output_cost_per_token": 0.000001,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "cache_read_input_token_cost": 1.35e-7,
      "input_cost_per_token_cache_hit": 1.35e-7,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "deepseek-v3.1-terminus",
    "displayName": "deepseek-v3.1-terminus"
  },
  {
    "id": "novita/qwen/qwen3-vl-235b-a22b-instruct",
    "name": "qwen3-vl-235b-a22b-instruct",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 3e-7,
      "output_cost_per_token": 0.0000015,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "provider": "novita"
    },
    "slug": "qwen3-vl-235b-a22b-instruct",
    "displayName": "qwen3-vl-235b-a22b-instruct"
  },
  {
    "id": "novita/qwen/qwen3-max",
    "name": "qwen3-max",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 0.00000211,
      "output_cost_per_token": 0.00000845,
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "max_tokens": 65536,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "provider": "novita"
    },
    "slug": "qwen3-max",
    "displayName": "qwen3-max"
  },
  {
    "id": "novita/skywork/r1v4-lite",
    "name": "r1v4-lite",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 6e-7,
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "max_tokens": 65536,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "provider": "novita"
    },
    "slug": "r1v4-lite",
    "displayName": "r1v4-lite"
  },
  {
    "id": "novita/deepseek/deepseek-v3.1",
    "name": "deepseek-v3.1",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 2.7e-7,
      "output_cost_per_token": 0.000001,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "cache_read_input_token_cost": 1.35e-7,
      "input_cost_per_token_cache_hit": 1.35e-7,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "deepseek-v3.1",
    "displayName": "deepseek-v3.1"
  },
  {
    "id": "novita/moonshotai/kimi-k2-0905",
    "name": "kimi-k2-0905",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 6e-7,
      "output_cost_per_token": 0.0000025,
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "max_tokens": 262144,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "provider": "novita"
    },
    "slug": "kimi-k2-0905",
    "displayName": "kimi-k2-0905"
  },
  {
    "id": "novita/qwen/qwen3-coder-480b-a35b-instruct",
    "name": "qwen3-coder-480b-a35b-instruct",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 3e-7,
      "output_cost_per_token": 0.0000013,
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "max_tokens": 65536,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "provider": "novita"
    },
    "slug": "qwen3-coder-480b-a35b-instruct",
    "displayName": "qwen3-coder-480b-a35b-instruct"
  },
  {
    "id": "novita/qwen/qwen3-coder-30b-a3b-instruct",
    "name": "qwen3-coder-30b-a3b-instruct",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 7e-8,
      "output_cost_per_token": 2.7e-7,
      "max_input_tokens": 160000,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "provider": "novita"
    },
    "slug": "qwen3-coder-30b-a3b-instruct",
    "displayName": "qwen3-coder-30b-a3b-instruct"
  },
  {
    "id": "novita/openai/gpt-oss-120b",
    "name": "gpt-oss-120b",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 5e-8,
      "output_cost_per_token": 2.5e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "gpt-oss-120b",
    "displayName": "gpt-oss-120b"
  },
  {
    "id": "novita/moonshotai/kimi-k2-instruct",
    "name": "kimi-k2-instruct",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 5.7e-7,
      "output_cost_per_token": 0.0000023,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "provider": "novita"
    },
    "slug": "kimi-k2-instruct",
    "displayName": "kimi-k2-instruct"
  },
  {
    "id": "novita/deepseek/deepseek-v3-0324",
    "name": "deepseek-v3-0324",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 2.7e-7,
      "output_cost_per_token": 0.00000112,
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "max_tokens": 163840,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "cache_read_input_token_cost": 1.35e-7,
      "input_cost_per_token_cache_hit": 1.35e-7,
      "provider": "novita"
    },
    "slug": "deepseek-v3-0324",
    "displayName": "deepseek-v3-0324"
  },
  {
    "id": "novita/zai-org/glm-4.5",
    "name": "glm-4.5",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 6e-7,
      "output_cost_per_token": 0.0000022,
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "max_tokens": 98304,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "cache_read_input_token_cost": 1.1e-7,
      "input_cost_per_token_cache_hit": 1.1e-7,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "glm-4.5",
    "displayName": "glm-4.5"
  },
  {
    "id": "novita/qwen/qwen3-235b-a22b-thinking-2507",
    "name": "qwen3-235b-a22b-thinking-2507",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 3e-7,
      "output_cost_per_token": 0.000003,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "qwen3-235b-a22b-thinking-2507",
    "displayName": "qwen3-235b-a22b-thinking-2507"
  },
  {
    "id": "novita/meta-llama/llama-3.1-8b-instruct",
    "name": "llama-3.1-8b-instruct",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 2e-8,
      "output_cost_per_token": 5e-8,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "supports_system_messages": true,
      "provider": "novita"
    },
    "slug": "llama-3.1-8b-instruct",
    "displayName": "llama-3.1-8b-instruct"
  },
  {
    "id": "novita/google/gemma-3-12b-it",
    "name": "gemma-3-12b-it",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 5e-8,
      "output_cost_per_token": 1e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "provider": "novita"
    },
    "slug": "gemma-3-12b-it",
    "displayName": "gemma-3-12b-it"
  },
  {
    "id": "novita/zai-org/glm-4.5v",
    "name": "glm-4.5v",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 6e-7,
      "output_cost_per_token": 0.0000018,
      "max_input_tokens": 65536,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "cache_read_input_token_cost": 1.1e-7,
      "input_cost_per_token_cache_hit": 1.1e-7,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "glm-4.5v",
    "displayName": "glm-4.5v"
  },
  {
    "id": "novita/openai/gpt-oss-20b",
    "name": "gpt-oss-20b",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 4e-8,
      "output_cost_per_token": 1.5e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "gpt-oss-20b",
    "displayName": "gpt-oss-20b"
  },
  {
    "id": "novita/qwen/qwen3-235b-a22b-instruct-2507",
    "name": "qwen3-235b-a22b-instruct-2507",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 9e-8,
      "output_cost_per_token": 5.8e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "provider": "novita"
    },
    "slug": "qwen3-235b-a22b-instruct-2507",
    "displayName": "qwen3-235b-a22b-instruct-2507"
  },
  {
    "id": "novita/deepseek/deepseek-r1-distill-qwen-14b",
    "name": "deepseek-r1-distill-qwen-14b",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 1.5e-7,
      "output_cost_per_token": 1.5e-7,
      "max_input_tokens": 32768,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "deepseek-r1-distill-qwen-14b",
    "displayName": "deepseek-r1-distill-qwen-14b"
  },
  {
    "id": "novita/meta-llama/llama-3.3-70b-instruct",
    "name": "llama-3.3-70b-instruct",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 1.35e-7,
      "output_cost_per_token": 4e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 120000,
      "max_tokens": 120000,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "provider": "novita"
    },
    "slug": "llama-3.3-70b-instruct",
    "displayName": "llama-3.3-70b-instruct"
  },
  {
    "id": "novita/qwen/qwen-2.5-72b-instruct",
    "name": "qwen-2.5-72b-instruct",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 3.8e-7,
      "output_cost_per_token": 4e-7,
      "max_input_tokens": 32000,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "provider": "novita"
    },
    "slug": "qwen-2.5-72b-instruct",
    "displayName": "qwen-2.5-72b-instruct"
  },
  {
    "id": "novita/mistralai/mistral-nemo",
    "name": "mistral-nemo",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 4e-8,
      "output_cost_per_token": 1.7e-7,
      "max_input_tokens": 60288,
      "max_output_tokens": 16000,
      "max_tokens": 16000,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "provider": "novita"
    },
    "slug": "mistral-nemo",
    "displayName": "mistral-nemo"
  },
  {
    "id": "novita/minimaxai/minimax-m1-80k",
    "name": "minimax-m1-80k",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 5.5e-7,
      "output_cost_per_token": 0.0000022,
      "max_input_tokens": 1000000,
      "max_output_tokens": 40000,
      "max_tokens": 40000,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "minimax-m1-80k",
    "displayName": "minimax-m1-80k"
  },
  {
    "id": "novita/deepseek/deepseek-r1-0528",
    "name": "deepseek-r1-0528",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 7e-7,
      "output_cost_per_token": 0.0000025,
      "max_input_tokens": 163840,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "cache_read_input_token_cost": 3.5e-7,
      "input_cost_per_token_cache_hit": 3.5e-7,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "deepseek-r1-0528",
    "displayName": "deepseek-r1-0528"
  },
  {
    "id": "novita/deepseek/deepseek-r1-distill-qwen-32b",
    "name": "deepseek-r1-distill-qwen-32b",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 3e-7,
      "output_cost_per_token": 3e-7,
      "max_input_tokens": 64000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "deepseek-r1-distill-qwen-32b",
    "displayName": "deepseek-r1-distill-qwen-32b"
  },
  {
    "id": "novita/meta-llama/llama-3-8b-instruct",
    "name": "llama-3-8b-instruct",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 4e-8,
      "output_cost_per_token": 4e-8,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "supports_system_messages": true,
      "provider": "novita"
    },
    "slug": "llama-3-8b-instruct",
    "displayName": "llama-3-8b-instruct"
  },
  {
    "id": "novita/microsoft/wizardlm-2-8x22b",
    "name": "wizardlm-2-8x22b",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 6.2e-7,
      "output_cost_per_token": 6.2e-7,
      "max_input_tokens": 65535,
      "max_output_tokens": 8000,
      "max_tokens": 8000,
      "supports_system_messages": true,
      "provider": "novita"
    },
    "slug": "wizardlm-2-8x22b",
    "displayName": "wizardlm-2-8x22b"
  },
  {
    "id": "novita/deepseek/deepseek-r1-0528-qwen3-8b",
    "name": "deepseek-r1-0528-qwen3-8b",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 6e-8,
      "output_cost_per_token": 9e-8,
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "supports_system_messages": true,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "deepseek-r1-0528-qwen3-8b",
    "displayName": "deepseek-r1-0528-qwen3-8b"
  },
  {
    "id": "novita/deepseek/deepseek-r1-distill-llama-70b",
    "name": "deepseek-r1-distill-llama-70b",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 8e-7,
      "output_cost_per_token": 8e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "deepseek-r1-distill-llama-70b",
    "displayName": "deepseek-r1-distill-llama-70b"
  },
  {
    "id": "novita/meta-llama/llama-3-70b-instruct",
    "name": "llama-3-70b-instruct",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 5.1e-7,
      "output_cost_per_token": 7.4e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 8000,
      "max_tokens": 8000,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "provider": "novita"
    },
    "slug": "llama-3-70b-instruct",
    "displayName": "llama-3-70b-instruct"
  },
  {
    "id": "novita/qwen/qwen3-235b-a22b-fp8",
    "name": "qwen3-235b-a22b-fp8",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 8e-7,
      "max_input_tokens": 40960,
      "max_output_tokens": 20000,
      "max_tokens": 20000,
      "supports_system_messages": true,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "qwen3-235b-a22b-fp8",
    "displayName": "qwen3-235b-a22b-fp8"
  },
  {
    "id": "novita/meta-llama/llama-4-maverick-17b-128e-instruct-fp8",
    "name": "llama-4-maverick-17b-128e-instruct-fp8",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 2.7e-7,
      "output_cost_per_token": 8.5e-7,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "supports_vision": true,
      "supports_system_messages": true,
      "provider": "novita"
    },
    "slug": "llama-4-maverick-17b-128e-instruct-fp8",
    "displayName": "llama-4-maverick-17b-128e-instruct-fp8"
  },
  {
    "id": "novita/meta-llama/llama-4-scout-17b-16e-instruct",
    "name": "llama-4-scout-17b-16e-instruct",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 1.8e-7,
      "output_cost_per_token": 5.9e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "supports_vision": true,
      "supports_system_messages": true,
      "provider": "novita"
    },
    "slug": "llama-4-scout-17b-16e-instruct",
    "displayName": "llama-4-scout-17b-16e-instruct"
  },
  {
    "id": "novita/nousresearch/hermes-2-pro-llama-3-8b",
    "name": "hermes-2-pro-llama-3-8b",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 1.4e-7,
      "output_cost_per_token": 1.4e-7,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "provider": "novita"
    },
    "slug": "hermes-2-pro-llama-3-8b",
    "displayName": "hermes-2-pro-llama-3-8b"
  },
  {
    "id": "novita/qwen/qwen2.5-vl-72b-instruct",
    "name": "qwen2.5-vl-72b-instruct",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 8e-7,
      "output_cost_per_token": 8e-7,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "supports_vision": true,
      "supports_system_messages": true,
      "provider": "novita"
    },
    "slug": "qwen2.5-vl-72b-instruct",
    "displayName": "qwen2.5-vl-72b-instruct"
  },
  {
    "id": "novita/sao10k/l3-70b-euryale-v2.1",
    "name": "l3-70b-euryale-v2.1",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 0.00000148,
      "output_cost_per_token": 0.00000148,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "provider": "novita"
    },
    "slug": "l3-70b-euryale-v2.1",
    "displayName": "l3-70b-euryale-v2.1"
  },
  {
    "id": "novita/baidu/ernie-4.5-21B-a3b-thinking",
    "name": "ernie-4.5-21B-a3b-thinking",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 7e-8,
      "output_cost_per_token": 2.8e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 65536,
      "max_tokens": 65536,
      "supports_system_messages": true,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "ernie-4.5-21b-a3b-thinking",
    "displayName": "ernie-4.5-21B-a3b-thinking"
  },
  {
    "id": "novita/sao10k/l3-8b-lunaris",
    "name": "l3-8b-lunaris",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 5e-8,
      "output_cost_per_token": 5e-8,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "provider": "novita"
    },
    "slug": "l3-8b-lunaris",
    "displayName": "l3-8b-lunaris"
  },
  {
    "id": "novita/baichuan/baichuan-m2-32b",
    "name": "baichuan-m2-32b",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 7e-8,
      "output_cost_per_token": 7e-8,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "max_tokens": 131072,
      "supports_system_messages": true,
      "provider": "novita"
    },
    "slug": "baichuan-m2-32b",
    "displayName": "baichuan-m2-32b"
  },
  {
    "id": "novita/baidu/ernie-4.5-vl-424b-a47b",
    "name": "ernie-4.5-vl-424b-a47b",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 4.2e-7,
      "output_cost_per_token": 0.00000125,
      "max_input_tokens": 123000,
      "max_output_tokens": 16000,
      "max_tokens": 16000,
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "ernie-4.5-vl-424b-a47b",
    "displayName": "ernie-4.5-vl-424b-a47b"
  },
  {
    "id": "novita/baidu/ernie-4.5-300b-a47b-paddle",
    "name": "ernie-4.5-300b-a47b-paddle",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 2.8e-7,
      "output_cost_per_token": 0.0000011,
      "max_input_tokens": 123000,
      "max_output_tokens": 12000,
      "max_tokens": 12000,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "provider": "novita"
    },
    "slug": "ernie-4.5-300b-a47b-paddle",
    "displayName": "ernie-4.5-300b-a47b-paddle"
  },
  {
    "id": "novita/deepseek/deepseek-prover-v2-671b",
    "name": "deepseek-prover-v2-671b",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 7e-7,
      "output_cost_per_token": 0.0000025,
      "max_input_tokens": 160000,
      "max_output_tokens": 160000,
      "max_tokens": 160000,
      "supports_system_messages": true,
      "provider": "novita"
    },
    "slug": "deepseek-prover-v2-671b",
    "displayName": "deepseek-prover-v2-671b"
  },
  {
    "id": "novita/qwen/qwen3-32b-fp8",
    "name": "qwen3-32b-fp8",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 4.5e-7,
      "max_input_tokens": 40960,
      "max_output_tokens": 20000,
      "max_tokens": 20000,
      "supports_system_messages": true,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "qwen3-32b-fp8",
    "displayName": "qwen3-32b-fp8"
  },
  {
    "id": "novita/qwen/qwen3-30b-a3b-fp8",
    "name": "qwen3-30b-a3b-fp8",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 9e-8,
      "output_cost_per_token": 4.5e-7,
      "max_input_tokens": 40960,
      "max_output_tokens": 20000,
      "max_tokens": 20000,
      "supports_system_messages": true,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "qwen3-30b-a3b-fp8",
    "displayName": "qwen3-30b-a3b-fp8"
  },
  {
    "id": "novita/google/gemma-3-27b-it",
    "name": "gemma-3-27b-it",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 1.19e-7,
      "output_cost_per_token": 2e-7,
      "max_input_tokens": 98304,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "supports_vision": true,
      "supports_system_messages": true,
      "provider": "novita"
    },
    "slug": "gemma-3-27b-it",
    "displayName": "gemma-3-27b-it"
  },
  {
    "id": "novita/deepseek/deepseek-v3-turbo",
    "name": "deepseek-v3-turbo",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 4e-7,
      "output_cost_per_token": 0.0000013,
      "max_input_tokens": 64000,
      "max_output_tokens": 16000,
      "max_tokens": 16000,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "provider": "novita"
    },
    "slug": "deepseek-v3-turbo",
    "displayName": "deepseek-v3-turbo"
  },
  {
    "id": "novita/deepseek/deepseek-r1-turbo",
    "name": "deepseek-r1-turbo",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 7e-7,
      "output_cost_per_token": 0.0000025,
      "max_input_tokens": 64000,
      "max_output_tokens": 16000,
      "max_tokens": 16000,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "deepseek-r1-turbo",
    "displayName": "deepseek-r1-turbo"
  },
  {
    "id": "novita/Sao10K/L3-8B-Stheno-v3.2",
    "name": "L3-8B-Stheno-v3.2",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 5e-8,
      "output_cost_per_token": 5e-8,
      "max_input_tokens": 8192,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "provider": "novita"
    },
    "slug": "l3-8b-stheno-v3.2",
    "displayName": "L3-8B-Stheno-v3.2"
  },
  {
    "id": "novita/gryphe/mythomax-l2-13b",
    "name": "mythomax-l2-13b",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 9e-8,
      "output_cost_per_token": 9e-8,
      "max_input_tokens": 4096,
      "max_output_tokens": 3200,
      "max_tokens": 3200,
      "supports_system_messages": true,
      "provider": "novita"
    },
    "slug": "mythomax-l2-13b",
    "displayName": "mythomax-l2-13b"
  },
  {
    "id": "novita/baidu/ernie-4.5-vl-28b-a3b-thinking",
    "name": "ernie-4.5-vl-28b-a3b-thinking",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 3.9e-7,
      "output_cost_per_token": 3.9e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 65536,
      "max_tokens": 65536,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "ernie-4.5-vl-28b-a3b-thinking",
    "displayName": "ernie-4.5-vl-28b-a3b-thinking"
  },
  {
    "id": "novita/qwen/qwen3-vl-8b-instruct",
    "name": "qwen3-vl-8b-instruct",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 8e-8,
      "output_cost_per_token": 5e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "provider": "novita"
    },
    "slug": "qwen3-vl-8b-instruct",
    "displayName": "qwen3-vl-8b-instruct"
  },
  {
    "id": "novita/zai-org/glm-4.5-air",
    "name": "glm-4.5-air",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 1.3e-7,
      "output_cost_per_token": 8.5e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "max_tokens": 98304,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "glm-4.5-air",
    "displayName": "glm-4.5-air"
  },
  {
    "id": "novita/qwen/qwen3-vl-30b-a3b-instruct",
    "name": "qwen3-vl-30b-a3b-instruct",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 7e-7,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "provider": "novita"
    },
    "slug": "qwen3-vl-30b-a3b-instruct",
    "displayName": "qwen3-vl-30b-a3b-instruct"
  },
  {
    "id": "novita/qwen/qwen3-vl-30b-a3b-thinking",
    "name": "qwen3-vl-30b-a3b-thinking",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 0.000001,
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "provider": "novita"
    },
    "slug": "qwen3-vl-30b-a3b-thinking",
    "displayName": "qwen3-vl-30b-a3b-thinking"
  },
  {
    "id": "novita/qwen/qwen3-omni-30b-a3b-thinking",
    "name": "qwen3-omni-30b-a3b-thinking",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 2.5e-7,
      "output_cost_per_token": 9.7e-7,
      "max_input_tokens": 65536,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "supports_reasoning": true,
      "supports_audio_input": true,
      "provider": "novita"
    },
    "slug": "qwen3-omni-30b-a3b-thinking",
    "displayName": "qwen3-omni-30b-a3b-thinking"
  },
  {
    "id": "novita/qwen/qwen3-omni-30b-a3b-instruct",
    "name": "qwen3-omni-30b-a3b-instruct",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 2.5e-7,
      "output_cost_per_token": 9.7e-7,
      "max_input_tokens": 65536,
      "max_output_tokens": 16384,
      "max_tokens": 16384,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "supports_audio_input": true,
      "supports_audio_output": true,
      "provider": "novita"
    },
    "slug": "qwen3-omni-30b-a3b-instruct",
    "displayName": "qwen3-omni-30b-a3b-instruct"
  },
  {
    "id": "novita/qwen/qwen-mt-plus",
    "name": "qwen-mt-plus",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 2.5e-7,
      "output_cost_per_token": 7.5e-7,
      "max_input_tokens": 16384,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "supports_system_messages": true,
      "provider": "novita"
    },
    "slug": "qwen-mt-plus",
    "displayName": "qwen-mt-plus"
  },
  {
    "id": "novita/baidu/ernie-4.5-vl-28b-a3b",
    "name": "ernie-4.5-vl-28b-a3b",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 1.4e-7,
      "output_cost_per_token": 5.6e-7,
      "max_input_tokens": 30000,
      "max_output_tokens": 8000,
      "max_tokens": 8000,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_vision": true,
      "supports_system_messages": true,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "ernie-4.5-vl-28b-a3b",
    "displayName": "ernie-4.5-vl-28b-a3b"
  },
  {
    "id": "novita/baidu/ernie-4.5-21B-a3b",
    "name": "ernie-4.5-21B-a3b",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 7e-8,
      "output_cost_per_token": 2.8e-7,
      "max_input_tokens": 120000,
      "max_output_tokens": 8000,
      "max_tokens": 8000,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "provider": "novita"
    },
    "slug": "ernie-4.5-21b-a3b",
    "displayName": "ernie-4.5-21B-a3b"
  },
  {
    "id": "novita/qwen/qwen3-8b-fp8",
    "name": "qwen3-8b-fp8",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 3.5e-8,
      "output_cost_per_token": 1.38e-7,
      "max_input_tokens": 128000,
      "max_output_tokens": 20000,
      "max_tokens": 20000,
      "supports_system_messages": true,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "qwen3-8b-fp8",
    "displayName": "qwen3-8b-fp8"
  },
  {
    "id": "novita/qwen/qwen3-4b-fp8",
    "name": "qwen3-4b-fp8",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 3e-8,
      "output_cost_per_token": 3e-8,
      "max_input_tokens": 128000,
      "max_output_tokens": 20000,
      "max_tokens": 20000,
      "supports_system_messages": true,
      "supports_reasoning": true,
      "provider": "novita"
    },
    "slug": "qwen3-4b-fp8",
    "displayName": "qwen3-4b-fp8"
  },
  {
    "id": "novita/qwen/qwen2.5-7b-instruct",
    "name": "qwen2.5-7b-instruct",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 7e-8,
      "output_cost_per_token": 7e-8,
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "supports_response_schema": true,
      "provider": "novita"
    },
    "slug": "qwen2.5-7b-instruct",
    "displayName": "qwen2.5-7b-instruct"
  },
  {
    "id": "novita/meta-llama/llama-3.2-3b-instruct",
    "name": "llama-3.2-3b-instruct",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 3e-8,
      "output_cost_per_token": 5e-8,
      "max_input_tokens": 32768,
      "max_output_tokens": 32000,
      "max_tokens": 32000,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "provider": "novita"
    },
    "slug": "llama-3.2-3b-instruct",
    "displayName": "llama-3.2-3b-instruct"
  },
  {
    "id": "novita/sao10k/l31-70b-euryale-v2.2",
    "name": "l31-70b-euryale-v2.2",
    "provider": "novita",
    "data": {
      "mode": "chat",
      "input_cost_per_token": 0.00000148,
      "output_cost_per_token": 0.00000148,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "max_tokens": 8192,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_tool_choice": true,
      "supports_system_messages": true,
      "provider": "novita"
    },
    "slug": "l31-70b-euryale-v2.2",
    "displayName": "l31-70b-euryale-v2.2"
  },
  {
    "id": "novita/qwen/qwen3-embedding-0.6b",
    "name": "qwen3-embedding-0.6b",
    "provider": "novita",
    "data": {
      "mode": "embedding",
      "input_cost_per_token": 7e-8,
      "output_cost_per_token": 0,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "max_tokens": 32768,
      "provider": "novita"
    },
    "slug": "qwen3-embedding-0.6b",
    "displayName": "qwen3-embedding-0.6b"
  },
  {
    "id": "novita/qwen/qwen3-embedding-8b",
    "name": "qwen3-embedding-8b",
    "provider": "novita",
    "data": {
      "mode": "embedding",
      "input_cost_per_token": 7e-8,
      "output_cost_per_token": 0,
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "provider": "novita"
    },
    "slug": "qwen3-embedding-8b",
    "displayName": "qwen3-embedding-8b"
  },
  {
    "id": "novita/baai/bge-m3",
    "name": "bge-m3",
    "provider": "novita",
    "data": {
      "mode": "embedding",
      "input_cost_per_token": 1e-8,
      "output_cost_per_token": 1e-8,
      "max_input_tokens": 8192,
      "max_output_tokens": 96000,
      "max_tokens": 96000,
      "provider": "novita"
    },
    "slug": "bge-m3",
    "displayName": "bge-m3"
  },
  {
    "id": "novita/qwen/qwen3-reranker-8b",
    "name": "qwen3-reranker-8b",
    "provider": "novita",
    "data": {
      "mode": "rerank",
      "input_cost_per_token": 5e-8,
      "output_cost_per_token": 5e-8,
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "max_tokens": 4096,
      "provider": "novita"
    },
    "slug": "qwen3-reranker-8b",
    "displayName": "qwen3-reranker-8b"
  },
  {
    "id": "novita/baai/bge-reranker-v2-m3",
    "name": "bge-reranker-v2-m3",
    "provider": "novita",
    "data": {
      "mode": "rerank",
      "input_cost_per_token": 1e-8,
      "output_cost_per_token": 1e-8,
      "max_input_tokens": 8000,
      "max_output_tokens": 8000,
      "max_tokens": 8000,
      "provider": "novita"
    },
    "slug": "bge-reranker-v2-m3",
    "displayName": "bge-reranker-v2-m3"
  },
  {
    "id": "llamagate/llama-3.1-8b",
    "name": "llama-3.1-8b",
    "provider": "llamagate",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_token": 3e-8,
      "output_cost_per_token": 5e-8,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "provider": "llamagate"
    },
    "slug": "llama-3.1-8b",
    "displayName": "llama-3.1-8b"
  },
  {
    "id": "llamagate/llama-3.2-3b",
    "name": "llama-3.2-3b",
    "provider": "llamagate",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_token": 4e-8,
      "output_cost_per_token": 8e-8,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "provider": "llamagate"
    },
    "slug": "llama-3.2-3b",
    "displayName": "llama-3.2-3b"
  },
  {
    "id": "llamagate/mistral-7b-v0.3",
    "name": "mistral-7b-v0.3",
    "provider": "llamagate",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1.5e-7,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "provider": "llamagate"
    },
    "slug": "mistral-7b-v0.3",
    "displayName": "mistral-7b-v0.3"
  },
  {
    "id": "llamagate/qwen3-8b",
    "name": "qwen3-8b",
    "provider": "llamagate",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "input_cost_per_token": 4e-8,
      "output_cost_per_token": 1.4e-7,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "provider": "llamagate"
    },
    "slug": "qwen3-8b",
    "displayName": "qwen3-8b"
  },
  {
    "id": "llamagate/dolphin3-8b",
    "name": "dolphin3-8b",
    "provider": "llamagate",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 8e-8,
      "output_cost_per_token": 1.5e-7,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "provider": "llamagate"
    },
    "slug": "dolphin3-8b",
    "displayName": "dolphin3-8b"
  },
  {
    "id": "llamagate/deepseek-r1-8b",
    "name": "deepseek-r1-8b",
    "provider": "llamagate",
    "data": {
      "max_tokens": 16384,
      "max_input_tokens": 65536,
      "max_output_tokens": 16384,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_reasoning": true,
      "provider": "llamagate"
    },
    "slug": "deepseek-r1-8b",
    "displayName": "deepseek-r1-8b"
  },
  {
    "id": "llamagate/deepseek-r1-7b-qwen",
    "name": "deepseek-r1-7b-qwen",
    "provider": "llamagate",
    "data": {
      "max_tokens": 16384,
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "input_cost_per_token": 8e-8,
      "output_cost_per_token": 1.5e-7,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_reasoning": true,
      "provider": "llamagate"
    },
    "slug": "deepseek-r1-7b-qwen",
    "displayName": "deepseek-r1-7b-qwen"
  },
  {
    "id": "llamagate/openthinker-7b",
    "name": "openthinker-7b",
    "provider": "llamagate",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "input_cost_per_token": 8e-8,
      "output_cost_per_token": 1.5e-7,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_reasoning": true,
      "provider": "llamagate"
    },
    "slug": "openthinker-7b",
    "displayName": "openthinker-7b"
  },
  {
    "id": "llamagate/qwen2.5-coder-7b",
    "name": "qwen2.5-coder-7b",
    "provider": "llamagate",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "input_cost_per_token": 6e-8,
      "output_cost_per_token": 1.2e-7,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "provider": "llamagate"
    },
    "slug": "qwen2.5-coder-7b",
    "displayName": "qwen2.5-coder-7b"
  },
  {
    "id": "llamagate/deepseek-coder-6.7b",
    "name": "deepseek-coder-6.7b",
    "provider": "llamagate",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "input_cost_per_token": 6e-8,
      "output_cost_per_token": 1.2e-7,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "provider": "llamagate"
    },
    "slug": "deepseek-coder-6.7b",
    "displayName": "deepseek-coder-6.7b"
  },
  {
    "id": "llamagate/codellama-7b",
    "name": "codellama-7b",
    "provider": "llamagate",
    "data": {
      "max_tokens": 4096,
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "input_cost_per_token": 6e-8,
      "output_cost_per_token": 1.2e-7,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "provider": "llamagate"
    },
    "slug": "codellama-7b",
    "displayName": "codellama-7b"
  },
  {
    "id": "llamagate/qwen3-vl-8b",
    "name": "qwen3-vl-8b",
    "provider": "llamagate",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1.5e-7,
      "output_cost_per_token": 5.5e-7,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "provider": "llamagate"
    },
    "slug": "qwen3-vl-8b",
    "displayName": "qwen3-vl-8b"
  },
  {
    "id": "llamagate/llava-7b",
    "name": "llava-7b",
    "provider": "llamagate",
    "data": {
      "max_tokens": 2048,
      "max_input_tokens": 4096,
      "max_output_tokens": 2048,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 2e-7,
      "mode": "chat",
      "supports_response_schema": true,
      "supports_vision": true,
      "provider": "llamagate"
    },
    "slug": "llava-7b",
    "displayName": "llava-7b"
  },
  {
    "id": "llamagate/gemma3-4b",
    "name": "gemma3-4b",
    "provider": "llamagate",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 3e-8,
      "output_cost_per_token": 8e-8,
      "mode": "chat",
      "supports_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "provider": "llamagate"
    },
    "slug": "gemma3-4b",
    "displayName": "gemma3-4b"
  },
  {
    "id": "llamagate/nomic-embed-text",
    "name": "nomic-embed-text",
    "provider": "llamagate",
    "data": {
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "input_cost_per_token": 2e-8,
      "output_cost_per_token": 0,
      "mode": "embedding",
      "provider": "llamagate"
    },
    "slug": "nomic-embed-text",
    "displayName": "nomic-embed-text"
  },
  {
    "id": "llamagate/qwen3-embedding-8b",
    "name": "qwen3-embedding-8b",
    "provider": "llamagate",
    "data": {
      "max_tokens": 40960,
      "max_input_tokens": 40960,
      "input_cost_per_token": 2e-8,
      "output_cost_per_token": 0,
      "mode": "embedding",
      "provider": "llamagate"
    },
    "slug": "qwen3-embedding-8b",
    "displayName": "qwen3-embedding-8b"
  }
] as const;

export const LLM_PROVIDERS: string[] = [
  "ai21",
  "aleph_alpha",
  "amazon_nova",
  "anthropic",
  "anyscale",
  "azure",
  "azure_ai",
  "azure_text",
  "bedrock",
  "bedrock_converse",
  "cerebras",
  "cloudflare",
  "cohere",
  "cohere_chat",
  "dashscope",
  "databricks",
  "deepinfra",
  "deepseek",
  "fireworks_ai",
  "fireworks_ai-embedding-models",
  "friendliai",
  "gemini",
  "gmi",
  "gradient_ai",
  "groq",
  "hyperbolic",
  "jina_ai",
  "lambda_ai",
  "llamagate",
  "minimax",
  "mistral",
  "moonshot",
  "morph",
  "nlp_cloud",
  "novita",
  "nscale",
  "oci",
  "openai",
  "openrouter",
  "ovhcloud",
  "palm",
  "perplexity",
  "replicate",
  "sambanova",
  "text-completion-openai",
  "together_ai",
  "v0",
  "vercel_ai_gateway",
  "vertex_ai",
  "vertex_ai-ai21_models",
  "vertex_ai-anthropic_models",
  "vertex_ai-chat-models",
  "vertex_ai-code-chat-models",
  "vertex_ai-code-text-models",
  "vertex_ai-deepseek_models",
  "vertex_ai-embedding-models",
  "vertex_ai-language-models",
  "vertex_ai-llama_models",
  "vertex_ai-minimax_models",
  "vertex_ai-mistral_models",
  "vertex_ai-moonshot_models",
  "vertex_ai-openai_models",
  "vertex_ai-qwen_models",
  "vertex_ai-text-models",
  "vertex_ai-vision-models",
  "vertex_ai-zai_models",
  "voyage",
  "wandb",
  "watsonx",
  "xai",
  "zai"
];

export const LLM_MODES: string[] = [
  "audio_speech",
  "audio_transcription",
  "chat",
  "completion",
  "embedding",
  "image_generation",
  "ocr",
  "rerank",
  "responses"
];

// Helper maps for quick lookups
export const MODELS_BY_SLUG = new Map<string, ProcessedModel>(
  LLM_MODELS.map(model => [model.slug, model])
);

export const MODELS_BY_PROVIDER = new Map<string, ProcessedModel[]>();
for (const model of LLM_MODELS) {
  const existing = MODELS_BY_PROVIDER.get(model.provider) || [];
  existing.push(model);
  MODELS_BY_PROVIDER.set(model.provider, existing);
}

// Stats
export const LLM_STATS = {
  totalModels: 1914,
  totalProviders: 71,
  totalModes: 9,
  generatedAt: '2026-02-05T14:05:19.428Z',
};
